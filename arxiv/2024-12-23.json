[
    {
        "id": "1",
        "title": "SyncFlow: Toward Temporally Aligned Joint Audio-Video Generation from Text",
        "author": [
            "Haohe Liu",
            "Gael Le Lan",
            "Xinhao Mei",
            "Zhaoheng Ni",
            "Anurag Kumar",
            "Varun Nagaraja",
            "Wenwu Wang",
            "Mark D. Plumbley",
            "Yangyang Shi",
            "Vikas Chandra"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15220",
        "abstract": "Video and audio are closely correlated modalities that humans naturally perceive together. While recent advancements have enabled the generation of audio or video from text, producing both modalities simultaneously still typically relies on either a cascaded process or multi-modal contrastive encoders. These approaches, however, often lead to suboptimal results due to inherent information losses during inference and conditioning. In this paper, we introduce SyncFlow, a system that is capable of simultaneously generating temporally synchronized audio and video from text. The core of SyncFlow is the proposed dual-diffusion-transformer (d-DiT) architecture, which enables joint video and audio modelling with proper information fusion. To efficiently manage the computational cost of joint audio and video modelling, SyncFlow utilizes a multi-stage training strategy that separates video and audio learning before joint fine-tuning. Our empirical evaluations demonstrate that SyncFlow produces audio and video outputs that are more correlated than baseline methods with significantly enhanced audio quality and audio-visual correspondence. Moreover, we demonstrate strong zero-shot capabilities of SyncFlow, including zero-shot video-to-audio generation and adaptation to novel video resolutions without further training.",
        "tags": [
            "DiT",
            "Diffusion",
            "Diffusion Transformer",
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "2",
        "title": "Learning-by-teaching with ChatGPT: The effect of teachable ChatGPT agent on programming education",
        "author": [
            "Angxuan Chen",
            "Yuang Wei",
            "Huixiao Le",
            "Yan Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15226",
        "abstract": "This study investigates the potential of using ChatGPT as a teachable agent to support students' learning by teaching process, specifically in programming education. While learning by teaching is an effective pedagogical strategy for promoting active learning, traditional teachable agents have limitations, particularly in facilitating natural language dialogue. Our research explored whether ChatGPT, with its ability to engage learners in natural conversations, can support this process. The findings reveal that interacting with ChatGPT improves students' knowledge gains and programming abilities, particularly in writing readable and logically sound code. However, it had limited impact on developing learners' error-correction skills, likely because ChatGPT tends to generate correct code, reducing opportunities for students to practice debugging. Additionally, students' self-regulated learning (SRL) abilities improved, suggesting that teaching ChatGPT fosters learners' higher self-efficacy and better implementation of SRL strategies. This study discussed the role of natural dialogue in fostering socialized learning by teaching, and explored ChatGPT's specific contributions in supporting students' SRL through the learning by teaching process. Overall, the study highlights ChatGPT's potential as a teachable agent, offering insights for future research on ChatGPT-supported education.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "3",
        "title": "OG-RAG: Ontology-Grounded Retrieval-Augmented Generation For Large Language Models",
        "author": [
            "Kartik Sharma",
            "Peeyush Kumar",
            "Yunqing Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15235",
        "abstract": "This paper presents OG-RAG, an Ontology-Grounded Retrieval Augmented Generation method designed to enhance LLM-generated responses by anchoring retrieval processes in domain-specific ontologies. While LLMs are widely used for tasks like question answering and search, they struggle to adapt to specialized knowledge, such as industrial workflows or knowledge work, without expensive fine-tuning or sub-optimal retrieval methods. Existing retrieval-augmented models, such as RAG, offer improvements but fail to account for structured domain knowledge, leading to suboptimal context generation. Ontologies, which conceptually organize domain knowledge by defining entities and their interrelationships, offer a structured representation to address this gap. OG-RAG constructs a hypergraph representation of domain documents, where each hyperedge encapsulates clusters of factual knowledge grounded using domain-specific ontology. An optimization algorithm then retrieves the minimal set of hyperedges that constructs a precise, conceptually grounded context for the LLM. This method enables efficient retrieval while preserving the complex relationships between entities. OG-RAG applies to domains where fact-based reasoning is essential, particularly in tasks that require workflows or decision-making steps to follow predefined rules and procedures. These include industrial workflows in healthcare, legal, and agricultural sectors, as well as knowledge-driven tasks such as news journalism, investigative research, consulting and more. Our evaluations demonstrate that OG-RAG increases the recall of accurate facts by 55% and improves response correctness by 40% across four different LLMs. Additionally, OG-RAG enables 30% faster attribution of responses to context and boosts fact-based reasoning accuracy by 27% compared to baseline methods.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "4",
        "title": "Dipper: Diversity in Prompts for Producing Large Language Model Ensembles in Reasoning tasks",
        "author": [
            "Gregory Kang Ruey Lau",
            "Wenyang Hu",
            "Diwen Liu",
            "Jizhuo Chen",
            "See-Kiong Ng",
            "Bryan Kian Hsiang Low"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15238",
        "abstract": "Large Language Models still encounter substantial challenges in reasoning tasks, especially for smaller models, which many users may be restricted to due to resource constraints (e.g. GPU memory restrictions). Inference-time methods to boost LLM performance, such as prompting methods to invoke certain reasoning pathways in responses, have been shown effective in past works, though they largely rely on sequential queries. The ensemble method, which consists of multiple constituent models running in parallel, is a promising approach to achieving better inference-time performance, especially given recent developments that enabled significant speed-ups in LLM batch inference. In this work, we propose a novel, training-free LLM ensemble framework where a single LLM model is fed an optimized, diverse set of prompts in parallel, effectively producing an ensemble at inference time to achieve performance improvement in reasoning tasks. We empirically demonstrate that our method leads to significant gains on math reasoning tasks, e.g., on MATH, where our ensemble consisting of a few small models (e.g., three Qwen2-MATH-1.5B-it models) can outperform a larger model (e.g., Qwen2-MATH-7B-it).",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "5",
        "title": "Modeling Story Expectations to Understand Engagement: A Generative Framework Using LLMs",
        "author": [
            "Hortense Fong",
            "George Gui"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15239",
        "abstract": "Understanding when and why consumers engage with stories is crucial for content creators and platforms. While existing theories suggest that audience beliefs of what is going to happen should play an important role in engagement decisions, empirical work has mostly focused on developing techniques to directly extract features from actual content, rather than capturing forward-looking beliefs, due to the lack of a principled way to model such beliefs in unstructured narrative data. To complement existing feature extraction techniques, this paper introduces a novel framework that leverages large language models to model audience forward-looking beliefs about how stories might unfold. Our method generates multiple potential continuations for each story and extracts features related to expectations, uncertainty, and surprise using established content analysis techniques. Applying our method to over 30,000 book chapters from Wattpad, we demonstrate that our framework complements existing feature engineering techniques by amplifying their marginal explanatory power on average by 31%. The results reveal that different types of engagement-continuing to read, commenting, and voting-are driven by distinct combinations of current and anticipated content features. Our framework provides a novel way to study and explore how audience forward-looking beliefs shape their engagement with narrative media, with implications for marketing strategy in content-focused industries.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "6",
        "title": "ChainStream: An LLM-based Framework for Unified Synthetic Sensing",
        "author": [
            "Jiacheng Liu",
            "Yuanchun Li",
            "Liangyan Li",
            "Yi Sun",
            "Hao Wen",
            "Xiangyu Li",
            "Yao Guo",
            "Yunxin Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15240",
        "abstract": "Many applications demand context sensing to offer personalized and timely services. Yet, developing sensing programs can be challenging for developers and using them is privacy-concerning for end-users. In this paper, we propose to use natural language as the unified interface to process personal data and sense user context, which can effectively ease app development and make the data pipeline more transparent. Our work is inspired by large language models (LLMs) and other generative models, while directly applying them does not solve the problem - letting the model directly process the data cannot handle complex sensing requests and letting the model write the data processing program suffers error-prone code generation. We address the problem with 1) a unified data processing framework that makes context-sensing programs simpler and 2) a feedback-guided query optimizer that makes data query more informative. To evaluate the performance of natural language-based context sensing, we create a benchmark that contains 133 context sensing tasks. Extensive evaluation has shown that our approach is able to automatically solve the context-sensing tasks efficiently and precisely. The code is opensourced at https://github.com/MobileLLM/ChainStream.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "7",
        "title": "MPPO: Multi Pair-wise Preference Optimization for LLMs with Arbitrary Negative Samples",
        "author": [
            "Shuo Xie",
            "Fangzhi Zhu",
            "Jiahui Wang",
            "Lulu Wen",
            "Wei Dai",
            "Xiaowei Chen",
            "Junxiong Zhu",
            "Kai Zhou",
            "Bo Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15244",
        "abstract": "Aligning Large Language Models (LLMs) with human feedback is crucial for their development. Existing preference optimization methods such as DPO and KTO, while improved based on Reinforcement Learning from Human Feedback (RLHF), are inherently derived from PPO, requiring a reference model that adds GPU memory resources and relies heavily on abundant preference data. Meanwhile, current preference optimization research mainly targets single-question scenarios with two replies, neglecting optimization with multiple replies, which leads to a waste of data in the application. This study introduces the MPPO algorithm, which leverages the average likelihood of model responses to fit the reward function and maximizes the utilization of preference data. Through a comparison of Point-wise, Pair-wise, and List-wise implementations, we found that the Pair-wise approach achieves the best performance, significantly enhancing the quality of model responses. Experimental results demonstrate MPPO's outstanding performance across various benchmarks. On MT-Bench, MPPO outperforms DPO, ORPO, and SimPO. Notably, on Arena-Hard, MPPO surpasses DPO and ORPO by substantial margins. These achievements underscore the remarkable advantages of MPPO in preference optimization tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "8",
        "title": "Accelerating Retrieval-Augmented Generation",
        "author": [
            "Derrick Quinn",
            "Mohammad Nouri",
            "Neel Patel",
            "John Salihu",
            "Alireza Salemi",
            "Sukhan Lee",
            "Hamed Zamani",
            "Mohammad Alian"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15246",
        "abstract": "An evolving solution to address hallucination and enhance accuracy in large language models (LLMs) is Retrieval-Augmented Generation (RAG), which involves augmenting LLMs with information retrieved from an external knowledge source, such as the web. This paper profiles several RAG execution pipelines and demystifies the complex interplay between their retrieval and generation phases. We demonstrate that while exact retrieval schemes are expensive, they can reduce inference time compared to approximate retrieval variants because an exact retrieval model can send a smaller but more accurate list of documents to the generative model while maintaining the same end-to-end accuracy. This observation motivates the acceleration of the exact nearest neighbor search for RAG.\nIn this work, we design Intelligent Knowledge Store (IKS), a type-2 CXL device that implements a scale-out near-memory acceleration architecture with a novel cache-coherent interface between the host CPU and near-memory accelerators. IKS offers 13.4-27.9x faster exact nearest neighbor search over a 512GB vector database compared with executing the search on Intel Sapphire Rapids CPUs. This higher search performance translates to 1.7-26.3x lower end-to-end inference time for representative RAG applications. IKS is inherently a memory expander; its internal DRAM can be disaggregated and used for other applications running on the server to prevent DRAM, which is the most expensive component in today's servers, from being stranded.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "9",
        "title": "Streamlining Systematic Reviews: A Novel Application of Large Language Models",
        "author": [
            "Fouad Trad",
            "Ryan Yammine",
            "Jana Charafeddine",
            "Marlene Chakhtoura",
            "Maya Rahme",
            "Ghada El-Hajj Fuleihan",
            "Ali Chehab"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15247",
        "abstract": "Systematic reviews (SRs) are essential for evidence-based guidelines but are often limited by the time-consuming nature of literature screening. We propose and evaluate an in-house system based on Large Language Models (LLMs) for automating both title/abstract and full-text screening, addressing a critical gap in the literature. Using a completed SR on Vitamin D and falls (14,439 articles), the LLM-based system employed prompt engineering for title/abstract screening and Retrieval-Augmented Generation (RAG) for full-text screening. The system achieved an article exclusion rate (AER) of 99.5%, specificity of 99.6%, a false negative rate (FNR) of 0%, and a negative predictive value (NPV) of 100%. After screening, only 78 articles required manual review, including all 20 identified by traditional methods, reducing manual screening time by 95.5%. For comparison, Rayyan, a commercial tool for title/abstract screening, achieved an AER of 72.1% and FNR of 5% when including articles Rayyan considered as undecided or likely to include. Lowering Rayyan's inclusion thresholds improved FNR to 0% but increased screening time. By addressing both screening phases, the LLM-based system significantly outperformed Rayyan and traditional methods, reducing total screening time to 25.5 hours while maintaining high accuracy. These findings highlight the transformative potential of LLMs in SR workflows by offering a scalable, efficient, and accurate solution, particularly for the full-text screening phase, which has lacked automation tools.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "10",
        "title": "RoundTripOCR: A Data Generation Technique for Enhancing Post-OCR Error Correction in Low-Resource Devanagari Languages",
        "author": [
            "Harshvivek Kashid",
            "Pushpak Bhattacharyya"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15248",
        "abstract": "Optical Character Recognition (OCR) technology has revolutionized the digitization of printed text, enabling efficient data extraction and analysis across various domains. Just like Machine Translation systems, OCR systems are prone to errors. In this work, we address the challenge of data generation and post-OCR error correction, specifically for low-resource languages. We propose an approach for synthetic data generation for Devanagari languages, RoundTripOCR, that tackles the scarcity of the post-OCR Error Correction datasets for low-resource languages. We release post-OCR text correction datasets for Hindi, Marathi, Bodo, Nepali, Konkani and Sanskrit. We also present a novel approach for OCR error correction by leveraging techniques from machine translation. Our method involves translating erroneous OCR output into a corrected form by treating the OCR errors as mistranslations in a parallel text corpus, employing pre-trained transformer models to learn the mapping from erroneous to correct text pairs, effectively correcting OCR errors.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "11",
        "title": "LLMs for Literature Review: Are we there yet?",
        "author": [
            "Shubham Agarwal",
            "Gaurav Sahu",
            "Abhay Puri",
            "Issam H. Laradji",
            "Krishnamurthy DJ Dvijotham",
            "Jason Stanley",
            "Laurent Charlin",
            "Christopher Pal"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15249",
        "abstract": "Literature reviews are an essential component of scientific research, but they remain time-intensive and challenging to write, especially due to the recent influx of research papers. This paper explores the zero-shot abilities of recent Large Language Models (LLMs) in assisting with the writing of literature reviews based on an abstract. We decompose the task into two components: 1. Retrieving related works given a query abstract, and 2. Writing a literature review based on the retrieved results. We analyze how effective LLMs are for both components. For retrieval, we introduce a novel two-step search strategy that first uses an LLM to extract meaningful keywords from the abstract of a paper and then retrieves potentially relevant papers by querying an external knowledge base. Additionally, we study a prompting-based re-ranking mechanism with attribution and show that re-ranking doubles the normalized recall compared to naive search methods, while providing insights into the LLM's decision-making process. In the generation phase, we propose a two-step approach that first outlines a plan for the review and then executes steps in the plan to generate the actual review. To evaluate different LLM-based literature review methods, we create test sets from arXiv papers using a protocol designed for rolling use with newly released LLMs to avoid test set contamination in zero-shot evaluations. We release this evaluation protocol to promote additional research and development in this regard. Our empirical results suggest that LLMs show promising potential for writing literature reviews when the task is decomposed into smaller components of retrieval and planning. Further, we demonstrate that our planning-based approach achieves higher-quality reviews by minimizing hallucinated references in the generated review by 18-26% compared to existing simpler LLM-based generation methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "12",
        "title": "An Enhanced Text Compression Approach Using Transformer-based Language Models",
        "author": [
            "Chowdhury Mofizur Rahman",
            "Mahbub E Sobhani",
            "Anika Tasnim Rodela",
            "Swakkhar Shatabda"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15250",
        "abstract": "Text compression shrinks textual data while keeping crucial information, eradicating constraints on storage, bandwidth, and computational efficacy. The integration of lossless compression techniques with transformer-based text decompression has received negligible attention, despite the increasing volume of English text data in communication. The primary barrier in advancing text compression and restoration involves optimizing transformer-based approaches with efficient pre-processing and integrating lossless compression algorithms, that remained unresolved in the prior attempts. Here, we propose a transformer-based method named RejuvenateForme for text decompression, addressing prior issues by harnessing a new pre-processing technique and a lossless compression method. Our meticulous pre-processing technique incorporating the Lempel-Ziv-Welch algorithm achieves compression ratios of 12.57, 13.38, and 11.42 on the BookCorpus, EN-DE, and EN-FR corpora, thus showing state-of-the-art compression ratios compared to other deep learning and traditional approaches. Furthermore, the RejuvenateForme achieves a BLEU score of 27.31, 25.78, and 50.45 on the EN-DE, EN-FR, and BookCorpus corpora, showcasing its comprehensive efficacy. In contrast, the pre-trained T5-Small exhibits better performance over prior state-of-the-art models.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "13",
        "title": "AgentPS: Agentic Process Supervision for Multi-modal Content Quality Assurance through Multi-round QA",
        "author": [
            "Gorden Liu",
            "Yu Sun",
            "Ruixiao Sun",
            "Xin Dong",
            "Hongyu Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15251",
        "abstract": "The advanced processing and reasoning capabilities of multimodal large language models (MLLMs) have driven substantial progress in vision-language (VL) understanding tasks. However, while effective for tasks governed by straightforward logic, MLLMs often encounter challenges when reasoning over complex, interdependent logic structures. To address this limitation, we introduce \\textit{AgentPS}, a novel framework that integrates Agentic Process Supervision into MLLMs via multi-round question answering during fine-tuning. \\textit{AgentPS} demonstrates significant performance improvements over baseline MLLMs on proprietary TikTok datasets, due to its integration of process supervision and structured sequential reasoning. Furthermore, we show that replacing human-annotated labels with LLM-generated labels retains much of the performance gain, highlighting the framework's practical scalability in industrial applications. These results position \\textit{AgentPS} as a highly effective and efficient architecture for multimodal classification tasks. Its adaptability and scalability, especially when enhanced by automated annotation generation, make it a powerful tool for handling large-scale, real-world challenges.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "14",
        "title": "NER- RoBERTa: Fine-Tuning RoBERTa for Named Entity Recognition (NER) within low-resource languages",
        "author": [
            "Abdulhady Abas Abdullah",
            "Srwa Hasan Abdulla",
            "Dalia Mohammad Toufiq",
            "Halgurd S. Maghdid",
            "Tarik A. Rashid",
            "Pakshan F. Farho",
            "Shadan Sh. Sabr",
            "Akar H. Taher",
            "Darya S. Hamad",
            "Hadi Veisi",
            "Aras T. Asaad"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15252",
        "abstract": "Nowadays, Natural Language Processing (NLP) is an important tool for most people's daily life routines, ranging from understanding speech, translation, named entity recognition (NER), and text categorization, to generative text models such as ChatGPT. Due to the existence of big data and consequently large corpora for widely used languages like English, Spanish, Turkish, Persian, and many more, these applications have been developed accurately. However, the Kurdish language still requires more corpora and large datasets to be included in NLP applications. This is because Kurdish has a rich linguistic structure, varied dialects, and a limited dataset, which poses unique challenges for Kurdish NLP (KNLP) application development. While several studies have been conducted in KNLP for various applications, Kurdish NER (KNER) remains a challenge for many KNLP tasks, including text analysis and classification. In this work, we address this limitation by proposing a methodology for fine-tuning the pre-trained RoBERTa model for KNER. To this end, we first create a Kurdish corpus, followed by designing a modified model architecture and implementing the training procedures. To evaluate the trained model, a set of experiments is conducted to demonstrate the performance of the KNER model using different tokenization methods and trained models. The experimental results show that fine-tuned RoBERTa with the SentencePiece tokenization method substantially improves KNER performance, achieving a 12.8% improvement in F1-score compared to traditional models, and consequently establishes a new benchmark for KNLP.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "15",
        "title": "Using Machine Learning to Distinguish Human-written from Machine-generated Creative Fiction",
        "author": [
            "Andrea Cristina McGlinchey",
            "Peter J Barclay"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15253",
        "abstract": "Following the universal availability of generative AI systems with the release of ChatGPT, automatic detection of deceptive text created by Large Language Models has focused on domains such as academic plagiarism and \"fake news\". However, generative AI also poses a threat to the livelihood of creative writers, and perhaps to literary culture in general, through reduction in quality of published material. Training a Large Language Model on writers' output to generate \"sham books\" in a particular style seems to constitute a new form of plagiarism. This problem has been little researched. In this study, we trained Machine Learning classifier models to distinguish short samples of human-written from machine-generated creative fiction, focusing on classic detective novels. Our results show that a Naive Bayes and a Multi-Layer Perceptron classifier achieved a high degree of success (accuracy > 95%), significantly outperforming human judges (accuracy < 55%). This approach worked well with short text samples (around 100 words), which previous research has shown to be difficult to classify. We have deployed an online proof-of-concept classifier tool, AI Detective, as a first step towards developing lightweight and reliable applications for use by editors and publishers, with the aim of protecting the economic and cultural contribution of human authors.",
        "tags": [
            "ChatGPT",
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "16",
        "title": "RIRO: Reshaping Inputs, Refining Outputs Unlocking the Potential of Large Language Models in Data-Scarce Contexts",
        "author": [
            "Ali Hamdi",
            "Hozaifa Kassab",
            "Mohamed Bahaa",
            "Marwa Mohamed"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15254",
        "abstract": "Large language models (LLMs) have significantly advanced natural language processing, excelling in areas like text generation, summarization, and question-answering. Despite their capabilities, these models face challenges when fine-tuned on small, domain-specific datasets, often struggling to generalize and deliver accurate results with unfamiliar inputs. To tackle this issue, we introduce RIRO, a novel two-layer architecture designed to improve performance in data-scarce environments. The first layer leverages advanced prompt engineering to reformulate inputs, ensuring better alignment with training data, while the second layer focuses on refining outputs to minimize inconsistencies. Through fine-tuning models like Phi-2, Falcon 7B, and Falcon 1B, with Phi-2 outperforming the others. Additionally, we introduce a benchmark using evaluation metrics such as cosine similarity, Levenshtein distance, BLEU score, ROUGE-1, ROUGE-2, and ROUGE-L. While these advancements improve performance, challenges like computational demands and overfitting persist, limiting the potential of LLMs in data-scarce, high-stakes environments such as healthcare, legal documentation, and software testing.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "17",
        "title": "Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation",
        "author": [
            "Jonibek Mansurov",
            "Akhmed Sakip",
            "Alham Fikri Aji"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15255",
        "abstract": "In this paper, we show that knowledge distillation can be subverted to manipulate language model benchmark scores, revealing a critical vulnerability in current evaluation practices. We introduce \"Data Laundering,\" a three-phase process analogous to financial money laundering, that enables the covert transfer of benchmark-specific knowledge through seemingly legitimate intermediate training steps. Through extensive experiments with a 2-layer BERT student model, we show how this approach can achieve substantial improvements in benchmark accuracy (up to 75\\% on GPQA) without developing genuine reasoning capabilities. Notably, this method can be exploited intentionally or even unintentionally, as researchers may inadvertently adopt this method that inflates scores using knowledge distillation without realizing the implications. While our findings demonstrate the effectiveness of this technique, we present them as a cautionary tale highlighting the urgent need for more robust evaluation methods in AI. This work aims to contribute to the ongoing discussion about evaluation integrity in AI development and the need for benchmarks that more accurately reflect true model capabilities. The code is available at \\url{https://github.com/mbzuai-nlp/data_laundering}.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "18",
        "title": "Analyzing Images of Legal Documents: Toward Multi-Modal LLMs for Access to Justice",
        "author": [
            "Hannes Westermann",
            "Jaromir Savelka"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15260",
        "abstract": "Interacting with the legal system and the government requires the assembly and analysis of various pieces of information that can be spread across different (paper) documents, such as forms, certificates and contracts (e.g. leases). This information is required in order to understand one's legal rights, as well as to fill out forms to file claims in court or obtain government benefits. However, finding the right information, locating the correct forms and filling them out can be challenging for laypeople. Large language models (LLMs) have emerged as a powerful technology that has the potential to address this gap, but still rely on the user to provide the correct information, which may be challenging and error-prone if the information is only available in complex paper documents. We present an investigation into utilizing multi-modal LLMs to analyze images of handwritten paper forms, in order to automatically extract relevant information in a structured format. Our initial results are promising, but reveal some limitations (e.g., when the image quality is low). Our work demonstrates the potential of integrating multi-modal LLMs to support laypeople and self-represented litigants in finding and assembling relevant information.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "19",
        "title": "Chinese SafetyQA: A Safety Short-form Factuality Benchmark for Large Language Models",
        "author": [
            "Yingshui Tan",
            "Boren Zheng",
            "Baihui Zheng",
            "Kerui Cao",
            "Huiyun Jing",
            "Jincheng Wei",
            "Jiaheng Liu",
            "Yancheng He",
            "Wenbo Su",
            "Xiangyong Zhu",
            "Bo Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15265",
        "abstract": "With the rapid advancement of Large Language Models (LLMs), significant safety concerns have emerged. Fundamentally, the safety of large language models is closely linked to the accuracy, comprehensiveness, and clarity of their understanding of safety knowledge, particularly in domains such as law, policy and ethics. This factuality ability is crucial in determining whether these models can be deployed and applied safely and compliantly within specific regions. To address these challenges and better evaluate the factuality ability of LLMs to answer short questions, we introduce the Chinese SafetyQA benchmark. Chinese SafetyQA has several properties (i.e., Chinese, Diverse, High-quality, Static, Easy-to-evaluate, Safety-related, Harmless). Based on Chinese SafetyQA, we perform a comprehensive evaluation on the factuality abilities of existing LLMs and analyze how these capabilities relate to LLM abilities, e.g., RAG ability and robustness against attacks.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "20",
        "title": "Toxicity Detection towards Adaptability to Changing Perturbations",
        "author": [
            "Hankun Kang",
            "Jianhao Chen",
            "Yongqi Li",
            "Xin Miao",
            "Mayi Xu",
            "Ming Zhong",
            "Yuanyuan Zhu",
            "Tieyun Qian"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15267",
        "abstract": "Toxicity detection is crucial for maintaining the peace of the society. While existing methods perform well on normal toxic contents or those generated by specific perturbation methods, they are vulnerable to evolving perturbation patterns. However, in real-world scenarios, malicious users tend to create new perturbation patterns for fooling the detectors. For example, some users may circumvent the detector of large language models (LLMs) by adding `I am a scientist' at the beginning of the prompt. In this paper, we introduce a novel problem, i.e., continual learning jailbreak perturbation patterns, into the toxicity detection field. To tackle this problem, we first construct a new dataset generated by 9 types of perturbation patterns, 7 of them are summarized from prior work and 2 of them are developed by us. We then systematically validate the vulnerability of current methods on this new perturbation pattern-aware dataset via both the zero-shot and fine tuned cross-pattern detection. Upon this, we present the domain incremental learning paradigm and the corresponding benchmark to ensure the detector's robustness to dynamically emerging types of perturbed toxic text. Our code and dataset are provided in the appendix and will be publicly available at GitHub, by which we wish to offer new research opportunities for the security-relevant communities.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "21",
        "title": "Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph",
        "author": [
            "Yibo Zhao",
            "Jiapeng Zhu",
            "Can Xu",
            "Xiang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15268",
        "abstract": "The rapid growth of social media platforms has raised significant concerns regarding online content toxicity. When Large Language Models (LLMs) are used for toxicity detection, two key challenges emerge: 1) the absence of domain-specific toxic knowledge leads to false negatives; 2) the excessive sensitivity of LLMs to toxic speech results in false positives, limiting freedom of speech. To address these issues, we propose a novel method called MetaTox, leveraging graph search on a meta-toxic knowledge graph to enhance hatred and toxicity detection. First, we construct a comprehensive meta-toxic knowledge graph by utilizing LLMs to extract toxic information through a three-step pipeline, with toxic benchmark datasets serving as corpora. Second, we query the graph via retrieval and ranking processes to supplement accurate, relevant toxic knowledge. Extensive experiments and in-depth case studies across multiple datasets demonstrate that our MetaTox significantly decreases the false positive rate while boosting overall toxicity detection performance. Our code will be available soon.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "22",
        "title": "Baichuan4-Finance Technical Report",
        "author": [
            "Hanyu Zhang",
            "Boyu Qiu",
            "Yuhao Feng",
            "Shuqi Li",
            "Qian Ma",
            "Xiyuan Zhang",
            "Qiang Ju",
            "Dong Yan",
            "Jian Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15270",
        "abstract": "Large language models (LLMs) have demonstrated strong capabilities in language understanding, generation, and reasoning, yet their potential in finance remains underexplored due to the complexity and specialization of financial knowledge. In this work, we report the development of the Baichuan4-Finance series, including a comprehensive suite of foundational Baichuan4-Finance-Base and an aligned language model Baichuan4-Finance, which are built upon Baichuan4-Turbo base model and tailored for finance domain. Firstly, we have dedicated significant effort to building a detailed pipeline for improving data quality. Moreover, in the continual pre-training phase, we propose a novel domain self-constraint training strategy, which enables Baichuan4-Finance-Base to acquire financial knowledge without losing general capabilities. After Supervised Fine-tuning and Reinforcement Learning from Human Feedback and AI Feedback, the chat model Baichuan4-Finance is able to tackle various financial certification questions and real-world scenario applications. We evaluate Baichuan4-Finance on many widely used general datasets and two holistic financial benchmarks. The evaluation results show that Baichuan4-Finance-Base surpasses almost all competitive baselines on financial tasks by significant margins without sacrificing performance on general LLM benchmarks. At the same time, Baichuan4-Finance demonstrates even more impressive performance on financial application scenarios, showcasing its potential to foster community innovation in the financial LLM field.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "23",
        "title": "SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation",
        "author": [
            "Yuzheng Cai",
            "Zhenyue Guo",
            "Yiwen Pei",
            "Wanrui Bian",
            "Weiguo Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15272",
        "abstract": "Recent advancements in large language models (LLMs) have shown impressive versatility across various tasks. To eliminate its hallucinations, retrieval-augmented generation (RAG) has emerged as a powerful approach, leveraging external knowledge sources like knowledge graphs (KGs). In this paper, we study the task of KG-driven RAG and propose a novel Similar Graph Enhanced Retrieval-Augmented Generation (SimGRAG) method. It effectively addresses the challenge of aligning query texts and KG structures through a two-stage process: (1) query-to-pattern, which uses an LLM to transform queries into a desired graph pattern, and (2) pattern-to-subgraph, which quantifies the alignment between the pattern and candidate subgraphs using a graph semantic distance (GSD) metric. We also develop an optimized retrieval algorithm that efficiently identifies the top-$k$ subgraphs within 1-second latency on a 10-million-scale KG. Extensive experiments show that SimGRAG outperforms state-of-the-art KG-driven RAG methods in both question answering and fact verification, offering superior plug-and-play usability and scalability.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "24",
        "title": "Memory-Augmented Agent Training for Business Document Understanding",
        "author": [
            "Jiale Liu",
            "Yifan Zeng",
            "Malte Højmark-Bertelsen",
            "Marie Normann Gadeberg",
            "Huazheng Wang",
            "Qingyun Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15274",
        "abstract": "Traditional enterprises face significant challenges in processing business documents, where tasks like extracting transport references from invoices remain largely manual despite their crucial role in logistics operations. While Large Language Models offer potential automation, their direct application to specialized business domains often yields unsatisfactory results. We introduce Matrix (Memory-Augmented agent Training through Reasoning and Iterative eXploration), a novel paradigm that enables LLM agents to progressively build domain expertise through experience-driven memory refinement and iterative learning. To validate this approach, we collaborate with one of the world's largest logistics companies to create a dataset of Universal Business Language format invoice documents, focusing on the task of transport reference extraction. Experiments demonstrate that Matrix outperforms prompting a single LLM by 30.3%, vanilla LLM agent by 35.2%. We further analyze the metrics of the optimized systems and observe that the agent system requires less API calls, fewer costs and can analyze longer documents on average. Our methods establish a new approach to transform general-purpose LLMs into specialized business tools through systematic memory enhancement in document processing tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "25",
        "title": "Fooling LLM graders into giving better grades through neural activity guided adversarial prompting",
        "author": [
            "Atsushi Yamamura",
            "Surya Ganguli"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15275",
        "abstract": "The deployment of artificial intelligence (AI) in critical decision-making and evaluation processes raises concerns about inherent biases that malicious actors could exploit to distort decision outcomes. We propose a systematic method to reveal such biases in AI evaluation systems and apply it to automated essay grading as an example. Our approach first identifies hidden neural activity patterns that predict distorted decision outcomes and then optimizes an adversarial input suffix to amplify such patterns. We demonstrate that this combination can effectively fool large language model (LLM) graders into assigning much higher grades than humans would. We further show that this white-box attack transfers to black-box attacks on other models, including commercial closed-source models like Gemini. They further reveal the existence of a \"magic word\" that plays a pivotal role in the efficacy of the attack. We trace the origin of this magic word bias to the structure of commonly-used chat templates for supervised fine-tuning of LLMs and show that a minor change in the template can drastically reduce the bias. This work not only uncovers vulnerabilities in current LLMs but also proposes a systematic method to identify and remove hidden biases, contributing to the goal of ensuring AI safety and security.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "26",
        "title": "PLPP: Prompt Learning with Perplexity Is Self-Distillation for Vision-Language Models",
        "author": [
            "Biao Liu",
            "Wenyi Fang",
            "Xiaoyu Wu",
            "Yang Zheng",
            "Zheng Hu",
            "Bo Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15277",
        "abstract": "Pre-trained Vision-Language (VL) models such as CLIP have demonstrated their excellent performance across numerous downstream tasks. A recent method, Context Optimization (CoOp), further improves the performance of VL models on downstream tasks by introducing prompt learning. CoOp optimizes a set of learnable vectors, aka prompt, and freezes the whole CLIP model. However, relying solely on CLIP loss to fine-tune prompts can lead to models that are prone to overfitting on downstream task. To address this issue, we propose a plug-in prompt-regularization method called PLPP (Prompt Learning with PerPlexity), which use perplexity loss to regularize prompt learning. PLPP designs a two-step operation to compute the perplexity for prompts: (a) calculating cosine similarity between the weight of the embedding layer and prompts to get labels, (b) introducing a language model (LM) head that requires no training behind text encoder to output word probability distribution. Meanwhile, we unveil that the essence of PLPP is inherently a form of self-distillation. To further prevent overfitting as well as to reduce the additional computation introduced by PLPP, we turn the hard label to soft label and choose top-$k$ values for calculating the perplexity loss. For accelerating model convergence, we introduce mutual self-distillation learning, that is perplexity and inverted perplexity loss. The experiments conducted on four classification tasks indicate that PLPP exhibits superior performance compared to existing methods.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "27",
        "title": "Context-DPO: Aligning Language Models for Context-Faithfulness",
        "author": [
            "Baolong Bi",
            "Shaohan Huang",
            "Yiwei Wang",
            "Tianchi Yang",
            "Zihan Zhang",
            "Haizhen Huang",
            "Lingrui Mei",
            "Junfeng Fang",
            "Zehao Li",
            "Furu Wei",
            "Weiwei Deng",
            "Feng Sun",
            "Qi Zhang",
            "Shenghua Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15280",
        "abstract": "Reliable responses from large language models (LLMs) require adherence to user instructions and retrieved information. While alignment techniques help LLMs align with human intentions and values, improving context-faithfulness through alignment remains underexplored. To address this, we propose $\\textbf{Context-DPO}$, the first alignment method specifically designed to enhance LLMs' context-faithfulness. We introduce $\\textbf{ConFiQA}$, a benchmark that simulates Retrieval-Augmented Generation (RAG) scenarios with knowledge conflicts to evaluate context-faithfulness. By leveraging faithful and stubborn responses to questions with provided context from ConFiQA, our Context-DPO aligns LLMs through direct preference optimization. Extensive experiments demonstrate that our Context-DPO significantly improves context-faithfulness, achieving 35% to 280% improvements on popular open-source models. Further analysis demonstrates that Context-DPO preserves LLMs' generative capabilities while providing interpretable insights into context utilization. Our code and data are released at https://github.com/byronBBL/Context-DPO",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "28",
        "title": "A Systematic Examination of Preference Learning through the Lens of Instruction-Following",
        "author": [
            "Joongwon Kim",
            "Anirudh Goyal",
            "Aston Zhang",
            "Bo Xiong",
            "Rui Hou",
            "Melanie Kambadur",
            "Dhruv Mahajan",
            "Hannaneh Hajishirzi",
            "Liang Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15282",
        "abstract": "Preference learning is a widely adopted post-training technique that aligns large language models (LLMs) to human preferences and improves specific downstream task capabilities. In this work we systematically investigate how specific attributes of preference datasets affect the alignment and downstream performance of LLMs in instruction-following tasks. We use a novel synthetic data generation pipeline to generate 48,000 unique instruction-following prompts with combinations of 23 verifiable constraints that enable fine-grained and automated quality assessments of model responses. With our synthetic prompts, we use two preference dataset curation methods - rejection sampling (RS) and Monte Carlo Tree Search (MCTS) - to obtain pairs of (chosen, rejected) responses. Then, we perform experiments investigating the effects of (1) the presence of shared prefixes between the chosen and rejected responses, (2) the contrast and quality of the chosen, rejected responses and (3) the complexity of the training prompts. Our experiments reveal that shared prefixes in preference pairs, as generated by MCTS, provide marginal but consistent improvements and greater stability across challenging training configurations. High-contrast preference pairs generally outperform low-contrast pairs; however, combining both often yields the best performance by balancing diversity and learning efficiency. Additionally, training on prompts of moderate difficulty leads to better generalization across tasks, even for more complex evaluation scenarios, compared to overly challenging prompts. Our findings provide actionable insights into optimizing preference data curation for instruction-following tasks, offering a scalable and effective framework for enhancing LLM training and alignment.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "29",
        "title": "Channel Merging: Preserving Specialization for Merged Experts",
        "author": [
            "Mingyang Zhang",
            "Jing Liu",
            "Ganggui Ding",
            "Xinyi Yu",
            "Linlin Ou",
            "Bohan Zhuang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15283",
        "abstract": "Lately, the practice of utilizing task-specific fine-tuning has been implemented to improve the performance of large language models (LLM) in subsequent tasks. Through the integration of diverse LLMs, the overall competency of LLMs is significantly boosted. Nevertheless, traditional ensemble methods are notably memory-intensive, necessitating the simultaneous loading of all specialized models into GPU memory. To address the inefficiency, model merging strategies have emerged, merging all LLMs into one model to reduce the memory footprint during inference. Despite these advances, model merging often leads to parameter conflicts and performance decline as the number of experts increases. Previous methods to mitigate these conflicts include post-pruning and partial merging. However, both approaches have limitations, particularly in terms of performance and storage efficiency when merged experts increase. To address these challenges, we introduce Channel Merging, a novel strategy designed to minimize parameter conflicts while enhancing storage efficiency. This method clusters and merges channel parameters based on their similarity to form several groups offline. By ensuring that only highly similar parameters are merged within each group, it significantly reduces parameter conflicts. During inference, we can instantly look up the expert parameters from the merged groups, preserving specialized knowledge. Our experiments demonstrate that Channel Merging consistently delivers high performance, matching unmerged models in tasks like English and Chinese reasoning, mathematical reasoning, and code generation. Moreover, it obtains results comparable to model ensemble with just 53% parameters when used with a task-specific router.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "30",
        "title": "Maximize Your Data's Potential: Enhancing LLM Accuracy with Two-Phase Pretraining",
        "author": [
            "Steven Feng",
            "Shrimai Prabhumoye",
            "Kezhi Kong",
            "Dan Su",
            "Mostofa Patwary",
            "Mohammad Shoeybi",
            "Bryan Catanzaro"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15285",
        "abstract": "Pretraining large language models effectively requires strategic data selection, blending and ordering. However, key details about data mixtures especially their scalability to longer token horizons and larger model sizes remain underexplored due to limited disclosure by model developers. To address this, we formalize the concept of two-phase pretraining and conduct an extensive systematic study on how to select and mix data to maximize model accuracies for the two phases. Our findings illustrate that a two-phase approach for pretraining outperforms random data ordering and natural distribution of tokens by 3.4% and 17% on average accuracies. We provide in-depth guidance on crafting optimal blends based on quality of the data source and the number of epochs to be seen. We propose to design blends using downsampled data at a smaller scale of 1T tokens and then demonstrate effective scaling of our approach to larger token horizon of 15T tokens and larger model size of 25B model size. These insights provide a series of steps practitioners can follow to design and scale their data blends.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "31",
        "title": "Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models",
        "author": [
            "Yinlam Chow",
            "Guy Tennenholtz",
            "Izzeddin Gur",
            "Vincent Zhuang",
            "Bo Dai",
            "Sridhar Thiagarajan",
            "Craig Boutilier",
            "Rishabh Agarwal",
            "Aviral Kumar",
            "Aleksandra Faust"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15287",
        "abstract": "Recent studies have indicated that effectively utilizing inference-time compute is crucial for attaining better performance from large language models (LLMs). In this work, we propose a novel inference-aware fine-tuning paradigm, in which the model is fine-tuned in a manner that directly optimizes the performance of the inference-time strategy. We study this paradigm using the simple yet effective Best-of-N (BoN) inference strategy, in which a verifier selects the best out of a set of LLM-generated responses. We devise the first imitation learning and reinforcement learning~(RL) methods for BoN-aware fine-tuning, overcoming the challenging, non-differentiable argmax operator within BoN. We empirically demonstrate that our BoN-aware models implicitly learn a meta-strategy that interleaves best responses with more diverse responses that might be better suited to a test-time input -- a process reminiscent of the exploration-exploitation trade-off in RL. Our experiments demonstrate the effectiveness of BoN-aware fine-tuning in terms of improved performance and inference-time compute. In particular, we show that our methods improve the Bo32 performance of Gemma 2B on Hendrycks MATH from 26.8% to 30.8%, and pass@32 from 60.0% to 67.0%, as well as the pass@16 on HumanEval from 61.6% to 67.1%.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "32",
        "title": "SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage",
        "author": [
            "Xiaoning Dong",
            "Wenbo Hu",
            "Wei Xu",
            "Tianxing He"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15289",
        "abstract": "Large language models (LLMs) have made significant advancements across various tasks, but their safety alignment remain a major concern. Exploring jailbreak prompts can expose LLMs' vulnerabilities and guide efforts to secure them. Existing methods primarily design sophisticated instructions for the LLM to follow, or rely on multiple iterations, which could hinder the performance and efficiency of jailbreaks. In this work, we propose a novel jailbreak paradigm, Simple Assistive Task Linkage (SATA), which can effectively circumvent LLM safeguards and elicit harmful responses. Specifically, SATA first masks harmful keywords within a malicious query to generate a relatively benign query containing one or multiple [MASK] special tokens. It then employs a simple assistive task such as a masked language model task or an element lookup by position task to encode the semantics of the masked keywords. Finally, SATA links the assistive task with the masked query to jointly perform the jailbreak. Extensive experiments show that SATA achieves state-of-the-art performance and outperforms baselines by a large margin. Specifically, on AdvBench dataset, with mask language model (MLM) assistive task, SATA achieves an overall attack success rate (ASR) of 85% and harmful score (HS) of 4.57, and with element lookup by position (ELP) assistive task, SATA attains an overall ASR of 76% and HS of 4.43.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "33",
        "title": "A Large-scale Empirical Study on Large Language Models for Election Prediction",
        "author": [
            "Chenxiao Yu",
            "Zhaotian Weng",
            "Yuangang Li",
            "Zheng Li",
            "Xiyang Hu",
            "Yue Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15291",
        "abstract": "Can Large Language Models (LLMs) accurately predict election outcomes? While LLMs have demonstrated impressive performance in healthcare, legal analysis, and creative applications, their capabilities in election forecasting remain uncertain. Notably, election prediction poses unique challenges: limited voter-level data, evolving political contexts, and the complexity of modeling human behavior. In the first part of this paper, we explore and introduce a multi-step reasoning framework for election prediction, which systematically integrates demographic, ideological, and time-sensitive factors. Validated on 2016 and 2020 real-world data and extensive synthetic personas, our approach adapts to changing political landscapes, reducing bias and significantly improving predictive accuracy. We further apply our pipeline to the 2024 U.S. presidential election, illustrating its ability to generalize beyond observed historical data. Beyond enhancing accuracy, the second part of the paper provides insights into the broader implications of LLM-based election forecasting. We identify potential political biases embedded in pretrained corpora, examine how demographic patterns can become exaggerated, and suggest strategies for mitigating these issues. Together, this project, a large-scale LLM empirical study, advances the accuracy of election predictions and establishes directions for more balanced, transparent, and context-aware modeling in political science research and practice.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "34",
        "title": "A Universal Model for Human Mobility Prediction",
        "author": [
            "Qingyue Long",
            "Yuan Yuan",
            "Yong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15294",
        "abstract": "Predicting human mobility is crucial for urban planning, traffic control, and emergency response. Mobility behaviors can be categorized into individual and collective, and these behaviors are recorded by diverse mobility data, such as individual trajectory and crowd flow. As different modalities of mobility data, individual trajectory and crowd flow have a close coupling relationship. Crowd flows originate from the bottom-up aggregation of individual trajectories, while the constraints imposed by crowd flows shape these individual trajectories. Existing mobility prediction methods are limited to single tasks due to modal gaps between individual trajectory and crowd flow. In this work, we aim to unify mobility prediction to break through the limitations of task-specific models. We propose a universal human mobility prediction model (named UniMob), which can be applied to both individual trajectory and crowd flow. UniMob leverages a multi-view mobility tokenizer that transforms both trajectory and flow data into spatiotemporal tokens, facilitating unified sequential modeling through a diffusion transformer architecture. To bridge the gap between the different characteristics of these two data modalities, we implement a novel bidirectional individual and collective alignment mechanism. This mechanism enables learning common spatiotemporal patterns from different mobility data, facilitating mutual enhancement of both trajectory and flow predictions. Extensive experiments on real-world datasets validate the superiority of our model over state-of-the-art baselines in trajectory and flow prediction. Especially in noisy and scarce data scenarios, our model achieves the highest performance improvement of more than 14% and 25% in MAPE and Accuracy@5.",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "Transformer"
        ]
    },
    {
        "id": "35",
        "title": "Confidence in the Reasoning of Large Language Models",
        "author": [
            "Yudi Pawitan",
            "Chris Holmes"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15296",
        "abstract": "There is a growing literature on reasoning by large language models (LLMs), but the discussion on the uncertainty in their responses is still lacking. Our aim is to assess the extent of confidence that LLMs have in their answers and how it correlates with accuracy. Confidence is measured (i) qualitatively in terms of persistence in keeping their answer when prompted to reconsider, and (ii) quantitatively in terms of self-reported confidence score. We investigate the performance of three LLMs -- GPT4o, GPT4-turbo and Mistral -- on two benchmark sets of questions on causal judgement and formal fallacies and a set of probability and statistical puzzles and paradoxes. Although the LLMs show significantly better performance than random guessing, there is a wide variability in their tendency to change their initial answers. There is a positive correlation between qualitative confidence and accuracy, but the overall accuracy for the second answer is often worse than for the first answer. There is a strong tendency to overstate the self-reported confidence score. Confidence is only partially explained by the underlying token-level probability. The material effects of prompting on qualitative confidence and the strong tendency for overconfidence indicate that current LLMs do not have any internally coherent sense of confidence.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "36",
        "title": "A Comparative Study of DSPy Teleprompter Algorithms for Aligning Large Language Models Evaluation Metrics to Human Evaluation",
        "author": [
            "Bhaskarjit Sarmah",
            "Kriti Dutta",
            "Anna Grigoryan",
            "Sachin Tiwari",
            "Stefano Pasquali",
            "Dhagash Mehta"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15298",
        "abstract": "We argue that the Declarative Self-improving Python (DSPy) optimizers are a way to align the large language model (LLM) prompts and their evaluations to the human annotations. We present a comparative analysis of five teleprompter algorithms, namely, Cooperative Prompt Optimization (COPRO), Multi-Stage Instruction Prompt Optimization (MIPRO), BootstrapFewShot, BootstrapFewShot with Optuna, and K-Nearest Neighbor Few Shot, within the DSPy framework with respect to their ability to align with human evaluations. As a concrete example, we focus on optimizing the prompt to align hallucination detection (using LLM as a judge) to human annotated ground truth labels for a publicly available benchmark dataset. Our experiments demonstrate that optimized prompts can outperform various benchmark methods to detect hallucination, and certain telemprompters outperform the others in at least these experiments.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "37",
        "title": "Tokenphormer: Structure-aware Multi-token Graph Transformer for Node Classification",
        "author": [
            "Zijie Zhou",
            "Zhaoqi Lu",
            "Xuekai Wei",
            "Rongqin Chen",
            "Shenghui Zhang",
            "Pak Lon Ip",
            "Leong Hou U"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15302",
        "abstract": "Graph Neural Networks (GNNs) are widely used in graph data mining tasks. Traditional GNNs follow a message passing scheme that can effectively utilize local and structural information. However, the phenomena of over-smoothing and over-squashing limit the receptive field in message passing processes. Graph Transformers were introduced to address these issues, achieving a global receptive field but suffering from the noise of irrelevant nodes and loss of structural information. Therefore, drawing inspiration from fine-grained token-based representation learning in Natural Language Processing (NLP), we propose the Structure-aware Multi-token Graph Transformer (Tokenphormer), which generates multiple tokens to effectively capture local and structural information and explore global information at different levels of granularity. Specifically, we first introduce the walk-token generated by mixed walks consisting of four walk types to explore the graph and capture structure and contextual information flexibly. To ensure local and global information coverage, we also introduce the SGPM-token (obtained through the Self-supervised Graph Pre-train Model, SGPM) and the hop-token, extending the length and density limit of the walk-token, respectively. Finally, these expressive tokens are fed into the Transformer model to learn node representations collaboratively. Experimental results demonstrate that the capability of the proposed Tokenphormer can achieve state-of-the-art performance on node classification tasks.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "38",
        "title": "Self-Evolution Knowledge Distillation for LLM-based Machine Translation",
        "author": [
            "Yuncheng Song",
            "Liang Ding",
            "Changtong Zan",
            "Shujian Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15303",
        "abstract": "Knowledge distillation (KD) has shown great promise in transferring knowledge from larger teacher models to smaller student models. However, existing KD strategies for large language models often minimize output distributions between student and teacher models indiscriminately for each token. This overlooks the imbalanced nature of tokens and their varying transfer difficulties. In response, we propose a distillation strategy called Self-Evolution KD. The core of this approach involves dynamically integrating teacher distribution and one-hot distribution of ground truth into the student distribution as prior knowledge, which promotes the distillation process. It adjusts the ratio of prior knowledge based on token learning difficulty, fully leveraging the teacher model's potential. Experimental results show our method brings an average improvement of approximately 1.4 SacreBLEU points across four translation directions in the WMT22 test sets. Further analysis indicates that the improvement comes from better knowledge transfer from teachers, confirming our hypothesis.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "39",
        "title": "Tree-of-Code: A Tree-Structured Exploring Framework for End-to-End Code Generation and Execution in Complex Task Handling",
        "author": [
            "Ziyi Ni",
            "Yifan Li",
            "Ning Yang",
            "Dou Shen",
            "Pin Lv",
            "Daxiang Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15305",
        "abstract": "Solving complex reasoning tasks is a key real-world application of agents. Thanks to the pretraining of Large Language Models (LLMs) on code data, recent approaches like CodeAct successfully use code as LLM agents' action, achieving good results. However, CodeAct greedily generates the next action's code block by relying on fragmented thoughts, resulting in inconsistency and instability. Moreover, CodeAct lacks action-related ground-truth (GT), making its supervision signals and termination conditions questionable in multi-turn interactions. To address these issues, we first introduce a simple yet effective end-to-end code generation paradigm, CodeProgram, which leverages code's systematic logic to align with global reasoning and enable cohesive problem-solving. Then, we propose Tree-of-Code (ToC), which self-grows CodeProgram nodes based on the executable nature of the code and enables self-supervision in a GT-free scenario. Experimental results on two datasets using ten popular zero-shot LLMs show ToC remarkably boosts accuracy by nearly 20% over CodeAct with less than 1/4 turns. Several LLMs even perform better on one-turn CodeProgram than on multi-turn CodeAct. To further investigate the trade-off between efficacy and efficiency, we test different ToC tree sizes and exploration mechanisms. We also highlight the potential of ToC's end-to-end data generation for supervised and reinforced fine-tuning.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "40",
        "title": "MIETT: Multi-Instance Encrypted Traffic Transformer for Encrypted Traffic Classification",
        "author": [
            "Xu-Yang Chen",
            "Lu Han",
            "De-Chuan Zhan",
            "Han-Jia Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15306",
        "abstract": "Network traffic includes data transmitted across a network, such as web browsing and file transfers, and is organized into packets (small units of data) and flows (sequences of packets exchanged between two endpoints). Classifying encrypted traffic is essential for detecting security threats and optimizing network management. Recent advancements have highlighted the superiority of foundation models in this task, particularly for their ability to leverage large amounts of unlabeled data and demonstrate strong generalization to unseen data. However, existing methods that focus on token-level relationships fail to capture broader flow patterns, as tokens, defined as sequences of hexadecimal digits, typically carry limited semantic information in encrypted traffic. These flow patterns, which are crucial for traffic classification, arise from the interactions between packets within a flow, not just their internal structure. To address this limitation, we propose a Multi-Instance Encrypted Traffic Transformer (MIETT), which adopts a multi-instance approach where each packet is treated as a distinct instance within a larger bag representing the entire flow. This enables the model to capture both token-level and packet-level relationships more effectively through Two-Level Attention (TLA) layers, improving the model's ability to learn complex packet dynamics and flow patterns. We further enhance the model's understanding of temporal and flow-specific dynamics by introducing two novel pre-training tasks: Packet Relative Position Prediction (PRPP) and Flow Contrastive Learning (FCL). After fine-tuning, MIETT achieves state-of-the-art (SOTA) results across five datasets, demonstrating its effectiveness in classifying encrypted traffic and understanding complex network behaviors. Code is available at \\url{https://github.com/Secilia-Cxy/MIETT}.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "41",
        "title": "ViFactCheck: A New Benchmark Dataset and Methods for Multi-domain News Fact-Checking in Vietnamese",
        "author": [
            "Tran Thai Hoa",
            "Tran Quang Duy",
            "Khanh Quoc Tran",
            "Kiet Van Nguyen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15308",
        "abstract": "The rapid spread of information in the digital age highlights the critical need for effective fact-checking tools, particularly for languages with limited resources, such as Vietnamese. In response to this challenge, we introduce ViFactCheck, the first publicly available benchmark dataset designed specifically for Vietnamese fact-checking across multiple online news domains. This dataset contains 7,232 human-annotated pairs of claim-evidence combinations sourced from reputable Vietnamese online news, covering 12 diverse topics. It has been subjected to a meticulous annotation process to ensure high quality and reliability, achieving a Fleiss Kappa inter-annotator agreement score of 0.83. Our evaluation leverages state-of-the-art pre-trained and large language models, employing fine-tuning and prompting techniques to assess performance. Notably, the Gemma model demonstrated superior effectiveness, with an impressive macro F1 score of 89.90%, thereby establishing a new standard for fact-checking benchmarks. This result highlights the robust capabilities of Gemma in accurately identifying and verifying facts in Vietnamese. To further promote advances in fact-checking technology and improve the reliability of digital media, we have made the ViFactCheck dataset, model checkpoints, fact-checking pipelines, and source code freely available on GitHub. This initiative aims to inspire further research and enhance the accuracy of information in low-resource languages.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "42",
        "title": "Conceptual In-Context Learning and Chain of Concepts: Solving Complex Conceptual Problems Using Large Language Models",
        "author": [
            "Nishtha N. Vaidya",
            "Thomas Runkler",
            "Thomas Hubauer",
            "Veronika Haderlein-Hoegberg",
            "Maja Mlicic Brandt"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15309",
        "abstract": "Science and engineering problems fall in the category of complex conceptual problems that require specific conceptual information (CI) like math/logic -related know-how, process information, or engineering guidelines to solve them. Large Language Models (LLMs) are promising agents to solve such complex conceptual problems due to their implications in advancing engineering and science tasks like assisted problem-solving. But vanilla LLMs, trained on open-world data, lack the necessary CI. In this work, we specifically explore shallow customization methods (SCMs) of LLMs for solving complex conceptual problems. We propose two novel SCM algorithms for LLM, to augment LLMs with CI and enable LLMs to solve complex conceptual problems: Conceptual In-Context Learning (C-ICL) and Chain of Concepts (CoC). The problem tackled in this paper is generation of proprietary data models in the engineering/industry domain based on conceptual information in data modelling guidelines. We evaluate our algorithms on varied sizes of the OpenAI LLMs against four evaluation metrics related to syntactic and semantic correctness, time and cost incurred. The proposed algorithms perform better than currently popular LLM SCMs like In-context Learning (ICL) and Chain of Thoughts (CoT). It was observed that as compared to CoT, response correctness increased by 30.6% and 29.88% for the new SCMs C-ICL and CoC respectively. Qualitative analysis suggests that the proposed new SCMs activate emergent capabilities in LLMs, previously unobserved in the existing SCMs. They make problem-solving processes more transparent and reduce hallucinations and the tendency of model responses to copy examples from prompts (parroting).",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "43",
        "title": "PCA-Featured Transformer for Jamming Detection in 5G UAV Networks",
        "author": [
            "Joseanne Viana",
            "Hamed Farkhari",
            "Pedro Sebastiao",
            "Victor P Gil Jimenez",
            "Lester Ho"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15312",
        "abstract": "Jamming attacks pose a threat to Unmanned Aerial Vehicle (UAV) wireless communication systems, potentially disrupting essential services and compromising network reliability. Current detection approaches struggle with sophisticated artificial intelligence (AI) jamming techniques that adapt their patterns while existing machine learning solutions often require extensive feature engineering and fail to capture complex temporal dependencies in attack signatures. Furthermore, 5G networks using either Time Division Duplex (TDD) or Frequency Division Duplex (FDD) methods can face service degradation from intentional interference sources. To address these challenges, we present a novel transformer-based deep learning framework for jamming detection with Principal Component Analysis (PCA) added features. Our architecture leverages the transformer's self-attention mechanism to capture complex temporal dependencies and spatial correlations in wireless signal characteristics, enabling more robust jamming detection techniques. The U-shaped model incorporates a modified transformer encoder that processes signal features including received signal strength indicator (RSSI) and signal-to-noise ratio (SINR) measurements, alongside a specialized positional encoding scheme that accounts for the periodic nature of wireless signals. In addition, we propose a batch size scheduler and implement chunking techniques to optimize training convergence for time series data. These advancements contribute to achieving up to a ten times improvement in training speed within the advanced U-shaped encoder-decoder model introduced. Simulation results demonstrate that our approach achieves a detection accuracy of 90.33 \\% in Line-of-Sight (LoS) and 84.35 % in non-Line-of-Sight (NLoS) and outperforms machine learning methods and existing deep learning solutions such as the XGBoost (XGB) classifier in approximately 4%.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "44",
        "title": "Eliciting Causal Abilities in Large Language Models for Reasoning Tasks",
        "author": [
            "Yajing Wang",
            "Zongwei Luo",
            "Jingzhe Wang",
            "Zhanke Zhou",
            "Yongqiang Chen",
            "Bo Han"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15314",
        "abstract": "Prompt optimization automatically refines prompting expressions, unlocking the full potential of LLMs in downstream tasks. However, current prompt optimization methods are costly to train and lack sufficient interpretability. This paper proposes enhancing LLMs' reasoning performance by eliciting their causal inference ability from prompting instructions to correct answers. Specifically, we introduce the Self-Causal Instruction Enhancement (SCIE) method, which enables LLMs to generate high-quality, low-quantity observational data, then estimates the causal effect based on these data, and ultimately generates instructions with the optimized causal effect. In SCIE, the instructions are treated as the treatment, and textual features are used to process natural language, establishing causal relationships through treatments between instructions and downstream tasks. Additionally, we propose applying Object-Relational (OR) principles, where the uncovered causal relationships are treated as the inheritable class across task objects, ensuring low-cost reusability. Extensive experiments demonstrate that our method effectively generates instructions that enhance reasoning performance with reduced training cost of prompts, leveraging interpretable textual features to provide actionable insights.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "45",
        "title": "Taming Multimodal Joint Training for High-Quality Video-to-Audio Synthesis",
        "author": [
            "Ho Kei Cheng",
            "Masato Ishii",
            "Akio Hayakawa",
            "Takashi Shibuya",
            "Alexander Schwing",
            "Yuki Mitsufuji"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15322",
        "abstract": "We propose to synthesize high-quality and synchronized audio, given video and optional text conditions, using a novel multimodal joint training framework MMAudio. In contrast to single-modality training conditioned on (limited) video data only, MMAudio is jointly trained with larger-scale, readily available text-audio data to learn to generate semantically aligned high-quality audio samples. Additionally, we improve audio-visual synchrony with a conditional synchronization module that aligns video conditions with audio latents at the frame level. Trained with a flow matching objective, MMAudio achieves new video-to-audio state-of-the-art among public models in terms of audio quality, semantic alignment, and audio-visual synchronization, while having a low inference time (1.23s to generate an 8s clip) and just 157M parameters. MMAudio also achieves surprisingly competitive performance in text-to-audio generation, showing that joint training does not hinder single-modality performance. Code and demo are available at: https://hkchengrex.github.io/MMAudio",
        "tags": [
            "CLIP",
            "Flow Matching"
        ]
    },
    {
        "id": "46",
        "title": "Efficient Fine-Tuning and Concept Suppression for Pruned Diffusion Models",
        "author": [
            "Reza Shirkavand",
            "Peiran Yu",
            "Shangqian Gao",
            "Gowthami Somepalli",
            "Tom Goldstein",
            "Heng Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15341",
        "abstract": "Recent advances in diffusion generative models have yielded remarkable progress. While the quality of generated content continues to improve, these models have grown considerably in size and complexity. This increasing computational burden poses significant challenges, particularly in resource-constrained deployment scenarios such as mobile devices. The combination of model pruning and knowledge distillation has emerged as a promising solution to reduce computational demands while preserving generation quality. However, this technique inadvertently propagates undesirable behaviors, including the generation of copyrighted content and unsafe concepts, even when such instances are absent from the fine-tuning dataset. In this paper, we propose a novel bilevel optimization framework for pruned diffusion models that consolidates the fine-tuning and unlearning processes into a unified phase. Our approach maintains the principal advantages of distillation-namely, efficient convergence and style transfer capabilities-while selectively suppressing the generation of unwanted content. This plug-in framework is compatible with various pruning and concept unlearning methods, facilitating efficient, safe deployment of diffusion models in controlled environments.",
        "tags": [
            "Diffusion",
            "Style Transfer"
        ]
    },
    {
        "id": "47",
        "title": "Large Language Models on Small Resource-Constrained Systems: Performance Characterization, Analysis and Trade-offs",
        "author": [
            "Liam Seymour",
            "Basar Kutukcu",
            "Sabur Baidya"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15352",
        "abstract": "Generative AI like the Large Language Models (LLMs) has become more available for the general consumer in recent years. Publicly available services, e.g., ChatGPT, perform token generation on networked cloud server hardware, effectively removing the hardware entry cost for end users. However, the reliance on network access for these services, privacy and security risks involved, and sometimes the needs of the application make it necessary to run LLMs locally on edge devices. A significant amount of research has been done on optimization of LLMs and other transformer-based models on non-networked, resource-constrained devices, but they typically target older hardware. Our research intends to provide a 'baseline' characterization of more recent commercially available embedded hardware for LLMs, and to provide a simple utility to facilitate batch testing LLMs on recent Jetson hardware. We focus on the latest line of NVIDIA Jetson devices (Jetson Orin), and a set of publicly available LLMs (Pythia) ranging between 70 million and 1.4 billion parameters. Through detailed experimental evaluation with varying software and hardware parameters, we showcase trade-off spaces and optimization choices. Additionally, we design our testing structure to facilitate further research that involves performing batch LLM testing on Jetson hardware.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "48",
        "title": "Dataset Augmentation by Mixing Visual Concepts",
        "author": [
            "Abdullah Al Rahat",
            "Hemanth Venkateswara"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15358",
        "abstract": "This paper proposes a dataset augmentation method by fine-tuning pre-trained diffusion models. Generating images using a pre-trained diffusion model with textual conditioning often results in domain discrepancy between real data and generated images. We propose a fine-tuning approach where we adapt the diffusion model by conditioning it with real images and novel text embeddings. We introduce a unique procedure called Mixing Visual Concepts (MVC) where we create novel text embeddings from image captions. The MVC enables us to generate multiple images which are diverse and yet similar to the real data enabling us to perform effective dataset augmentation. We perform comprehensive qualitative and quantitative evaluations with the proposed dataset augmentation approach showcasing both coarse-grained and finegrained changes in generated images. Our approach outperforms state-of-the-art augmentation techniques on benchmark classification tasks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "49",
        "title": "Decade of Natural Language Processing in Chronic Pain: A Systematic Review",
        "author": [
            "Swati Rajwal"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15360",
        "abstract": "In recent years, the intersection of Natural Language Processing (NLP) and public health has opened innovative pathways for investigating various domains, including chronic pain in textual datasets. Despite the promise of NLP in chronic pain, the literature is dispersed across various disciplines, and there is a need to consolidate existing knowledge, identify knowledge gaps in the literature, and inform future research directions in this emerging field. This review aims to investigate the state of the research on NLP-based interventions designed for chronic pain research. A search strategy was formulated and executed across PubMed, Web of Science, IEEE Xplore, Scopus, and ACL Anthology to find studies published in English between 2014 and 2024. After screening 132 papers, 26 studies were included in the final review. Key findings from this review underscore the significant potential of NLP techniques to address pressing challenges in chronic pain research. The past 10 years in this field have showcased the utilization of advanced methods (transformers like RoBERTa and BERT) achieving high-performance metrics (e.g., F1>0.8) in classification tasks, while unsupervised approaches like Latent Dirichlet Allocation (LDA) and k-means clustering have proven effective for exploratory analyses. Results also reveal persistent challenges such as limited dataset diversity, inadequate sample sizes, and insufficient representation of underrepresented populations. Future research studies should explore multimodal data validation systems, context-aware mechanistic modeling, and the development of standardized evaluation metrics to enhance reproducibility and equity in chronic pain research.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "50",
        "title": "Spatiotemporally Coherent Probabilistic Generation of Weather from Climate",
        "author": [
            "Jonathan Schmidt",
            "Luca Schmidt",
            "Felix Strnad",
            "Nicole Ludwig",
            "Philipp Hennig"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15361",
        "abstract": "Local climate information is crucial for impact assessment and decision-making, yet coarse global climate simulations cannot capture small-scale phenomena. Current statistical downscaling methods infer these phenomena as temporally decoupled spatial patches. However, to preserve physical properties, estimating spatio-temporally coherent high-resolution weather dynamics for multiple variables across long time horizons is crucial. We present a novel generative approach that uses a score-based diffusion model trained on high-resolution reanalysis data to capture the statistical properties of local weather dynamics. After training, we condition on coarse climate model data to generate weather patterns consistent with the aggregate information. As this inference task is inherently uncertain, we leverage the probabilistic nature of diffusion models and sample multiple trajectories. We evaluate our approach with high-resolution reanalysis information before applying it to the climate model downscaling task. We then demonstrate that the model generates spatially and temporally coherent weather dynamics that align with global climate output.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "51",
        "title": "Granger Causality Detection with Kolmogorov-Arnold Networks",
        "author": [
            "Hongyu Lin",
            "Mohan Ren",
            "Paolo Barucca",
            "Tomaso Aste"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15373",
        "abstract": "Discovering causal relationships in time series data is central in many scientific areas, ranging from economics to climate science. Granger causality is a powerful tool for causality detection. However, its original formulation is limited by its linear form and only recently nonlinear machine-learning generalizations have been introduced. This study contributes to the definition of neural Granger causality models by investigating the application of Kolmogorov-Arnold networks (KANs) in Granger causality detection and comparing their capabilities against multilayer perceptrons (MLP). In this work, we develop a framework called Granger Causality KAN (GC-KAN) along with a tailored training approach designed specifically for Granger causality detection. We test this framework on both Vector Autoregressive (VAR) models and chaotic Lorenz-96 systems, analysing the ability of KANs to sparsify input features by identifying Granger causal relationships, providing a concise yet accurate model for Granger causality detection. Our findings show the potential of KANs to outperform MLPs in discerning interpretable Granger causal relationships, particularly for the ability of identifying sparse Granger causality patterns in high-dimensional settings, and more generally, the potential of AI in causality discovery for the dynamical laws in physical systems.",
        "tags": [
            "Detection",
            "KAN",
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "52",
        "title": "Automatic Extraction of Metaphoric Analogies from Literary Texts: Task Formulation, Dataset Construction, and Evaluation",
        "author": [
            "Joanne Boisson",
            "Zara Siddique",
            "Hsuvas Borkakoty",
            "Dimosthenis Antypas",
            "Luis Espinosa Anke",
            "Jose Camacho-Collados"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15375",
        "abstract": "Extracting metaphors and analogies from free text requires high-level reasoning abilities such as abstraction and language understanding. Our study focuses on the extraction of the concepts that form metaphoric analogies in literary texts. To this end, we construct a novel dataset in this domain with the help of domain experts. We compare the out-of-the-box ability of recent large language models (LLMs) to structure metaphoric mappings from fragments of texts containing proportional analogies. The models are further evaluated on the generation of implicit elements of the analogy, which are indirectly suggested in the texts and inferred by human readers. The competitive results obtained by LLMs in our experiments are encouraging and open up new avenues such as automatically extracting analogies and metaphors from text instead of investing resources in domain experts to manually label data.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "53",
        "title": "Systematic Evaluation of Long-Context LLMs on Financial Concepts",
        "author": [
            "Lavanya Gupta",
            "Saket Sharma",
            "Yiyun Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15386",
        "abstract": "Long-context large language models (LC LLMs) promise to increase reliability of LLMs in real-world tasks requiring processing and understanding of long input documents. However, this ability of LC LLMs to reliably utilize their growing context windows remains under investigation. In this work, we evaluate the performance of state-of-the-art GPT-4 suite of LC LLMs in solving a series of progressively challenging tasks, as a function of factors such as context length, task difficulty, and position of key information by creating a real world financial news dataset. Our findings indicate that LC LLMs exhibit brittleness at longer context lengths even for simple tasks, with performance deteriorating sharply as task complexity increases. At longer context lengths, these state-of-the-art models experience catastrophic failures in instruction following resulting in degenerate outputs. Our prompt ablations also reveal unfortunate continued sensitivity to both the placement of the task instruction in the context window as well as minor markdown formatting. Finally, we advocate for more rigorous evaluation of LC LLMs by employing holistic metrics such as F1 (rather than recall) and reporting confidence intervals, thereby ensuring robust and conclusive findings.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "54",
        "title": "Learning Visual Composition through Improved Semantic Guidance",
        "author": [
            "Austin Stone",
            "Hagen Soltau",
            "Robert Geirhos",
            "Xi Yi",
            "Ye Xia",
            "Bingyi Cao",
            "Kaifeng Chen",
            "Abhijit Ogale",
            "Jonathon Shlens"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15396",
        "abstract": "Visual imagery does not consist of solitary objects, but instead reflects the composition of a multitude of fluid concepts. While there have been great advances in visual representation learning, such advances have focused on building better representations for a small number of discrete objects bereft of an understanding of how these objects are interacting. One can observe this limitation in representations learned through captions or contrastive learning -- where the learned model treats an image essentially as a bag of words. Several works have attempted to address this limitation through the development of bespoke learned architectures to directly address the shortcomings in compositional learning. In this work, we focus on simple, and scalable approaches. In particular, we demonstrate that by substantially improving weakly labeled data, i.e. captions, we can vastly improve the performance of standard contrastive learning approaches. Previous CLIP models achieved near chance rate on challenging tasks probing compositional learning. However, our simple approach boosts performance of CLIP substantially and surpasses all bespoke architectures. Furthermore, we showcase our results on a relatively new captioning benchmark derived from DOCCI. We demonstrate through a series of ablations that a standard CLIP model trained with enhanced data may demonstrate impressive performance on image retrieval tasks.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "55",
        "title": "SolidGS: Consolidating Gaussian Surfel Splatting for Sparse-View Surface Reconstruction",
        "author": [
            "Zhuowen Shen",
            "Yuan Liu",
            "Zhang Chen",
            "Zhong Li",
            "Jiepeng Wang",
            "Yongqing Liang",
            "Zhengming Yu",
            "Jingdong Zhang",
            "Yi Xu",
            "Scott Schaefer",
            "Xin Li",
            "Wenping Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15400",
        "abstract": "Gaussian splatting has achieved impressive improvements for both novel-view synthesis and surface reconstruction from multi-view images. However, current methods still struggle to reconstruct high-quality surfaces from only sparse view input images using Gaussian splatting. In this paper, we propose a novel method called SolidGS to address this problem. We observed that the reconstructed geometry can be severely inconsistent across multi-views, due to the property of Gaussian function in geometry rendering. This motivates us to consolidate all Gaussians by adopting a more solid kernel function, which effectively improves the surface reconstruction quality. With the additional help of geometrical regularization and monocular normal estimation, our method achieves superior performance on the sparse view surface reconstruction than all the Gaussian splatting methods and neural field methods on the widely used DTU, Tanks-and-Temples, and LLFF datasets.",
        "tags": [
            "Gaussian Splatting"
        ]
    },
    {
        "id": "56",
        "title": "Deciphering Social Behaviour: a Novel Biological Approach For Social Users Classification",
        "author": [
            "Edoardo Allegrini",
            "Edoardo Di Paolo",
            "Marinella Petrocchi",
            "Angelo Spognardi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15410",
        "abstract": "Social media platforms continue to struggle with the growing presence of social bots-automated accounts that can influence public opinion and facilitate the spread of disinformation. Over time, these social bots have advanced significantly, making them increasingly difficult to distinguish from genuine users. Recently, new groups of bots have emerged, utilizing Large Language Models to generate content for posting, further complicating detection efforts. This paper proposes a novel approach that uses algorithms to measure the similarity between DNA strings, commonly used in biological contexts, to classify social users as bots or not. Our approach begins by clustering social media users into distinct macro species based on the similarities (and differences) observed in their timelines. These macro species are subsequently classified as either bots or genuine users, using a novel metric we developed that evaluates their behavioral characteristics in a way that mirrors biological comparison methods. This study extends beyond past approaches that focus solely on identical behaviors via analyses of the accounts' timelines. By incorporating new metrics, our approach systematically classifies non-trivial accounts into appropriate categories, effectively peeling back layers to reveal non-obvious species.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "57",
        "title": "MoEtion: Efficient and Reliable Checkpointing for Mixture-of-Experts Models at Scale",
        "author": [
            "Swapnil Gandhi",
            "Christos Kozyrakis"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15411",
        "abstract": "As large language models scale, distributed training systems increasingly rely on thousands of GPUs running for days or weeks. Fault tolerance is essential and periodic model checkpointing is the standard for achieving it. However, the already popular class of sparsely activated Mixture-of-Experts (MoE) models poses unique challenges. While their computational demands are similar to dense models, their larger size necessitates bigger checkpoints that cannot fully overlap with training iterations, causing throughput degradation or reduced checkpoint frequency.\nWe present MoEtion, a distributed in-memory checkpointing system designed for efficient and reliable training of large MoE models with near-zero overhead. MoEtion reduces checkpoint size by up to $9\\times$, comparable to dense models, by exploiting the skewness in expert popularity. It dynamically selects the critical subset of experts to snapshot in each checkpointing step. MoEtion increases checkpointing frequency by up to $15\\times$ compared to state-of-the-art, in memory checkpointing systems like Gemini. The reduced size allows checkpointing on every training iteration and full overlap between checkpointing with training operations. Finally, MoEtion preserves model convergence properties. After faults, MoEtion adjusts expert capacities to ensure consistent token processing without degrading accuracy.\nExperiments on MoE-GPT models with 8 to 64 experts show that MoEtion reduces checkpointing overheads by up to $12\\times$, while maintaining model accuracy and fault tolerance. These results underscore MoEtion's ability to improve training efficiency and reliability.",
        "tags": [
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "58",
        "title": "Time Will Tell: Timing Side Channels via Output Token Count in Large Language Models",
        "author": [
            "Tianchen Zhang",
            "Gururaj Saileshwar",
            "David Lie"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15431",
        "abstract": "This paper demonstrates a new side-channel that enables an adversary to extract sensitive information about inference inputs in large language models (LLMs) based on the number of output tokens in the LLM response. We construct attacks using this side-channel in two common LLM tasks: recovering the target language in machine translation tasks and recovering the output class in classification tasks. In addition, due to the auto-regressive generation mechanism in LLMs, an adversary can recover the output token count reliably using a timing channel, even over the network against a popular closed-source commercial LLM. Our experiments show that an adversary can learn the output language in translation tasks with more than 75% precision across three different models (Tower, M2M100, MBart50). Using this side-channel, we also show the input class in text classification tasks can be leaked out with more than 70% precision from open-source LLMs like Llama-3.1, Llama-3.2, Gemma2, and production models like GPT-4o. Finally, we propose tokenizer-, system-, and prompt-based mitigations against the output token count side-channel.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "59",
        "title": "Efficient Neural Network Encoding for 3D Color Lookup Tables",
        "author": [
            "Vahid Zehtab",
            "David B. Lindell",
            "Marcus A. Brubaker",
            "Michael S. Brown"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15438",
        "abstract": "3D color lookup tables (LUTs) enable precise color manipulation by mapping input RGB values to specific output RGB values. 3D LUTs are instrumental in various applications, including video editing, in-camera processing, photographic filters, computer graphics, and color processing for displays. While an individual LUT does not incur a high memory overhead, software and devices may need to store dozens to hundreds of LUTs that can take over 100 MB. This work aims to develop a neural network architecture that can encode hundreds of LUTs in a single compact representation. To this end, we propose a model with a memory footprint of less than 0.25 MB that can reconstruct 512 LUTs with only minor color distortion ($\\bar{\\Delta}E_M$ $\\leq$ 2.0) over the entire color gamut. We also show that our network can weight colors to provide further quality gains on natural image colors ($\\bar{\\Delta}{E}_M$ $\\leq$ 1.0). Finally, we show that minor modifications to the network architecture enable a bijective encoding that produces LUTs that are invertible, allowing for reverse color processing. Our code is available at https://github.com/vahidzee/ennelut.",
        "tags": [
            "3D",
            "Video Editing"
        ]
    },
    {
        "id": "60",
        "title": "SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval",
        "author": [
            "Aakash Mahalingam",
            "Vinesh Kumar Gande",
            "Aman Chadha",
            "Vinija Jain",
            "Divya Chaudhary"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15443",
        "abstract": "Retrieval-Augmented Generation (RAG) systems have become pivotal in leveraging vast corpora to generate informed and contextually relevant responses, notably reducing hallucinations in Large Language Models. Despite significant advancements, these systems struggle to efficiently process and retrieve information from large datasets while maintaining a comprehensive understanding of the context. This paper introduces SKETCH, a novel methodology that enhances the RAG retrieval process by integrating semantic text retrieval with knowledge graphs, thereby merging structured and unstructured data for a more holistic comprehension. SKETCH, demonstrates substantial improvements in retrieval performance and maintains superior context integrity compared to traditional methods. Evaluated across four diverse datasets: QuALITY, QASPER, NarrativeQA, and Italian Cuisine-SKETCH consistently outperforms baseline approaches on key RAGAS metrics such as answer_relevancy, faithfulness, context_precision and context_recall. Notably, on the Italian Cuisine dataset, SKETCH achieved an answer relevancy of 0.94 and a context precision of 0.99, representing the highest performance across all evaluated metrics. These results highlight SKETCH's capability in delivering more accurate and contextually relevant responses, setting new benchmarks for future retrieval systems.",
        "tags": [
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "61",
        "title": "LiHi-GS: LiDAR-Supervised Gaussian Splatting for Highway Driving Scene Reconstruction",
        "author": [
            "Pou-Chun Kung",
            "Xianling Zhang",
            "Katherine A. Skinner",
            "Nikita Jaipuria"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15447",
        "abstract": "Photorealistic 3D scene reconstruction plays an important role in autonomous driving, enabling the generation of novel data from existing datasets to simulate safety-critical scenarios and expand training data without additional acquisition costs. Gaussian Splatting (GS) facilitates real-time, photorealistic rendering with an explicit 3D Gaussian representation of the scene, providing faster processing and more intuitive scene editing than the implicit Neural Radiance Fields (NeRFs). While extensive GS research has yielded promising advancements in autonomous driving applications, they overlook two critical aspects: First, existing methods mainly focus on low-speed and feature-rich urban scenes and ignore the fact that highway scenarios play a significant role in autonomous driving. Second, while LiDARs are commonplace in autonomous driving platforms, existing methods learn primarily from images and use LiDAR only for initial estimates or without precise sensor modeling, thus missing out on leveraging the rich depth information LiDAR offers and limiting the ability to synthesize LiDAR data. In this paper, we propose a novel GS method for dynamic scene synthesis and editing with improved scene reconstruction through LiDAR supervision and support for LiDAR rendering. Unlike prior works that are tested mostly on urban datasets, to the best of our knowledge, we are the first to focus on the more challenging and highly relevant highway scenes for autonomous driving, with sparse sensor views and monotone backgrounds.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "62",
        "title": "Fietje: An open, efficient LLM for Dutch",
        "author": [
            "Bram Vanroy"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15450",
        "abstract": "This paper introduces Fietje, a family of small language models (SLMs) specifically designed for the Dutch language. The model is based on Phi 2, an English-centric model of 2.7 billion parameters. Fietje demonstrated competitive results with larger language models upon its release. A core emphasis of this work is transparency and reproducibility: Fietje is fully open-source, with model weights, datasets, training, and evaluation code all publicly accessible.\nThe paper discusses the performance of Fietje and many other models on an extensive evaluation suite of benchmarks on reasoning, sentiment analysis, world knowledge, linguistic acceptability and word sense disambiguation. Evaluation results illustrate the rapid progress in the field of LLMs, where recent small models outperform older, larger models that were fine-tuned for Dutch. This trend signals an exciting future for Dutch language processing, suggesting that even compact LLMs are becoming increasingly capable. Furthermore, ongoing and future efforts to adapt LLMs to Dutch are poised to enhance these models even further, broadening their applicability and accessibility. Fietje is only an intermediate step in improving accessibility to language technology for users of the Dutch language.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "63",
        "title": "Northeastern Uni at Multilingual Counterspeech Generation: Enhancing Counter Speech Generation with LLM Alignment through Direct Preference Optimization",
        "author": [
            "Sahil Wadhwa",
            "Chengtian Xu",
            "Haoming Chen",
            "Aakash Mahalingam",
            "Akankshya Kar",
            "Divya Chaudhary"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15453",
        "abstract": "The automatic generation of counter-speech (CS) is a critical strategy for addressing hate speech by providing constructive and informed responses. However, existing methods often fail to generate high-quality, impactful, and scalable CS, particularly across diverse linguistic contexts. In this paper, we propose a novel methodology to enhance CS generation by aligning Large Language Models (LLMs) using Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). Our approach leverages DPO to align LLM outputs with human preferences, ensuring contextually appropriate and linguistically adaptable responses. Additionally, we incorporate knowledge grounding to enhance the factual accuracy and relevance of generated CS. Experimental results demonstrate that DPO-aligned models significantly outperform SFT baselines on CS benchmarks while scaling effectively to multiple languages. These findings highlight the potential of preference-based alignment techniques to advance CS generation across varied linguistic settings. The model supervision and alignment is done in English and the same model is used for reporting metrics across other languages like Basque, Italian, and Spanish.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "64",
        "title": "TalkWithMachines: Enhancing Human-Robot Interaction for Interpretable Industrial Robotics Through Large/Vision Language Models",
        "author": [
            "Ammar N. Abbas",
            "Csaba Beleznai"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15462",
        "abstract": "TalkWithMachines aims to enhance human-robot interaction by contributing to interpretable industrial robotic systems, especially for safety-critical applications. The presented paper investigates recent advancements in Large Language Models (LLMs) and Vision Language Models (VLMs), in combination with robotic perception and control. This integration allows robots to understand and execute commands given in natural language and to perceive their environment through visual and/or descriptive inputs. Moreover, translating the LLM's internal states and reasoning into text that humans can easily understand ensures that operators gain a clearer insight into the robot's current state and intentions, which is essential for effective and safe operation. Our paper outlines four LLM-assisted simulated robotic control workflows, which explore (i) low-level control, (ii) the generation of language-based feedback that describes the robot's internal states, (iii) the use of visual information as additional input, and (iv) the use of robot structure information for generating task plans and feedback, taking the robot's physical capabilities and limitations into account. The proposed concepts are presented in a set of experiments, along with a brief discussion. Project description, videos, and supplementary materials will be available on the project website: https://talk-machines.github.io.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Robot",
            "Robotics"
        ]
    },
    {
        "id": "65",
        "title": "Continual Learning Using Only Large Language Model Prompting",
        "author": [
            "Jiabao Qiu",
            "Zixuan Ke",
            "Bing Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15479",
        "abstract": "We introduce CLOB, a novel continual learning (CL) paradigm wherein a large language model (LLM) is regarded as a black box. Learning is done incrementally via only verbal prompting. CLOB does not fine-tune any part of the LLM or add any trainable parameters to it. It is particularly suitable for LLMs that are accessible via APIs. We also propose a new CL technique, called CIS, based on incremental summarization that also overcomes the LLM's input length limit. Experiments show CIS outperforms baselines by a very large margin.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "66",
        "title": "Toward Robust Hyper-Detailed Image Captioning: A Multiagent Approach and Dual Evaluation Metrics for Factuality and Coverage",
        "author": [
            "Saehyung Lee",
            "Seunghyun Yoon",
            "Trung Bui",
            "Jing Shi",
            "Sungroh Yoon"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15484",
        "abstract": "Multimodal large language models (MLLMs) excel at generating highly detailed captions but often produce hallucinations. Our analysis reveals that existing hallucination detection methods struggle with detailed captions. We attribute this to the increasing reliance of MLLMs on their generated text, rather than the input image, as the sequence length grows. To address this issue, we propose a multiagent approach that leverages LLM-MLLM collaboration to correct given captions. Additionally, we introduce an evaluation framework and a benchmark dataset to facilitate the systematic analysis of detailed captions. Our experiments demonstrate that our proposed evaluation method better aligns with human judgments of factuality than existing metrics and that existing approaches to improve the MLLM factuality may fall short in hyper-detailed image captioning tasks. In contrast, our proposed method significantly enhances the factual accuracy of captions, even improving those generated by GPT-4V. Finally, we highlight a limitation of VQA-centric benchmarking by demonstrating that an MLLM's performance on VQA benchmarks may not correlate with its ability to generate detailed image captions.",
        "tags": [
            "Detection",
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "67",
        "title": "Multi-LLM Text Summarization",
        "author": [
            "Jiangnan Fang",
            "Cheng-Tse Liu",
            "Jieun Kim",
            "Yash Bhedaru",
            "Ethan Liu",
            "Nikhil Singh",
            "Nedim Lipka",
            "Puneet Mathur",
            "Nesreen K. Ahmed",
            "Franck Dernoncourt",
            "Ryan A. Rossi",
            "Hanieh Deilamsalehy"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15487",
        "abstract": "In this work, we propose a Multi-LLM summarization framework, and investigate two different multi-LLM strategies including centralized and decentralized. Our multi-LLM summarization framework has two fundamentally important steps at each round of conversation: generation and evaluation. These steps are different depending on whether our multi-LLM decentralized summarization is used or centralized. In both our multi-LLM decentralized and centralized strategies, we have k different LLMs that generate diverse summaries of the text. However, during evaluation, our multi-LLM centralized summarization approach leverages a single LLM to evaluate the summaries and select the best one whereas k LLMs are used for decentralized multi-LLM summarization. Overall, we find that our multi-LLM summarization approaches significantly outperform the baselines that leverage only a single LLM by up to 3x. These results indicate the effectiveness of multi-LLM approaches for summarization.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "68",
        "title": "GCA-3D: Towards Generalized and Consistent Domain Adaptation of 3D Generators",
        "author": [
            "Hengjia Li",
            "Yang Liu",
            "Yibo Zhao",
            "Haoran Cheng",
            "Yang Yang",
            "Linxuan Xia",
            "Zekai Luo",
            "Qibo Qiu",
            "Boxi Wu",
            "Tu Zheng",
            "Zheng Yang",
            "Deng Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15491",
        "abstract": "Recently, 3D generative domain adaptation has emerged to adapt the pre-trained generator to other domains without collecting massive datasets and camera pose distributions. Typically, they leverage large-scale pre-trained text-to-image diffusion models to synthesize images for the target domain and then fine-tune the 3D model. However, they suffer from the tedious pipeline of data generation, which inevitably introduces pose bias between the source domain and synthetic dataset. Furthermore, they are not generalized to support one-shot image-guided domain adaptation, which is more challenging due to the more severe pose bias and additional identity bias introduced by the single image reference. To address these issues, we propose GCA-3D, a generalized and consistent 3D domain adaptation method without the intricate pipeline of data generation. Different from previous pipeline methods, we introduce multi-modal depth-aware score distillation sampling loss to efficiently adapt 3D generative models in a non-adversarial manner. This multi-modal loss enables GCA-3D in both text prompt and one-shot image prompt adaptation. Besides, it leverages per-instance depth maps from the volume rendering module to mitigate the overfitting problem and retain the diversity of results. To enhance the pose and identity consistency, we further propose a hierarchical spatial consistency loss to align the spatial structure between the generated images in the source and target domain. Experiments demonstrate that GCA-3D outperforms previous methods in terms of efficiency, generalization, pose accuracy, and identity consistency.",
        "tags": [
            "3D",
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "69",
        "title": "TL-Training: A Task-Feature-Based Framework for Training Large Language Models in Tool Use",
        "author": [
            "Junjie Ye",
            "Yilong Wu",
            "Sixian Li",
            "Yuming Yang",
            "Tao Gui",
            "Qi Zhang",
            "Xuanjing Huang",
            "Peng Wang",
            "Zhongchao Shi",
            "Jianping Fan",
            "Zhengyin Du"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15495",
        "abstract": "Large language models (LLMs) achieve remarkable advancements by leveraging tools to interact with external environments, a critical step toward generalized AI. However, the standard supervised fine-tuning (SFT) approach, which relies on large-scale datasets, often overlooks task-specific characteristics in tool use, leading to performance bottlenecks. To address this issue, we analyze three existing LLMs and uncover key insights: training data can inadvertently impede tool-use behavior, token importance is distributed unevenly, and errors in tool calls fall into a small set of distinct categories. Building on these findings, we propose TL-Training, a task-feature-based framework that mitigates the effects of suboptimal training data, dynamically adjusts token weights to prioritize key tokens during SFT, and incorporates a robust reward mechanism tailored to error categories, optimized through proximal policy optimization. We validate TL-Training by training CodeLLaMA-2-7B and evaluating it on four diverse open-source test sets. Our results demonstrate that the LLM trained by our method matches or surpasses both open- and closed-source LLMs in tool-use performance using only 1,217 training data points. Additionally, our method enhances robustness in noisy environments and improves general task performance, offering a scalable and efficient paradigm for tool-use training in LLMs. The code and data are available at https://github.com/Junjie-Ye/TL-Training.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "70",
        "title": "Humanlike Cognitive Patterns as Emergent Phenomena in Large Language Models",
        "author": [
            "Zhisheng Tang",
            "Mayank Kejriwal"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15501",
        "abstract": "Research on emergent patterns in Large Language Models (LLMs) has gained significant traction in both psychology and artificial intelligence, motivating the need for a comprehensive review that offers a synthesis of this complex landscape. In this article, we systematically review LLMs' capabilities across three important cognitive domains: decision-making biases, reasoning, and creativity. We use empirical studies drawing on established psychological tests and compare LLMs' performance to human benchmarks. On decision-making, our synthesis reveals that while LLMs demonstrate several human-like biases, some biases observed in humans are absent, indicating cognitive patterns that only partially align with human decision-making. On reasoning, advanced LLMs like GPT-4 exhibit deliberative reasoning akin to human System-2 thinking, while smaller models fall short of human-level performance. A distinct dichotomy emerges in creativity: while LLMs excel in language-based creative tasks, such as storytelling, they struggle with divergent thinking tasks that require real-world context. Nonetheless, studies suggest that LLMs hold considerable potential as collaborators, augmenting creativity in human-machine problem-solving settings. Discussing key limitations, we also offer guidance for future research in areas such as memory, attention, and open-source model development.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "71",
        "title": "Mitigating Social Bias in Large Language Models: A Multi-Objective Approach within a Multi-Agent Framework",
        "author": [
            "Zhenjie Xu",
            "Wenqing Chen",
            "Yi Tang",
            "Xuanying Li",
            "Cheng Hu",
            "Zhixuan Chu",
            "Kui Ren",
            "Zibin Zheng",
            "Zhichao Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15504",
        "abstract": "Natural language processing (NLP) has seen remarkable advancements with the development of large language models (LLMs). Despite these advancements, LLMs often produce socially biased outputs. Recent studies have mainly addressed this problem by prompting LLMs to behave ethically, but this approach results in unacceptable performance degradation. In this paper, we propose a multi-objective approach within a multi-agent framework (MOMA) to mitigate social bias in LLMs without significantly compromising their performance. The key idea of MOMA involves deploying multiple agents to perform causal interventions on bias-related contents of the input questions, breaking the shortcut connection between these contents and the corresponding answers. Unlike traditional debiasing techniques leading to performance degradation, MOMA substantially reduces bias while maintaining accuracy in downstream tasks. Our experiments conducted on two datasets and two models demonstrate that MOMA reduces bias scores by up to 87.7%, with only a marginal performance degradation of up to 6.8% in the BBQ dataset. Additionally, it significantly enhances the multi-objective metric icat in the StereoSet dataset by up to 58.1%. Code will be made available at https://github.com/Cortantse/MOMA.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "72",
        "title": "Stylish and Functional: Guided Interpolation Subject to Physical Constraints",
        "author": [
            "Yan-Ying Chen",
            "Nikos Arechiga",
            "Chenyang Yuan",
            "Matthew Hong",
            "Matt Klenk",
            "Charlene Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15507",
        "abstract": "Generative AI is revolutionizing engineering design practices by enabling rapid prototyping and manipulation of designs. One example of design manipulation involves taking two reference design images and using them as prompts to generate a design image that combines aspects of both. Real engineering designs have physical constraints and functional requirements in addition to aesthetic design considerations. Internet-scale foundation models commonly used for image generation, however, are unable to take these physical constraints and functional requirements into consideration as part of the generation process. We consider the problem of generating a design inspired by two input designs, and propose a zero-shot framework toward enforcing physical, functional requirements over the generation process by leveraging a pretrained diffusion model as the backbone. As a case study, we consider the example of rotational symmetry in generation of wheel designs. Automotive wheels are required to be rotationally symmetric for physical stability. We formulate the requirement of rotational symmetry by the use of a symmetrizer, and we use this symmetrizer to guide the diffusion process towards symmetric wheel generations. Our experimental results find that the proposed approach makes generated interpolations with higher realism than methods in related work, as evaluated by Fréchet inception distance (FID). We also find that our approach generates designs that more closely satisfy physical and functional requirements than generating without the symmetry guidance.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "73",
        "title": "PolySmart @ TRECVid 2024 Video-To-Text",
        "author": [
            "Jiaxin Wu",
            "Wengyu Zhang",
            "Xiao-Yong Wei",
            "Qing Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15509",
        "abstract": "In this paper, we present our methods and results for the Video-To-Text (VTT) task at TRECVid 2024, exploring the capabilities of Vision-Language Models (VLMs) like LLaVA and LLaVA-NeXT-Video in generating natural language descriptions for video content. We investigate the impact of fine-tuning VLMs on VTT datasets to enhance description accuracy, contextual relevance, and linguistic consistency. Our analysis reveals that fine-tuning substantially improves the model's ability to produce more detailed and domain-aligned text, bridging the gap between generic VLM tasks and the specialized needs of VTT. Experimental results demonstrate that our fine-tuned model outperforms baseline VLMs across various evaluation metrics, underscoring the importance of domain-specific tuning for complex VTT tasks.",
        "tags": [
            "LLaVA"
        ]
    },
    {
        "id": "74",
        "title": "PreNeT: Leveraging Computational Features to Predict Deep Neural Network Training Time",
        "author": [
            "Alireza Pourali",
            "Arian Boukani",
            "Hamzeh Khazaei"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15519",
        "abstract": "Training deep learning models, particularly Transformer-based architectures such as Large Language Models (LLMs), demands substantial computational resources and extended training periods. While optimal configuration and infrastructure selection can significantly reduce associated costs, this optimization requires preliminary analysis tools. This paper introduces PreNeT, a novel predictive framework designed to address this optimization challenge. PreNeT facilitates training optimization by integrating comprehensive computational metrics, including layer-specific parameters, arithmetic operations and memory utilization. A key feature of PreNeT is its capacity to accurately predict training duration on previously unexamined hardware infrastructures, including novel accelerator architectures. This framework employs a sophisticated approach to capture and analyze the distinct characteristics of various neural network layers, thereby enhancing existing prediction methodologies. Through proactive implementation of PreNeT, researchers and practitioners can determine optimal configurations, parameter settings, and hardware specifications to maximize cost-efficiency and minimize training duration. Experimental results demonstrate that PreNeT achieves up to 72% improvement in prediction accuracy compared to contemporary state-of-the-art frameworks.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "75",
        "title": "HREF: Human Response-Guided Evaluation of Instruction Following in Language Models",
        "author": [
            "Xinxi Lyu",
            "Yizhong Wang",
            "Hannaneh Hajishirzi",
            "Pradeep Dasigi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15524",
        "abstract": "Evaluating the capability of Large Language Models (LLMs) in following instructions has heavily relied on a powerful LLM as the judge, introducing unresolved biases that deviate the judgments from human judges. In this work, we reevaluate various choices for automatic evaluation on a wide range of instruction-following tasks. We experiment with methods that leverage human-written responses and observe that they enhance the reliability of automatic evaluations across a wide range of tasks, resulting in up to a 3.2% improvement in agreement with human judges. We also discovered that human-written responses offer an orthogonal perspective to model-generated responses in following instructions and should be used as an additional context when comparing model responses. Based on these observations, we develop a new evaluation benchmark, Human Response-Guided Evaluation of Instruction Following (HREF), comprising 4,258 samples across 11 task categories with a composite evaluation setup, employing a composite evaluation setup that selects the most reliable method for each category. In addition to providing reliable evaluation, HREF emphasizes individual task performance and is free from contamination. Finally, we study the impact of key design choices in HREF, including the size of the evaluation set, the judge model, the baseline model, and the prompt template. We host a live leaderboard that evaluates LLMs on the private evaluation set of HREF.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "76",
        "title": "XRAG: eXamining the Core -- Benchmarking Foundational Components in Advanced Retrieval-Augmented Generation",
        "author": [
            "Qianren Mao",
            "Yangyifei Luo",
            "Jinlong Zhang",
            "Hanwen Hao",
            "Zhilong Cao",
            "Xiaolong Wang",
            "Xiao Guan",
            "Zhenting Huang",
            "Weifeng Jiang",
            "Shuyu Guo",
            "Zhentao Han",
            "Qili Zhang",
            "Siyuan Tao",
            "Yujie Liu",
            "Junnan Liu",
            "Zhixing Tan",
            "Jie Sun",
            "Bo Li",
            "Xudong Liu",
            "Richong Zhang",
            "Jianxin Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15529",
        "abstract": "Retrieval-augmented generation (RAG) synergizes the retrieval of pertinent data with the generative capabilities of Large Language Models (LLMs), ensuring that the generated output is not only contextually relevant but also accurate and http://current.We introduce XRAG, an open-source, modular codebase that facilitates exhaustive evaluation of the performance of foundational components of advanced RAG modules. These components are systematically categorized into four core phases: pre-retrieval, retrieval, post-retrieval, and generation. We systematically analyse them across reconfigured datasets, providing a comprehensive benchmark for their effectiveness. Given the escalating complexity of RAG systems, we underscore the necessity of identifying potential failure points of RAG modules. We formulate a suite of experimental methodologies and diagnostic testing protocols to dissect the failure points inherent in the engineering of RAG modules. Subsequently, we proffer bespoke solutions that are designed to augment the validation processes and bolster the overall performance of these modules. Our work thoroughly evaluates the performance of core advanced components in RAG systems, providing insights into optimizations for prevalent failure points.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "77",
        "title": "MRAG: A Modular Retrieval Framework for Time-Sensitive Question Answering",
        "author": [
            "Zhang Siyue",
            "Xue Yuxiang",
            "Zhang Yiming",
            "Wu Xiaobao",
            "Luu Anh Tuan",
            "Zhao Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15540",
        "abstract": "Understanding temporal relations and answering time-sensitive questions is crucial yet a challenging task for question-answering systems powered by large language models (LLMs). Existing approaches either update the parametric knowledge of LLMs with new facts, which is resource-intensive and often impractical, or integrate LLMs with external knowledge retrieval (i.e., retrieval-augmented generation). However, off-the-shelf retrievers often struggle to identify relevant documents that require intensive temporal reasoning. To systematically study time-sensitive question answering, we introduce the TempRAGEval benchmark, which repurposes existing datasets by incorporating temporal perturbations and gold evidence labels. As anticipated, all existing retrieval methods struggle with these temporal reasoning-intensive questions. We further propose Modular Retrieval (MRAG), a trainless framework that includes three modules: (1) Question Processing that decomposes question into a main content and a temporal constraint; (2) Retrieval and Summarization that retrieves evidence and uses LLMs to summarize according to the main content; (3) Semantic-Temporal Hybrid Ranking that scores each evidence summarization based on both semantic and temporal relevance. On TempRAGEval, MRAG significantly outperforms baseline retrievers in retrieval performance, leading to further improvements in final answer accuracy.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "78",
        "title": "ChangeDiff: A Multi-Temporal Change Detection Data Generator with Flexible Text Prompts via Diffusion Model",
        "author": [
            "Qi Zang",
            "Jiayi Yang",
            "Shuang Wang",
            "Dong Zhao",
            "Wenjun Yi",
            "Zhun Zhong"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15541",
        "abstract": "Data-driven deep learning models have enabled tremendous progress in change detection (CD) with the support of pixel-level annotations. However, collecting diverse data and manually annotating them is costly, laborious, and knowledge-intensive. Existing generative methods for CD data synthesis show competitive potential in addressing this issue but still face the following limitations: 1) difficulty in flexibly controlling change events, 2) dependence on additional data to train the data generators, 3) focus on specific change detection tasks. To this end, this paper focuses on the semantic CD (SCD) task and develops a multi-temporal SCD data generator ChangeDiff by exploring powerful diffusion models. ChangeDiff innovatively generates change data in two steps: first, it uses text prompts and a text-to-layout (T2L) model to create continuous layouts, and then it employs layout-to-image (L2I) to convert these layouts into images. Specifically, we propose multi-class distribution-guided text prompts (MCDG-TP), allowing for layouts to be generated flexibly through controllable classes and their corresponding ratios. Subsequently, to generalize the T2L model to the proposed MCDG-TP, a class distribution refinement loss is further designed as training supervision. %For the former, a multi-classdistribution-guided text prompt (MCDG-TP) is proposed to complement via controllable classes and ratios. To generalize the text-to-image diffusion model to the proposed MCDG-TP, a class distribution refinement loss is designed as training supervision. For the latter, MCDG-TP in three modes is proposed to synthesize new layout masks from various texts. Our generated data shows significant progress in temporal continuity, spatial diversity, and quality realism, empowering change detectors with accuracy and transferability. The code is available at https://github.com/DZhaoXd/ChangeDiff",
        "tags": [
            "Detection",
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "79",
        "title": "EGSRAL: An Enhanced 3D Gaussian Splatting based Renderer with Automated Labeling for Large-Scale Driving Scene",
        "author": [
            "Yixiong Huo",
            "Guangfeng Jiang",
            "Hongyang Wei",
            "Ji Liu",
            "Song Zhang",
            "Han Liu",
            "Xingliang Huang",
            "Mingjie Lu",
            "Jinzhang Peng",
            "Dong Li",
            "Lu Tian",
            "Emad Barsoum"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15550",
        "abstract": "3D Gaussian Splatting (3D GS) has gained popularity due to its faster rendering speed and high-quality novel view synthesis. Some researchers have explored using 3D GS for reconstructing driving scenes. However, these methods often rely on various data types, such as depth maps, 3D boxes, and trajectories of moving objects. Additionally, the lack of annotations for synthesized images limits their direct application in downstream tasks. To address these issues, we propose EGSRAL, a 3D GS-based method that relies solely on training images without extra annotations. EGSRAL enhances 3D GS's capability to model both dynamic objects and static backgrounds and introduces a novel adaptor for auto labeling, generating corresponding annotations based on existing annotations. We also propose a grouping strategy for vanilla 3D GS to address perspective issues in rendering large-scale, complex scenes. Our method achieves state-of-the-art performance on multiple datasets without any extra annotation. For example, the PSNR metric reaches 29.04 on the nuScenes dataset. Moreover, our automated labeling can significantly improve the performance of 2D/3D detection tasks. Code is available at https://github.com/jiangxb98/EGSRAL.",
        "tags": [
            "3D",
            "Detection",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "80",
        "title": "AutoRank: MCDA Based Rank Personalization for LoRA-Enabled Distributed Learning",
        "author": [
            "Shuaijun Chen",
            "Omid Tavallaie",
            "Niousha Nazemi",
            "Xin Chen",
            "Albert Y. Zomaya"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15553",
        "abstract": "As data volumes expand rapidly, distributed machine learning has become essential for addressing the growing computational demands of modern AI systems. However, training models in distributed environments is challenging with participants hold skew, Non-Independent-Identically distributed (Non-IID) data. Low-Rank Adaptation (LoRA) offers a promising solution to this problem by personalizing low-rank updates rather than optimizing the entire model, LoRA-enabled distributed learning minimizes computational and maximize personalization for each participant. Enabling more robust and efficient training in distributed learning settings, especially in large-scale, heterogeneous systems. Despite the strengths of current state-of-the-art methods, they often require manual configuration of the initial rank, which is increasingly impractical as the number of participants grows. This manual tuning is not only time-consuming but also prone to suboptimal configurations. To address this limitation, we propose AutoRank, an adaptive rank-setting algorithm inspired by the bias-variance trade-off. AutoRank leverages the MCDA method TOPSIS to dynamically assign local ranks based on the complexity of each participant's data. By evaluating data distribution and complexity through our proposed data complexity metrics, AutoRank provides fine-grained adjustments to the rank of each participant's local LoRA model. This adaptive approach effectively mitigates the challenges of double-imbalanced, non-IID data. Experimental results demonstrate that AutoRank significantly reduces computational overhead, enhances model performance, and accelerates convergence in highly heterogeneous federated learning environments. Through its strong adaptability, AutoRank offers a scalable and flexible solution for distributed machine learning.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "81",
        "title": "In-context Continual Learning Assisted by an External Continual Learner",
        "author": [
            "Saleh Momeni",
            "Sahisnu Mazumder",
            "Zixuan Ke",
            "Bing Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15563",
        "abstract": "Existing continual learning (CL) methods mainly rely on fine-tuning or adapting large language models (LLMs). They still suffer from catastrophic forgetting (CF). Little work has been done to exploit in-context learning (ICL) to leverage the extensive knowledge within LLMs for CL without updating any parameters. However, incrementally learning each new task in ICL necessitates adding training examples from each class of the task to the prompt, which hampers scalability as the prompt length increases. This issue not only leads to excessively long prompts that exceed the input token limit of the underlying LLM but also degrades the model's performance due to the overextended context. To address this, we introduce InCA, a novel approach that integrates an external continual learner (ECL) with ICL to enable scalable CL without CF. The ECL is built incrementally to pre-select a small subset of likely classes for each test instance. By restricting the ICL prompt to only these selected classes, InCA prevents prompt lengths from becoming excessively long, while maintaining high performance. Experimental results demonstrate that InCA significantly outperforms existing CL baselines, achieving substantial performance gains.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "82",
        "title": "DefFiller: Mask-Conditioned Diffusion for Salient Steel Surface Defect Generation",
        "author": [
            "Yichun Tai",
            "Zhenzhen Huang",
            "Tao Peng",
            "Zhijiang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15570",
        "abstract": "Current saliency-based defect detection methods show promise in industrial settings, but the unpredictability of defects in steel production environments complicates dataset creation, hampering model performance. Existing data augmentation approaches using generative models often require pixel-level annotations, which are time-consuming and resource-intensive. To address this, we introduce DefFiller, a mask-conditioned defect generation method that leverages a layout-to-image diffusion model. DefFiller generates defect samples paired with mask conditions, eliminating the need for pixel-level annotations and enabling direct use in model training. We also develop an evaluation framework to assess the quality of generated samples and their impact on detection performance. Experimental results on the SD-Saliency-900 dataset demonstrate that DefFiller produces high-quality defect images that accurately match the provided mask conditions, significantly enhancing the performance of saliency-based defect detection models trained on the augmented dataset.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "83",
        "title": "J-EDI QA: Benchmark for deep-sea organism-specific multimodal LLM",
        "author": [
            "Takero Yoshida",
            "Yuikazu Ito",
            "Yoshihiro Fujiwara",
            "Shinji Tsuchida",
            "Daisuke Sugiyama",
            "Daisuke Matsuoka"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15574",
        "abstract": "Japan Agency for Marine-Earth Science and Technology (JAMSTEC) has made available the JAMSTEC Earth Deep-sea Image (J-EDI), a deep-sea video and image archive (https://www.godac.jamstec.go.jp/jedi/e/index.html). This archive serves as a valuable resource for researchers and scholars interested in deep-sea imagery. The dataset comprises images and videos of deep-sea phenomena, predominantly of marine organisms, but also of the seafloor and physical processes. In this study, we propose J-EDI QA, a benchmark for understanding images of deep-sea organisms using a multimodal large language model (LLM). The benchmark is comprised of 100 images, accompanied by questions and answers with four options by JAMSTEC researchers for each image. The QA pairs are provided in Japanese, and the benchmark assesses the ability to understand deep-sea species in Japanese. In the evaluation presented in this paper, OpenAI o1 achieved a 50% correct response rate. This result indicates that even with the capabilities of state-of-the-art models as of December 2024, deep-sea species comprehension is not yet at an expert level. Further advances in deep-sea species-specific LLMs are therefore required.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "84",
        "title": "QUART-Online: Latency-Free Large Multimodal Language Model for Quadruped Robot Learning",
        "author": [
            "Xinyang Tong",
            "Pengxiang Ding",
            "Donglin Wang",
            "Wenjie Zhang",
            "Can Cui",
            "Mingyang Sun",
            "Yiguo Fan",
            "Han Zhao",
            "Hongyin Zhang",
            "Yonghao Dang",
            "Siteng Huang",
            "Shangke Lyu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15576",
        "abstract": "This paper addresses the inherent inference latency challenges associated with deploying multimodal large language models (MLLM) in quadruped vision-language-action (QUAR-VLA) tasks. Our investigation reveals that conventional parameter reduction techniques ultimately impair the performance of the language foundation model during the action instruction tuning phase, making them unsuitable for this purpose. We introduce a novel latency-free quadruped MLLM model, dubbed QUART-Online, designed to enhance inference efficiency without degrading the performance of the language foundation model. By incorporating Action Chunk Discretization (ACD), we compress the original action representation space, mapping continuous action values onto a smaller set of discrete representative vectors while preserving critical information. Subsequently, we fine-tune the MLLM to integrate vision, language, and compressed actions into a unified semantic space. Experimental results demonstrate that QUART-Online operates in tandem with the existing MLLM system, achieving real-time inference in sync with the underlying controller frequency, significantly boosting the success rate across various tasks by 65\\%. Our project page is \\href{https://quart-online.github.io}https://quart-online.github.io.",
        "tags": [
            "Large Language Models",
            "Robot"
        ]
    },
    {
        "id": "85",
        "title": "To Rely or Not to Rely? Evaluating Interventions for Appropriate Reliance on Large Language Models",
        "author": [
            "Jessica Y. Bo",
            "Sophia Wan",
            "Ashton Anderson"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15584",
        "abstract": "As Large Language Models become integral to decision-making, optimism about their power is tempered with concern over their errors. Users may over-rely on LLM advice that is confidently stated but wrong, or under-rely due to mistrust. Reliance interventions have been developed to help users of LLMs, but they lack rigorous evaluation for appropriate reliance. We benchmark the performance of three relevant interventions by conducting a randomized online experiment with 400 participants attempting two challenging tasks: LSAT logical reasoning and image-based numerical estimation. For each question, participants first answered independently, then received LLM advice modified by one of three reliance interventions and answered the question again. Our findings indicate that while interventions reduce over-reliance, they generally fail to improve appropriate reliance. Furthermore, people became more confident after making incorrect reliance decisions in certain contexts, demonstrating poor calibration. Based on our findings, we discuss implications for designing effective reliance interventions in human-LLM collaboration.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "86",
        "title": "NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional Generalization",
        "author": [
            "Danial Kamali",
            "Elham J. Barezi",
            "Parisa Kordjamshidi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15588",
        "abstract": "Compositional generalization is crucial for artificial intelligence agents to solve complex vision-language reasoning tasks. Neuro-symbolic approaches have demonstrated promise in capturing compositional structures, but they face critical challenges: (a) reliance on predefined predicates for symbolic representations that limit adaptability, (b) difficulty in extracting predicates from raw data, and (c) using non-differentiable operations for combining primitive concepts. To address these issues, we propose NeSyCoCo, a neuro-symbolic framework that leverages large language models (LLMs) to generate symbolic representations and map them to differentiable neural computations. NeSyCoCo introduces three innovations: (a) augmenting natural language inputs with dependency structures to enhance the alignment with symbolic representations, (b) employing distributed word representations to link diverse, linguistically motivated logical predicates to neural modules, and (c) using the soft composition of normalized predicate scores to align symbolic and differentiable reasoning. Our framework achieves state-of-the-art results on the ReaSCAN and CLEVR-CoGenT compositional generalization benchmarks and demonstrates robust performance with novel concepts in the CLEVR-SYN benchmark.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "87",
        "title": "Mask-RadarNet: Enhancing Transformer With Spatial-Temporal Semantic Context for Radar Object Detection in Autonomous Driving",
        "author": [
            "Yuzhi Wu",
            "Jun Liu",
            "Guangfeng Jiang",
            "Weijian Liu",
            "Danilo Orlando"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15595",
        "abstract": "As a cost-effective and robust technology, automotive radar has seen steady improvement during the last years, making it an appealing complement to commonly used sensors like camera and LiDAR in autonomous driving. Radio frequency data with rich semantic information are attracting more and more attention. Most current radar-based models take radio frequency image sequences as the input. However, these models heavily rely on convolutional neural networks and leave out the spatial-temporal semantic context during the encoding stage. To solve these problems, we propose a model called Mask-RadarNet to fully utilize the hierarchical semantic features from the input radar data. Mask-RadarNet exploits the combination of interleaved convolution and attention operations to replace the traditional architecture in transformer-based models. In addition, patch shift is introduced to the Mask-RadarNet for efficient spatial-temporal feature learning. By shifting part of patches with a specific mosaic pattern in the temporal dimension, Mask-RadarNet achieves competitive performance while reducing the computational burden of the spatial-temporal modeling. In order to capture the spatial-temporal semantic contextual information, we design the class masking attention module (CMAM) in our encoder. Moreover, a lightweight auxiliary decoder is added to our model to aggregate prior maps generated from the CMAM. Experiments on the CRUW dataset demonstrate the superiority of the proposed method to some state-of-the-art radar-based object detection algorithms. With relatively lower computational complexity and fewer parameters, the proposed Mask-RadarNet achieves higher recognition accuracy for object detection in autonomous driving.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "88",
        "title": "Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks",
        "author": [
            "Brian J Chan",
            "Chao-Ting Chen",
            "Jui-Hung Cheng",
            "Hen-Hsen Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15605",
        "abstract": "Retrieval-augmented generation (RAG) has gained traction as a powerful approach for enhancing language models by integrating external knowledge sources. However, RAG introduces challenges such as retrieval latency, potential errors in document selection, and increased system complexity. With the advent of large language models (LLMs) featuring significantly extended context windows, this paper proposes an alternative paradigm, cache-augmented generation (CAG) that bypasses real-time retrieval. Our method involves preloading all relevant resources, especially when the documents or knowledge for retrieval are of a limited and manageable size, into the LLM's extended context and caching its runtime parameters. During inference, the model utilizes these preloaded parameters to answer queries without additional retrieval steps. Comparative analyses reveal that CAG eliminates retrieval latency and minimizes retrieval errors while maintaining context relevance. Performance evaluations across multiple benchmarks highlight scenarios where long-context LLMs either outperform or complement traditional RAG pipelines. These findings suggest that, for certain applications, particularly those with a constrained knowledge base, CAG provide a streamlined and efficient alternative to RAG, achieving comparable or superior results with reduced complexity.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "89",
        "title": "Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool Usage",
        "author": [
            "Zhi Gao",
            "Bofei Zhang",
            "Pengxiang Li",
            "Xiaojian Ma",
            "Tao Yuan",
            "Yue Fan",
            "Yuwei Wu",
            "Yunde Jia",
            "Song-Chun Zhu",
            "Qing Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15606",
        "abstract": "The advancement of large language models (LLMs) prompts the development of multi-modal agents, which are used as a controller to call external tools, providing a feasible way to solve practical tasks. In this paper, we propose a multi-modal agent tuning method that automatically generates multi-modal tool-usage data and tunes a vision-language model (VLM) as the controller for powerful tool-usage reasoning. To preserve the data quality, we prompt the GPT-4o mini model to generate queries, files, and trajectories, followed by query-file and trajectory verifiers. Based on the data synthesis pipeline, we collect the MM-Traj dataset that contains 20K tasks with trajectories of tool usage. Then, we develop the T3-Agent via \\underline{T}rajectory \\underline{T}uning on VLMs for \\underline{T}ool usage using MM-Traj. Evaluations on the GTA and GAIA benchmarks show that the T3-Agent consistently achieves improvements on two popular VLMs: MiniCPM-V-8.5B and {Qwen2-VL-7B}, which outperforms untrained VLMs by $20\\%$, showing the effectiveness of the proposed data synthesis pipeline, leading to high-quality data for tool-usage capabilities.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "90",
        "title": "AvatarPerfect: User-Assisted 3D Gaussian Splatting Avatar Refinement with Automatic Pose Suggestion",
        "author": [
            "Jotaro Sakamiya",
            "I-Chao Shen",
            "Jinsong Zhang",
            "Mustafa Doga Dogan",
            "Takeo Igarashi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15609",
        "abstract": "Creating high-quality 3D avatars using 3D Gaussian Splatting (3DGS) from a monocular video benefits virtual reality and telecommunication applications. However, existing automatic methods exhibit artifacts under novel poses due to limited information in the input video. We propose AvatarPerfect, a novel system that allows users to iteratively refine 3DGS avatars by manually editing the rendered avatar images. In each iteration, our system suggests a new body and camera pose to help users identify and correct artifacts. The edited images are then used to update the current avatar, and our system suggests the next body and camera pose for further refinement. To investigate the effectiveness of AvatarPerfect, we conducted a user study comparing our method to an existing 3DGS editor SuperSplat, which allows direct manipulation of Gaussians without automatic pose suggestions. The results indicate that our system enables users to obtain higher quality refined 3DGS avatars than the existing 3DGS editor.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "91",
        "title": "Technical Report for ICML 2024 TiFA Workshop MLLM Attack Challenge: Suffix Injection and Projected Gradient Descent Can Easily Fool An MLLM",
        "author": [
            "Yangyang Guo",
            "Ziwei Xu",
            "Xilie Xu",
            "YongKang Wong",
            "Liqiang Nie",
            "Mohan Kankanhalli"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15614",
        "abstract": "This technical report introduces our top-ranked solution that employs two approaches, \\ie suffix injection and projected gradient descent (PGD) , to address the TiFA workshop MLLM attack challenge. Specifically, we first append the text from an incorrectly labeled option (pseudo-labeled) to the original query as a suffix. Using this modified query, our second approach applies the PGD method to add imperceptible perturbations to the image. Combining these two techniques enables successful attacks on the LLaVA 1.5 model.",
        "tags": [
            "LLaVA"
        ]
    },
    {
        "id": "92",
        "title": "3D Shape Tokenization",
        "author": [
            "Jen-Hao Rick Chang",
            "Yuyang Wang",
            "Miguel Angel Bautista Martin",
            "Jiatao Gu",
            "Josh Susskind",
            "Oncel Tuzel"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15618",
        "abstract": "We introduce Shape Tokens, a 3D representation that is continuous, compact, and easy to incorporate into machine learning models. Shape Tokens act as conditioning vectors that represent shape information in a 3D flow-matching model. The flow-matching model is trained to approximate probability density functions corresponding to delta functions concentrated on the surfaces of shapes in 3D. By attaching Shape Tokens to various machine learning models, we can generate new shapes, convert images to 3D, align 3D shapes with text and images, and render shapes directly at variable, user specified, resolution. Moreover, Shape Tokens enable a systematic analysis of geometric properties such as normal, density, and deformation field. Across all tasks and experiments, utilizing Shape Tokens demonstrate strong performance compared to existing baselines.",
        "tags": [
            "3D",
            "Flow Matching"
        ]
    },
    {
        "id": "93",
        "title": "JailPO: A Novel Black-box Jailbreak Framework via Preference Optimization against Aligned LLMs",
        "author": [
            "Hongyi Li",
            "Jiawei Ye",
            "Jie Wu",
            "Tianjie Yan",
            "Chu Wang",
            "Zhixin Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15623",
        "abstract": "Large Language Models (LLMs) aligned with human feedback have recently garnered significant attention. However, it remains vulnerable to jailbreak attacks, where adversaries manipulate prompts to induce harmful outputs. Exploring jailbreak attacks enables us to investigate the vulnerabilities of LLMs and further guides us in enhancing their security. Unfortunately, existing techniques mainly rely on handcrafted templates or generated-based optimization, posing challenges in scalability, efficiency and universality. To address these issues, we present JailPO, a novel black-box jailbreak framework to examine LLM alignment. For scalability and universality, JailPO meticulously trains attack models to automatically generate covert jailbreak prompts. Furthermore, we introduce a preference optimization-based attack method to enhance the jailbreak effectiveness, thereby improving efficiency. To analyze model vulnerabilities, we provide three flexible jailbreak patterns. Extensive experiments demonstrate that JailPO not only automates the attack process while maintaining effectiveness but also exhibits superior performance in efficiency, universality, and robustness against defenses compared to baselines. Additionally, our analysis of the three JailPO patterns reveals that attacks based on complex templates exhibit higher attack strength, whereas covert question transformations elicit riskier responses and are more likely to bypass defense mechanisms.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "94",
        "title": "Insights from the Frontline: GenAI Utilization Among Software Engineering Students",
        "author": [
            "Rudrajit Choudhuri",
            "Ambareesh Ramakrishnan",
            "Amreeta Chatterjee",
            "Bianca Trinkenreich",
            "Igor Steinmacher",
            "Marco Gerosa",
            "Anita Sarma"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15624",
        "abstract": "Generative AI (genAI) tools (e.g., ChatGPT, Copilot) have become ubiquitous in software engineering (SE). As SE educators, it behooves us to understand the consequences of genAI usage among SE students and to create a holistic view of where these tools can be successfully used. Through 16 reflective interviews with SE students, we explored their academic experiences of using genAI tools to complement SE learning and implementations. We uncover the contexts where these tools are helpful and where they pose challenges, along with examining why these challenges arise and how they impact students. We validated our findings through member checking and triangulation with instructors. Our findings provide practical considerations of where and why genAI should (not) be used in the context of supporting SE students.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "95",
        "title": "Can Input Attributions Interpret the Inductive Reasoning Process Elicited in In-Context Learning?",
        "author": [
            "Mengyu Ye",
            "Tatsuki Kuribayashi",
            "Goro Kobayashi",
            "Jun Suzuki"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15628",
        "abstract": "Elucidating the rationale behind neural models' outputs has been challenging in the machine learning field, which is indeed applicable in this age of large language models (LLMs) and in-context learning (ICL). When it comes to estimating input attributions (IA), ICL poses a new issue of interpreting which example in the prompt, consisting of a set of examples, contributed to identifying the task/rule to be solved. To this end, in this paper, we introduce synthetic diagnostic tasks inspired by the poverty of the stimulus design in inductive reasoning; here, most in-context examples are ambiguous w.r.t. their underlying rule, and one critical example disambiguates the task demonstrated. The question is whether conventional IA methods can identify such an example in interpreting the inductive reasoning process in ICL. Our experiments provide several practical findings; for example, a certain simple IA method works the best, and the larger the model, the generally harder it is to interpret the ICL with gradient-based IA methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "96",
        "title": "A New Method to Capturing Compositional Knowledge in Linguistic Space",
        "author": [
            "Jiahe Wan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15632",
        "abstract": "Compositional understanding allows visual language models to interpret complex relationships between objects, attributes, and relations in images and text. However, most existing methods often rely on hard negative examples and fine-tuning, which can overestimate improvements and are limited by the difficulty of obtaining hard negatives. In this work, we introduce Zero-Shot Compositional Understanding (ZS-CU), a novel task that enhances compositional understanding without requiring hard negative training data. We propose YUKINO (Yielded Compositional Understanding Knowledge via Textual Inversion with NO), which uses textual inversion to map unlabeled images to pseudo-tokens in a pre-trained CLIP model. We propose introducing \"no\" logical regularization to address the issue of token interaction in inversion. Additionally, we suggest using knowledge distillation to reduce the time complexity of textual inversion. Experimental results show that YUKINO outperforms the existing multi-modal SOTA models by over 8% on the SugarCREPE benchmark, and also achieves significant improvements in image retrieval tasks.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "97",
        "title": "Darkit: A User-Friendly Software Toolkit for Spiking Large Language Model",
        "author": [
            "Xin Du",
            "Shifan Ye",
            "Qian Zheng",
            "Yangfan Hu",
            "Rui Yan",
            "Shunyu Qi",
            "Shuyang Chen",
            "Huajin Tang",
            "Gang Pan",
            "Shuiguang Deng"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15634",
        "abstract": "Large language models (LLMs) have been widely applied in various practical applications, typically comprising billions of parameters, with inference processes requiring substantial energy and computational resources. In contrast, the human brain, employing bio-plausible spiking mechanisms, can accomplish the same tasks while significantly reducing energy consumption, even with a similar number of parameters. Based on this, several pioneering researchers have proposed and implemented various large language models that leverage spiking neural networks. They have demonstrated the feasibility of these models, validated their performance, and open-sourced their frameworks and partial source code. To accelerate the adoption of brain-inspired large language models and facilitate secondary development for researchers, we are releasing a software toolkit named DarwinKit (Darkit). The toolkit is designed specifically for learners, researchers, and developers working on spiking large models, offering a suite of highly user-friendly features that greatly simplify the learning, deployment, and development processes.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "98",
        "title": "CustomTTT: Motion and Appearance Customized Video Generation via Test-Time Training",
        "author": [
            "Xiuli Bi",
            "Jian Lu",
            "Bo Liu",
            "Xiaodong Cun",
            "Yong Zhang",
            "Weisheng Li",
            "Bin Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15646",
        "abstract": "Benefiting from large-scale pre-training of text-video pairs, current text-to-video (T2V) diffusion models can generate high-quality videos from the text description. Besides, given some reference images or videos, the parameter-efficient fine-tuning method, i.e. LoRA, can generate high-quality customized concepts, e.g., the specific subject or the motions from a reference video. However, combining the trained multiple concepts from different references into a single network shows obvious artifacts. To this end, we propose CustomTTT, where we can joint custom the appearance and the motion of the given video easily. In detail, we first analyze the prompt influence in the current video diffusion model and find the LoRAs are only needed for the specific layers for appearance and motion customization. Besides, since each LoRA is trained individually, we propose a novel test-time training technique to update parameters after combination utilizing the trained customized models. We conduct detailed experiments to verify the effectiveness of the proposed methods. Our method outperforms several state-of-the-art works in both qualitative and quantitative evaluations.",
        "tags": [
            "Diffusion",
            "LoRA",
            "Test-Time Training",
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "99",
        "title": "Beyond Human Data: Aligning Multimodal Large Language Models by Iterative Self-Evolution",
        "author": [
            "Wentao Tan",
            "Qiong Cao",
            "Yibing Zhan",
            "Chao Xue",
            "Changxing Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15650",
        "abstract": "Human preference alignment can greatly enhance Multimodal Large Language Models (MLLMs), but collecting high-quality preference data is costly. A promising solution is the self-evolution strategy, where models are iteratively trained on data they generate. However, current techniques still rely on human- or GPT-annotated data and sometimes require additional models or ground truth answers. To address these issues, we propose a novel multimodal self-evolution framework that enables the model to autonomously generate high-quality questions and answers using only unannotated images.\nFirst, we implement an image-driven self-questioning mechanism, allowing the model to create and evaluate questions based on image content, regenerating them if they are irrelevant or unanswerable. This sets a strong foundation for answer generation. Second, we introduce an answer self-enhancement technique, starting with image captioning to improve answer quality. We also use corrupted images to generate rejected answers, forming distinct preference pairs for optimization. Finally, we incorporate an image content alignment loss function alongside Direct Preference Optimization (DPO) loss to reduce hallucinations, ensuring the model focuses on image content.\nExperiments show that our framework performs competitively with methods using external information, offering a more efficient and scalable approach to MLLMs.",
        "tags": [
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "100",
        "title": "MathSpeech: Leveraging Small LMs for Accurate Conversion in Mathematical Speech-to-Formula",
        "author": [
            "Sieun Hyeon",
            "Kyudan Jung",
            "Jaehee Won",
            "Nam-Joon Kim",
            "Hyun Gon Ryu",
            "Hyuk-Jae Lee",
            "Jaeyoung Do"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15655",
        "abstract": "In various academic and professional settings, such as mathematics lectures or research presentations, it is often necessary to convey mathematical expressions orally. However, reading mathematical expressions aloud without accompanying visuals can significantly hinder comprehension, especially for those who are hearing-impaired or rely on subtitles due to language barriers. For instance, when a presenter reads Euler's Formula, current Automatic Speech Recognition (ASR) models often produce a verbose and error-prone textual description (e.g., e to the power of i x equals cosine of x plus i $\\textit{side}$ of x), instead of the concise $\\LaTeX{}$ format (i.e., $ e^{ix} = \\cos(x) + i\\sin(x) $), which hampers clear understanding and communication. To address this issue, we introduce MathSpeech, a novel pipeline that integrates ASR models with small Language Models (sLMs) to correct errors in mathematical expressions and accurately convert spoken expressions into structured $\\LaTeX{}$ representations. Evaluated on a new dataset derived from lecture recordings, MathSpeech demonstrates $\\LaTeX{}$ generation capabilities comparable to leading commercial Large Language Models (LLMs), while leveraging fine-tuned small language models of only 120M parameters. Specifically, in terms of CER, BLEU, and ROUGE scores for $\\LaTeX{}$ translation, MathSpeech demonstrated significantly superior capabilities compared to GPT-4o. We observed a decrease in CER from 0.390 to 0.298, and higher ROUGE/BLEU scores compared to GPT-4o.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "101",
        "title": "Adaptable and Precise: Enterprise-Scenario LLM Function-Calling Capability Training Pipeline",
        "author": [
            "Guancheng Zeng",
            "Wentao Ding",
            "Beining Xu",
            "Chi Zhang",
            "Wenqiang Han",
            "Gang Li",
            "Jingjing Mo",
            "Pengxu Qiu",
            "Xinran Tao",
            "Wang Tao",
            "Haowen Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15660",
        "abstract": "Enterprises possess a vast array of API assets scattered across various functions, forming the backbone of existing business processes. By leveraging these APIs as functional tools, enterprises can design diverse, scenario-specific agent applications, driven by on-premise function-calling models as the core engine. However, generic models often fail to meet enterprise requirements in terms of computational efficiency, output accuracy, and stability, necessitating scenario-specific adaptation. In this paper, we propose a training pipeline for function-calling capabilities tailored to real-world business scenarios. This pipeline includes the synthesis and augmentation of scenario-specific function-calling data, model fine-tuning, and performance evaluation and analysis. Using this pipeline, we generated 1,260 fully AI-generated samples and 1,035 augmented manually-labeled samples in digital HR agent scenario. The Qwen2.5-Coder-7B-Instruct model was employed as the base model and fine-tuned using the LoRA method on four GPUs with 24GB VRAM. Our fine-tuned model demonstrated outstanding performance in evaluations and practical applications, surpassing GPT-4 and GPT-4o in accuracy on the test set. These results validate the reliability of the proposed pipeline for training scenario-specific function-calling models.",
        "tags": [
            "GPT",
            "LoRA"
        ]
    },
    {
        "id": "102",
        "title": "SCENIC: Scene-aware Semantic Navigation with Instruction-guided Control",
        "author": [
            "Xiaohan Zhang",
            "Sebastian Starke",
            "Vladimir Guzov",
            "Zhensong Zhang",
            "Eduardo Pérez Pellitero",
            "Gerard Pons-Moll"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15664",
        "abstract": "Synthesizing natural human motion that adapts to complex environments while allowing creative control remains a fundamental challenge in motion synthesis. Existing models often fall short, either by assuming flat terrain or lacking the ability to control motion semantics through text. To address these limitations, we introduce SCENIC, a diffusion model designed to generate human motion that adapts to dynamic terrains within virtual scenes while enabling semantic control through natural language. The key technical challenge lies in simultaneously reasoning about complex scene geometry while maintaining text control. This requires understanding both high-level navigation goals and fine-grained environmental constraints. The model must ensure physical plausibility and precise navigation across varied terrain, while also preserving user-specified text control, such as ``carefully stepping over obstacles\" or ``walking upstairs like a zombie.\" Our solution introduces a hierarchical scene reasoning approach. At its core is a novel scene-dependent, goal-centric canonicalization that handles high-level goal constraint, and is complemented by an ego-centric distance field that captures local geometric details. This dual representation enables our model to generate physically plausible motion across diverse 3D scenes. By implementing frame-wise text alignment, our system achieves seamless transitions between different motion styles while maintaining scene constraints. Experiments demonstrate our novel diffusion model generates arbitrarily long human motions that both adapt to complex scenes with varying terrain surfaces and respond to textual prompts. Additionally, we show SCENIC can generalize to four real-scene datasets. Our code, dataset, and models will be released at \\url{https://virtualhumans.mpi-inf.mpg.de/scenic/}.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "103",
        "title": "Learning Group Interactions and Semantic Intentions for Multi-Object Trajectory Prediction",
        "author": [
            "Mengshi Qi",
            "Yuxin Yang",
            "Huadong Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15673",
        "abstract": "Effective modeling of group interactions and dynamic semantic intentions is crucial for forecasting behaviors like trajectories or movements. In complex scenarios like sports, agents' trajectories are influenced by group interactions and intentions, including team strategies and opponent actions. To this end, we propose a novel diffusion-based trajectory prediction framework that integrates group-level interactions into a conditional diffusion model, enabling the generation of diverse trajectories aligned with specific group activity. To capture dynamic semantic intentions, we frame group interaction prediction as a cooperative game, using Banzhaf interaction to model cooperation trends. We then fuse semantic intentions with enhanced agent embeddings, which are refined through both global and local aggregation. Furthermore, we expand the NBA SportVU dataset by adding human annotations of team-level tactics for trajectory and tactic prediction tasks. Extensive experiments on three widely-adopted datasets demonstrate that our model outperforms state-of-the-art methods. Our source code and data are available at https://github.com/aurora-xin/Group2Int-trajectory.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "104",
        "title": "PersonaMagic: Stage-Regulated High-Fidelity Face Customization with Tandem Equilibrium",
        "author": [
            "Xinzhe Li",
            "Jiahui Zhan",
            "Shengfeng He",
            "Yangyang Xu",
            "Junyu Dong",
            "Huaidong Zhang",
            "Yong Du"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15674",
        "abstract": "Personalized image generation has made significant strides in adapting content to novel concepts. However, a persistent challenge remains: balancing the accurate reconstruction of unseen concepts with the need for editability according to the prompt, especially when dealing with the complex nuances of facial features. In this study, we delve into the temporal dynamics of the text-to-image conditioning process, emphasizing the crucial role of stage partitioning in introducing new concepts. We present PersonaMagic, a stage-regulated generative technique designed for high-fidelity face customization. Using a simple MLP network, our method learns a series of embeddings within a specific timestep interval to capture face concepts. Additionally, we develop a Tandem Equilibrium mechanism that adjusts self-attention responses in the text encoder, balancing text description and identity preservation, improving both areas. Extensive experiments confirm the superiority of PersonaMagic over state-of-the-art methods in both qualitative and quantitative evaluations. Moreover, its robustness and flexibility are validated in non-facial domains, and it can also serve as a valuable plug-in for enhancing the performance of pretrained personalization models.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "105",
        "title": "DOLLAR: Few-Step Video Generation via Distillation and Latent Reward Optimization",
        "author": [
            "Zihan Ding",
            "Chi Jin",
            "Difan Liu",
            "Haitian Zheng",
            "Krishna Kumar Singh",
            "Qiang Zhang",
            "Yan Kang",
            "Zhe Lin",
            "Yuchen Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15689",
        "abstract": "Diffusion probabilistic models have shown significant progress in video generation; however, their computational efficiency is limited by the large number of sampling steps required. Reducing sampling steps often compromises video quality or generation diversity. In this work, we introduce a distillation method that combines variational score distillation and consistency distillation to achieve few-step video generation, maintaining both high quality and diversity. We also propose a latent reward model fine-tuning approach to further enhance video generation performance according to any specified reward metric. This approach reduces memory usage and does not require the reward to be differentiable. Our method demonstrates state-of-the-art performance in few-step generation for 10-second videos (128 frames at 12 FPS). The distilled student model achieves a score of 82.57 on VBench, surpassing the teacher model as well as baseline models Gen-3, T2V-Turbo, and Kling. One-step distillation accelerates the teacher model's diffusion sampling by up to 278.6 times, enabling near real-time generation. Human evaluations further validate the superior performance of our 4-step student models compared to teacher model using 50-step DDIM sampling.",
        "tags": [
            "DDIM",
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "106",
        "title": "Exploiting Multimodal Spatial-temporal Patterns for Video Object Tracking",
        "author": [
            "Xiantao Hu",
            "Ying Tai",
            "Xu Zhao",
            "Chen Zhao",
            "Zhenyu Zhang",
            "Jun Li",
            "Bineng Zhong",
            "Jian Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15691",
        "abstract": "Multimodal tracking has garnered widespread attention as a result of its ability to effectively address the inherent limitations of traditional RGB tracking. However, existing multimodal trackers mainly focus on the fusion and enhancement of spatial features or merely leverage the sparse temporal relationships between video frames. These approaches do not fully exploit the temporal correlations in multimodal videos, making it difficult to capture the dynamic changes and motion information of targets in complex scenarios. To alleviate this problem, we propose a unified multimodal spatial-temporal tracking approach named STTrack. In contrast to previous paradigms that solely relied on updating reference information, we introduced a temporal state generator (TSG) that continuously generates a sequence of tokens containing multimodal temporal information. These temporal information tokens are used to guide the localization of the target in the next time state, establish long-range contextual relationships between video frames, and capture the temporal trajectory of the target. Furthermore, at the spatial level, we introduced the mamba fusion and background suppression interactive (BSI) modules. These modules establish a dual-stage mechanism for coordinating information interaction and fusion between modalities. Extensive comparisons on five benchmark datasets illustrate that STTrack achieves state-of-the-art performance across various multimodal tracking scenarios. Code is available at: https://github.com/NJU-PCALab/STTrack.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "107",
        "title": "Cracking the Code: Evaluating Zero-Shot Prompting Methods for Providing Programming Feedback",
        "author": [
            "Niklas Ippisch",
            "Anna-Carolina Haensch",
            "Jan Simson",
            "Jacob Beck",
            "Markus Herklotz",
            "Malte Schierholz"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15702",
        "abstract": "Despite the growing use of large language models (LLMs) for providing feedback, limited research has explored how to achieve high-quality feedback. This case study introduces an evaluation framework to assess different zero-shot prompt engineering methods. We varied the prompts systematically and analyzed the provided feedback on programming errors in R. The results suggest that prompts suggesting a stepwise procedure increase the precision, while omitting explicit specifications about which provided data to analyze improves error identification.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "108",
        "title": "Contrastive Learning for Task-Independent SpeechLLM-Pretraining",
        "author": [
            "Maike Züfle",
            "Jan Niehues"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15712",
        "abstract": "Large language models (LLMs) excel in natural language processing but adapting these LLMs to speech processing tasks efficiently is not straightforward. Direct task-specific fine-tuning is limited by overfitting risks, data requirements, and computational costs. To address these challenges, we propose a scalable, two-stage training approach: (1) A task-independent speech pretraining stage using contrastive learning to align text and speech representations over all layers, followed by (2) a task-specific fine-tuning stage requiring minimal data. This approach outperforms traditional ASR pretraining and enables the model to surpass models specialized on speech translation and question answering while being trained on only 10% of the task-specific data.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "109",
        "title": "AutoLife: Automatic Life Journaling with Smartphones and LLMs",
        "author": [
            "Huatao Xu",
            "Panron Tong",
            "Mo Li",
            "Mani Srivastava"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15714",
        "abstract": "This paper introduces a novel mobile sensing application - life journaling - designed to generate semantic descriptions of users' daily lives. We present AutoLife, an automatic life journaling system based on commercial smartphones. AutoLife only inputs low-cost sensor data (without photos or audio) from smartphones and can automatically generate comprehensive life journals for users. To achieve this, we first derive time, motion, and location contexts from multimodal sensor data, and harness the zero-shot capabilities of Large Language Models (LLMs), enriched with commonsense knowledge about human lives, to interpret diverse contexts and generate life journals. To manage the task complexity and long sensing duration, a multilayer framework is proposed, which decomposes tasks and seamlessly integrates LLMs with other techniques for life journaling. This study establishes a real-life dataset as a benchmark and extensive experiment results demonstrate that AutoLife produces accurate and reliable life journals.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "110",
        "title": "Towards Secure AI-driven Industrial Metaverse with NFT Digital Twins",
        "author": [
            "Ravi Prakash",
            "Tony Thomas"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15716",
        "abstract": "The rise of the industrial metaverse has brought digital twins (DTs) to the forefront. Blockchain-powered non-fungible tokens (NFTs) offer a decentralized approach to creating and owning these cloneable DTs. However, the potential for unauthorized duplication, or counterfeiting, poses a significant threat to the security of NFT-DTs. Existing NFT clone detection methods often rely on static information like metadata and images, which can be easily manipulated. To address these limitations, we propose a novel deep-learning-based solution as a combination of an autoencoder and RNN-based classifier. This solution enables real-time pattern recognition to detect fake NFT-DTs. Additionally, we introduce the concept of dynamic metadata, providing a more reliable way to verify authenticity through AI-integrated smart contracts. By effectively identifying counterfeit DTs, our system contributes to strengthening the security of NFT-based assets in the metaverse.",
        "tags": [
            "Detection",
            "RNN"
        ]
    },
    {
        "id": "111",
        "title": "VORD: Visual Ordinal Calibration for Mitigating Object Hallucinations in Large Vision-Language Models",
        "author": [
            "Dexter Neo",
            "Tsuhan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15739",
        "abstract": "Large Vision-Language Models (LVLMs) have made remarkable developments along with the recent surge of large language models. Despite their advancements, LVLMs have a tendency to generate plausible yet inaccurate or inconsistent information based on the provided source content. This phenomenon, also known as ``hallucinations\" can have serious downstream implications during the deployment of LVLMs. To address this, we present VORD a simple and effective method that alleviates hallucinations by calibrating token predictions based on ordinal relationships between modified image pairs. VORD is presented in two forms: 1.) a minimalist training-free variant which eliminates implausible tokens from modified image pairs, and 2.) a trainable objective function that penalizes unlikely tokens. Our experiments demonstrate that VORD delivers better calibration and effectively mitigates object hallucinations on a wide-range of LVLM benchmarks.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "112",
        "title": "Extracting Interpretable Task-Specific Circuits from Large Language Models for Faster Inference",
        "author": [
            "Jorge García-Carrasco",
            "Alejandro Maté",
            "Juan Trujillo"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15750",
        "abstract": "Large Language Models (LLMs) have shown impressive performance across a wide range of tasks. However, the size of LLMs is steadily increasing, hindering their application on computationally constrained environments. On the other hand, despite their general capabilities, there are many situations where only one specific task is performed, rendering all other capabilities unnecessary and wasteful. This leads us to the following question: Is it possible to extract the minimal subset from an LLM that is able to perform a specific task in a faster, standalone manner? Recent works on Mechanistic Interpretability (MI) have shown that specific tasks are performed by a localized subset of components, or circuit. However, current techniques used to identify the circuit cannot be used to extract it for its standalone usage. In this work, we propose a novel approach to automatically extract the subset of the LLM that properly performs a targeted task requiring no additional training and a small amount of data samples. We evaluate our approach on different tasks and show that the resulting models are (i) considerably smaller, reducing the number of parameters up to 82.77% and (ii) more interpretable, as they focus on the circuit that is used to carry out the specific task, and can therefore be understood using MI techniques.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "113",
        "title": "Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning",
        "author": [
            "Sungjin Park",
            "Xiao Liu",
            "Yeyun Gong",
            "Edward Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15797",
        "abstract": "Despite recent advances in large language models, open-source models often struggle to consistently perform well on complex reasoning tasks. Existing ensemble methods, whether applied at the token or output levels, fail to address these challenges. In response, we present Language model Ensemble with Monte Carlo Tree Search (LE-MCTS), a novel framework for process-level ensembling of language models. LE-MCTS formulates step-by-step reasoning with an ensemble of language models as a Markov decision process. In this framework, states represent intermediate reasoning paths, while actions consist of generating the next reasoning step using one of the language models selected from a predefined pool. Guided by a process-based reward model, LE-MCTS performs a tree search over the reasoning steps generated by different language models, identifying the most accurate reasoning chain. Experimental results on five mathematical reasoning benchmarks demonstrate that our approach outperforms both single language model decoding algorithms and language model ensemble methods. Notably, LE-MCTS improves performance by 3.6% and 4.3% on the MATH and MQA datasets, respectively, highlighting its effectiveness in solving complex reasoning problems.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "114",
        "title": "Diffusion-Based Conditional Image Editing through Optimized Inference with Guidance",
        "author": [
            "Hyunsoo Lee",
            "Minsoo Kang",
            "Bohyung Han"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15798",
        "abstract": "We present a simple but effective training-free approach for text-driven image-to-image translation based on a pretrained text-to-image diffusion model. Our goal is to generate an image that aligns with the target task while preserving the structure and background of a source image. To this end, we derive the representation guidance with a combination of two objectives: maximizing the similarity to the target prompt based on the CLIP score and minimizing the structural distance to the source latent variable. This guidance improves the fidelity of the generated target image to the given target prompt while maintaining the structure integrity of the source image. To incorporate the representation guidance component, we optimize the target latent variable of diffusion model's reverse process with the guidance. Experimental results demonstrate that our method achieves outstanding image-to-image translation performance on various tasks when combined with the pretrained Stable Diffusion model.",
        "tags": [
            "CLIP",
            "Diffusion",
            "Image Editing",
            "Text-to-Image"
        ]
    },
    {
        "id": "115",
        "title": "WebLLM: A High-Performance In-Browser LLM Inference Engine",
        "author": [
            "Charlie F. Ruan",
            "Yucheng Qin",
            "Xun Zhou",
            "Ruihang Lai",
            "Hongyi Jin",
            "Yixin Dong",
            "Bohan Hou",
            "Meng-Shiun Yu",
            "Yiyan Zhai",
            "Sudeep Agarwal",
            "Hangrui Cao",
            "Siyuan Feng",
            "Tianqi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15803",
        "abstract": "Advancements in large language models (LLMs) have unlocked remarkable capabilities. While deploying these models typically requires server-grade GPUs and cloud-based inference, the recent emergence of smaller open-source models and increasingly powerful consumer devices have made on-device deployment practical. The web browser as a platform for on-device deployment is universally accessible, provides a natural agentic environment, and conveniently abstracts out the different backends from diverse device vendors. To address this opportunity, we introduce WebLLM, an open-source JavaScript framework that enables high-performance LLM inference entirely within web browsers. WebLLM provides an OpenAI-style API for seamless integration into web applications, and leverages WebGPU for efficient local GPU acceleration and WebAssembly for performant CPU computation. With machine learning compilers MLC-LLM and Apache TVM, WebLLM leverages optimized WebGPU kernels, overcoming the absence of performant WebGPU kernel libraries. Evaluations show that WebLLM can retain up to 80% native performance on the same device, with room to further close the gap. WebLLM paves the way for universally accessible, privacy-preserving, personalized, and locally powered LLM applications in web browsers. The code is available at: https://github.com/mlc-ai/web-llm.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "116",
        "title": "Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary Differential Equations",
        "author": [
            "Yi Zhang",
            "Chun-Wun Cheng",
            "Junyi He",
            "Zhihai He",
            "Carola-Bibiane Schönlieb",
            "Yuyan Chen",
            "Angelica I Aviles-Rivero"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15813",
        "abstract": "We introduce SONO, a novel method leveraging Second-Order Neural Ordinary Differential Equations (Second-Order NODEs) to enhance cross-modal few-shot learning. By employing a simple yet effective architecture consisting of a Second-Order NODEs model paired with a cross-modal classifier, SONO addresses the significant challenge of overfitting, which is common in few-shot scenarios due to limited training examples. Our second-order approach can approximate a broader class of functions, enhancing the model's expressive power and feature generalization capabilities. We initialize our cross-modal classifier with text embeddings derived from class-relevant prompts, streamlining training efficiency by avoiding the need for frequent text encoder processing. Additionally, we utilize text-based image augmentation, exploiting CLIP's robust image-text correlation to enrich training data significantly. Extensive experiments across multiple datasets demonstrate that SONO outperforms existing state-of-the-art methods in few-shot learning performance.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "117",
        "title": "Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback",
        "author": [
            "Jiaming Ji",
            "Jiayi Zhou",
            "Hantao Lou",
            "Boyuan Chen",
            "Donghai Hong",
            "Xuyao Wang",
            "Wenqi Chen",
            "Kaile Wang",
            "Rui Pan",
            "Jiahao Li",
            "Mohan Wang",
            "Josef Dai",
            "Tianyi Qiu",
            "Hua Xu",
            "Dong Li",
            "Weipeng Chen",
            "Jun Song",
            "Bo Zheng",
            "Yaodong Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15838",
        "abstract": "Reinforcement learning from human feedback (RLHF) has proven effective in enhancing the instruction-following capabilities of large language models; however, it remains underexplored in the cross-modality domain. As the number of modalities increases, aligning all-modality models with human intentions -- such as instruction following -- becomes a pressing challenge. In this work, we make the first attempt to fine-tune all-modality models (i.e. input and output with any modality, also named any-to-any models) using human preference data across all modalities (including text, image, audio, and video), ensuring its behavior aligns with human intentions. This endeavor presents several challenges. First, there is no large-scale all-modality human preference data in existing open-source resources, as most datasets are limited to specific modalities, predominantly text and image. Secondly, the effectiveness of binary preferences in RLHF for post-training alignment in complex all-modality scenarios remains an unexplored area. Finally, there is a lack of a systematic framework to evaluate the capabilities of all-modality models, particularly regarding modality selection and synergy. To address these challenges, we propose the align-anything framework, which includes meticulously annotated 200k all-modality human preference data. Then, we introduce an alignment method that learns from unified language feedback, effectively capturing complex modality-specific human preferences and enhancing the model's instruction-following capabilities. Furthermore, to assess performance improvements in all-modality models after post-training alignment, we construct a challenging all-modality capability evaluation framework -- eval-anything. All data, models, and code frameworks have been open-sourced for the community. For more details, please refer to https://github.com/PKU-Alignment/align-anything.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "118",
        "title": "A non-recursive Schur-Decomposition Algorithm for $N$-Dimensional Matrix Equations",
        "author": [
            "Carlota M. Cuesta Romero",
            "Francisco de la Hoz"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15840",
        "abstract": "In this paper, we develop an iterative method, based on the Bartels-Stewart algorithm to solve $N$-dimensional matrix equations, that relies on the Schur decomposition of the matrices involved. We remark that, unlike other possible implementations of that algorithm, ours avoids recursivity, and makes an efficient use of the available computational resources, which enables considering arbitrarily large problems, up to the size of the available memory. In this respect, we have successfully solved matrix equations in up to $N = 29$ dimensions.\nWe explain carefully all the steps, and calculate accurately the computational cost required. Furthermore, in order to ease the understanding, we offer both pseudocodes and full Matlab codes, and special emphasis is put on making the implementation of the method completely independent from the number of dimensions. As an important application, the method allows to compute the solution of linear $N$-dimensional systems of ODEs of constant coefficients at any time $t$, and, hence, of evolutionary PDEs, after discretizing the spatial derivatives by means of matrices. In this regard, we are able to compute with great accuracy the solution of an advection-diffusion equation on $\\mathbb R^N$.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "119",
        "title": "Multi-dimensional Visual Prompt Enhanced Image Restoration via Mamba-Transformer Aggregation",
        "author": [
            "Aiwen Jiang",
            "Hourong Chen",
            "Zhiwen Chen",
            "Jihua Ye",
            "Mingwen Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15845",
        "abstract": "Recent efforts on image restoration have focused on developing \"all-in-one\" models that can handle different degradation types and levels within single model. However, most of mainstream Transformer-based ones confronted with dilemma between model capabilities and computation burdens, since self-attention mechanism quadratically increase in computational complexity with respect to image size, and has inadequacies in capturing long-range dependencies. Most of Mamba-related ones solely scanned feature map in spatial dimension for global modeling, failing to fully utilize information in channel dimension. To address aforementioned problems, this paper has proposed to fully utilize complementary advantages from Mamba and Transformer without sacrificing computation efficiency. Specifically, the selective scanning mechanism of Mamba is employed to focus on spatial modeling, enabling capture long-range spatial dependencies under linear complexity. The self-attention mechanism of Transformer is applied to focus on channel modeling, avoiding high computation burdens that are in quadratic growth with image's spatial dimensions. Moreover, to enrich informative prompts for effective image restoration, multi-dimensional prompt learning modules are proposed to learn prompt-flows from multi-scale encoder/decoder layers, benefiting for revealing underlying characteristic of various degradations from both spatial and channel perspectives, therefore, enhancing the capabilities of \"all-in-one\" model to solve various restoration tasks. Extensive experiment results on several image restoration benchmark tasks such as image denoising, dehazing, and deraining, have demonstrated that the proposed method can achieve new state-of-the-art performance, compared with many popular mainstream methods. Related source codes and pre-trained parameters will be public on github https://github.com/12138-chr/MTAIR.",
        "tags": [
            "Mamba",
            "Transformer"
        ]
    },
    {
        "id": "120",
        "title": "Semi-Supervised Adaptation of Diffusion Models for Handwritten Text Generation",
        "author": [
            "Kai Brandenbusch"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15853",
        "abstract": "The generation of images of realistic looking, readable handwritten text is a challenging task which is referred to as handwritten text generation (HTG). Given a string and examples from a writer, the goal is to synthesize an image depicting the correctly spelled word in handwriting with the calligraphic style of the desired writer. An important application of HTG is the generation of training images in order to adapt downstream models for new data sets. With their success in natural image generation, diffusion models (DMs) have become the state-of-the-art approach in HTG. In this work, we present an extension of a latent DM for HTG to enable generation of writing styles not seen during training by learning style conditioning with a masked auto encoder. Our proposed content encoder allows for different ways of conditioning the DM on textual and calligraphic features. Additionally, we employ classifier-free guidance and explore the influence on the quality of the generated training images. For adapting the model to a new unlabeled data set, we propose a semi-supervised training scheme. We evaluate our approach on the IAM-database and use the RIMES-database to examine the generation of data not seen during training achieving improvements in this particularly promising application of DMs for HTG.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "121",
        "title": "IRGS: Inter-Reflective Gaussian Splatting with 2D Gaussian Ray Tracing",
        "author": [
            "Chun Gu",
            "Xiaofei Wei",
            "Zixuan Zeng",
            "Yuxuan Yao",
            "Li Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15867",
        "abstract": "In inverse rendering, accurately modeling visibility and indirect radiance for incident light is essential for capturing secondary effects. Due to the absence of a powerful Gaussian ray tracer, previous 3DGS-based methods have either adopted a simplified rendering equation or used learnable parameters to approximate incident light, resulting in inaccurate material and lighting estimations. To this end, we introduce inter-reflective Gaussian splatting (IRGS) for inverse rendering. To capture inter-reflection, we apply the full rendering equation without simplification and compute incident radiance on the fly using the proposed differentiable 2D Gaussian ray tracing. Additionally, we present an efficient optimization scheme to handle the computational demands of Monte Carlo sampling for rendering equation evaluation. Furthermore, we introduce a novel strategy for querying the indirect radiance of incident light when relighting the optimized scenes. Extensive experiments on multiple standard benchmarks validate the effectiveness of IRGS, demonstrating its capability to accurately model complex inter-reflection effects.",
        "tags": [
            "Gaussian Splatting"
        ]
    },
    {
        "id": "122",
        "title": "AI-in-the-loop: The future of biomedical visual analytics applications in the era of AI",
        "author": [
            "Katja Bühler",
            "Thomas Höllt",
            "Thomas Schulz",
            "Pere-Pau Vázquez"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15876",
        "abstract": "AI is the workhorse of modern data analytics and omnipresent across many sectors. Large Language Models and multi-modal foundation models are today capable of generating code, charts, visualizations, etc. How will these massive developments of AI in data analytics shape future data visualizations and visual analytics workflows? What is the potential of AI to reshape methodology and design of future visual analytics applications? What will be our role as visualization researchers in the future? What are opportunities, open challenges and threats in the context of an increasingly powerful AI? This Visualization Viewpoint discusses these questions in the special context of biomedical data analytics as an example of a domain in which critical decisions are taken based on complex and sensitive data, with high requirements on transparency, efficiency, and reliability. We map recent trends and developments in AI on the elements of interactive visualization and visual analytics workflows and highlight the potential of AI to transform biomedical visualization as a research field. Given that agency and responsibility have to remain with human experts, we argue that it is helpful to keep the focus on human-centered workflows, and to use visual analytics as a tool for integrating ``AI-in-the-loop''. This is in contrast to the more traditional term ``human-in-the-loop'', which focuses on incorporating human expertise into AI-based systems.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "123",
        "title": "TelcoLM: collecting data, adapting, and benchmarking language models for the telecommunication domain",
        "author": [
            "Camille Barboule",
            "Viet-Phi Huynh",
            "Adrien Bufort",
            "Yoan Chabot",
            "Géraldine Damnati",
            "Gwénolé Lecorvé"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15891",
        "abstract": "Despite outstanding processes in many tasks, Large Language Models (LLMs) still lack accuracy when dealing with highly technical domains. Especially, telecommunications (telco) is a particularly challenging domain due the large amount of lexical, semantic and conceptual peculiarities. Yet, this domain holds many valuable use cases, directly linked to industrial needs. Hence, this paper studies how LLMs can be adapted to the telco domain. It reports our effort to (i) collect a massive corpus of domain-specific data (800M tokens, 80K instructions), (ii) perform adaptation using various methodologies, and (iii) benchmark them against larger generalist models in downstream tasks that require extensive knowledge of telecommunications. Our experiments on Llama-2-7b show that domain-adapted models can challenge the large generalist models. They also suggest that adaptation can be restricted to a unique instruction-tuning step, dicarding the need for any fine-tuning on raw texts beforehand.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "124",
        "title": "Evaluation of Reliability Criteria for News Publishers with Large Language Models",
        "author": [
            "Manuel Pratelli",
            "John Bianchi",
            "Fabio Pinelli",
            "Marinella Petrocchi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15896",
        "abstract": "In this study, we investigate the use of a large language model to assist in the evaluation of the reliability of the vast number of existing online news publishers, addressing the impracticality of relying solely on human expert annotators for this task. In the context of the Italian news media market, we first task the model with evaluating expert-designed reliability criteria using a representative sample of news articles. We then compare the model's answers with those of human experts. The dataset consists of 340 news articles, each annotated by two human experts and the LLM. Six criteria are taken into account, for a total of 6,120 annotations. We observe good agreement between LLM and human annotators in three of the six evaluated criteria, including the critical ability to detect instances where a text negatively targets an entity or individual. For two additional criteria, such as the detection of sensational language and the recognition of bias in news content, LLMs generate fair annotations, albeit with certain trade-offs. Furthermore, we show that the LLM is able to help resolve disagreements among human experts, especially in tasks such as identifying cases of negative targeting.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "125",
        "title": "A Thorough Investigation into the Application of Deep CNN for Enhancing Natural Language Processing Capabilities",
        "author": [
            "Chang Weng",
            "Scott Rood",
            "Mehdi Ali Ramezani",
            "Amir Aslani",
            "Reza Zarrab",
            "Wang Zwuo",
            "Sanjeev Salimans",
            "Tim Satheesh"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15900",
        "abstract": "Natural Language Processing (NLP) is widely used in fields like machine translation and sentiment analysis. However, traditional NLP models struggle with accuracy and efficiency. This paper introduces Deep Convolutional Neural Networks (DCNN) into NLP to address these issues. By integrating DCNN, machine learning (ML) algorithms, and generative adversarial networks (GAN), the study improves language understanding, reduces ambiguity, and enhances task performance. The high-performance NLP model shows a 10% improvement in segmentation accuracy and a 4% increase in recall rate compared to traditional models. This integrated approach excels in tasks such as word segmentation, part-of-speech tagging, machine translation, and text classification, offering better recognition accuracy and processing efficiency.",
        "tags": [
            "GAN",
            "Segmentation"
        ]
    },
    {
        "id": "126",
        "title": "On the Suitability of pre-trained foundational LLMs for Analysis in German Legal Education",
        "author": [
            "Lorenz Wendlinger",
            "Christian Braun",
            "Abdullah Al Zubaer",
            "Simon Alexander Nonn",
            "Sarah Großkopf",
            "Christofer Fellicious",
            "Michael Granitzer"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15902",
        "abstract": "We show that current open-source foundational LLMs possess instruction capability and German legal background knowledge that is sufficient for some legal analysis in an educational context. However, model capability breaks down in very specific tasks, such as the classification of \"Gutachtenstil\" appraisal style components, or with complex contexts, such as complete legal opinions. Even with extended context and effective prompting strategies, they cannot match the Bag-of-Words baseline. To combat this, we introduce a Retrieval Augmented Generation based prompt example selection method that substantially improves predictions in high data availability scenarios. We further evaluate the performance of pre-trained LLMs on two standard tasks for argument mining and automated essay scoring and find it to be more adequate. Throughout, pre-trained LLMs improve upon the baseline in scenarios with little or no labeled data with Chain-of-Thought prompting further helping in the zero-shot case.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "127",
        "title": "Less is More: Towards Green Code Large Language Models via Unified Structural Pruning",
        "author": [
            "Guang Yang",
            "Yu Zhou",
            "Xiangyu Zhang",
            "Wei Cheng",
            "Ke Liu",
            "Xiang Chen",
            "Terry Yue Zhuo",
            "Taolue Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15921",
        "abstract": "The extensive application of Large Language Models (LLMs) in generative coding tasks has raised concerns due to their high computational demands and energy consumption. Unlike previous structural pruning methods designed for classification models that deal with lowdimensional classification logits, generative Code LLMs produce high-dimensional token logit sequences, making traditional pruning objectives inherently limited. Moreover, existing single component pruning approaches further constrain the effectiveness when applied to generative Code LLMs. In response, we propose Flab-Pruner, an innovative unified structural pruning method that combines vocabulary, layer, and Feed-Forward Network (FFN) pruning. This approach effectively reduces model parameters while maintaining performance. Additionally, we introduce a customized code instruction data strategy for coding tasks to enhance the performance recovery efficiency of the pruned model. Through extensive evaluations on three state-of-the-art Code LLMs across multiple generative coding tasks, the results demonstrate that Flab-Pruner retains 97% of the original performance after pruning 22% of the parameters and achieves the same or even better performance after post-training. The pruned models exhibit significant improvements in storage, GPU usage, computational efficiency, and environmental impact, while maintaining well robustness. Our research provides a sustainable solution for green software engineering and promotes the efficient deployment of LLMs in real-world generative coding intelligence applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "128",
        "title": "Large Language Model assisted Hybrid Fuzzing",
        "author": [
            "Ruijie Meng",
            "Gregory J. Duck",
            "Abhik Roychoudhury"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15931",
        "abstract": "Greybox fuzzing is one of the most popular methods for detecting software vulnerabilities, which conducts a biased random search within the program input space. To enhance its effectiveness in achieving deep coverage of program behaviors, greybox fuzzing is often combined with concolic execution, which performs a path-sensitive search over the domain of program inputs. In hybrid fuzzing, conventional greybox fuzzing is followed by concolic execution in an iterative loop, where reachability roadblocks encountered by greybox fuzzing are tackled by concolic execution. However, such hybrid fuzzing still suffers from difficulties conventionally faced by symbolic execution, such as the need for environment modeling and system call support. In this work, we show how to achieve the effect of concolic execution without having to compute and solve symbolic path constraints. When coverage-based greybox fuzzing reaches a roadblock in terms of reaching certain branches, we conduct a slicing on the execution trace and suggest modifications of the input to reach the relevant branches. A Large Language Model (LLM) is used as a solver to generate the modified input for reaching the desired branches. Compared with both the vanilla greybox fuzzer AFL and hybrid fuzzers Intriguer and Qsym, our LLM-based hybrid fuzzer HyLLfuzz (pronounced \"hill fuzz\") demonstrates superior coverage. Furthermore, the LLM-based concolic execution in HyLLfuzz takes a time that is 4-19 times faster than the concolic execution running in existing hybrid fuzzing tools. This experience shows that LLMs can be effectively inserted into the iterative loop of hybrid fuzzers, to efficiently expose more program behaviors.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "129",
        "title": "Trust Calibration in IDEs: Paving the Way for Widespread Adoption of AI Refactoring",
        "author": [
            "Markus Borg"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15948",
        "abstract": "In the software industry, the drive to add new features often overshadows the need to improve existing code. Large Language Models (LLMs) offer a new approach to improving codebases at an unprecedented scale through AI-assisted refactoring. However, LLMs come with inherent risks such as braking changes and the introduction of security vulnerabilities. We advocate for encapsulating the interaction with the models in IDEs and validating refactoring attempts using trustworthy safeguards. However, equally important for the uptake of AI refactoring is research on trust development. In this position paper, we position our future work based on established models from research on human factors in automation. We outline action research within CodeScene on development of 1) novel LLM safeguards and 2) user interaction that conveys an appropriate level of trust. The industry collaboration enables large-scale repository analysis and A/B testing to continuously guide the design of our research interventions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "130",
        "title": "BabyHGRN: Exploring RNNs for Sample-Efficient Training of Language Models",
        "author": [
            "Patrick Haller",
            "Jonas Golde",
            "Alan Akbik"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15978",
        "abstract": "This paper explores the potential of recurrent neural networks (RNNs) and other subquadratic architectures as competitive alternatives to transformer-based models in low-resource language modeling scenarios. We utilize HGRN2 (Qin et al., 2024), a recently proposed RNN-based architecture, and comparatively evaluate its effectiveness against transformer-based baselines and other subquadratic architectures (LSTM, xLSTM, Mamba). Our experimental results show that BABYHGRN, our HGRN2 language model, outperforms transformer-based models in both the 10M and 100M word tracks of the challenge, as measured by their performance on the BLiMP, EWoK, GLUE and BEAR benchmarks. Further, we show the positive impact of knowledge distillation. Our findings challenge the prevailing focus on transformer architectures and indicate the viability of RNN-based models, particularly in resource-constrained environments.",
        "tags": [
            "Mamba",
            "RNN",
            "Transformer"
        ]
    },
    {
        "id": "131",
        "title": "iRadar: Synthesizing Millimeter-Waves from Wearable Inertial Inputs for Human Gesture Sensing",
        "author": [
            "Huanqi Yang",
            "Mingda Han",
            "Xinyue Li",
            "Di Duan",
            "Tianxing Li",
            "Weitao Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15980",
        "abstract": "Millimeter-wave (mmWave) radar-based gesture recognition is gaining attention as a key technology to enable intuitive human-machine interaction. Nevertheless, the significant challenge lies in obtaining large-scale, high-quality mmWave gesture datasets. To tackle this problem, we present iRadar, a novel cross-modal gesture recognition framework that employs Inertial Measurement Unit (IMU) data to synthesize the radar signals generated by the corresponding gestures. The key idea is to exploit the IMU signals, which are commonly available in contemporary wearable devices, to synthesize the radar signals that would be produced if the same gesture was performed in front of a mmWave radar. However, several technical obstacles must be overcome due to the differences between mmWave and IMU signals, the noisy gesture sensing of mmWave radar, and the dynamics of human gestures. Firstly, we develop a method for processing IMU and mmWave data to extract critical gesture features. Secondly, we propose a diffusion-based IMU-to-radar translation model that accurately transforms IMU data into mmWave data. Lastly, we devise a novel transformer model to enhance gesture recognition performance. We thoroughly evaluate iRadar, involving 18 gestures and 30 subjects in three scenarios, using five wearable devices. Experimental results demonstrate that iRadar consistently achieves 99.82% Top-3 accuracy across diverse scenarios.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "132",
        "title": "APIRL: Deep Reinforcement Learning for REST API Fuzzing",
        "author": [
            "Myles Foley",
            "Sergio Maffeis"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15991",
        "abstract": "REST APIs have become key components of web services. However, they often contain logic flaws resulting in server side errors or security vulnerabilities. HTTP requests are used as test cases to find and mitigate such issues. Existing methods to modify requests, including those using deep learning, suffer from limited performance and precision, relying on undirected search or making limited usage of the contextual information. In this paper we propose APIRL, a fully automated deep reinforcement learning tool for testing REST APIs. A key novelty of our approach is the use of feedback from a transformer module pre-trained on JSON-structured data, akin to that used in API responses. This allows APIRL to learn the subtleties relating to test outcomes, and generalise to unseen API endpoints. We show APIRL can find significantly more bugs than the state-of-the-art in real world REST APIs while minimising the number of required test cases. We also study how reward functions, and other key design choices, affect learnt policies in a thorough ablation study.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "133",
        "title": "Fearful Falcons and Angry Llamas: Emotion Category Annotations of Arguments by Humans and LLMs",
        "author": [
            "Lynn Greschner",
            "Roman Klinger"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15993",
        "abstract": "Arguments evoke emotions, influencing the effect of the argument itself. Not only the emotional intensity but also the category influence the argument's effects, for instance, the willingness to adapt stances. While binary emotionality has been studied in arguments, there is no work on discrete emotion categories (e.g., \"Anger\") in such data. To fill this gap, we crowdsource subjective annotations of emotion categories in a German argument corpus and evaluate automatic LLM-based labeling methods. Specifically, we compare three prompting strategies (zero-shot, one-shot, chain-of-thought) on three large instruction-tuned language models (Falcon-7b-instruct, Llama-3.1-8B-instruct, GPT-4o-mini). We further vary the definition of the output space to be binary (is there emotionality in the argument?), closed-domain (which emotion from a given label set is in the argument?), or open-domain (which emotion is in the argument?). We find that emotion categories enhance the prediction of emotionality in arguments, emphasizing the need for discrete emotion annotations in arguments. Across all prompt settings and models, automatic predictions show a high recall but low precision for predicting anger and fear, indicating a strong bias toward negative emotions.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA"
        ]
    },
    {
        "id": "134",
        "title": "The Only Way is Ethics: A Guide to Ethical Research with Large Language Models",
        "author": [
            "Eddie L. Ungless",
            "Nikolas Vitsakis",
            "Zeerak Talat",
            "James Garforth",
            "Björn Ross",
            "Arno Onken",
            "Atoosa Kasirzadeh",
            "Alexandra Birch"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16022",
        "abstract": "There is a significant body of work looking at the ethical considerations of large language models (LLMs): critiquing tools to measure performance and harms; proposing toolkits to aid in ideation; discussing the risks to workers; considering legislation around privacy and security etc. As yet there is no work that integrates these resources into a single practical guide that focuses on LLMs; we attempt this ambitious goal. We introduce 'LLM Ethics Whitepaper', which we provide as an open and living resource for NLP practitioners, and those tasked with evaluating the ethical implications of others' work. Our goal is to translate ethics literature into concrete recommendations and provocations for thinking with clear first steps, aimed at computer scientists. 'LLM Ethics Whitepaper' distils a thorough literature review into clear Do's and Don'ts, which we present also in this paper. We likewise identify useful toolkits to support ethical work. We refer the interested reader to the full LLM Ethics Whitepaper, which provides a succinct discussion of ethical considerations at each stage in a project lifecycle, as well as citations for the hundreds of papers from which we drew our recommendations. The present paper can be thought of as a pocket guide to conducting ethical research with LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "135",
        "title": "CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images",
        "author": [
            "Jungho Lee",
            "Suhwan Cho",
            "Taeoh Kim",
            "Ho-Deok Jang",
            "Minhyeok Lee",
            "Geonho Cha",
            "Dongyoon Wee",
            "Dogyoon Lee",
            "Sangyoun Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16028",
        "abstract": "3D Gaussian Splatting (3DGS) has attracted significant attention for its high-quality novel view rendering, inspiring research to address real-world challenges. While conventional methods depend on sharp images for accurate scene reconstruction, real-world scenarios are often affected by defocus blur due to finite depth of field, making it essential to account for realistic 3D scene representation. In this study, we propose CoCoGaussian, a Circle of Confusion-aware Gaussian Splatting that enables precise 3D scene representation using only defocused images. CoCoGaussian addresses the challenge of defocus blur by modeling the Circle of Confusion (CoC) through a physically grounded approach based on the principles of photographic defocus. Exploiting 3D Gaussians, we compute the CoC diameter from depth and learnable aperture information, generating multiple Gaussians to precisely capture the CoC shape. Furthermore, we introduce a learnable scaling factor to enhance robustness and provide more flexibility in handling unreliable depth in scenes with reflective or refractive surfaces. Experiments on both synthetic and real-world datasets demonstrate that CoCoGaussian achieves state-of-the-art performance across multiple benchmarks.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "136",
        "title": "SafeCFG: Redirecting Harmful Classifier-Free Guidance for Safe Generation",
        "author": [
            "Jiadong Pan",
            "Hongcheng Gao",
            "Liang Li",
            "Zheng-Jun Zha",
            "Qingming Huang",
            "Jiebo Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16039",
        "abstract": "Diffusion models (DMs) have demonstrated exceptional performance in text-to-image (T2I) tasks, leading to their widespread use. With the introduction of classifier-free guidance (CFG), the quality of images generated by DMs is improved. However, DMs can generate more harmful images by maliciously guiding the image generation process through CFG. Some safe guidance methods aim to mitigate the risk of generating harmful images but often reduce the quality of clean image generation. To address this issue, we introduce the Harmful Guidance Redirector (HGR), which redirects harmful CFG direction while preserving clean CFG direction during image generation, transforming CFG into SafeCFG and achieving high safety and quality generation. We train HGR to redirect multiple harmful CFG directions simultaneously, demonstrating its ability to eliminate various harmful elements while preserving high-quality generation. Additionally, we find that HGR can detect image harmfulness, allowing for unsupervised fine-tuning of safe diffusion models without pre-defined clean or harmful labels. Experimental results show that by incorporating HGR, images generated by diffusion models achieve both high quality and strong safety, and safe DMs trained through unsupervised methods according to the harmfulness detected by HGR also exhibit good safety performance. The codes will be publicly available.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "137",
        "title": "Label-Efficient Data Augmentation with Video Diffusion Models for Guidewire Segmentation in Cardiac Fluoroscopy",
        "author": [
            "Shaoyan Pan",
            "Yikang Liu",
            "Lin Zhao",
            "Eric Z. Chen",
            "Xiao Chen",
            "Terrence Chen",
            "Shanhui Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16050",
        "abstract": "The accurate segmentation of guidewires in interventional cardiac fluoroscopy videos is crucial for computer-aided navigation tasks. Although deep learning methods have demonstrated high accuracy and robustness in wire segmentation, they require substantial annotated datasets for generalizability, underscoring the need for extensive labeled data to enhance model performance. To address this challenge, we propose the Segmentation-guided Frame-consistency Video Diffusion Model (SF-VD) to generate large collections of labeled fluoroscopy videos, augmenting the training data for wire segmentation networks. SF-VD leverages videos with limited annotations by independently modeling scene distribution and motion distribution. It first samples the scene distribution by generating 2D fluoroscopy images with wires positioned according to a specified input mask, and then samples the motion distribution by progressively generating subsequent frames, ensuring frame-to-frame coherence through a frame-consistency strategy. A segmentation-guided mechanism further refines the process by adjusting wire contrast, ensuring a diverse range of visibility in the synthesized image. Evaluation on a fluoroscopy dataset confirms the superior quality of the generated videos and shows significant improvements in guidewire segmentation.",
        "tags": [
            "Diffusion",
            "Segmentation"
        ]
    },
    {
        "id": "138",
        "title": "Formal Mathematical Reasoning: A New Frontier in AI",
        "author": [
            "Kaiyu Yang",
            "Gabriel Poesia",
            "Jingxuan He",
            "Wenda Li",
            "Kristin Lauter",
            "Swarat Chaudhuri",
            "Dawn Song"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16075",
        "abstract": "AI for Mathematics (AI4Math) is not only intriguing intellectually but also crucial for AI-driven discovery in science, engineering, and beyond. Extensive efforts on AI4Math have mirrored techniques in NLP, in particular, training large language models on carefully curated math datasets in text form. As a complementary yet less explored avenue, formal mathematical reasoning is grounded in formal systems such as proof assistants, which can verify the correctness of reasoning and provide automatic feedback. In this position paper, we advocate for formal mathematical reasoning and argue that it is indispensable for advancing AI4Math to the next level. In recent years, we have seen steady progress in using AI to perform formal reasoning, including core tasks such as theorem proving and autoformalization, as well as emerging applications such as verifiable generation of code and hardware designs. However, significant challenges remain to be solved for AI to truly master mathematics and achieve broader impact. We summarize existing progress, discuss open challenges, and envision critical milestones to measure future success. At this inflection point for formal mathematical reasoning, we call on the research community to come together to drive transformative advancements in this field.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "139",
        "title": "The Evolution of LLM Adoption in Industry Data Curation Practices",
        "author": [
            "Crystal Qian",
            "Michael Xieyang Liu",
            "Emily Reif",
            "Grady Simon",
            "Nada Hussein",
            "Nathan Clement",
            "James Wexler",
            "Carrie J. Cai",
            "Michael Terry",
            "Minsuk Kahng"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16089",
        "abstract": "As large language models (LLMs) grow increasingly adept at processing unstructured text data, they offer new opportunities to enhance data curation workflows. This paper explores the evolution of LLM adoption among practitioners at a large technology company, evaluating the impact of LLMs in data curation tasks through participants' perceptions, integration strategies, and reported usage scenarios. Through a series of surveys, interviews, and user studies, we provide a timely snapshot of how organizations are navigating a pivotal moment in LLM evolution. In Q2 2023, we conducted a survey to assess LLM adoption in industry for development tasks (N=84), and facilitated expert interviews to assess evolving data needs (N=10) in Q3 2023. In Q2 2024, we explored practitioners' current and anticipated LLM usage through a user study involving two LLM-based prototypes (N=12). While each study addressed distinct research goals, they revealed a broader narrative about evolving LLM usage in aggregate. We discovered an emerging shift in data understanding from heuristic-first, bottom-up approaches to insights-first, top-down workflows supported by LLMs. Furthermore, to respond to a more complex data landscape, data practitioners now supplement traditional subject-expert-created 'golden datasets' with LLM-generated 'silver' datasets and rigorously validated 'super golden' datasets curated by diverse experts. This research sheds light on the transformative role of LLMs in large-scale analysis of unstructured data and highlights opportunities for further tool development.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "140",
        "title": "Explainable AI for Multivariate Time Series Pattern Exploration: Latent Space Visual Analytics with Time Fusion Transformer and Variational Autoencoders in Power Grid Event Diagnosis",
        "author": [
            "Haowen Xu",
            "Ali Boyaci",
            "Jianming Lian",
            "Aaron Wilson"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16098",
        "abstract": "Detecting and analyzing complex patterns in multivariate time-series data is crucial for decision-making in urban and environmental system operations. However, challenges arise from the high dimensionality, intricate complexity, and interconnected nature of complex patterns, which hinder the understanding of their underlying physical processes. Existing AI methods often face limitations in interpretability, computational efficiency, and scalability, reducing their applicability in real-world scenarios. This paper proposes a novel visual analytics framework that integrates two generative AI models, Time Fusion Transformer (TFT) and Variational Autoencoders (VAEs), to reduce complex patterns into lower-dimensional latent spaces and visualize them in 2D using dimensionality reduction techniques such as PCA, t-SNE, and UMAP with DBSCAN. These visualizations, presented through coordinated and interactive views and tailored glyphs, enable intuitive exploration of complex multivariate temporal patterns, identifying patterns' similarities and uncover their potential correlations for a better interpretability of the AI outputs. The framework is demonstrated through a case study on power grid signal data, where it identifies multi-label grid event signatures, including faults and anomalies with diverse root causes. Additionally, novel metrics and visualizations are introduced to validate the models and evaluate the performance, efficiency, and consistency of latent maps generated by TFT and VAE under different configurations. These analyses provide actionable insights for model parameter tuning and reliability improvements. Comparative results highlight that TFT achieves shorter run times and superior scalability to diverse time-series data shapes compared to VAE. This work advances fault diagnosis in multivariate time series, fostering explainable AI to support critical system operations.",
        "tags": [
            "Transformer",
            "VAE"
        ]
    },
    {
        "id": "141",
        "title": "Demystifying the Potential of ChatGPT-4 Vision for Construction Progress Monitoring",
        "author": [
            "Ahmet Bahaddin Ersoz"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16108",
        "abstract": "The integration of Large Vision-Language Models (LVLMs) such as OpenAI's GPT-4 Vision into various sectors has marked a significant evolution in the field of artificial intelligence, particularly in the analysis and interpretation of visual data. This paper explores the practical application of GPT-4 Vision in the construction industry, focusing on its capabilities in monitoring and tracking the progress of construction projects. Utilizing high-resolution aerial imagery of construction sites, the study examines how GPT-4 Vision performs detailed scene analysis and tracks developmental changes over time. The findings demonstrate that while GPT-4 Vision is proficient in identifying construction stages, materials, and machinery, it faces challenges with precise object localization and segmentation. Despite these limitations, the potential for future advancements in this technology is considerable. This research not only highlights the current state and opportunities of using LVLMs in construction but also discusses future directions for enhancing the model's utility through domain-specific training and integration with other computer vision techniques and digital twins.",
        "tags": [
            "ChatGPT",
            "GPT",
            "Segmentation"
        ]
    },
    {
        "id": "142",
        "title": "CLEAR: Conv-Like Linearization Revs Pre-Trained Diffusion Transformers Up",
        "author": [
            "Songhua Liu",
            "Zhenxiong Tan",
            "Xinchao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16112",
        "abstract": "Diffusion Transformers (DiT) have become a leading architecture in image generation. However, the quadratic complexity of attention mechanisms, which are responsible for modeling token-wise relationships, results in significant latency when generating high-resolution images. To address this issue, we aim at a linear attention mechanism in this paper that reduces the complexity of pre-trained DiTs to linear. We begin our exploration with a comprehensive summary of existing efficient attention mechanisms and identify four key factors crucial for successful linearization of pre-trained DiTs: locality, formulation consistency, high-rank attention maps, and feature integrity. Based on these insights, we introduce a convolution-like local attention strategy termed CLEAR, which limits feature interactions to a local window around each query token, and thus achieves linear complexity. Our experiments indicate that, by fine-tuning the attention layer on merely 10K self-generated samples for 10K iterations, we can effectively transfer knowledge from a pre-trained DiT to a student model with linear complexity, yielding results comparable to the teacher model. Simultaneously, it reduces attention computations by 99.5% and accelerates generation by 6.3 times for generating 8K-resolution images. Furthermore, we investigate favorable properties in the distilled attention layers, such as zero-shot generalization cross various models and plugins, and improved support for multi-GPU parallel inference. Models and codes are available here: https://github.com/Huage001/CLEAR.",
        "tags": [
            "DiT",
            "Diffusion"
        ]
    },
    {
        "id": "143",
        "title": "The Content Moderator's Dilemma: Removal of Toxic Content and Distortions to Online Discourse",
        "author": [
            "Mahyar Habibi",
            "Dirk Hovy",
            "Carlo Schwarz"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16114",
        "abstract": "There is an ongoing debate about how to moderate toxic speech on social media and how content moderation affects online discourse. We propose and validate a methodology for measuring the content-moderation-induced distortions in online discourse using text embeddings from computational linguistics. We test our measure on a representative dataset of 5 million US political Tweets and find that removing toxic Tweets distorts online content. This finding is consistent across different embedding models, toxicity metrics, and samples. Importantly, we demonstrate that content-moderation-induced distortions are not caused by the toxic language. Instead, we show that, as a side effect, content moderation shifts the mean and variance of the embedding space, distorting the topic composition of online content. Finally, we propose an alternative approach to content moderation that uses generative Large Language Models to rephrase toxic Tweets to preserve their salvageable content rather than removing them entirely. We demonstrate that this rephrasing strategy reduces toxicity while minimizing distortions in online content.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "144",
        "title": "PruneVid: Visual Token Pruning for Efficient Video Large Language Models",
        "author": [
            "Xiaohu Huang",
            "Hao Zhou",
            "Kai Han"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16117",
        "abstract": "In this paper, we introduce PruneVid, a visual token pruning method designed to enhance the efficiency of multi-modal video understanding. Large Language Models (LLMs) have shown promising performance in video tasks due to their extended capabilities in comprehending visual modalities. However, the substantial redundancy in video data presents significant computational challenges for LLMs. To address this issue, we introduce a training-free method that 1) minimizes video redundancy by merging spatial-temporal tokens, and 2) leverages LLMs' reasoning capabilities to selectively prune visual features relevant to question tokens, enhancing model efficiency. We validate our method across multiple video benchmarks, which demonstrate that PruneVid can prune over 80% of tokens while maintaining competitive performance combined with different model networks. This highlights its superior effectiveness and efficiency compared to existing pruning methods. Code: https://github.com/Visual-AI/PruneVid.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "145",
        "title": "Deciphering the Underserved: Benchmarking LLM OCR for Low-Resource Scripts",
        "author": [
            "Muhammad Abdullah Sohail",
            "Salaar Masood",
            "Hamza Iqbal"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16119",
        "abstract": "This study investigates the potential of Large Language Models (LLMs), particularly GPT-4o, for Optical Character Recognition (OCR) in low-resource scripts such as Urdu, Albanian, and Tajik, with English serving as a benchmark. Using a meticulously curated dataset of 2,520 images incorporating controlled variations in text length, font size, background color, and blur, the research simulates diverse real-world challenges. Results emphasize the limitations of zero-shot LLM-based OCR, particularly for linguistically complex scripts, highlighting the need for annotated datasets and fine-tuned models. This work underscores the urgency of addressing accessibility gaps in text digitization, paving the way for inclusive and robust OCR solutions for underserved languages.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "146",
        "title": "PromptOptMe: Error-Aware Prompt Compression for LLM-based MT Evaluation Metrics",
        "author": [
            "Daniil Larionov",
            "Steffen Eger"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16120",
        "abstract": "Evaluating the quality of machine-generated natural language content is a challenging task in Natural Language Processing (NLP). Recently, large language models (LLMs) like GPT-4 have been employed for this purpose, but they are computationally expensive due to the extensive token usage required by complex evaluation prompts. In this paper, we propose a prompt optimization approach that uses a smaller, fine-tuned language model to compress input data for evaluation prompt, thus reducing token usage and computational cost when using larger LLMs for downstream evaluation. Our method involves a two-stage fine-tuning process: supervised fine-tuning followed by preference optimization to refine the model's outputs based on human preferences. We focus on Machine Translation (MT) evaluation and utilize the GEMBA-MQM metric as a starting point. Our results show a $2.37\\times$ reduction in token usage without any loss in evaluation quality. This work makes state-of-the-art LLM-based metrics like GEMBA-MQM more cost-effective and efficient, enhancing their accessibility for broader use.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "147",
        "title": "Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models into Assembly Code Obfuscation",
        "author": [
            "Seyedreza Mohseni",
            "Seyedali Mohammadi",
            "Deepa Tilwani",
            "Yash Saxena",
            "Gerald Ndwula",
            "Sriram Vema",
            "Edward Raff",
            "Manas Gaur"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16135",
        "abstract": "Malware authors often employ code obfuscations to make their malware harder to detect. Existing tools for generating obfuscated code often require access to the original source code (e.g., C++ or Java), and adding new obfuscations is a non-trivial, labor-intensive process. In this study, we ask the following question: Can Large Language Models (LLMs) potentially generate a new obfuscated assembly code? If so, this poses a risk to anti-virus engines and potentially increases the flexibility of attackers to create new obfuscation patterns. We answer this in the affirmative by developing the MetamorphASM benchmark comprising MetamorphASM Dataset (MAD) along with three code obfuscation techniques: dead code, register substitution, and control flow change. The MetamorphASM systematically evaluates the ability of LLMs to generate and analyze obfuscated code using MAD, which contains 328,200 obfuscated assembly code samples. We release this dataset and analyze the success rate of various LLMs (e.g., GPT-3.5/4, GPT-4o-mini, Starcoder, CodeGemma, CodeLlama, CodeT5, and LLaMA 3.1) in generating obfuscated assembly code. The evaluation was performed using established information-theoretic metrics and manual human review to ensure correctness and provide the foundation for researchers to study and develop remediations to this risk. The source code can be found at the following GitHub link: https://github.com/mohammadi-ali/MetamorphASM.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "148",
        "title": "Offline Reinforcement Learning for LLM Multi-Step Reasoning",
        "author": [
            "Huaijie Wang",
            "Shibo Hao",
            "Hanze Dong",
            "Shenao Zhang",
            "Yilin Bao",
            "Ziran Yang",
            "Yi Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16145",
        "abstract": "Improving the multi-step reasoning ability of large language models (LLMs) with offline reinforcement learning (RL) is essential for quickly adapting them to complex tasks. While Direct Preference Optimization (DPO) has shown promise in aligning LLMs with human preferences, it is less suitable for multi-step reasoning tasks because (1) DPO relies on paired preference data, which is not readily available for multi-step reasoning tasks, and (2) it treats all tokens uniformly, making it ineffective for credit assignment in multi-step reasoning tasks, which often come with sparse reward. In this work, we propose OREO (Offline Reasoning Optimization), an offline RL method for enhancing LLM multi-step reasoning. Building on insights from previous works of maximum entropy reinforcement learning, it jointly learns a policy model and value function by optimizing the soft Bellman Equation. We show in principle that it reduces the need to collect pairwise data and enables better credit assignment. Empirically, OREO surpasses existing offline learning methods on multi-step reasoning benchmarks, including mathematical reasoning tasks (GSM8K, MATH) and embodied agent control (ALFWorld). The approach can be extended to a multi-iteration framework when additional resources are available. Furthermore, the learned value function can be leveraged to guide the tree search for free, which can further boost performance during test time.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "149",
        "title": "Mamba2D: A Natively Multi-Dimensional State-Space Model for Vision Tasks",
        "author": [
            "Enis Baty",
            "Alejandro Hernández Díaz",
            "Chris Bridges",
            "Rebecca Davidson",
            "Steve Eckersley",
            "Simon Hadfield"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16146",
        "abstract": "State-Space Models (SSMs) have recently emerged as a powerful and efficient alternative to the long-standing transformer architecture. However, existing SSM conceptualizations retain deeply rooted biases from their roots in natural language processing. This constrains their ability to appropriately model the spatially-dependent characteristics of visual inputs. In this paper, we address these limitations by re-deriving modern selective state-space techniques, starting from a natively multidimensional formulation. Currently, prior works attempt to apply natively 1D SSMs to 2D data (i.e. images) by relying on arbitrary combinations of 1D scan directions to capture spatial dependencies. In contrast, Mamba2D improves upon this with a single 2D scan direction that factors in both dimensions of the input natively, effectively modelling spatial dependencies when constructing hidden states. Mamba2D shows comparable performance to prior adaptations of SSMs for vision tasks, on standard image classification evaluations with the ImageNet-1K dataset.",
        "tags": [
            "SSMs",
            "State Space Models",
            "Transformer"
        ]
    },
    {
        "id": "150",
        "title": "Personalized Representation from Personalized Generation",
        "author": [
            "Shobhita Sundaram",
            "Julia Chae",
            "Yonglong Tian",
            "Sara Beery",
            "Phillip Isola"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16156",
        "abstract": "Modern vision models excel at general purpose downstream tasks. It is unclear, however, how they may be used for personalized vision tasks, which are both fine-grained and data-scarce. Recent works have successfully applied synthetic data to general-purpose representation learning, while advances in T2I diffusion models have enabled the generation of personalized images from just a few real examples. Here, we explore a potential connection between these ideas, and formalize the challenge of using personalized synthetic data to learn personalized representations, which encode knowledge about an object of interest and may be flexibly applied to any downstream task relating to the target object. We introduce an evaluation suite for this challenge, including reformulations of two existing datasets and a novel dataset explicitly constructed for this purpose, and propose a contrastive learning approach that makes creative use of image generators. We show that our method improves personalized representation learning for diverse downstream tasks, from recognition to segmentation, and analyze characteristics of image generation approaches that are key to this gain.",
        "tags": [
            "Diffusion",
            "Segmentation"
        ]
    },
    {
        "id": "151",
        "title": "HoVLE: Unleashing the Power of Monolithic Vision-Language Models with Holistic Vision-Language Embedding",
        "author": [
            "Chenxin Tao",
            "Shiqian Su",
            "Xizhou Zhu",
            "Chenyu Zhang",
            "Zhe Chen",
            "Jiawen Liu",
            "Wenhai Wang",
            "Lewei Lu",
            "Gao Huang",
            "Yu Qiao",
            "Jifeng Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2412.16158",
        "abstract": "The rapid advance of Large Language Models (LLMs) has catalyzed the development of Vision-Language Models (VLMs). Monolithic VLMs, which avoid modality-specific encoders, offer a promising alternative to the compositional ones but face the challenge of inferior performance. Most existing monolithic VLMs require tuning pre-trained LLMs to acquire vision abilities, which may degrade their language capabilities. To address this dilemma, this paper presents a novel high-performance monolithic VLM named HoVLE. We note that LLMs have been shown capable of interpreting images, when image embeddings are aligned with text embeddings. The challenge for current monolithic VLMs actually lies in the lack of a holistic embedding module for both vision and language inputs. Therefore, HoVLE introduces a holistic embedding module that converts visual and textual inputs into a shared space, allowing LLMs to process images in the same way as texts. Furthermore, a multi-stage training strategy is carefully designed to empower the holistic embedding module. It is first trained to distill visual features from a pre-trained vision encoder and text embeddings from the LLM, enabling large-scale training with unpaired random images and text tokens. The whole model further undergoes next-token prediction on multi-modal data to align the embeddings. Finally, an instruction-tuning stage is incorporated. Our experiments show that HoVLE achieves performance close to leading compositional models on various benchmarks, outperforming previous monolithic models by a large margin. Model available at https://huggingface.co/OpenGVLab/HoVLE.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "152",
        "title": "Leveraging Generative Adversarial Networks for Addressing Data Imbalance in Financial Market Supervision",
        "author": [
            "Mohan Jiang",
            "Yaxin Liang",
            "Siyuan Han",
            "Kunyuan Ma",
            "Yuan Chen",
            "Zhen Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15222",
        "abstract": "This study explores the application of generative adversarial networks in financial market supervision, especially for solving the problem of data imbalance to improve the accuracy of risk prediction. Since financial market data are often imbalanced, especially high-risk events such as market manipulation and systemic risk occur less frequently, traditional models have difficulty effectively identifying these minority events. This study proposes to generate synthetic data with similar characteristics to these minority events through GAN to balance the dataset, thereby improving the prediction performance of the model in financial supervision. Experimental results show that compared with traditional oversampling and undersampling methods, the data generated by GAN has significant advantages in dealing with imbalance problems and improving the prediction accuracy of the model. This method has broad application potential in financial regulatory agencies such as the U.S. Securities and Exchange Commission (SEC), the Financial Industry Regulatory Authority (FINRA), the Federal Deposit Insurance Corporation (FDIC), and the Federal Reserve.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "153",
        "title": "Multi-Branch Mutual-Distillation Transformer for EEG-Based Seizure Subtype Classification",
        "author": [
            "Ruimin Peng",
            "Zhenbang Du",
            "Changming Zhao",
            "Jingwei Luo",
            "Wenzhong Liu",
            "Xinxing Chen",
            "Dongrui Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15224",
        "abstract": "Cross-subject electroencephalogram (EEG) based seizure subtype classification is very important in precise epilepsy diagnostics. Deep learning is a promising solution, due to its ability to automatically extract latent patterns. However, it usually requires a large amount of training data, which may not always be available in clinical practice. This paper proposes Multi-Branch Mutual-Distillation (MBMD) Transformer for cross-subject EEG-based seizure subtype classification, which can be effectively trained from small labeled data. MBMD Transformer replaces all even-numbered encoder blocks of the vanilla Vision Transformer by our designed multi-branch encoder blocks. A mutual-distillation strategy is proposed to transfer knowledge between the raw EEG data and its wavelets of different frequency bands. Experiments on two public EEG datasets demonstrated that our proposed MBMD Transformer outperformed several traditional machine learning and state-of-the-art deep learning approaches. To our knowledge, this is the first work on knowledge distillation for EEG-based seizure subtype classification.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "154",
        "title": "Enhancing Masked Time-Series Modeling via Dropping Patches",
        "author": [
            "Tianyu Qiu",
            "Yi Xie",
            "Yun Xiong",
            "Hao Niu",
            "Xiaofeng Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15315",
        "abstract": "This paper explores how to enhance existing masked time-series modeling by randomly dropping sub-sequence level patches of time series. On this basis, a simple yet effective method named DropPatch is proposed, which has two remarkable advantages: 1) It improves the pre-training efficiency by a square-level advantage; 2) It provides additional advantages for modeling in scenarios such as in-domain, cross-domain, few-shot learning and cold start. This paper conducts comprehensive experiments to verify the effectiveness of the method and analyze its internal mechanism. Empirically, DropPatch strengthens the attention mechanism, reduces information redundancy and serves as an efficient means of data augmentation. Theoretically, it is proved that DropPatch slows down the rate at which the Transformer representations collapse into the rank-1 linear subspace by randomly dropping patches, thus optimizing the quality of the learned representations",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "155",
        "title": "Modeling Autonomous Shifts Between Focus State and Mind-Wandering Using a Predictive-Coding-Inspired Variational RNN Model",
        "author": [
            "Henrique Oyama",
            "Jun Tani"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15620",
        "abstract": "The current study investigates possible neural mechanisms underling autonomous shifts between focus state and mind-wandering by conducting model simulation experiments. On this purpose, we modeled perception processes of continuous sensory sequences using our previous proposed variational RNN model which was developed based on the free energy principle. The current study extended this model by introducing an adaptation mechanism of a meta-level parameter, referred to as the meta-prior $\\mathbf{w}$, which regulates the complexity term in the free energy. Our simulation experiments demonstrated that autonomous shifts between focused perception and mind-wandering take place when $\\mathbf{w}$ switches between low and high values associated with decrease and increase of the average reconstruction error over the past window. In particular, high $\\mathbf{w}$ prioritized top-down predictions while low $\\mathbf{w}$ emphasized bottom-up sensations. This paper explores how our experiment results align with existing studies and highlights their potential for future research.",
        "tags": [
            "RNN"
        ]
    },
    {
        "id": "156",
        "title": "Mamba-based Deep Learning Approaches for Sleep Staging on a Wireless Multimodal Wearable System without Electroencephalography",
        "author": [
            "Andrew H. Zhang",
            "Alex He-Mo",
            "Richard Fei Yin",
            "Chunlin Li",
            "Yuzhi Tang",
            "Dharmendra Gurve",
            "Nasim Montazeri Ghahjaverestan",
            "Maged Goubran",
            "Bo Wang",
            "Andrew S. P. Lim"
        ],
        "pdf": "https://arxiv.org/pdf/2412.15947",
        "abstract": "Study Objectives: We investigate using Mamba-based deep learning approaches for sleep staging on signals from ANNE One (Sibel Health, Evanston, IL), a minimally intrusive dual-sensor wireless wearable system measuring chest electrocardiography (ECG), triaxial accelerometry, and temperature, as well as finger photoplethysmography (PPG) and temperature.\nMethods: We obtained wearable sensor recordings from 360 adults undergoing concurrent clinical polysomnography (PSG) at a tertiary care sleep lab. PSG recordings were scored according to AASM criteria. PSG and wearable sensor data were automatically aligned using their ECG channels with manual confirmation by visual inspection. We trained Mamba-based models with both convolutional-recurrent neural network (CRNN) and the recurrent neural network (RNN) architectures on these recordings. Ensembling of model variants with similar architectures was performed.\nResults: Our best approach, after ensembling, attains a 3-class (wake, NREM, REM) balanced accuracy of 83.50%, F1 score of 84.16%, Cohen's $\\kappa$ of 72.68%, and a MCC score of 72.84%; a 4-class (wake, N1/N2, N3, REM) balanced accuracy of 74.64%, F1 score of 74.56%, Cohen's $\\kappa$ of 61.63%, and MCC score of 62.04%; a 5-class (wake, N1, N2, N3, REM) balanced accuracy of 64.30%, F1 score of 66.97%, Cohen's $\\kappa$ of 53.23%, MCC score of 54.38%.\nConclusions: Deep learning models can infer major sleep stages from a wearable system without electroencephalography (EEG) and can be successfully applied to data from adults attending a tertiary care sleep clinic.",
        "tags": [
            "Mamba",
            "RNN"
        ]
    }
]