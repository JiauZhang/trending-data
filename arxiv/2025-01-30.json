[
    {
        "id": "1",
        "title": "Document-Level Sentiment Analysis of Urdu Text Using Deep Learning Techniques",
        "author": [
            "Ammarah Irum",
            "M. Ali Tahir"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17175",
        "abstract": "Document level Urdu Sentiment Analysis (SA) is a challenging Natural Language Processing (NLP) task as it deals with large documents in a resource-poor language. In large documents, there are ample amounts of words that exhibit different viewpoints. Deep learning (DL) models comprise of complex neural network architectures that have the ability to learn diverse features of the data to classify various sentiments. Besides audio, image and video classification; DL algorithms are now extensively used in text-based classification problems. To explore the powerful DL techniques for Urdu SA, we have applied five different DL architectures namely, Bidirectional Long Short Term Memory (BiLSTM), Convolutional Neural Network (CNN), Convolutional Neural Network with Bidirectional Long Short Term Memory (CNN-BiLSTM), Bidirectional Encoder Representation from Transformer (BERT). In this paper, we have proposed a DL hybrid model that integrates BiLSTM with Single Layer Multi Filter Convolutional Neural Network (BiLSTM-SLMFCNN). The proposed and baseline techniques are applied on Urdu Customer Support data set and IMDB Urdu movie review data set by using pretrained Urdu word embeddings that are suitable for (SA) at the document level. Results of these techniques are evaluated and our proposed model outperforms all other DL techniques for Urdu SA. BiLSTM-SLMFCNN outperformed the baseline DL models and achieved 83{\\%}, 79{\\%}, 83{\\%} and 94{\\%} accuracy on small, medium and large sized IMDB Urdu movie review data set and Urdu Customer Support data set respectively.",
        "tags": [
            "BERT",
            "Transformer"
        ]
    },
    {
        "id": "2",
        "title": "Prompt-Based Cost-Effective Evaluation and Operation of ChatGPT as a Computer Programming Teaching Assistant",
        "author": [
            "Marc Ballestero-RibÃ³",
            "Daniel Ortiz-MartÃ­nez"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17176",
        "abstract": "The dream of achieving a student-teacher ratio of 1:1 is closer than ever thanks to the emergence of large language models (LLMs). One potential application of these models in the educational field would be to provide feedback to students in university introductory programming courses, so that a student struggling to solve a basic implementation problem could seek help from an LLM available 24/7. This article focuses on studying three aspects related to such an application. First, the performance of two well-known models, GPT-3.5T and GPT-4T, in providing feedback to students is evaluated. The empirical results showed that GPT-4T performs much better than GPT-3.5T, however, it is not yet ready for use in a real-world scenario. This is due to the possibility of generating incorrect information that potential users may not always be able to detect. Second, the article proposes a carefully designed prompt using in-context learning techniques that allows automating important parts of the evaluation process, as well as providing a lower bound for the fraction of feedbacks containing incorrect information, saving time and effort. This was possible because the resulting feedback has a programmatically analyzable structure that incorporates diagnostic information about the LLM's performance in solving the requested task. Third, the article also suggests a possible strategy for implementing a practical learning tool based on LLMs, which is rooted on the proposed prompting techniques. This strategy opens up a whole range of interesting possibilities from a pedagogical perspective.",
        "tags": [
            "ChatGPT",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "3",
        "title": "Tuning LLM Judges Hyperparameters",
        "author": [
            "David Salinas",
            "Omar Swelam",
            "Frank Hutter"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17178",
        "abstract": "Evaluating Large Language Models (LLMs) often requires costly human annotations. To address this, LLM-based judges have been proposed, which compare the outputs of two LLMs enabling the ranking of models without human intervention. While several approaches have been proposed, many confounding factors are present between different papers. For instance the model, the prompt and other hyperparameters are typically changed at the same time making apple-to-apple comparisons challenging. In this paper, we propose to systematically analyze and tune hyperparameter of LLM judges. To alleviate the high cost of evaluating a judge, we propose to leverage multi-objective multi-fidelity which allows to find judges that trades accuracy for cost and also reduce significantly the cost of the search. Our method identifies judges that not only outperform existing benchmarks in accuracy and cost-efficiency but also utilize open-weight models, ensuring greater accessibility and reproducibility.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "4",
        "title": "An AI-Driven Live Systematic Reviews in the Brain-Heart Interconnectome: Minimizing Research Waste and Advancing Evidence Synthesis",
        "author": [
            "Arya Rahgozar",
            "Pouria Mortezaagha",
            "Jodi Edwards",
            "Douglas Manuel",
            "Jessie McGowen",
            "Merrick Zwarenstein",
            "Dean Fergusson",
            "Andrea Tricco",
            "Kelly Cobey",
            "Margaret Sampson",
            "Malcolm King",
            "Dawn Richards",
            "Alexandra Bodnaruc",
            "David Moher"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17181",
        "abstract": "The Brain-Heart Interconnectome (BHI) combines neurology and cardiology but is hindered by inefficiencies in evidence synthesis, poor adherence to quality standards, and research waste. To address these challenges, we developed an AI-driven system to enhance systematic reviews in the BHI domain. The system integrates automated detection of Population, Intervention, Comparator, Outcome, and Study design (PICOS), semantic search using vector embeddings, graph-based querying, and topic modeling to identify redundancies and underexplored areas. Core components include a Bi-LSTM model achieving 87% accuracy for PICOS compliance, a study design classifier with 95.7% accuracy, and Retrieval-Augmented Generation (RAG) with GPT-3.5, which outperformed GPT-4 for graph-based and topic-driven queries. The system provides real-time updates, reducing research waste through a living database and offering an interactive interface with dashboards and conversational AI. While initially developed for BHI, the system's adaptable architecture enables its application across various biomedical fields, supporting rigorous evidence synthesis, efficient resource allocation, and informed clinical decision-making.",
        "tags": [
            "Detection",
            "GPT",
            "RAG"
        ]
    },
    {
        "id": "5",
        "title": "LLM Evaluation Based on Aerospace Manufacturing Expertise: Automated Generation and Multi-Model Question Answering",
        "author": [
            "Beiming Liu",
            "Zhizhuo Cui",
            "Siteng Hu",
            "Xiaohua Li",
            "Haifeng Lin",
            "Zhengxin Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17183",
        "abstract": "Aerospace manufacturing demands exceptionally high precision in technical parameters. The remarkable performance of Large Language Models (LLMs), such as GPT-4 and QWen, in Natural Language Processing has sparked industry interest in their application to tasks including process design, material selection, and tool information retrieval. However, LLMs are prone to generating \"hallucinations\" in specialized domains, producing inaccurate or false information that poses significant risks to the quality of aerospace products and flight safety. This paper introduces a set of evaluation metrics tailored for LLMs in aerospace manufacturing, aiming to assess their accuracy by analyzing their performance in answering questions grounded in professional knowledge. Firstly, key information is extracted through in-depth textual analysis of classic aerospace manufacturing textbooks and guidelines. Subsequently, utilizing LLM generation techniques, we meticulously construct multiple-choice questions with multiple correct answers of varying difficulty. Following this, different LLM models are employed to answer these questions, and their accuracy is recorded. Experimental results demonstrate that the capabilities of LLMs in aerospace professional knowledge are in urgent need of improvement. This study provides a theoretical foundation and practical guidance for the application of LLMs in aerospace manufacturing, addressing a critical gap in the field.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "6",
        "title": "Visualizing Uncertainty in Translation Tasks: An Evaluation of LLM Performance and Confidence Metrics",
        "author": [
            "Jin Hyun Park",
            "Utsawb Laminchhane",
            "Umer Farooq",
            "Uma Sivakumar",
            "Arpan Kumar"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17187",
        "abstract": "Large language models (LLMs) are increasingly utilized for machine translation, yet their predictions often exhibit uncertainties that hinder interpretability and user trust. Effectively visualizing these uncertainties can enhance the usability of LLM outputs, particularly in contexts where translation accuracy is critical. This paper addresses two primary objectives: (1) providing users with token-level insights into model confidence and (2) developing a web-based visualization tool to quantify and represent translation uncertainties. To achieve these goals, we utilized the T5 model with the WMT19 dataset for translation tasks and evaluated translation quality using established metrics such as BLEU, METEOR, and ROUGE. We introduced three novel uncertainty quantification (UQ) metrics: (1) the geometric mean of token probabilities, (2) the arithmetic mean of token probabilities, and (3) the arithmetic mean of the kurtosis of token distributions. These metrics provide a simple yet effective framework for evaluating translation performance. Our analysis revealed a linear relationship between the traditional evaluation metrics and our UQ metrics, demonstrating the validity of our approach. Additionally, we developed an interactive web-based visualization that uses a color gradient to represent token confidence. This tool offers users a clear and intuitive understanding of translation quality while providing valuable insights into model performance. Overall, we show that our UQ metrics and visualization are both robust and interpretable, offering practical tools for evaluating and accessing machine translation systems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "7",
        "title": "Improving LLM Leaderboards with Psychometrical Methodology",
        "author": [
            "Denis Federiakin"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17200",
        "abstract": "The rapid development of large language models (LLMs) has necessitated the creation of benchmarks to evaluate their performance. These benchmarks resemble human tests and surveys, as they consist of sets of questions designed to measure emergent properties in the cognitive behavior of these systems. However, unlike the well-defined traits and abilities studied in social sciences, the properties measured by these benchmarks are often vaguer and less rigorously defined. The most prominent benchmarks are often grouped into leaderboards for convenience, aggregating performance metrics and enabling comparisons between models. Unfortunately, these leaderboards typically rely on simplistic aggregation methods, such as taking the average score across benchmarks. In this paper, we demonstrate the advantages of applying contemporary psychometric methodologies - originally developed for human tests and surveys - to improve the ranking of large language models on leaderboards. Using data from the Hugging Face Leaderboard as an example, we compare the results of the conventional naive ranking approach with a psychometrically informed ranking. The findings highlight the benefits of adopting psychometric techniques for more robust and meaningful evaluation of LLM performance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "8",
        "title": "Audio Large Language Models Can Be Descriptive Speech Quality Evaluators",
        "author": [
            "Chen Chen",
            "Yuchen Hu",
            "Siyin Wang",
            "Helin Wang",
            "Zhehuai Chen",
            "Chao Zhang",
            "Chao-Han Huck Yang",
            "Eng Siong Chng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17202",
        "abstract": "An ideal multimodal agent should be aware of the quality of its input modalities. Recent advances have enabled large language models (LLMs) to incorporate auditory systems for handling various speech-related tasks. However, most audio LLMs remain unaware of the quality of the speech they process. This limitation arises because speech quality evaluation is typically excluded from multi-task training due to the lack of suitable datasets. To address this, we introduce the first natural language-based speech evaluation corpus, generated from authentic human ratings. In addition to the overall Mean Opinion Score (MOS), this corpus offers detailed analysis across multiple dimensions and identifies causes of quality degradation. It also enables descriptive comparisons between two speech samples (A/B tests) with human-like judgment. Leveraging this corpus, we propose an alignment approach with LLM distillation (ALLD) to guide the audio LLM in extracting relevant information from raw speech and generating meaningful responses. Experimental results demonstrate that ALLD outperforms the previous state-of-the-art regression model in MOS prediction, with a mean square error of 0.17 and an A/B test accuracy of 98.6%. Additionally, the generated responses achieve BLEU scores of 25.8 and 30.2 on two tasks, surpassing the capabilities of task-specific models. This work advances the comprehensive perception of speech signals by audio LLMs, contributing to the development of real-world auditory and sensory intelligent agents.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "9",
        "title": "Integrating Reinforcement Learning and AI Agents for Adaptive Robotic Interaction and Assistance in Dementia Care",
        "author": [
            "Fengpei Yuan",
            "Nehal Hasnaeen",
            "Ran Zhang",
            "Bryce Bible",
            "Joseph Riley Taylor",
            "Hairong Qi",
            "Fenghui Yao",
            "Xiaopeng Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17206",
        "abstract": "This study explores a novel approach to advancing dementia care by integrating socially assistive robotics, reinforcement learning (RL), large language models (LLMs), and clinical domain expertise within a simulated environment. This integration addresses the critical challenge of limited experimental data in socially assistive robotics for dementia care, providing a dynamic simulation environment that realistically models interactions between persons living with dementia (PLWDs) and robotic caregivers. The proposed framework introduces a probabilistic model to represent the cognitive and emotional states of PLWDs, combined with an LLM-based behavior simulation to emulate their responses. We further develop and train an adaptive RL system enabling humanoid robots, such as Pepper, to deliver context-aware and personalized interactions and assistance based on PLWDs' cognitive and emotional states. The framework also generalizes to computer-based agents, highlighting its versatility. Results demonstrate that the RL system, enhanced by LLMs, effectively interprets and responds to the complex needs of PLWDs, providing tailored caregiving strategies. This research contributes to human-computer and human-robot interaction by offering a customizable AI-driven caregiving platform, advancing understanding of dementia-related challenges, and fostering collaborative innovation in assistive technologies. The proposed approach has the potential to enhance the independence and quality of life for PLWDs while alleviating caregiver burden, underscoring the transformative role of interaction-focused AI systems in dementia care.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL",
            "Robot",
            "Robotics"
        ]
    },
    {
        "id": "10",
        "title": "NUS-Emo at SemEval-2024 Task 3: Instruction-Tuning LLM for Multimodal Emotion-Cause Analysis in Conversations",
        "author": [
            "Meng Luo",
            "Han Zhang",
            "Shengqiong Wu",
            "Bobo Li",
            "Hong Han",
            "Hao Fei"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17261",
        "abstract": "This paper describes the architecture of our system developed for Task 3 of SemEval-2024: Multimodal Emotion-Cause Analysis in Conversations. Our project targets the challenges of subtask 2, dedicated to Multimodal Emotion-Cause Pair Extraction with Emotion Category (MECPE-Cat), and constructs a dual-component system tailored to the unique challenges of this task. We divide the task into two subtasks: emotion recognition in conversation (ERC) and emotion-cause pair extraction (ECPE). To address these subtasks, we capitalize on the abilities of Large Language Models (LLMs), which have consistently demonstrated state-of-the-art performance across various natural language processing tasks and domains. Most importantly, we design an approach of emotion-cause-aware instruction-tuning for LLMs, to enhance the perception of the emotions with their corresponding causal rationales. Our method enables us to adeptly navigate the complexities of MECPE-Cat, achieving a weighted average 34.71% F1 score of the task, and securing the 2nd rank on the leaderboard. The code and metadata to reproduce our experiments are all made publicly available.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "11",
        "title": "Tailored Truths: Optimizing LLM Persuasion with Personalization and Fabricated Statistics",
        "author": [
            "Jasper Timm",
            "Chetan Talele",
            "Jacob Haimes"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17273",
        "abstract": "Large Language Models (LLMs) are becoming increasingly persuasive, demonstrating the ability to personalize arguments in conversation with humans by leveraging their personal data. This may have serious impacts on the scale and effectiveness of disinformation campaigns. We studied the persuasiveness of LLMs in a debate setting by having humans $(n=33)$ engage with LLM-generated arguments intended to change the human's opinion. We quantified the LLM's effect by measuring human agreement with the debate's hypothesis pre- and post-debate and analyzing both the magnitude of opinion change, as well as the likelihood of an update in the LLM's direction. We compare persuasiveness across established persuasion strategies, including personalized arguments informed by user demographics and personality, appeal to fabricated statistics, and a mixed strategy utilizing both personalized arguments and fabricated statistics. We found that static arguments generated by humans and GPT-4o-mini have comparable persuasive power. However, the LLM outperformed static human-written arguments when leveraging the mixed strategy in an interactive debate setting. This approach had a $\\mathbf{51\\%}$ chance of persuading participants to modify their initial position, compared to $\\mathbf{32\\%}$ for the static human-written arguments. Our results highlight the concerning potential for LLMs to enable inexpensive and persuasive large-scale disinformation campaigns.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "12",
        "title": "From Natural Language to Extensive-Form Game Representations",
        "author": [
            "Shilong Deng",
            "Yongzhao Wang",
            "Rahul Savani"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17282",
        "abstract": "We introduce a framework for translating game descriptions in natural language into extensive-form representations in game theory, leveraging Large Language Models (LLMs) and in-context learning. Given the varying levels of strategic complexity in games, such as perfect versus imperfect information, directly applying in-context learning would be insufficient. To address this, we introduce a two-stage framework with specialized modules to enhance in-context learning, enabling it to divide and conquer the problem effectively. In the first stage, we tackle the challenge of imperfect information by developing a module that identifies information sets along and the corresponding partial tree structure. With this information, the second stage leverages in-context learning alongside a self-debugging module to produce a complete extensive-form game tree represented using pygambit, the Python API of a recognized game-theoretic analysis tool called Gambit. Using this python representation enables the automation of tasks such as computing Nash equilibria directly from natural language descriptions. We evaluate the performance of the full framework, as well as its individual components, using various LLMs on games with different levels of strategic complexity. Our experimental results show that the framework significantly outperforms baseline models in generating accurate extensive-form games, with each module playing a critical role in its success.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "13",
        "title": "Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization",
        "author": [
            "Zilu Tang",
            "Rajen Chatterjee",
            "Sarthak Garg"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17295",
        "abstract": "Machine Translation (MT) is undergoing a paradigm shift, with systems based on fine-tuned large language models (LLM) becoming increasingly competitive with traditional encoder-decoder models trained specifically for translation tasks. However, LLM-based systems are at a higher risk of generating hallucinations, which can severely undermine user's trust and safety. Most prior research on hallucination mitigation focuses on traditional MT models, with solutions that involve post-hoc mitigation - detecting hallucinated translations and re-translating them. While effective, this approach introduces additional complexity in deploying extra tools in production and also increases latency. To address these limitations, we propose a method that intrinsically learns to mitigate hallucinations during the model training phase. Specifically, we introduce a data creation framework to generate hallucination focused preference datasets. Fine-tuning LLMs on these preference datasets reduces the hallucination rate by an average of 96% across five language pairs, while preserving overall translation quality. In a zero-shot setting our approach reduces hallucinations by 89% on an average across three unseen target languages.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "14",
        "title": "\"Ownership, Not Just Happy Talk\": Co-Designing a Participatory Large Language Model for Journalism",
        "author": [
            "Emily Tseng",
            "Meg Young",
            "Marianne Aubin Le QuÃ©rÃ©",
            "Aimee Rinehart",
            "Harini Suresh"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17299",
        "abstract": "Journalism has emerged as an essential domain for understanding the uses, limitations, and impacts of large language models (LLMs) in the workplace. News organizations face divergent financial incentives: LLMs already permeate newswork processes within financially constrained organizations, even as ongoing legal challenges assert that AI companies violate their copyright. At stake are key questions about what LLMs are created to do, and by whom: How might a journalist-led LLM work, and what can participatory design illuminate about the present-day challenges about adapting ``one-size-fits-all'' foundation models to a given context of use? In this paper, we undertake a co-design exploration to understand how a participatory approach to LLMs might address opportunities and challenges around AI in journalism. Our 20 interviews with reporters, data journalists, editors, labor organizers, product leads, and executives highlight macro, meso, and micro tensions that designing for this opportunity space must address. From these desiderata, we describe the result of our co-design work: organizational structures and functionality for a journalist-controlled LLM. In closing, we discuss the limitations of commercial foundation models for workplace use, and the methodological implications of applying participatory methods to LLM co-design.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "15",
        "title": "Moment-based adaptive time integration for thermal radiation transport",
        "author": [
            "Ben S. Southworth",
            "Steven Walton",
            "Steven B. Roberts",
            "HyeongKae Park"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17301",
        "abstract": "In this paper we develop a framework for moment-based adaptive time integration of deterministic multifrequency thermal radiation transpot (TRT). We generalize our recent semi-implicit-explicit (IMEX) integration framework for gray TRT to multifrequency TRT, and also introduce a semi-implicit variation that facilitates higher-order integration of TRT, where each stage is implicit in all components except opacities. To appeal to the broad literature on adaptivity with Runge--Kutta methods, we derive new embedded methods for four asymptotic preserving IMEX Runge--Kutta schemes we have found to be robust in our previous work on TRT and radiation hydrodynamics. We then use a moment-based high-order-low-order representation of the transport equations. Due to the high dimensionality, memory is always a concern in simulating TRT. We form error estimates and adaptivity in time purely based on temperature and radiation energy, for a trivial overhead in computational cost and memory usage compared with the base second order integrators. We then test the adaptivity in time on the tophat and Larsen problem, demonstrating the ability of the adaptive algorithm to naturally vary the timestep across 4--5 orders of magnitude, ranging from the dynamical timescales of the streaming regime to the thick diffusion limit.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "16",
        "title": "Probing LLM World Models: Enhancing Guesstimation with Wisdom of Crowds Decoding",
        "author": [
            "Yun-Shiuan Chuang",
            "Nikunj Harlalka",
            "Sameer Narendran",
            "Alexander Cheung",
            "Sizhe Gao",
            "Siddharth Suresh",
            "Junjie Hu",
            "Timothy T. Rogers"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17310",
        "abstract": "Guesstimation, the task of making approximate quantity estimates, is a common real-world challenge. However, it has been largely overlooked in large language models (LLMs) and vision language models (VLMs) research. We introduce a novel guesstimation dataset, MARBLES. This dataset requires one to estimate how many items (e.g., marbles) can fit into containers (e.g., a one-cup measuring cup), both with and without accompanying images. Inspired by the social science concept of the ``{Wisdom of Crowds'' (WOC) - taking the median from estimates from a crowd), which has proven effective in guesstimation, we propose ``WOC decoding'' strategy for LLM guesstimation. We show that LLMs/VLMs perform well on guesstimation, suggesting that they possess some level of a \"world model\" necessary for guesstimation. Moreover, similar to human performance, the WOC decoding method improves LLM/VLM guesstimation accuracy. Furthermore, the inclusion of images in the multimodal condition enhances model performance. These results highlight the value of WOC decoding strategy for LLMs/VLMs and position guesstimation as a probe for evaluating LLMs/VLMs' world model.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "17",
        "title": "Attribution analysis of legal language as used by LLM",
        "author": [
            "Richard K. Belew"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17330",
        "abstract": "Three publicly-available LLM specifically designed for legal tasks have been implemented and shown that classification accuracy can benefit from training over legal corpora, but why and how? Here we use two publicly-available legal datasets, a simpler binary classification task of ``overruling'' texts, and a more elaborate multiple choice task identifying ``holding'' judicial decisions. We report on experiments contrasting the legal LLM and a generic BERT model for comparison, against both datasets. We use integrated gradient attribution techniques to impute ``causes'' of variation in the models' perfomance, and characterize them in terms of the tokenizations each use. We find that while all models can correctly classify some test examples from the casehold task, other examples can only be identified by only one, model, and attribution can be used to highlight the reasons for this. We find that differential behavior of the models' tokenizers accounts for most of the difference and analyze these differences in terms of the legal language they process. Frequency analysis of tokens generated by dataset texts, combined with use of known ``stop word'' lists, allow identification of tokens that are clear signifiers of legal topics.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "18",
        "title": "Context-Aware Semantic Recomposition Mechanism for Large Language Models",
        "author": [
            "Richard Katrix",
            "Quentin Carroway",
            "Rowan Hawkesbury",
            "Matthias Heathfield"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17386",
        "abstract": "Context-aware processing mechanisms have increasingly become a critical area of exploration for improving the semantic and contextual capabilities of language generation models. The Context-Aware Semantic Recomposition Mechanism (CASRM) was introduced as a novel framework designed to address limitations in coherence, contextual adaptability, and error propagation in large-scale text generation tasks. Through the integration of dynamically generated context vectors and attention modulation layers, CASRM enhances the alignment between token-level representations and broader contextual dependencies. Experimental evaluations demonstrated significant improvements in semantic coherence across multiple domains, including technical, conversational, and narrative text. The ability to adapt to unseen domains and ambiguous inputs was evaluated using a diverse set of test scenarios, highlighting the robustness of the proposed mechanism. A detailed computational analysis revealed that while CASRM introduces additional processing overhead, the gains in linguistic precision and contextual relevance outweigh the marginal increase in complexity. The framework also successfully mitigates error propagation in sequential tasks, improving performance in dialogue continuation and multi-step text synthesis. Additional investigations into token-level attention distribution emphasized the dynamic focus shifts enabled through context-aware enhancements. The findings suggest that CASRM offers a scalable and flexible solution for integrating contextual intelligence into existing language model architectures.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "19",
        "title": "Assessing the Capability of YOLO- and Transformer-based Object Detectors for Real-time Weed Detection",
        "author": [
            "Alicia Allmendinger",
            "Ahmet OÄuz SaltÄ±k",
            "Gerassimos G. Peteinatos",
            "Anthony Stein",
            "Roland Gerhards"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17387",
        "abstract": "Spot spraying represents an efficient and sustainable method for reducing the amount of pesticides, particularly herbicides, used in agricultural fields. To achieve this, it is of utmost importance to reliably differentiate between crops and weeds, and even between individual weed species in situ and under real-time conditions. To assess suitability for real-time application, different object detection models that are currently state-of-the-art are compared. All available models of YOLOv8, YOLOv9, YOLOv10, and RT-DETR are trained and evaluated with images from a real field situation. The images are separated into two distinct datasets: In the initial data set, each species of plants is trained individually; in the subsequent dataset, a distinction is made between monocotyledonous weeds, dicotyledonous weeds, and three chosen crops. The results demonstrate that while all models perform equally well in the metrics evaluated, the YOLOv9 models, particularly the YOLOv9s and YOLOv9e, stand out in terms of their strong recall scores (66.58 \\% and 72.36 \\%), as well as mAP50 (73.52 \\% and 79.86 \\%), and mAP50-95 (43.82 \\% and 47.00 \\%) in dataset 2. However, the RT-DETR models, especially RT-DETR-l, excel in precision with reaching 82.44 \\% on dataset 1 and 81.46 \\% in dataset 2, making them particularly suitable for scenarios where minimizing false positives is critical. In particular, the smallest variants of the YOLO models (YOLOv8n, YOLOv9t, and YOLOv10n) achieve substantially faster inference times down to 7.58 ms for dataset 2 on the NVIDIA GeForce RTX 4090 GPU for analyzing one frame, while maintaining competitive accuracy, highlighting their potential for deployment in resource-constrained embedded computing devices as typically used in productive setups.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "20",
        "title": "Leveraging In-Context Learning and Retrieval-Augmented Generation for Automatic Question Generation in Educational Domains",
        "author": [
            "Subhankar Maity",
            "Aniket Deroy",
            "Sudeshna Sarkar"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17397",
        "abstract": "Question generation in education is a time-consuming and cognitively demanding task, as it requires creating questions that are both contextually relevant and pedagogically sound. Current automated question generation methods often generate questions that are out of context. In this work, we explore advanced techniques for automated question generation in educational contexts, focusing on In-Context Learning (ICL), Retrieval-Augmented Generation (RAG), and a novel Hybrid Model that merges both methods. We implement GPT-4 for ICL using few-shot examples and BART with a retrieval module for RAG. The Hybrid Model combines RAG and ICL to address these issues and improve question quality. Evaluation is conducted using automated metrics, followed by human evaluation metrics. Our results show that both the ICL approach and the Hybrid Model consistently outperform other methods, including baseline models, by generating more contextually accurate and relevant questions.",
        "tags": [
            "GPT",
            "RAG"
        ]
    },
    {
        "id": "21",
        "title": "MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs",
        "author": [
            "Ved Sirdeshmukh",
            "Kaustubh Deshpande",
            "Johannes Mols",
            "Lifeng Jin",
            "Ed-Yeremai Cardona",
            "Dean Lee",
            "Jeremy Kritz",
            "Willow Primack",
            "Summer Yue",
            "Chen Xing"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17399",
        "abstract": "We present MultiChallenge, a pioneering benchmark evaluating large language models (LLMs) on conducting multi-turn conversations with human users, a crucial yet underexamined capability for their applications. MultiChallenge identifies four categories of challenges in multi-turn conversations that are not only common and realistic among current human-LLM interactions, but are also challenging to all current frontier LLMs. All 4 challenges require accurate instruction-following, context allocation, and in-context reasoning at the same time. We also develop LLM as judge with instance-level rubrics to facilitate an automatic evaluation method with fair agreement with experienced human raters. Despite achieving near-perfect scores on existing multi-turn evaluation benchmarks, all frontier models have less than 50% accuracy on MultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving just a 41.4% average accuracy.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "22",
        "title": "General Scene Adaptation for Vision-and-Language Navigation",
        "author": [
            "Haodong Hong",
            "Yanyuan Qiao",
            "Sen Wang",
            "Jiajun Liu",
            "Qi Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17403",
        "abstract": "Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on one-time execution of individual instructions across multiple environments, aiming to develop agents capable of functioning in any environment in a zero-shot manner. However, real-world navigation robots often operate in persistent environments with relatively consistent physical layouts, visual observations, and language styles from instructors. Such a gap in the task setting presents an opportunity to improve VLN agents by incorporating continuous adaptation to specific environments. To better reflect these real-world conditions, we introduce GSA-VLN, a novel task requiring agents to execute navigation instructions within a specific scene and simultaneously adapt to it for improved performance over time. To evaluate the proposed task, one has to address two challenges in existing VLN datasets: the lack of OOD data, and the limited number and style diversity of instructions for each scene. Therefore, we propose a new dataset, GSA-R2R, which significantly expands the diversity and quantity of environments and instructions for the R2R dataset to evaluate agent adaptability in both ID and OOD contexts. Furthermore, we design a three-stage instruction orchestration pipeline that leverages LLMs to refine speaker-generated instructions and apply role-playing techniques to rephrase instructions into different speaking styles. This is motivated by the observation that each individual user often has consistent signatures or preferences in their instructions. We conducted extensive experiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various methods. Based on our findings, we propose a novel method, GR-DUET, which incorporates memory-based navigation graphs with an environment-specific training strategy, achieving state-of-the-art results on all GSA-R2R splits.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "23",
        "title": "A Genetic Algorithm-Based Approach for Automated Optimization of Kolmogorov-Arnold Networks in Classification Tasks",
        "author": [
            "Quan Long",
            "Bin Wang",
            "Bing Xue",
            "Mengjie Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17411",
        "abstract": "To address the issue of interpretability in multilayer perceptrons (MLPs), Kolmogorov-Arnold Networks (KANs) are introduced in 2024. However, optimizing KAN structures is labor-intensive, typically requiring manual intervention and parameter tuning. This paper proposes GA-KAN, a genetic algorithm-based approach that automates the optimization of KANs, requiring no human intervention in the design process. To the best of our knowledge, this is the first time that evolutionary computation is explored to optimize KANs automatically. Furthermore, inspired by the use of sparse connectivity in MLPs in effectively reducing the number of parameters, GA-KAN further explores sparse connectivity to tackle the challenge of extensive parameter spaces in KANs. GA-KAN is validated on two toy datasets, achieving optimal results without the manual tuning required by the original KAN. Additionally, GA-KAN demonstrates superior performance across five classification datasets, outperforming traditional methods on all datasets and providing interpretable symbolic formulae for the Wine and Iris datasets, thereby enhancing model transparency. Furthermore, GA-KAN significantly reduces the number of parameters over the standard KAN across all the five datasets. The core contributions of GA-KAN include automated optimization, a new encoding strategy, and a new decoding process, which together improve the accuracy and interpretability, and reduce the number of parameters.",
        "tags": [
            "KAN",
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "24",
        "title": "Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models",
        "author": [
            "Yuxuan Li",
            "Hirokazu Shirado",
            "Sauvik Das"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17420",
        "abstract": "While advances in fairness and alignment have helped mitigate overt biases exhibited by large language models (LLMs) when explicitly prompted, we hypothesize that these models may still exhibit implicit biases when simulating human behavior. To test this hypothesis, we propose a technique to systematically uncover such biases across a broad range of sociodemographic categories by assessing decision-making disparities among agents with LLM-generated, sociodemographically-informed personas. Using our technique, we tested six LLMs across three sociodemographic groups and four decision-making scenarios. Our results show that state-of-the-art LLMs exhibit significant sociodemographic disparities in nearly all simulations, with more advanced models exhibiting greater implicit biases despite reducing explicit biases. Furthermore, when comparing our findings to real-world disparities reported in empirical studies, we find that the biases we uncovered are directionally aligned but markedly amplified. This directional alignment highlights the utility of our technique in uncovering systematic biases in LLMs rather than random variations; moreover, the presence and amplification of implicit biases emphasizes the need for novel strategies to address these biases.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "25",
        "title": "Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation",
        "author": [
            "Tiansheng Huang",
            "Sihao Hu",
            "Fatih Ilhan",
            "Selim Furkan Tekin",
            "Ling Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17433",
        "abstract": "Recent research shows that Large Language Models (LLMs) are vulnerable to harmful fine-tuning attacks -- models lose their safety alignment ability after fine-tuning on a few harmful samples. For risk mitigation, a guardrail is typically used to filter out harmful samples before fine-tuning. By designing a new red-teaming method, we in this paper show that purely relying on the moderation guardrail for data filtration is not reliable. Our proposed attack method, dubbed Virus, easily bypasses the guardrail moderation by slightly modifying the harmful data. Experimental results show that the harmful data optimized by Virus is not detectable by the guardrail with up to 100\\% leakage ratio, and can simultaneously achieve superior attack performance. Finally, the key message we want to convey through this paper is that: \\textbf{it is reckless to consider guardrail moderation as a clutch at straws towards harmful fine-tuning attack}, as it cannot solve the inherent safety issue of the pre-trained LLMs. Our code is available at https://github.com/git-disl/Virus",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "26",
        "title": "Towards Making Flowchart Images Machine Interpretable",
        "author": [
            "Shreya Shukla",
            "Prajwal Gatti",
            "Yogesh Kumar",
            "Vikash Yadav",
            "Anand Mishra"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17441",
        "abstract": "Computer programming textbooks and software documentations often contain flowcharts to illustrate the flow of an algorithm or procedure. Modern OCR engines often tag these flowcharts as graphics and ignore them in further processing. In this paper, we work towards making flowchart images machine-interpretable by converting them to executable Python codes. To this end, inspired by the recent success in natural language to code generation literature, we present a novel transformer-based framework, namely FloCo-T5. Our model is well-suited for this task,as it can effectively learn semantics, structure, and patterns of programming languages, which it leverages to generate syntactically correct code. We also used a task-specific pre-training objective to pre-train FloCo-T5 using a large number of logic-preserving augmented code samples. Further, to perform a rigorous study of this problem, we introduce theFloCo dataset that contains 11,884 flowchart images and their corresponding Python codes. Our experiments show promising results, and FloCo-T5 clearly outperforms related competitive baselines on code generation metrics. We make our dataset and implementation publicly available.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "27",
        "title": "Cross-Language Approach for Quranic QA",
        "author": [
            "Islam Oshallah",
            "Mohamed Basem",
            "Ali Hamdi",
            "Ammar Mohammed"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17449",
        "abstract": "Question answering systems face critical limitations in languages with limited resources and scarce data, making the development of robust models especially challenging. The Quranic QA system holds significant importance as it facilitates a deeper understanding of the Quran, a Holy text for over a billion people worldwide. However, these systems face unique challenges, including the linguistic disparity between questions written in Modern Standard Arabic and answers found in Quranic verses written in Classical Arabic, and the small size of existing datasets, which further restricts model performance. To address these challenges, we adopt a cross-language approach by (1) Dataset Augmentation: expanding and enriching the dataset through machine translation to convert Arabic questions into English, paraphrasing questions to create linguistic diversity, and retrieving answers from an English translation of the Quran to align with multilingual training requirements; and (2) Language Model Fine-Tuning: utilizing pre-trained models such as BERT-Medium, RoBERTa-Base, DeBERTa-v3-Base, ELECTRA-Large, Flan-T5, Bloom, and Falcon to address the specific requirements of Quranic QA. Experimental results demonstrate that this cross-language approach significantly improves model performance, with RoBERTa-Base achieving the highest MAP@10 (0.34) and MRR (0.52), while DeBERTa-v3-Base excels in Recall@10 (0.50) and Precision@10 (0.24). These findings underscore the effectiveness of cross-language strategies in overcoming linguistic barriers and advancing Quranic QA systems",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "28",
        "title": "Large Language Models for Single-Step and Multi-Step Flight Trajectory Prediction",
        "author": [
            "Kaiwei Luo",
            "Jiliu Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17459",
        "abstract": "Flight trajectory prediction is a critical time series task in aviation. While deep learning methods have shown significant promise, the application of large language models (LLMs) to this domain remains underexplored. This study pioneers the use of LLMs for flight trajectory prediction by reframing it as a language modeling problem. Specifically, We extract features representing the aircraft's position and status from ADS-B flight data to construct a prompt-based dataset, where trajectory waypoints are converted into language tokens. The dataset is then employed to fine-tune LLMs, enabling them to learn complex spatiotemporal patterns for accurate predictions. Comprehensive experiments demonstrate that LLMs achieve notable performance improvements in both single-step and multi-step predictions compared to traditional methods, with LLaMA-3.1 model achieving the highest overall accuracy. However, the high inference latency of LLMs poses a challenge for real-time applications, underscoring the need for further research in this promising direction.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "29",
        "title": "AugmenTest: Enhancing Tests with LLM-Driven Oracles",
        "author": [
            "Shaker Mahmud Khandaker",
            "Fitsum Kifetew",
            "Davide Prandi",
            "Angelo Susi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17461",
        "abstract": "Automated test generation is crucial for ensuring the reliability and robustness of software applications while at the same time reducing the effort needed. While significant progress has been made in test generation research, generating valid test oracles still remains an open problem. To address this challenge, we present AugmenTest, an approach leveraging Large Language Models (LLMs) to infer correct test oracles based on available documentation of the software under test. Unlike most existing methods that rely on code, AugmenTest utilizes the semantic capabilities of LLMs to infer the intended behavior of a method from documentation and developer comments, without looking at the code. AugmenTest includes four variants: Simple Prompt, Extended Prompt, RAG with a generic prompt (without the context of class or method under test), and RAG with Simple Prompt, each offering different levels of contextual information to the LLMs. To evaluate our work, we selected 142 Java classes and generated multiple mutants for each. We then generated tests from these mutants, focusing only on tests that passed on the mutant but failed on the original class, to ensure that the tests effectively captured bugs. This resulted in 203 unique tests with distinct bugs, which were then used to evaluate AugmenTest. Results show that in the most conservative scenario, AugmenTest's Extended Prompt consistently outperformed the Simple Prompt, achieving a success rate of 30\\% for generating correct assertions. In comparison, the state-of-the-art TOGA approach achieved 8.2\\%. Contrary to our expectations, the RAG-based approaches did not lead to improvements, with performance of 18.2\\% success rate for the most conservative scenario.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "30",
        "title": "Solving Inverse Problems using Diffusion with Fast Iterative Renoising",
        "author": [
            "Matt C. Bendel",
            "Saurav K. Shastri",
            "Rizwan Ahmad",
            "Philip Schniter"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17468",
        "abstract": "Imaging inverse problems can be solved in an unsupervised manner using pre-trained diffusion models. In most cases, that involves approximating the gradient of the measurement-conditional score function in the reverse process. Since the approximations produced by existing methods are quite poor, especially early in the reverse process, we propose a new approach that re-estimates and renoises the image several times per diffusion step. Renoising adds carefully shaped colored noise that ensures the pre-trained diffusion model sees white-Gaussian error, in accordance with how it was trained. We demonstrate the effectiveness of our \"DDfire\" method at 20, 100, and 1000 neural function evaluations on linear inverse problems and phase retrieval.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "31",
        "title": "DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance",
        "author": [
            "Seffi Cohen",
            "Niv Goldshlager",
            "Nurit Cohen-Inger",
            "Bracha Shapira",
            "Lior Rokach"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17479",
        "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across various natural language processing tasks but often struggle to excel uniformly in diverse or complex domains. We propose a novel ensemble method - Diverse Fingerprint Ensemble (DFPE), which leverages the complementary strengths of multiple LLMs to achieve more robust performance. Our approach involves: (1) clustering models based on response \"fingerprints\" patterns, (2) applying a quantile-based filtering mechanism to remove underperforming models at a per-subject level, and (3) assigning adaptive weights to remaining models based on their subject-wise validation accuracy. In experiments on the Massive Multitask Language Understanding (MMLU) benchmark, DFPE outperforms the best single model by 3% overall accuracy and 5% in discipline-level accuracy. This method increases the robustness and generalization of LLMs and underscores how model selection, diversity preservation, and performance-driven weighting can effectively address challenging, multi-faceted language understanding tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "32",
        "title": "DINT Transformer",
        "author": [
            "Yueyang Cang",
            "Yuhang Liu",
            "Xiaoteng Zhang",
            "Erlu Zhao",
            "Li Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17486",
        "abstract": "DIFF Transformer addresses the issue of irrelevant context interference by introducing a differential attention mechanism that enhances the robustness of local attention. However, it has two critical limitations: the lack of global context modeling, which is essential for identifying globally significant tokens, and numerical instability due to the absence of strict row normalization in the attention matrix. To overcome these challenges, we propose DINT Transformer, which extends DIFF Transformer by incorporating a differential-integral mechanism. By computing global importance scores and integrating them into the attention matrix, DINT Transformer improves its ability to capture global dependencies. Moreover, the unified parameter design enforces row-normalized attention matrices, improving numerical stability. Experimental results demonstrate that DINT Transformer excels in accuracy and robustness across various practical applications, such as long-context language modeling and key information retrieval. These results position DINT Transformer as a highly effective and promising architecture.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "33",
        "title": "Neural Spelling: A Spell-Based BCI System for Language Neural Decoding",
        "author": [
            "Xiaowei Jiang",
            "Charles Zhou",
            "Yiqun Duan",
            "Ziyi Zhao",
            "Thomas Do",
            "Chin-Teng Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17489",
        "abstract": "Brain-computer interfaces (BCIs) present a promising avenue by translating neural activity directly into text, eliminating the need for physical actions. However, existing non-invasive BCI systems have not successfully covered the entire alphabet, limiting their practicality. In this paper, we propose a novel non-invasive EEG-based BCI system with Curriculum-based Neural Spelling Framework, which recognizes all 26 alphabet letters by decoding neural signals associated with handwriting first, and then apply a Generative AI (GenAI) to enhance spell-based neural language decoding tasks. Our approach combines the ease of handwriting with the accessibility of EEG technology, utilizing advanced neural decoding algorithms and pre-trained large language models (LLMs) to translate EEG patterns into text with high accuracy. This system show how GenAI can improve the performance of typical spelling-based neural language decoding task, and addresses the limitations of previous methods, offering a scalable and user-friendly solution for individuals with communication impairments, thereby enhancing inclusive communication options.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "34",
        "title": "Towards Supporting Penetration Testing Education with Large Language Models: an Evaluation and Comparison",
        "author": [
            "Martin Nizon-Deladoeuille",
            "BrynjÃ³lfur StefÃ¡nsson",
            "Helmut Neukirchen",
            "Thomas Welsh"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17539",
        "abstract": "Cybersecurity education is challenging and it is helpful for educators to understand Large Language Models' (LLMs') capabilities for supporting education. This study evaluates the effectiveness of LLMs in conducting a variety of penetration testing tasks. Fifteen representative tasks were selected to cover a comprehensive range of real-world scenarios. We evaluate the performance of 6 models (GPT-4o mini, GPT-4o, Gemini 1.5 Flash, Llama 3.1 405B, Mixtral 8x7B and WhiteRabbitNeo) upon the Metasploitable v3 Ubuntu image and OWASP WebGOAT. Our findings suggest that GPT-4o mini currently offers the most consistent support making it a valuable tool for educational purposes. However, its use in conjonction with WhiteRabbitNeo should be considered, because of its innovative approach to tool and command recommendations. This study underscores the need for continued research into optimising LLMs for complex, domain-specific tasks in cybersecurity education.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "35",
        "title": "Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models",
        "author": [
            "Wooyoung Kim",
            "Byungyoon Park",
            "Wooju Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17549",
        "abstract": "Graph-structured data plays a vital role in numerous domains, such as social networks, citation networks, commonsense reasoning graphs and knowledge graphs. While graph neural networks have been employed for graph processing, recent advancements have explored integrating large language models for graph-based tasks. In this paper, we propose a novel approach named Learnable Graph Pooling Token (LGPT), which addresses the limitations of the scalability issues in node-level projection and information loss in graph-level projection. LGPT enables flexible and efficient graph representation by introducing learnable parameters that act as tokens in large language models, balancing fine-grained and global graph information. Additionally, we investigate an Early Query Fusion technique, which fuses query context before constructing the graph representation, leading to more effective graph embeddings. Our method achieves a 4.13\\% performance improvement on the GraphQA benchmark without training the large language model, demonstrating significant gains in handling complex textual-attributed graph data.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "36",
        "title": "A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks",
        "author": [
            "Elie Antoine",
            "FrÃ©dÃ©ric BÃ©chet",
            "GÃ©raldine Damnati",
            "Philippe Langlais"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17569",
        "abstract": "We introduce an evaluation methodology for reading comprehension tasks based on the intuition that certain examples, by the virtue of their linguistic complexity, consistently yield lower scores regardless of model size or architecture. We capitalize on semantic frame annotation for characterizing this complexity, and study seven complexity factors that may account for model's difficulty. We first deploy this methodology on a carefully annotated French reading comprehension benchmark showing that two of those complexity factors are indeed good predictors of models' failure, while others are less so. We further deploy our methodology on a well studied English benchmark by using Chat-GPT as a proxy for semantic annotation. Our study reveals that fine-grained linguisticallymotivated automatic evaluation of a reading comprehension task is not only possible, but helps understand models' abilities to handle specific linguistic characteristics of input examples. It also shows that current state-of-the-art models fail with some for those characteristics which suggests that adequately handling them requires more than merely increasing model size.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "37",
        "title": "Music2Latent2: Audio Compression with Summary Embeddings and Autoregressive Decoding",
        "author": [
            "Marco Pasini",
            "Stefan Lattner",
            "George Fazekas"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17578",
        "abstract": "Efficiently compressing high-dimensional audio signals into a compact and informative latent space is crucial for various tasks, including generative modeling and music information retrieval (MIR). Existing audio autoencoders, however, often struggle to achieve high compression ratios while preserving audio fidelity and facilitating efficient downstream applications. We introduce Music2Latent2, a novel audio autoencoder that addresses these limitations by leveraging consistency models and a novel approach to representation learning based on unordered latent embeddings, which we call summary embeddings. Unlike conventional methods that encode local audio features into ordered sequences, Music2Latent2 compresses audio signals into sets of summary embeddings, where each embedding can capture distinct global features of the input sample. This enables to achieve higher reconstruction quality at the same compression ratio. To handle arbitrary audio lengths, Music2Latent2 employs an autoregressive consistency model trained on two consecutive audio chunks with causal masking, ensuring coherent reconstruction across segment boundaries. Additionally, we propose a novel two-step decoding procedure that leverages the denoising capabilities of consistency models to further refine the generated audio at no additional cost. Our experiments demonstrate that Music2Latent2 outperforms existing continuous audio autoencoders regarding audio quality and performance on downstream tasks. Music2Latent2 paves the way for new possibilities in audio compression.",
        "tags": [
            "Consistency Models"
        ]
    },
    {
        "id": "38",
        "title": "CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs",
        "author": [
            "Amey Hengle",
            "Aswini Kumar",
            "Anil Bandhakavi",
            "Tanmoy Chakraborty"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17581",
        "abstract": "Counterspeech has been popular as an effective approach to counter online hate speech, leading to increasing research interest in automated counterspeech generation using language models. However, this field lacks standardised evaluation protocols and robust automated evaluation metrics that align with human judgement. Current automatic evaluation methods, primarily based on similarity metrics, do not effectively capture the complex and independent attributes of counterspeech quality, such as contextual relevance, aggressiveness, or argumentative coherence. This has led to an increased dependency on labor-intensive human evaluations to assess automated counter-speech generation methods. To address these challenges, we introduce CSEval, a novel dataset and framework for evaluating counterspeech quality across four dimensions: contextual-relevance, aggressiveness, argument-coherence, and suitableness. Furthermore, we propose Auto-Calibrated COT for Counterspeech Evaluation (ACE), a prompt-based method with auto-calibrated chain-of-thoughts (CoT) for scoring counterspeech using large language models. Our experiments show that ACE outperforms traditional metrics like ROUGE, METEOR, and BertScore in correlating with human judgement, indicating a significant advancement in automated counterspeech evaluation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "39",
        "title": "GLLM: Self-Corrective G-Code Generation using Large Language Models with User Feedback",
        "author": [
            "Mohamed Abdelaal",
            "Samuel Lokadjaja",
            "Gilbert Engert"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17584",
        "abstract": "This paper introduces GLLM, an innovative tool that leverages Large Language Models (LLMs) to automatically generate G-code from natural language instructions for Computer Numerical Control (CNC) machining. GLLM addresses the challenges of manual G-code writing by bridging the gap between human-readable task descriptions and machine-executable code. The system incorporates a fine-tuned StarCoder-3B model, enhanced with domain-specific training data and a Retrieval-Augmented Generation (RAG) mechanism. GLLM employs advanced prompting strategies and a novel self-corrective code generation approach to ensure both syntactic and semantic correctness of the generated G-code. The architecture includes robust validation mechanisms, including syntax checks, G-code-specific verifications, and functional correctness evaluations using Hausdorff distance. By combining these techniques, GLLM aims to democratize CNC programming, making it more accessible to users without extensive programming experience while maintaining high accuracy and reliability in G-code generation.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "40",
        "title": "Watch Your STEPP: Semantic Traversability Estimation using Pose Projected Features",
        "author": [
            "Sebastian Ãgidius",
            "Dennis Hadjivelichkov",
            "Jianhao Jiao",
            "Jonathan Embley-Riches",
            "Dimitrios Kanoulas"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17594",
        "abstract": "Understanding the traversability of terrain is essential for autonomous robot navigation, particularly in unstructured environments such as natural landscapes. Although traditional methods, such as occupancy mapping, provide a basic framework, they often fail to account for the complex mobility capabilities of some platforms such as legged robots. In this work, we propose a method for estimating terrain traversability by learning from demonstrations of human walking. Our approach leverages dense, pixel-wise feature embeddings generated using the DINOv2 vision Transformer model, which are processed through an encoder-decoder MLP architecture to analyze terrain segments. The averaged feature vectors, extracted from the masked regions of interest, are used to train the model in a reconstruction-based framework. By minimizing reconstruction loss, the network distinguishes between familiar terrain with a low reconstruction error and unfamiliar or hazardous terrain with a higher reconstruction error. This approach facilitates the detection of anomalies, allowing a legged robot to navigate more effectively through challenging terrain. We run real-world experiments on the ANYmal legged robot both indoor and outdoor to prove our proposed method. The code is open-source, while video demonstrations can be found on our website: https://rpl-cs-ucl.github.io/STEPP",
        "tags": [
            "Detection",
            "Robot",
            "Transformer"
        ]
    },
    {
        "id": "41",
        "title": "Technical report on label-informed logit redistribution for better domain generalization in low-shot classification with foundation models",
        "author": [
            "Behraj Khan",
            "Tahir Syed"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17595",
        "abstract": "Confidence calibration is an emerging challenge in real-world decision systems based on foundations models when used for downstream vision classification tasks. Due to various reasons exposed, logit scores on the CLIP head remain large irrespective of whether the image-language pairs reconcile. It is difficult to address in data space, given the few-shot regime. We propose a penalty incorporated into loss objective that penalizes incorrect classifications whenever one is made during finetuning, by moving an amount of log-likelihood to the true class commensurate to the relative amplitudes of the two likelihoods. We refer to it as \\textit{confidence misalignment penalty (CMP)}. Extensive experiments on $12$ vision datasets and $5$ domain generalization datasets supports the calibration performance of our method against stat-of-the-art. CMP outperforms the benchmarked prompt learning methods, demonstrating average improvement in Expected Calibration Error (ECE) by average $6.01$\\%, $4.01$ \\% at minimum and $9.72$\\% at maximum. Anonymized sample source code for this paper can be found at: \\url{https://anonymous.4open.science/r/icml25-C5CB/readme.txt}",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "42",
        "title": "Semantic Consistency Regularization with Large Language Models for Semi-supervised Sentiment Analysis",
        "author": [
            "Kunrong Li",
            "Xinyu Liu",
            "Zhen Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17598",
        "abstract": "Accurate sentiment analysis of texts is crucial for a variety of applications, such as understanding customer feedback, monitoring market trends, and detecting public sentiment. However, manually annotating large sentiment corpora for supervised learning is labor-intensive and time-consuming. Therefore, it is essential and effective to develop a semi-supervised method for the sentiment analysis task. Although some methods have been proposed for semi-supervised text classification, they rely on the intrinsic information within the unlabeled data and the learning capability of the NLP model, which lack generalization ability to the sentiment analysis scenario and may prone to overfit. Inspired by the ability of pretrained Large Language Models (LLMs) in following instructions and generating coherent text, we propose a Semantic Consistency Regularization with Large Language Models (SCR) framework for semi-supervised sentiment analysis. We introduce two prompting strategies to semantically enhance unlabeled text using LLMs. The first is Entity-based Enhancement (SCR-EE), which involves extracting entities and numerical information, and querying the LLM to reconstruct the textual information. The second is Concept-based Enhancement (SCR-CE), which directly queries the LLM with the original sentence for semantic reconstruction. Subsequently, the LLM-augmented data is utilized for a consistency loss with confidence thresholding, which preserves high-quality agreement samples to provide additional supervision signals during training. Furthermore, to fully utilize the uncertain unlabeled data samples, we propose a class re-assembling strategy inspired by the class space shrinking theorem. Experiments show our method achieves remarkable performance over prior semi-supervised methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "43",
        "title": "VoicePrompter: Robust Zero-Shot Voice Conversion with Voice Prompt and Conditional Flow Matching",
        "author": [
            "Ha-Yeong Choi",
            "Jaehan Park"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17612",
        "abstract": "Despite remarkable advancements in recent voice conversion (VC) systems, enhancing speaker similarity in zero-shot scenarios remains challenging. This challenge arises from the difficulty of generalizing and adapting speaker characteristics in speech within zero-shot environments, which is further complicated by mismatch between the training and inference processes. To address these challenges, we propose VoicePrompter, a robust zero-shot VC model that leverages in-context learning with voice prompts. VoicePrompter is composed of (1) a factorization method that disentangles speech components and (2) a DiT-based conditional flow matching (CFM) decoder that conditions on these factorized features and voice prompts. Additionally, (3) latent mixup is used to enhance in-context learning by combining various speaker features. This approach improves speaker similarity and naturalness in zero-shot VC by applying mixup to latent representations. Experimental results demonstrate that VoicePrompter outperforms existing zero-shot VC systems in terms of speaker similarity, speech intelligibility, and audio quality. Our demo is available at \\url{https://hayeong0.github.io/VoicePrompter-demo/}.",
        "tags": [
            "DiT",
            "Flow Matching"
        ]
    },
    {
        "id": "44",
        "title": "Structured Context Recomposition for Large Language Models Using Probabilistic Layer Realignment",
        "author": [
            "Jonathan Teel",
            "Jocasta Cumberbatch",
            "Raphael Benington",
            "Quentin Baskerville"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17617",
        "abstract": "Extended sequence generation often leads to degradation in contextual consistency due to the inability of conventional self-attention mechanisms to effectively retain long-range dependencies. Existing approaches, including memory compression and retrieval-augmented conditioning, introduce computational trade-offs that either increase inference latency or impose additional storage overhead. Structured Context Recomposition (SCR) introduces a probabilistic layer realignment strategy that dynamically adjusts learned representations within transformer layers, ensuring that semantically relevant embeddings persist throughout extended transformations. The proposed method enhances coherence retention through a recursive weighting function that redistributes representational emphasis based on inferred contextual relevance rather than relying on fixed token-level attention scores. Empirical results indicate that probabilistic realignment mitigates abrupt topic shifts and logical inconsistencies, particularly in scenarios where sequences exceed standard attention window constraints. Sequence-level entropy analysis further reveals that SCR moderates representational variability without introducing excessive output regularization, allowing models to sustain generative diversity while preserving contextual alignment. Attention head deviation measurements confirm that hierarchical reweighting contributes to smoother token dependency transitions across transformer layers, reinforcing the stability of multi-turn interactions and document-level reasoning. Computational resource assessments show that while SCR incurs a moderate increase in processing time, memory overhead remains within feasible limits, making it suitable for practical deployment in autoregressive generative applications.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "45",
        "title": "The Imitation Game According To Turing",
        "author": [
            "Sharon Temtsin",
            "Diane Proudfoot",
            "David Kaber",
            "Christoph Bartneck"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17629",
        "abstract": "The current cycle of hype and anxiety concerning the benefits and risks to human society of Artificial Intelligence is fuelled, not only by the increasing use of generative AI and other AI tools by the general public, but also by claims made on behalf of such technology by popularizers and scientists. In particular, recent studies have claimed that Large Language Models (LLMs) can pass the Turing Test-a goal for AI since the 1950s-and therefore can \"think\". Large-scale impacts on society have been predicted as a result. Upon detailed examination, however, none of these studies has faithfully applied Turing's original instructions. Consequently, we conducted a rigorous Turing Test with GPT-4-Turbo that adhered closely to Turing's instructions for a three-player imitation game. We followed established scientific standards where Turing's instructions were ambiguous or missing. For example, we performed a Computer-Imitates-Human Game (CIHG) without constraining the time duration and conducted a Man-Imitates-Woman Game (MIWG) as a benchmark. All but one participant correctly identified the LLM, showing that one of today's most advanced LLMs is unable to pass a rigorous Turing Test. We conclude that recent extravagant claims for such models are unsupported, and do not warrant either optimism or concern about the social impact of thinking machines.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "46",
        "title": "In-Context Meta LoRA Generation",
        "author": [
            "Yihua Shao",
            "Minxi Yan",
            "Yang Liu",
            "Siyu Chen",
            "Wenjie Chen",
            "Xinwei Long",
            "Ziyang Yan",
            "Lei Li",
            "Chenyu Zhang",
            "Nicu Sebe",
            "Hao Tang",
            "Yan Wang",
            "Hao Zhao",
            "Mengzhu Wang",
            "Jingcai Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17635",
        "abstract": "Low-rank Adaptation (LoRA) has demonstrated remarkable capabilities for task specific fine-tuning. However, in scenarios that involve multiple tasks, training a separate LoRA model for each one results in considerable inefficiency in terms of storage and inference. Moreover, existing parameter generation methods fail to capture the correlations among these tasks, making multi-task LoRA parameter generation challenging. To address these limitations, we propose In-Context Meta LoRA (ICM-LoRA), a novel approach that efficiently achieves task-specific customization of large language models (LLMs). Specifically, we use training data from all tasks to train a tailored generator, Conditional Variational Autoencoder (CVAE). CVAE takes task descriptions as inputs and produces task-aware LoRA weights as outputs. These LoRA weights are then merged with LLMs to create task-specialized models without the need for additional fine-tuning. Furthermore, we utilize in-context meta-learning for knowledge enhancement and task mapping, to capture the relationship between tasks and parameter distributions. As a result, our method achieves more accurate LoRA parameter generation for diverse tasks using CVAE. ICM-LoRA enables more accurate LoRA parameter reconstruction than current parameter reconstruction methods and is useful for implementing task-specific enhancements of LoRA parameters. At the same time, our method occupies 283MB, only 1\\% storage compared with the original LoRA.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA"
        ]
    },
    {
        "id": "47",
        "title": "Efficient Redundancy Reduction for Open-Vocabulary Semantic Segmentation",
        "author": [
            "Lin Chen",
            "Qi Yang",
            "Kun Ding",
            "Zhihao Li",
            "Gang Shen",
            "Fei Li",
            "Qiyuan Cao",
            "Shiming Xiang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17642",
        "abstract": "Open-vocabulary semantic segmentation (OVSS) is an open-world task that aims to assign each pixel within an image to a specific class defined by arbitrary text descriptions. Recent advancements in large-scale vision-language models have demonstrated their open-vocabulary understanding capabilities, significantly facilitating the development of OVSS. However, most existing methods suffer from either suboptimal performance or long latency. This study introduces ERR-Seg, a novel framework that effectively reduces redundancy to balance accuracy and efficiency. ERR-Seg incorporates a training-free Channel Reduction Module (CRM) that leverages prior knowledge from vision-language models like CLIP to identify the most relevant classes while discarding others. Moreover, it incorporates Efficient Semantic Context Fusion (ESCF) with spatial-level and class-level sequence reduction strategies. CRM and ESCF result in substantial memory and computational savings without compromising accuracy. Additionally, recognizing the significance of hierarchical semantics extracted from middle-layer features for closed-set semantic segmentation, ERR-Seg introduces the Hierarchical Semantic Module (HSM) to exploit hierarchical semantics in the context of OVSS. Compared to previous state-of-the-art methods under the ADE20K-847 setting, ERR-Seg achieves +$5.6\\%$ mIoU improvement and reduces latency by $67.3\\%$.",
        "tags": [
            "CLIP",
            "Segmentation"
        ]
    },
    {
        "id": "48",
        "title": "Drivetrain simulation using variational autoencoders",
        "author": [
            "Pallavi Sharma",
            "Jorge-Humberto Urrea-Quintero",
            "Bogdan Bogdan",
            "Adrian-Dumitru Ciotec",
            "Laura Vasilie",
            "Henning Wessels",
            "Matteo Skull"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17653",
        "abstract": "This work proposes variational autoencoders (VAEs) to predict a vehicle's jerk from a given torque demand, addressing the limitations of sparse real-world datasets. Specifically, we implement unconditional and conditional VAEs to generate jerk signals that integrate features from different drivetrain scenarios. The VAEs are trained on experimental data collected from two variants of a fully electric SUV, which differ in maximum torque delivery and drivetrain configuration. New meaningful jerk signals are generated within an engineering context through the interpretation of the VAE's latent space. A performance comparison with baseline physics-based and hybrid models confirms the effectiveness of the VAEs. We show that VAEs bypass the need for exhaustive manual system parametrization while maintaining physical plausibility by conditioning data generation on specific inputs.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "49",
        "title": "FeatureGS: Eigenvalue-Feature Optimization in 3D Gaussian Splatting for Geometrically Accurate and Artifact-Reduced Reconstruction",
        "author": [
            "Miriam JÃ¤ger",
            "Markus Hillemann",
            "Boris Jutzi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17655",
        "abstract": "3D Gaussian Splatting (3DGS) has emerged as a powerful approach for 3D scene reconstruction using 3D Gaussians. However, neither the centers nor surfaces of the Gaussians are accurately aligned to the object surface, complicating their direct use in point cloud and mesh reconstruction. Additionally, 3DGS typically produces floater artifacts, increasing the number of Gaussians and storage requirements. To address these issues, we present FeatureGS, which incorporates an additional geometric loss term based on an eigenvalue-derived 3D shape feature into the optimization process of 3DGS. The goal is to improve geometric accuracy and enhance properties of planar surfaces with reduced structural entropy in local 3D http://neighborhoods.We present four alternative formulations for the geometric loss term based on 'planarity' of Gaussians, as well as 'planarity', 'omnivariance', and 'eigenentropy' of Gaussian neighborhoods. We provide quantitative and qualitative evaluations on 15 scenes of the DTU benchmark dataset focusing on following key aspects: Geometric accuracy and artifact-reduction, measured by the Chamfer distance, and memory efficiency, evaluated by the total number of Gaussians. Additionally, rendering quality is monitored by Peak Signal-to-Noise Ratio. FeatureGS achieves a 30 % improvement in geometric accuracy, reduces the number of Gaussians by 90 %, and suppresses floater artifacts, while maintaining comparable photometric rendering quality. The geometric loss with 'planarity' from Gaussians provides the highest geometric accuracy, while 'omnivariance' in Gaussian neighborhoods reduces floater artifacts and number of Gaussians the most. This makes FeatureGS a strong method for geometrically accurate, artifact-reduced and memory-efficient 3D scene reconstruction, enabling the direct use of Gaussian centers for geometric representation.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "50",
        "title": "ContourFormer:Real-Time Contour-Based End-to-End Instance Segmentation Transformer",
        "author": [
            "Weiwei yao",
            "Chen Li",
            "Minjun Xiong",
            "Wenbo Dong",
            "Hao Chen",
            "Xiong Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17688",
        "abstract": "This paper presents Contourformer, a real-time contour-based instance segmentation algorithm. The method is fully based on the DETR paradigm and achieves end-to-end inference through iterative and progressive mechanisms to optimize contours. To improve efficiency and accuracy, we develop two novel techniques: sub-contour decoupling mechanisms and contour fine-grained distribution http://refinement.In the sub-contour decoupling mechanism, we propose a deformable attention-based module that adaptively selects sampling regions based on the current predicted contour, enabling more effective capturing of object boundary information. Additionally, we design a multi-stage optimization process to enhance segmentation precision by progressively refining sub-contours. The contour fine-grained distribution refinement technique aims to further improve the ability to express fine details of http://contours.These innovations enable Contourformer to achieve stable and precise segmentation for each instance while maintaining real-time performance. Extensive experiments demonstrate the superior performance of Contourformer on multiple benchmark datasets, including SBD, COCO, and KINS. We conduct comprehensive evaluations and comparisons with existing state-of-the-art methods, showing significant improvements in both accuracy and inference http://speed.This work provides a new solution for contour-based instance segmentation tasks and lays a foundation for future research, with the potential to become a strong baseline method in this field.",
        "tags": [
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "51",
        "title": "Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate",
        "author": [
            "Yubo Wang",
            "Xiang Yue",
            "Wenhu Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17703",
        "abstract": "Supervised Fine-Tuning (SFT) is commonly used to train language models to imitate annotated responses for given instructions. In this paper, we challenge this paradigm and propose Critique Fine-Tuning (CFT), a strategy where models learn to critique noisy responses rather than simply imitate correct ones. Inspired by human learning processes that emphasize critical thinking, CFT encourages deeper analysis and nuanced understanding-traits often overlooked by standard SFT. To validate the effectiveness of CFT, we construct a 50K-sample dataset from WebInstruct, using GPT-4o as the teacher to generate critiques in the form of (input=[query; noisy response], output=critique). CFT on this dataset yields a consistent 4-10% improvement over SFT on six math benchmarks with different base models like Qwen2.5, Qwen2.5-Math and DeepSeek-Math. We further expand to MetaMath and NuminaMath datasets and observe similar gains over SFT. Notably, our Qwen2.5-Math-CFT model-trained on just 50K samples-matches or outperforms competitive models such as AceMath and Qwen2.5-Math-Instruct on most benchmarks, both of which use over 2M samples. Ablation studies show that CFT is robust to the source of noisy response and teacher critique model. Through these findings, we argue that critique-based training offers a more effective alternative to advance the reasoning of language models.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "52",
        "title": "RICoTA: Red-teaming of In-the-wild Conversation with Test Attempts",
        "author": [
            "Eujeong Choi",
            "Younghun Jeong",
            "Soomin Kim",
            "Won Ik Cho"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17715",
        "abstract": "User interactions with conversational agents (CAs) evolve in the era of heavily guardrailed large language models (LLMs). As users push beyond programmed boundaries to explore and build relationships with these systems, there is a growing concern regarding the potential for unauthorized access or manipulation, commonly referred to as \"jailbreaking.\" Moreover, with CAs that possess highly human-like qualities, users show a tendency toward initiating intimate sexual interactions or attempting to tame their chatbots. To capture and reflect these in-the-wild interactions into chatbot designs, we propose RICoTA, a Korean red teaming dataset that consists of 609 prompts challenging LLMs with in-the-wild user-made dialogues capturing jailbreak attempts. We utilize user-chatbot conversations that were self-posted on a Korean Reddit-like community, containing specific testing and gaming intentions with a social chatbot. With these prompts, we aim to evaluate LLMs' ability to identify the type of conversation and users' testing purposes to derive chatbot design implications for mitigating jailbreaking risks. Our dataset will be made publicly available via GitHub.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "53",
        "title": "Using Code Generation to Solve Open Instances of Combinatorial Design Problems",
        "author": [
            "Christopher D. Rosin"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17725",
        "abstract": "The Handbook of Combinatorial Designs catalogs many types of combinatorial designs, together with lists of open instances for which existence has not yet been determined. We develop a constructive protocol CPro1, which uses Large Language Models (LLMs) to generate code that constructs combinatorial designs and resolves some of these open instances. The protocol starts from a definition of a particular type of design, and a verifier that reliably confirms whether a proposed design is valid. The LLM selects strategies and implements them in code, and scaffolding provides automated hyperparameter tuning and execution feedback using the verifier. Most generated code fails, but by generating many candidates, the protocol automates exploration of a variety of standard methods (e.g. simulated annealing, genetic algorithms) and experimentation with variations (e.g. cost functions) to find successful approaches. Testing on 16 different types of designs, CPro1 constructs solutions to open instances for 6 of them: Symmetric and Skew Weighing Matrices, Equidistant Permutation Arrays, Packing Arrays, Balanced Ternary Designs, and Florentine Rectangles.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "54",
        "title": "Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation",
        "author": [
            "Aitor Arrieta",
            "Miriam Ugarte",
            "Pablo Valle",
            "JosÃ© Antonio Parejo",
            "Sergio Segura"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17749",
        "abstract": "Large Language Models (LLMs) have become an integral part of our daily lives. However, they impose certain risks, including those that can harm individuals' privacy, perpetuate biases and spread misinformation. These risks highlight the need for robust safety mechanisms, ethical guidelines, and thorough testing to ensure their responsible deployment. Safety of LLMs is a key property that needs to be thoroughly tested prior the model to be deployed and accessible to the general users. This paper reports the external safety testing experience conducted by researchers from Mondragon University and University of Seville on OpenAI's new o3-mini LLM as part of OpenAI's early access for safety testing program. In particular, we apply our tool, ASTRAL, to automatically and systematically generate up to date unsafe test inputs (i.e., prompts) that helps us test and assess different safety categories of LLMs. We automatically generate and execute a total of 10,080 unsafe test input on a early o3-mini beta version. After manually verifying the test cases classified as unsafe by ASTRAL, we identify a total of 87 actual instances of unsafe LLM behavior. We highlight key insights and findings uncovered during the pre-deployment external testing phase of OpenAI's latest LLM.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "55",
        "title": "Yin-Yang: Developing Motifs With Long-Term Structure And Controllability",
        "author": [
            "Keshav Bhandari",
            "Geraint A. Wiggins",
            "Simon Colton"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17759",
        "abstract": "Transformer models have made great strides in generating symbolically represented music with local coherence. However, controlling the development of motifs in a structured way with global form remains an open research area. One of the reasons for this challenge is due to the note-by-note autoregressive generation of such models, which lack the ability to correct themselves after deviations from the motif. In addition, their structural performance on datasets with shorter durations has not been studied in the literature. In this study, we propose Yin-Yang, a framework consisting of a phrase generator, phrase refiner, and phrase selector models for the development of motifs into melodies with long-term structure and controllability. The phrase refiner is trained on a novel corruption-refinement strategy which allows it to produce melodic and rhythmic variations of an original motif at generation time, thereby rectifying deviations of the phrase generator. We also introduce a new objective evaluation metric for quantifying how smoothly the motif manifests itself within the piece. Evaluation results show that our model achieves better performance compared to state-of-the-art transformer models while having the advantage of being controllable and making the generated musical structure semi-interpretable, paving the way for musical analysis. Our code and demo page can be found at https://github.com/keshavbhandari/yinyang.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "56",
        "title": "Generative Unordered Flow for Set-Structured Data Generation",
        "author": [
            "Yangming Li",
            "Carola-Bibiane SchÃ¶nlieb"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17770",
        "abstract": "Flow-based generative models have demonstrated promising performance across a broad spectrum of data modalities (e.g., image and text). However, there are few works exploring their extension to unordered data (e.g., spatial point set), which is not trivial because previous models are mostly designed for vector data that are naturally ordered. In this paper, we present unordered flow, a type of flow-based generative model for set-structured data generation. Specifically, we convert unordered data into an appropriate function representation, and learn the probability measure of such representations through function-valued flow matching. For the inverse map from a function representation to unordered data, we propose a method similar to particle filtering, with Langevin dynamics to first warm-up the initial particles and gradient-based search to update them until convergence. We have conducted extensive experiments on multiple real-world datasets, showing that our unordered flow model is very effective in generating set-structured data and significantly outperforms previous baselines.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "57",
        "title": "2SSP: A Two-Stage Framework for Structured Pruning of LLMs",
        "author": [
            "Fabrizio Sandri",
            "Elia Cunegatti",
            "Giovanni Iacca"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17771",
        "abstract": "We propose a novel Two-Stage framework for Structured Pruning (2SSP) for pruning Large Language Models (LLMs), which combines two different strategies of pruning, namely Width and Depth Pruning. The first stage (Width Pruning) removes entire neurons, hence their corresponding rows and columns, aiming to preserve the connectivity among the pruned structures in the intermediate state of the Feed-Forward Networks in each Transformer block. This is done based on an importance score measuring the impact of each neuron over the output magnitude. The second stage (Depth Pruning), instead, removes entire Attention submodules. This is done by applying an iterative process that removes the Attention submodules with the minimum impact on a given metric of interest (in our case, perplexity). We also propose a novel mechanism to balance the sparsity rate of the two stages w.r.t. to the desired global sparsity. We test 2SSP on four LLM families and three sparsity rates (25\\%, 37.5\\%, and 50\\%), measuring the resulting perplexity over three language modeling datasets as well as the performance over six downstream tasks. Our method consistently outperforms five state-of-the-art competitors over three language modeling and six downstream tasks, with an up to two-order-of-magnitude gain in terms of pruning time. The code is available at available at \\url{https://github.com/FabrizioSandri/2SSP}.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "58",
        "title": "AdditiveLLM: Large Language Models Predict Defects in Additive Manufacturing",
        "author": [
            "Peter Pak",
            "Amir Barati Farimani"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17784",
        "abstract": "In this work we investigate the ability of large language models to predict additive manufacturing defect regimes given a set of process parameter inputs. For this task we utilize a process parameter defect dataset to fine-tune a collection of models, titled AdditiveLLM, for the purpose of predicting potential defect regimes including Keyholing, Lack of Fusion, and Balling. We compare different methods of input formatting in order to gauge the model's performance to correctly predict defect regimes on our sparse Baseline dataset and our natural language Prompt dataset. The model displays robust predictive capability, achieving an accuracy of 93\\% when asked to provide the defect regimes associated with a set of process parameters. The incorporation of natural language input further simplifies the task of process parameters selection, enabling users to identify optimal settings specific to their build.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "59",
        "title": "Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare Scripts",
        "author": [
            "Yu-Fei Shih",
            "Zheng-Lin Lin",
            "Shu-Kai Hsieh"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17785",
        "abstract": "We explore the capabilities of LVLMs and LLMs in deciphering rare scripts not encoded in Unicode. We introduce a novel approach to construct a multimodal dataset of linguistic puzzles involving such scripts, utilizing a tokenization method for language glyphs. Our methods include the Picture Method for LVLMs and the Description Method for LLMs, enabling these models to tackle these challenges. We conduct experiments using prominent models, GPT-4o, Gemini, and Claude 3.5 Sonnet, on linguistic puzzles. Our findings reveal the strengths and limitations of current AI methods in linguistic decipherment, highlighting the impact of Unicode encoding on model performance and the challenges of modeling visual language tokens through descriptions. Our study advances understanding of AI's potential in linguistic decipherment and underscores the need for further research.",
        "tags": [
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "60",
        "title": "BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights",
        "author": [
            "Chan-Jan Hsu",
            "Yi-Cheng Lin",
            "Chia-Chun Lin",
            "Wei-Chih Chen",
            "Ho Lam Chung",
            "Chen-An Li",
            "Yi-Chang Chen",
            "Chien-Yu Yu",
            "Ming-Ji Lee",
            "Chien-Cheng Chen",
            "Ru-Heng Huang",
            "Hung-yi Lee",
            "Da-Shan Shiu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17790",
        "abstract": "We present BreezyVoice, a Text-to-Speech (TTS) system specifically adapted for Taiwanese Mandarin, highlighting phonetic control abilities to address the unique challenges of polyphone disambiguation in the language. Building upon CosyVoice, we incorporate a $S^{3}$ tokenizer, a large language model (LLM), an optimal-transport conditional flow matching model (OT-CFM), and a grapheme to phoneme prediction model, to generate realistic speech that closely mimics human utterances. Our evaluation demonstrates BreezyVoice's superior performance in both general and code-switching contexts, highlighting its robustness and effectiveness in generating high-fidelity speech. Additionally, we address the challenges of generalizability in modeling long-tail speakers and polyphone disambiguation. Our approach significantly enhances performance and offers valuable insights into the workings of neural codec TTS systems.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "61",
        "title": "CrowdSplat: Exploring Gaussian Splatting For Crowd Rendering",
        "author": [
            "Xiaohan Sun",
            "Yinghan Xu",
            "John Dingliana",
            "Carol O'Sullivan"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17792",
        "abstract": "We present CrowdSplat, a novel approach that leverages 3D Gaussian Splatting for real-time, high-quality crowd rendering. Our method utilizes 3D Gaussian functions to represent animated human characters in diverse poses and outfits, which are extracted from monocular videos. We integrate Level of Detail (LoD) rendering to optimize computational efficiency and quality. The CrowdSplat framework consists of two stages: (1) avatar reconstruction and (2) crowd synthesis. The framework is also optimized for GPU memory usage to enhance scalability. Quantitative and qualitative evaluations show that CrowdSplat achieves good levels of rendering quality, memory efficiency, and computational performance. Through these experiments, we demonstrate that CrowdSplat is a viable solution for dynamic, realistic crowd simulation in real-time applications.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "62",
        "title": "Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling",
        "author": [
            "Xiaokang Chen",
            "Zhiyu Wu",
            "Xingchao Liu",
            "Zizheng Pan",
            "Wen Liu",
            "Zhenda Xie",
            "Xingkai Yu",
            "Chong Ruan"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17811",
        "abstract": "In this work, we introduce Janus-Pro, an advanced version of the previous work Janus. Specifically, Janus-Pro incorporates (1) an optimized training strategy, (2) expanded training data, and (3) scaling to larger model size. With these improvements, Janus-Pro achieves significant advancements in both multimodal understanding and text-to-image instruction-following capabilities, while also enhancing the stability of text-to-image generation. We hope this work will inspire further exploration in the field. Code and models are publicly available.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "63",
        "title": "P-TAME: Explain Any Image Classifier with Trained Perturbations",
        "author": [
            "Mariano V. Ntrougkas",
            "Vasileios Mezaris",
            "Ioannis Patras"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17813",
        "abstract": "The adoption of Deep Neural Networks (DNNs) in critical fields where predictions need to be accompanied by justifications is hindered by their inherent black-box nature. In this paper, we introduce P-TAME (Perturbation-based Trainable Attention Mechanism for Explanations), a model-agnostic method for explaining DNN-based image classifiers. P-TAME employs an auxiliary image classifier to extract features from the input image, bypassing the need to tailor the explanation method to the internal architecture of the backbone classifier being explained. Unlike traditional perturbation-based methods, which have high computational requirements, P-TAME offers an efficient alternative by generating high-resolution explanations in a single forward pass during inference. We apply P-TAME to explain the decisions of VGG-16, ResNet-50, and ViT-B-16, three distinct and widely used image classifiers. Quantitative and qualitative results show that our method matches or outperforms previous explainability methods, including model-specific approaches. Code and trained models will be released upon acceptance.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "64",
        "title": "U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal Learning",
        "author": [
            "Md Kaykobad Reza",
            "Niki Nezakati",
            "Ameya Patil",
            "Mashhour Solh",
            "M. Salman Asif"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17823",
        "abstract": "Multimodal learning often relies on designing new models and complex training strategies to achieve optimal performance. We present Unified Unimodal Adaptation (U2A), which jointly fine-tunes pretrained unimodal encoders using low-rank adaptation (LoRA) for various multimodal tasks. Our method significantly reduces the number of learnable parameters and eliminates the need for complex training strategies, such as alternating training, gradient modifications, or unimodal fine-tuning. To address missing modalities during both training and testing, we introduce Mask Tokens (MT), which generate missing modality features from available modalities using a single token per modality. This simplifies the process, removing the need for specialized feature estimation or prompt-tuning methods. Our evaluation demonstrates that U2A matches or outperforms state-of-the-art methods in both complete and missing modality settings, showcasing strong performance and robustness across various modalities, tasks, and datasets. We also analyze and report the effectiveness of Mask Tokens in different missing modality scenarios. Overall, our method provides a robust, flexible, and efficient solution for multimodal learning, with minimal computational overhead.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "65",
        "title": "Langevin Soft Actor-Critic: Efficient Exploration through Uncertainty-Driven Critic Learning",
        "author": [
            "Haque Ishfaq",
            "Guangyuan Wang",
            "Sami Nur Islam",
            "Doina Precup"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17827",
        "abstract": "Existing actor-critic algorithms, which are popular for continuous control reinforcement learning (RL) tasks, suffer from poor sample efficiency due to lack of principled exploration mechanism within them. Motivated by the success of Thompson sampling for efficient exploration in RL, we propose a novel model-free RL algorithm, Langevin Soft Actor Critic (LSAC), which prioritizes enhancing critic learning through uncertainty estimation over policy optimization. LSAC employs three key innovations: approximate Thompson sampling through distributional Langevin Monte Carlo (LMC) based $Q$ updates, parallel tempering for exploring multiple modes of the posterior of the $Q$ function, and diffusion synthesized state-action samples regularized with $Q$ action gradients. Our extensive experiments demonstrate that LSAC outperforms or matches the performance of mainstream model-free RL algorithms for continuous control tasks. Notably, LSAC marks the first successful application of an LMC based Thompson sampling in continuous control tasks with continuous action spaces.",
        "tags": [
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "66",
        "title": "A Comprehensive Survey on Legal Summarization: Challenges and Future Directions",
        "author": [
            "Mousumi Akter",
            "Erion Cano",
            "Erik Weber",
            "Dennis Dobler",
            "Ivan Habernal"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17830",
        "abstract": "This article provides a systematic up-to-date survey of automatic summarization techniques, datasets, models, and evaluation methods in the legal domain. Through specific source selection criteria, we thoroughly review over 120 papers spanning the modern `transformer' era of natural language processing (NLP), thus filling a gap in existing systematic surveys on the matter. We present existing research along several axes and discuss trends, challenges, and opportunities for future research.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "67",
        "title": "Matrix Product Sketching via Coordinated Sampling",
        "author": [
            "Majid Daliri",
            "Juliana Freire",
            "Danrong Li",
            "Christopher Musco"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17836",
        "abstract": "We revisit the well-studied problem of approximating a matrix product, $\\mathbf{A}^T\\mathbf{B}$, based on small space sketches $\\mathcal{S}(\\mathbf{A})$ and $\\mathcal{S}(\\mathbf{B})$ of $\\mathbf{A} \\in \\R^{n \\times d}$ and $\\mathbf{B}\\in \\R^{n \\times m}$. We are interested in the setting where the sketches must be computed independently of each other, except for the use of a shared random seed. We prove that, when $\\mathbf{A}$ and $\\mathbf{B}$ are sparse, methods based on \\emph{coordinated random sampling} can outperform classical linear sketching approaches, like Johnson-Lindenstrauss Projection or CountSketch. For example, to obtain Frobenius norm error $\\epsilon\\|\\mathbf{A}\\|_F\\|\\mathbf{B}\\|_F$, coordinated sampling requires sketches of size $O(s/\\epsilon^2)$ when $\\mathbf{A}$ and $\\mathbf{B}$ have at most $s \\leq d,m$ non-zeros per row. In contrast, linear sketching leads to sketches of size $O(d/\\epsilon^2)$ and $O(m/\\epsilon^2)$ for $\\mathbf{A}$ and $\\mathbf{B}$. We empirically evaluate our approach on two applications: 1) distributed linear regression in databases, a problem motivated by tasks like dataset discovery and augmentation, and 2) approximating attention matrices in transformer-based language models. In both cases, our sampling algorithms yield an order of magnitude improvement over linear sketching.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "68",
        "title": "Learning Beyond the Surface: How Far Can Continual Pre-Training with LoRA Enhance LLMs' Domain-Specific Insight Learning?",
        "author": [
            "Pouya Pezeshkpour",
            "Estevam Hruschka"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17840",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance on various tasks, yet their ability to extract and internalize deeper insights from domain-specific datasets remains underexplored. In this study, we investigate how continual pre-training can enhance LLMs' capacity for insight learning across three distinct forms: declarative, statistical, and probabilistic insights. Focusing on two critical domains: medicine and finance, we employ LoRA to train LLMs on two existing datasets. To evaluate each insight type, we create benchmarks to measure how well continual pre-training helps models go beyond surface-level knowledge. We also assess the impact of document modification on capturing insights. The results show that, while continual pre-training on original documents has a marginal effect, modifying documents to retain only essential information significantly enhances the insight-learning capabilities of LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA"
        ]
    },
    {
        "id": "69",
        "title": "Improving Your Model Ranking on Chatbot Arena by Vote Rigging",
        "author": [
            "Rui Min",
            "Tianyu Pang",
            "Chao Du",
            "Qian Liu",
            "Minhao Cheng",
            "Min Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17858",
        "abstract": "Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles, where users vote for their preferred response from two randomly sampled anonymous models. While Chatbot Arena is widely regarded as a reliable LLM ranking leaderboard, we show that crowdsourced voting can be rigged to improve (or decrease) the ranking of a target model $m_{t}$. We first introduce a straightforward target-only rigging strategy that focuses on new battles involving $m_{t}$, identifying it via watermarking or a binary classifier, and exclusively voting for $m_{t}$ wins. However, this strategy is practically inefficient because there are over $190$ models on Chatbot Arena and on average only about $1\\%$ of new battles will involve $m_{t}$. To overcome this, we propose omnipresent rigging strategies, exploiting the Elo rating mechanism of Chatbot Arena that any new vote on a battle can influence the ranking of the target model $m_{t}$, even if $m_{t}$ is not directly involved in the battle. We conduct experiments on around $1.7$ million historical votes from the Chatbot Arena Notebook, showing that omnipresent rigging strategies can improve model rankings by rigging only hundreds of new votes. While we have evaluated several defense mechanisms, our findings highlight the importance of continued efforts to prevent vote rigging. Our code is available at https://github.com/sail-sg/Rigging-ChatbotArena.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "70",
        "title": "Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology",
        "author": [
            "Peilong Wang",
            "Zhengliang Liu",
            "Yiwei Li",
            "Jason Holmes",
            "Peng Shu",
            "Lian Zhang",
            "Xiang Li",
            "Quanzheng Li",
            "Brady S. Laughlin",
            "Diego Santos Toesca",
            "Sujay A. Vora",
            "Samir H. Patel",
            "Terence T. Sio",
            "Tianming Liu",
            "Wei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17286",
        "abstract": "Background: The radiation oncology clinical practice involves many steps relying on the dynamic interplay of abundant text data. Large language models have displayed remarkable capabilities in processing complex text information. But their direct applications in specific fields like radiation oncology remain underexplored.\nPurpose: This study aims to investigate whether fine-tuning LLMs with domain knowledge can improve the performance on Task (1) treatment regimen generation, Task (2) treatment modality selection (photon, proton, electron, or brachytherapy), and Task (3) ICD-10 code prediction in radiation oncology.\nMethods: Data for 15,724 patient cases were extracted. Cases where patients had a single diagnostic record, and a clearly identifiable primary treatment plan were selected for preprocessing and manual annotation to have 7,903 cases of the patient diagnosis, treatment plan, treatment modality, and ICD-10 code. Each case was used to construct a pair consisting of patient diagnostics details and an answer (treatment regimen, treatment modality, or ICD-10 code respectively) for the supervised fine-tuning of these three tasks. Open source LLaMA2-7B and Mistral-7B models were utilized for the fine-tuning with the Low-Rank Approximations method. Accuracy and ROUGE-1 score were reported for the fine-tuned models and original models. Clinical evaluation was performed on Task (1) by radiation oncologists, while precision, recall, and F-1 score were evaluated for Task (2) and (3). One-sided Wilcoxon signed-rank tests were used to statistically analyze the results.\nResults: Fine-tuned LLMs outperformed original LLMs across all tasks with p-value <= 0.001. Clinical evaluation demonstrated that over 60% of the fine-tuned LLMs-generated treatment regimens were clinically acceptable. Precision, recall, and F1-score showed improved performance of fine-tuned LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "71",
        "title": "Dilemmas and trade-offs in the diffusion of conventions",
        "author": [
            "Lucas Gautheron"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17300",
        "abstract": "Outside ideal settings, conventions are shaped by heterogeneous competing processes that can challenge the emergence of universal norms. This paper identifies three trade-offs challenging the diffusion of conventions and explores each of them empirically using observational behavioral data. The first trade-off (I) concerns the imperatives of social, sequential, and contextual consistency that individuals must balance when choosing between competing conventions. The second trade-off (II) involves the balance between local and global coordination, depending on whether individuals coordinate their behavior via interactions throughout a social network or external factors transcending the network. The third trade-off (III) is the balance between decision optimality (e.g., collective satisfaction) and decision costs when collectives with conflicting preferences choose one convention. We develop a utilitarian account of conventions which we translate into a broadly applicable statistical physics framework for measuring each of these trade-offs. We then apply this framework to a sign convention in physics using textual and network data. Our analysis suggests that the purpose of conventions may exceed coordination, and that multiple infrastructures (including prior cultural traits and social networks) concurrently shape individual preferences towards conventions. Additionally, we confirm the role of seniority in resolving conflicting preferences in collaborations, resulting in suboptimal outcomes.",
        "tags": [
            "Diffusion"
        ]
    }
]