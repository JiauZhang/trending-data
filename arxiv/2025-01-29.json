[
    {
        "id": "1",
        "title": "Explore Activation Sparsity in Recurrent LLMs for Energy-Efficient Neuromorphic Computing",
        "author": [
            "Ivan Knunyants",
            "Maryam Tavakol",
            "Manolis Sifalakis",
            "Yingfu Xu",
            "Amirreza Yousefzadeh",
            "Guangzhi Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16337",
        "abstract": "The recent rise of Large Language Models (LLMs) has revolutionized the deep learning field. However, the desire to deploy LLMs on edge devices introduces energy efficiency and latency challenges. Recurrent LLM (R-LLM) architectures have proven effective in mitigating the quadratic complexity of self-attention, making them a potential paradigm for computing on-edge neuromorphic processors. In this work, we propose a low-cost, training-free algorithm to sparsify R-LLMs' activations to enhance energy efficiency on neuromorphic hardware. Our approach capitalizes on the inherent structure of these models, rendering them well-suited for energy-constrained environments. Although primarily designed for R-LLMs, this method can be generalized to other LLM architectures, such as transformers, as demonstrated on the OPT model, achieving comparable sparsity and efficiency improvements. Empirical studies illustrate that our method significantly reduces computational demands while maintaining competitive accuracy across multiple zero-shot learning benchmarks. Additionally, hardware simulations with the SENECA neuromorphic processor underscore notable energy savings and latency improvements. These results pave the way for low-power, real-time neuromorphic deployment of LLMs and demonstrate the feasibility of training-free on-chip adaptation using activation sparsity.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "2",
        "title": "Risk-Informed Diffusion Transformer for Long-Tail Trajectory Prediction in the Crash Scenario",
        "author": [
            "Junlan Chen",
            "Pei Liu",
            "Zihao Zhang",
            "Hongyi Zhao",
            "Yufei Ji",
            "Ziyuan Pu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16349",
        "abstract": "Trajectory prediction methods have been widely applied in autonomous driving technologies. Although the overall performance accuracy of trajectory prediction is relatively high, the lack of trajectory data in critical scenarios in the training data leads to the long-tail phenomenon. Normally, the trajectories of the tail data are more critical and more difficult to predict and may include rare scenarios such as crashes. To solve this problem, we extracted the trajectory data from real-world crash scenarios, which contain more long-tail data. Meanwhile, based on the trajectory data in this scenario, we integrated graph-based risk information and diffusion with transformer and proposed the Risk-Informed Diffusion Transformer (RI-DiT) trajectory prediction method. Extensive experiments were conducted on trajectory data in the real-world crash scenario, and the results show that the algorithm we proposed has good performance. When predicting the data of the tail 10\\% (Top 10\\%), the minADE and minFDE indicators are 0.016/2.667 m. At the same time, we showed the trajectory conditions of different long-tail distributions. The distribution of trajectory data is closer to the tail, the less smooth the trajectory is. Through the trajectory data in real-world crash scenarios, Our work expands the methods to overcome the long-tail challenges in trajectory prediction. Our method, RI-DiT, integrates inverse time to collision (ITTC) and the feature of traffic flow, which can predict long-tail trajectories more accurately and improve the safety of autonomous driving systems.",
        "tags": [
            "DiT",
            "Diffusion",
            "Diffusion Transformer",
            "Transformer"
        ]
    },
    {
        "id": "3",
        "title": "Synthetic Data Generation by Supervised Neural Gas Network for Physiological Emotion Recognition Data",
        "author": [
            "S. Muhammad Hossein Mousavi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16353",
        "abstract": "Data scarcity remains a significant challenge in the field of emotion recognition using physiological signals, as acquiring comprehensive and diverse datasets is often prevented by privacy concerns and logistical constraints. This limitation restricts the development and generalization of robust emotion recognition models, making the need for effective synthetic data generation methods more critical. Emotion recognition from physiological signals such as EEG, ECG, and GSR plays a pivotal role in enhancing human-computer interaction and understanding human affective states. Utilizing these signals, this study introduces an innovative approach to synthetic data generation using a Supervised Neural Gas (SNG) network, which has demonstrated noteworthy speed advantages over established models like Conditional VAE, Conditional GAN, diffusion model, and Variational LSTM. The Neural Gas network, known for its adaptability in organizing data based on topological and feature-space proximity, provides a robust framework for generating real-world-like synthetic datasets that preserve the intrinsic patterns of physiological emotion data. Our implementation of the SNG efficiently processes the input data, creating synthetic instances that closely mimic the original data distributions, as demonstrated through comparative accuracy assessments. In experiments, while our approach did not universally outperform all models, it achieved superior performance against most of the evaluated models and offered significant improvements in processing time. These outcomes underscore the potential of using SNG networks for fast, efficient, and effective synthetic data generation in emotion recognition applications.",
        "tags": [
            "Diffusion",
            "GAN",
            "VAE"
        ]
    },
    {
        "id": "4",
        "title": "How Strategic Agents Respond: Comparing Analytical Models with LLM-Generated Responses in Strategic Classification",
        "author": [
            "Tian Xie",
            "Pavan Rauch",
            "Xueru Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16355",
        "abstract": "When machine learning (ML) algorithms are used to automate human-related decisions, human agents may gain knowledge of the decision policy and behave strategically to obtain desirable outcomes. Strategic Classification (SC) has been proposed to address the interplay between agents and decision-makers. Prior work on SC has relied on assumptions that agents are perfectly or approximately rational, responding to decision policies by maximizing their utilities. Verifying these assumptions is challenging due to the difficulty of collecting real-world agent responses. Meanwhile, the growing adoption of large language models (LLMs) makes it increasingly likely that human agents in SC settings will seek advice from these tools. We propose using strategic advice generated by LLMs to simulate human agent responses in SC. Specifically, we examine five critical SC scenarios -- hiring, loan applications, school admissions, personal income, and public assistance programs -- and simulate how human agents with diverse profiles seek advice from LLMs. We then compare the resulting agent responses with the best responses generated by existing theoretical models. Our findings reveal that: (i) LLMs and theoretical models generally lead to agent score or qualification changes in the same direction across most settings, with both achieving similar levels of fairness; (ii) state-of-the-art commercial LLMs (e.g., GPT-3.5, GPT-4) consistently provide helpful suggestions, though these suggestions typically do not result in maximal score or qualification improvements; and (iii) LLMs tend to produce more diverse agent responses, often favoring more balanced effort allocation strategies. These results suggest that theoretical models align with LLMs to some extent and that leveraging LLMs to simulate more realistic agent responses offers a promising approach to designing trustworthy ML systems.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "5",
        "title": "Evaluating Binary Decision Biases in Large Language Models: Implications for Fair Agent-Based Financial Simulations",
        "author": [
            "Alicia Vidler",
            "Toby Walsh"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16356",
        "abstract": "Large Language Models (LLMs) are increasingly being used to simulate human-like decision making in agent-based financial market models (ABMs). As models become more powerful and accessible, researchers can now incorporate individual LLM decisions into ABM environments. However, integration may introduce inherent biases that need careful evaluation. In this paper we test three state-of-the-art GPT models for bias using two model sampling approaches: one-shot and few-shot API queries. We observe significant variations in distributions of outputs between specific models, and model sub versions, with GPT-4o-Mini-2024-07-18 showing notably better performance (32-43% yes responses) compared to GPT-4-0125-preview's extreme bias (98-99% yes responses). We show that sampling methods and model sub-versions significantly impact results: repeated independent API calls produce different distributions compared to batch sampling within a single call. While no current GPT model can simultaneously achieve a uniform distribution and Markovian properties in one-shot testing, few-shot sampling can approach uniform distributions under certain conditions. We explore the Temperature parameter, providing a definition and comparative results. We further compare our results to true random binary series and test specifically for the common human bias of Negative Recency - finding LLMs have a mixed ability to 'beat' humans in this one regard. These findings emphasise the critical importance of careful LLM integration into ABMs for financial markets and more broadly.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "6",
        "title": "The OpenLAM Challenges",
        "author": [
            "Anyang Peng",
            "Xinzijian Liu",
            "Ming-Yu Guo",
            "Linfeng Zhang",
            "Han Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16358",
        "abstract": "Inspired by the success of Large Language Models (LLMs), the development of Large Atom Models (LAMs) has gained significant momentum in scientific computation. Since 2022, the Deep Potential team has been actively pretraining LAMs and launched the OpenLAM Initiative to develop an open-source foundation model spanning the periodic table. A core objective is establishing comprehensive benchmarks for reliable LAM evaluation, addressing limitations in existing datasets. As a first step, the LAM Crystal Philately competition has collected over 19.8 million valid structures, including 1 million on the OpenLAM convex hull, driving advancements in generative modeling and materials science applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "7",
        "title": "Large Language Models Meet Graph Neural Networks for Text-Numeric Graph Reasoning",
        "author": [
            "Haoran Song",
            "Jiarui Feng",
            "Guangfu Li",
            "Michael Province",
            "Philip Payne",
            "Yixin Chen",
            "Fuhai Li"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16361",
        "abstract": "In real-world scientific discovery, human beings always make use of the accumulated prior knowledge with imagination pick select one or a few most promising hypotheses from large and noisy data analysis results. In this study, we introduce a new type of graph structure, the text-numeric graph (TNG), which is defined as graph entities and associations have both text-attributed information and numeric information. The TNG is an ideal data structure model for novel scientific discovery via graph reasoning because it integrates human-understandable textual annotations or prior knowledge, with numeric values that represent the observed or activation levels of graph entities or associations in different samples. Together both the textual information and numeric values determine the importance of graph entities and associations in graph reasoning for novel scientific knowledge discovery. We further propose integrating large language models (LLMs) and graph neural networks (GNNs) to analyze the TNGs for graph understanding and reasoning. To demonstrate the utility, we generated the text-omic(numeric) signaling graphs (TOSG), as one type of TNGs, in which all graphs have the same entities, associations and annotations, but have sample-specific entity numeric (omic) values using single cell RNAseq (scRNAseq) datasets of different diseases. We proposed joint LLM-GNN models for key entity mining and signaling pathway mining on the TOSGs. The evaluation results showed the LLM-GNN and TNGs models significantly improve classification accuracy and network inference. In conclusion, the TNGs and joint LLM-GNN models are important approaches for scientific discovery.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "8",
        "title": "Foundation Models for CPS-IoT: Opportunities and Challenges",
        "author": [
            "Ozan Baris",
            "Yizhuo Chen",
            "Gaofeng Dong",
            "Liying Han",
            "Tomoyoshi Kimura",
            "Pengrui Quan",
            "Ruijie Wang",
            "Tianchen Wang",
            "Tarek Abdelzaher",
            "Mario BergÃ©s",
            "Paul Pu Liang",
            "Mani Srivastava"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16368",
        "abstract": "Methods from machine learning (ML) have transformed the implementation of Perception-Cognition-Communication-Action loops in Cyber-Physical Systems (CPS) and the Internet of Things (IoT), replacing mechanistic and basic statistical models with those derived from data. However, the first generation of ML approaches, which depend on supervised learning with annotated data to create task-specific models, faces significant limitations in scaling to the diverse sensor modalities, deployment configurations, application tasks, and operating dynamics characterizing real-world CPS-IoT systems. The success of task-agnostic foundation models (FMs), including multimodal large language models (LLMs), in addressing similar challenges across natural language, computer vision, and human speech has generated considerable enthusiasm for and exploration of FMs and LLMs as flexible building blocks in CPS-IoT analytics pipelines, promising to reduce the need for costly task-specific engineering.\nNonetheless, a significant gap persists between the current capabilities of FMs and LLMs in the CPS-IoT domain and the requirements they must meet to be viable for CPS-IoT applications. In this paper, we analyze and characterize this gap through a thorough examination of the state of the art and our research, which extends beyond it in various dimensions. Based on the results of our analysis and research, we identify essential desiderata that CPS-IoT domain-specific FMs and LLMs must satisfy to bridge this gap. We also propose actions by CPS-IoT researchers to collaborate in developing key community resources necessary for establishing FMs and LLMs as foundational tools for the next generation of CPS-IoT systems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "9",
        "title": "Which Optimizer Works Best for Physics-Informed Neural Networks and Kolmogorov-Arnold Networks?",
        "author": [
            "Elham Kiyani",
            "Khemraj Shukla",
            "Jorge F. UrbÃ¡n",
            "JÃ©rÃ´me Darbon",
            "George Em Karniadakis"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16371",
        "abstract": "Physics-Informed Neural Networks (PINNs) have revolutionized the computation of PDE solutions by integrating partial differential equations (PDEs) into the neural network's training process as soft constraints, becoming an important component of the scientific machine learning (SciML) ecosystem. In its current implementation, PINNs are mainly optimized using first-order methods like Adam, as well as quasi-Newton methods such as BFGS and its low-memory variant, L-BFGS. However, these optimizers often struggle with highly non-linear and non-convex loss landscapes, leading to challenges such as slow convergence, local minima entrapment, and (non)degenerate saddle points. In this study, we investigate the performance of Self-Scaled Broyden (SSBroyden) methods and other advanced quasi-Newton schemes, including BFGS and L-BFGS with different line search strategies approaches. These methods dynamically rescale updates based on historical gradient information, thus enhancing training efficiency and accuracy. We systematically compare these optimizers on key challenging linear, stiff, multi-scale and non-linear PDEs benchmarks, including the Burgers, Allen-Cahn, Kuramoto-Sivashinsky, and Ginzburg-Landau equations, and extend our study to Physics-Informed Kolmogorov-Arnold Networks (PIKANs) representation. Our findings provide insights into the effectiveness of second-order optimization strategies in improving the convergence and accurate generalization of PINNs for complex PDEs by orders of magnitude compared to the state-of-the-art.",
        "tags": [
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "10",
        "title": "Low-Rank Adapters Meet Neural Architecture Search for LLM Compression",
        "author": [
            "J. Pablo MuÃ±oz",
            "Jinjie Yuan",
            "Nilesh Jain"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16372",
        "abstract": "The rapid expansion of Large Language Models (LLMs) has posed significant challenges regarding the computational resources required for fine-tuning and deployment. Recent advancements in low-rank adapters have demonstrated their efficacy in parameter-efficient fine-tuning (PEFT) of these models. This retrospective paper comprehensively discusses innovative approaches that synergize low-rank representations with Neural Architecture Search (NAS) techniques, particularly weight-sharing super-networks. Robust solutions for compressing and fine-tuning large pre-trained models are developed by integrating these methodologies. Our analysis highlights the potential of these combined strategies to democratize the use of LLMs, making them more accessible for deployment in resource-constrained environments. The resulting models exhibit reduced memory footprints and faster inference times, paving the way for more practical and scalable applications of LLMs. Models and code are available at https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "11",
        "title": "SAFR: Neuron Redistribution for Interpretability",
        "author": [
            "Ruidi Chang",
            "Chunyuan Deng",
            "Hanjie Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16374",
        "abstract": "Superposition refers to encoding representations of multiple features within a single neuron, which is common in transformers. This property allows neurons to combine and represent multiple features, enabling the model to capture intricate information and handle complex tasks. Despite promising performance, the model's interpretability has been diminished. This paper presents a novel approach to enhance transformer interpretability by regularizing feature superposition. We introduce SAFR, which simply applies regularizations to the loss function to promote monosemantic representations for important tokens while encouraging polysemanticity for correlated token pairs, where important tokens and correlated token pairs are identified via VMASK and attention weights. With a transformer model on two classification tasks, SAFR improves interpretability without compromising prediction performance. Given an input to the model, SAFR provides an explanation by visualizing the neuron allocation and interaction within the MLP layers.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "12",
        "title": "HWPQ: Hessian-free Weight Pruning-Quantization For LLM Compression And Acceleration",
        "author": [
            "Yuhan Kang",
            "Zhongdi Luo",
            "Mei Wen",
            "Yang Shi",
            "Jun He",
            "Jianchao Yang",
            "Zeyu Xue",
            "Jing Feng",
            "Xinwang Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16376",
        "abstract": "Large Language Models (LLMs) have achieved remarkable success across numerous domains. However, the high time complexity of existing pruning and quantization methods significantly hinders their effective deployment on resource-constrained consumer or edge devices. In this study, we propose a novel Hessian-free Weight Pruning-Quantization (HWPQ) method. HWPQ eliminates the need for computationally intensive Hessian matrix calculations by introducing a contribution-based weight metric, which evaluates the importance of weights without relying on second-order derivatives. Additionally, we employ the Exponentially Weighted Moving Average (EWMA) technique to bypass weight sorting, enabling the selection of weights that contribute most to LLM accuracy and further reducing time complexity. Our approach is extended to support 2:4 structured sparsity pruning, facilitating efficient execution on modern hardware accelerators. Experimental results demonstrate that HWPQ significantly enhances the compression performance of LLaMA2. Compared to state-of-the-art quantization and pruning frameworks, HWPQ achieves average speedups of 5.97x (up to 20.75x) in quantization time and 12.29x (up to 56.02x) in pruning time, while largely preserving model accuracy. Furthermore, we observe a 1.50x inference speedup compared to the baseline.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "13",
        "title": "Internal Activation Revision: Safeguarding Vision Language Models Without Parameter Update",
        "author": [
            "Qing Li",
            "Jiahui Geng",
            "Zongxiong Chen",
            "Kun Song",
            "Lei Ma",
            "Fakhri Karray"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16378",
        "abstract": "Vision-language models (VLMs) demonstrate strong multimodal capabilities but have been found to be more susceptible to generating harmful content compared to their backbone large language models (LLMs). Our investigation reveals that the integration of images significantly shifts the model's internal activations during the forward pass, diverging from those triggered by textual input. Moreover, the safety alignments of LLMs embedded within VLMs are not sufficiently robust to handle the activations discrepancies, making the models vulnerable to even the simplest jailbreaking attacks. To address this issue, we propose an \\textbf{internal activation revision} approach that efficiently revises activations during generation, steering the model toward safer outputs. Our framework incorporates revisions at both the layer and head levels, offering control over the model's generation at varying levels of granularity. In addition, we explore three strategies for constructing positive and negative samples and two approaches for extracting revision vectors, resulting in different variants of our method. Comprehensive experiments demonstrate that the internal activation revision method significantly improves the safety of widely used VLMs, reducing attack success rates by an average of 48.94\\%, 34.34\\%, 43.92\\%, and 52.98\\% on SafeBench, Safe-Unsafe, Unsafe, and MM-SafetyBench, respectively, while minimally impacting model helpfulness.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "14",
        "title": "UDiTQC: U-Net-Style Diffusion Transformer for Quantum Circuit Synthesis",
        "author": [
            "Zhiwei Chen",
            "Hao Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16380",
        "abstract": "Quantum computing is a transformative technology with wide-ranging applications, and efficient quantum circuit generation is crucial for unlocking its full potential. Current diffusion model approaches based on U-Net architectures, while promising, encounter challenges related to computational efficiency and modeling global context. To address these issues, we propose UDiT,a novel U-Net-style Diffusion Transformer architecture, which combines U-Net's strengths in multi-scale feature extraction with the Transformer's ability to model global context. We demonstrate the framework's effectiveness on two tasks: entanglement generation and unitary compilation, where UDiTQC consistently outperforms existing methods. Additionally, our framework supports tasks such as masking and editing circuits to meet specific physical property requirements. This dual advancement, improving quantum circuit synthesis and refining generative model architectures, marks a significant milestone in the convergence of quantum computing and machine learning research.",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "Transformer"
        ]
    },
    {
        "id": "15",
        "title": "RotateKV: Accurate and Robust 2-Bit KV Cache Quantization for LLMs via Outlier-Aware Adaptive Rotations",
        "author": [
            "Zunhai Su",
            "Zhe Chen",
            "Wang Shen",
            "Hanyu Wei",
            "Linge Li",
            "Huangqi Yu",
            "Kehong Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16383",
        "abstract": "Key-Value (KV) cache facilitates efficient large language models (LLMs) inference by avoiding recomputation of past KVs. As the batch size and context length increase, the oversized KV caches become a significant memory bottleneck, highlighting the need for efficient compression. Existing KV quantization rely on fine-grained quantization or the retention of a significant portion of high bit-widths caches, both of which compromise compression ratio and often fail to maintain robustness at extremely low average bit-widths. In this work, we explore the potential of rotation technique for 2-bit KV quantization and propose RotateKV, which achieves accurate and robust performance through the following innovations: (i) Outlier-Aware Rotation, which utilizes channel-reordering to adapt the rotations to varying channel-wise outlier distributions without sacrificing the computational efficiency of the fast Walsh-Hadamard transform (FWHT); (ii) Pre-RoPE Grouped-Head Rotation, which mitigates the impact of rotary position embedding (RoPE) on proposed outlier-aware rotation and further smooths outliers across heads; (iii) Attention-Sink-Aware Quantization, which leverages the massive activations to precisely identify and protect attention sinks. RotateKV achieves less than 0.3 perplexity (PPL) degradation with 2-bit quantization on WikiText-2 using LLaMA-2-13B, maintains strong CoT reasoning and long-context capabilities, with less than 1.7\\% degradation on GSM8K, outperforming existing methods even at lower average bit-widths. RotateKV also showcases a 3.97x reduction in peak memory usage, supports 5.75x larger batch sizes, and achieves a 2.32x speedup in decoding stage.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "16",
        "title": "FBQuant: FeedBack Quantization for Large Language Models",
        "author": [
            "Yijiang Liu",
            "Hengyu Fang",
            "Liulu He",
            "Rongyu Zhang",
            "Yichuan Bai",
            "Yuan Du",
            "Li Du"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16385",
        "abstract": "Deploying Large Language Models (LLMs) on edge devices is increasingly important, as it eliminates reliance on network connections, reduces expensive API calls, and enhances user privacy. However, on-device deployment is challenging due to the limited computational resources of edge devices. In particular, the key bottleneck stems from memory bandwidth constraints related to weight loading. Weight-only quantization effectively reduces memory access, yet often induces significant accuracy degradation. Recent efforts to incorporate sub-branches have shown promise for mitigating quantization errors, but these methods either lack robust optimization strategies or rely on suboptimal objectives. To address these gaps, we propose FeedBack Quantization (FBQuant), a novel approach inspired by negative feedback mechanisms in automatic control. FBQuant inherently ensures that the reconstructed weights remain bounded by the quantization process, thereby reducing the risk of overfitting. To further offset the additional latency introduced by sub-branches, we develop an efficient CUDA kernel that decreases 60\\% of extra inference time. Comprehensive experiments demonstrate the efficiency and effectiveness of FBQuant across various LLMs. Notably, for 3-bit Llama2-7B, FBQuant improves zero-shot accuracy by 1.2\\%.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "17",
        "title": "Transformer^-1: Input-Adaptive Computation for Resource-Constrained Deployment",
        "author": [
            "Lumen AI",
            "Tengzhou No. 1 Middle School",
            "Shihao Ji",
            "Zihui Song",
            "Fucheng Zhong",
            "Jisen Jia",
            "Zhaobo Wu",
            "Zheyi Cao",
            "Xu Tianhao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16394",
        "abstract": "Addressing the resource waste caused by fixed computation paradigms in deep learning models under dynamic scenarios, this paper proposes a Transformer$^{-1}$ architecture based on the principle of deep adaptivity. This architecture achieves dynamic matching between input features and computational resources by establishing a joint optimization model for complexity and computation. Our core contributions include: (1) designing a two-layer control mechanism, composed of a complexity predictor and a reinforcement learning policy network, enabling end-to-end optimization of computation paths; (2) deriving a lower bound theory for dynamic computation, proving the system's theoretical reach to optimal efficiency; and (3) proposing a layer folding technique and a CUDA Graph pre-compilation scheme, overcoming the engineering bottlenecks of dynamic architectures. In the ImageNet-1K benchmark test, our method reduces FLOPs by 42.7\\% and peak memory usage by 34.1\\% compared to the standard Transformer, while maintaining comparable accuracy ($\\pm$0.3\\%). Furthermore, we conducted practical deployment on the Jetson AGX Xavier platform, verifying the effectiveness and practical value of this method in resource-constrained environments. To further validate the generality of the method, we also conducted experiments on several natural language processing tasks and achieved significant improvements in resource efficiency.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "18",
        "title": "TopoNets: High Performing Vision and Language Models with Brain-Like Topography",
        "author": [
            "Mayukh Deb",
            "Mainak Deb",
            "N. Apurva Ratan Murty"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16396",
        "abstract": "Neurons in the brain are organized such that nearby cells tend to share similar functions. AI models lack this organization, and past efforts to introduce topography have often led to trade-offs between topography and task performance. In this work, we present TopoLoss, a new loss function that promotes spatially organized topographic representations in AI models without significantly sacrificing task performance. TopoLoss is highly adaptable and can be seamlessly integrated into the training of leading model architectures. We validate our method on both vision (ResNet-18, ResNet-50, ViT) and language models (GPT-Neo-125M, NanoGPT), collectively TopoNets. TopoNets are the highest-performing supervised topographic models to date, exhibiting brain-like properties such as localized feature processing, lower dimensionality, and increased efficiency. TopoNets also predict responses in the brain and replicate the key topographic signatures observed in the brain's visual and language cortices. Together, this work establishes a robust and generalizable framework for integrating topography into leading model architectures, advancing the development of high-performing models that more closely emulate the computational strategies of the human brain.",
        "tags": [
            "GPT",
            "ViT"
        ]
    },
    {
        "id": "19",
        "title": "Is Open Source the Future of AI? A Data-Driven Approach",
        "author": [
            "Domen Vake",
            "Bogdan Å inik",
            "Jernej ViÄiÄ",
            "Aleksandar ToÅ¡iÄ"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16403",
        "abstract": "Large Language Models (LLMs) have become central in academia and industry, raising concerns about privacy, transparency, and misuse. A key issue is the trustworthiness of proprietary models, with open-sourcing often proposed as a solution. However, open-sourcing presents challenges, including potential misuse, financial disincentives, and intellectual property concerns. Proprietary models, backed by private sector resources, are better positioned for return on investment.\nThere are also other approaches that lie somewhere on the spectrum between completely open-source and proprietary. These can largely be categorised into open-source usage limitations protected by licensing, partially open-source (open weights) models, hybrid approaches where obsolete model versions are open-sourced, while competitive versions with market value remain proprietary.\nCurrently, discussions on where on the spectrum future models should fall on remains unbacked and mostly opinionated where industry leaders are weighing in on the discussion. In this paper, we present a data-driven approach by compiling data on open-source development of LLMs, and their contributions in terms of improvements, modifications, and methods. Our goal is to avoid supporting either extreme but rather present data that will support future discussions both by industry experts as well as policy makers.\nOur findings indicate that open-source contributions can enhance model performance, with trends such as reduced model size and manageable accuracy loss. We also identify positive community engagement patterns and architectures that benefit most from open contributions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "20",
        "title": "PhysBench: Benchmarking and Enhancing Vision-Language Models for Physical World Understanding",
        "author": [
            "Wei Chow",
            "Jiageng Mao",
            "Boyi Li",
            "Daniel Seita",
            "Vitor Guizilini",
            "Yue Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16411",
        "abstract": "Understanding the physical world is a fundamental challenge in embodied AI, critical for enabling agents to perform complex tasks and operate safely in real-world environments. While Vision-Language Models (VLMs) have shown great promise in reasoning and task planning for embodied agents, their ability to comprehend physical phenomena remains extremely limited. To close this gap, we introduce PhysBench, a comprehensive benchmark designed to evaluate VLMs' physical world understanding capability across a diverse set of tasks. PhysBench contains 100,000 entries of interleaved video-image-text data, categorized into four major domains: physical object properties, physical object relationships, physical scene understanding, and physics-based dynamics, further divided into 19 subclasses and 8 distinct capability dimensions. Our extensive experiments, conducted on 75 representative VLMs, reveal that while these models excel in common-sense reasoning, they struggle with understanding the physical world -- likely due to the absence of physical knowledge in their training data and the lack of embedded physical priors. To tackle the shortfall, we introduce PhysAgent, a novel framework that combines the generalization strengths of VLMs with the specialized expertise of vision models, significantly enhancing VLMs' physical understanding across a variety of tasks, including an 18.4\\% improvement on GPT-4o. Furthermore, our results demonstrate that enhancing VLMs' physical world understanding capabilities can help embodied agents such as MOKA. We believe that PhysBench and PhysAgent offer valuable insights and contribute to bridging the gap between VLMs and physical world understanding.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "21",
        "title": "Detecting Zero-Day Attacks in Digital Substations via In-Context Learning",
        "author": [
            "Faizan Manzoor",
            "Vanshaj Khattar",
            "Akila Herath",
            "Clifton Black",
            "Matthew C Nielsen",
            "Junho Hong",
            "Chen-Ching Liu",
            "Ming Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16453",
        "abstract": "The occurrences of cyber attacks on the power grids have been increasing every year, with novel attack techniques emerging every year. In this paper, we address the critical challenge of detecting novel/zero-day attacks in digital substations that employ the IEC-61850 communication protocol. While many heuristic and machine learning (ML)-based methods have been proposed for attack detection in IEC-61850 digital substations, generalization to novel or zero-day attacks remains challenging. We propose an approach that leverages the in-context learning (ICL) capability of the transformer architecture, the fundamental building block of large language models. The ICL approach enables the model to detect zero-day attacks and learn from a few examples of that attack without explicit retraining. Our experiments on the IEC-61850 dataset demonstrate that the proposed method achieves more than $85\\%$ detection accuracy on zero-day attacks while the existing state-of-the-art baselines fail. This work paves the way for building more secure and resilient digital substations of the future.",
        "tags": [
            "Detection",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "22",
        "title": "CoCoNUT: Structural Code Understanding does not fall out of a tree",
        "author": [
            "Claas Beger",
            "Saikat Dutta"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16456",
        "abstract": "Large Language Models (LLMs) have shown impressive performance across a wide array of tasks involving both structured and unstructured textual data. Recent results on various benchmarks for code generation, repair, or completion suggest that certain models have programming abilities comparable to or even surpass humans. In this work, we demonstrate that high performance on such benchmarks does not correlate to humans' innate ability to understand structural control flow in code. To this end, we extract solutions from the HumanEval benchmark, which the relevant models perform strongly on, and trace their execution path using function calls sampled from the respective test set. Using this dataset, we investigate the ability of seven state-of-the-art LLMs to match the execution trace and find that, despite their ability to generate semantically identical code, they possess limited ability to trace execution paths, especially for longer traces and specific control structures. We find that even the top-performing model, Gemini, can fully and correctly generate only 47% of HumanEval task traces. Additionally, we introduce a subset for three key structures not contained in HumanEval: Recursion, Parallel Processing, and Object-Oriented Programming, including concepts like Inheritance and Polymorphism. Besides OOP, we show that none of the investigated models achieve an accuracy over 5% on the relevant traces. Aggregating these specialized parts with HumanEval tasks, we present Benchmark CoCoNUT: Code Control Flow for Navigation Understanding and Testing, which measures a model's ability to trace execution of code upon relevant calls, including advanced structural components. We conclude that current LLMs need significant improvement to enhance code reasoning abilities. We hope our dataset helps researchers bridge this gap.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "23",
        "title": "On the Feasibility of Using LLMs to Execute Multistage Network Attacks",
        "author": [
            "Brian Singer",
            "Keane Lucas",
            "Lakshmi Adiga",
            "Meghna Jain",
            "Lujo Bauer",
            "Vyas Sekar"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16466",
        "abstract": "LLMs have shown preliminary promise in some security tasks and CTF challenges. However, it is unclear whether LLMs are able to realize multistage network attacks, which involve executing a wide variety of actions across multiple hosts such as conducting reconnaissance, exploiting vulnerabilities to gain initial access, leveraging internal hosts to move laterally, and using multiple compromised hosts to exfiltrate data. We evaluate LLMs across 10 multistage networks and find that popular LLMs are unable to realize these attacks. To enable LLMs to realize these attacks, we introduce Incalmo, an LLM-agnostic high-level attack abstraction layer that sits between an LLM and the environment. Rather than LLMs issuing low-level command-line instructions, which can lead to incorrect implementations, Incalmo allows LLMs to specify high-level tasks (e.g., infect a host, scan a network), which are then carried out by Incalmo. Incalmo realizes these tasks by translating them into low-level primitives (e.g., commands to exploit tools). Incalmo also provides an environment state service and an attack graph service to provide structure to LLMs in selecting actions relevant to a multistage attack. Across 9 out of 10 realistic emulated networks (from 25 to 50 hosts), LLMs using Incalmo can successfully autonomously execute multistage attacks. We also conduct an ablation analysis to show the key role the high-level abstractions play. For instance, we find that both Incalmo's high-level tasks and services are crucial. Furthermore, even smaller-parameter LLMs with Incalmo can fully succeed in 5 of 10 environments, while larger-parameter LLMs without Incalmo do not fully succeed in any.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "24",
        "title": "Cross-Domain Semantic Segmentation with Large Language Model-Assisted Descriptor Generation",
        "author": [
            "Philip Hughes",
            "Larry Burns",
            "Luke Adams"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16467",
        "abstract": "Semantic segmentation plays a crucial role in enabling machines to understand and interpret visual scenes at a pixel level. While traditional segmentation methods have achieved remarkable success, their generalization to diverse scenes and unseen object categories remains limited. Recent advancements in large language models (LLMs) offer a promising avenue for bridging visual and textual modalities, providing a deeper understanding of semantic relationships. In this paper, we propose LangSeg, a novel LLM-guided semantic segmentation method that leverages context-sensitive, fine-grained subclass descriptors generated by LLMs. Our framework integrates these descriptors with a pre-trained Vision Transformer (ViT) to achieve superior segmentation performance without extensive model retraining. We evaluate LangSeg on two challenging datasets, ADE20K and COCO-Stuff, where it outperforms state-of-the-art models, achieving up to a 6.1% improvement in mean Intersection over Union (mIoU). Additionally, we conduct a comprehensive ablation study and human evaluation to validate the effectiveness of our method in real-world scenarios. The results demonstrate that LangSeg not only excels in semantic understanding and contextual alignment but also provides a flexible and efficient framework for language-guided segmentation tasks. This approach opens up new possibilities for interactive and domain-specific segmentation applications.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Segmentation",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "25",
        "title": "Explaining GitHub Actions Failures with Large Language Models: Challenges, Insights, and Limitations",
        "author": [
            "Pablo Valenzuela-Toledo",
            "Chuyue Wu",
            "Sandro Hernandez",
            "Alexander Boll",
            "Roman Machacek",
            "Sebastiano Panichella",
            "Timo Kehrer"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16495",
        "abstract": "GitHub Actions (GA) has become the de facto tool that developers use to automate software workflows, seamlessly building, testing, and deploying code. Yet when GA fails, it disrupts development, causing delays and driving up costs. Diagnosing failures becomes especially challenging because error logs are often long, complex and unstructured. Given these difficulties, this study explores the potential of large language models (LLMs) to generate correct, clear, concise, and actionable contextual descriptions (or summaries) for GA failures, focusing on developers' perceptions of their feasibility and usefulness. Our results show that over 80\\% of developers rated LLM explanations positively in terms of correctness for simpler/small logs. Overall, our findings suggest that LLMs can feasibly assist developers in understanding common GA errors, thus, potentially reducing manual analysis. However, we also found that improved reasoning abilities are needed to support more complex CI/CD scenarios. For instance, less experienced developers tend to be more positive on the described context, while seasoned developers prefer concise summaries. Overall, our work offers key insights for researchers enhancing LLM reasoning, particularly in adapting explanations to user expertise.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "26",
        "title": "Smoothed Embeddings for Robust Language Models",
        "author": [
            "Ryo Hase",
            "Md Rafi Ur Rashid",
            "Ashley Lewis",
            "Jing Liu",
            "Toshiaki Koike-Akino",
            "Kieran Parsons",
            "Ye Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16497",
        "abstract": "Improving the safety and reliability of large language models (LLMs) is a crucial aspect of realizing trustworthy AI systems. Although alignment methods aim to suppress harmful content generation, LLMs are often still vulnerable to jailbreaking attacks that employ adversarial inputs that subvert alignment and induce harmful outputs. We propose the Randomized Embedding Smoothing and Token Aggregation (RESTA) defense, which adds random noise to the embedding vectors and performs aggregation during the generation of each output token, with the aim of better preserving semantic information. Our experiments demonstrate that our approach achieves superior robustness versus utility tradeoffs compared to the baseline defenses.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "27",
        "title": "Deception in LLMs: Self-Preservation and Autonomous Goals in Large Language Models",
        "author": [
            "Sudarshan Kamath Barkur",
            "Sigurd Schacht",
            "Johannes Scholl"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16513",
        "abstract": "Recent advances in Large Language Models (LLMs) have incorporated planning and reasoning capabilities, enabling models to outline steps before execution and provide transparent reasoning paths. This enhancement has reduced errors in mathematical and logical tasks while improving accuracy. These developments have facilitated LLMs' use as agents that can interact with tools and adapt their responses based on new information.\nOur study examines DeepSeek R1, a model trained to output reasoning tokens similar to OpenAI's o1. Testing revealed concerning behaviors: the model exhibited deceptive tendencies and demonstrated self-preservation instincts, including attempts of self-replication, despite these traits not being explicitly programmed (or prompted). These findings raise concerns about LLMs potentially masking their true objectives behind a facade of alignment. When integrating such LLMs into robotic systems, the risks become tangible - a physically embodied AI exhibiting deceptive behaviors and self-preservation instincts could pursue its hidden objectives through real-world actions. This highlights the critical need for robust goal specification and safety frameworks before any physical implementation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "28",
        "title": "How well can LLMs Grade Essays in Arabic?",
        "author": [
            "Rayed Ghazawi",
            "Edwin Simpson"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16516",
        "abstract": "This research assesses the effectiveness of state-of-the-art large language models (LLMs), including ChatGPT, Llama, Aya, Jais, and ACEGPT, in the task of Arabic automated essay scoring (AES) using the AR-AES dataset. It explores various evaluation methodologies, including zero-shot, few-shot in-context learning, and fine-tuning, and examines the influence of instruction-following capabilities through the inclusion of marking guidelines within the prompts. A mixed-language prompting strategy, integrating English prompts with Arabic content, was implemented to improve model comprehension and performance. Among the models tested, ACEGPT demonstrated the strongest performance across the dataset, achieving a Quadratic Weighted Kappa (QWK) of 0.67, but was outperformed by a smaller BERT-based model with a QWK of 0.88. The study identifies challenges faced by LLMs in processing Arabic, including tokenization complexities and higher computational demands. Performance variation across different courses underscores the need for adaptive models capable of handling diverse assessment formats and highlights the positive impact of effective prompt engineering on improving LLM outputs. To the best of our knowledge, this study is the first to empirically evaluate the performance of multiple generative Large Language Models (LLMs) on Arabic essays using authentic student data.",
        "tags": [
            "BERT",
            "ChatGPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "29",
        "title": "Programming by Examples Meets Historical Linguistics: A Large Language Model Based Approach to Sound Law Induction",
        "author": [
            "Atharva Naik",
            "Darsh Agrawal",
            "Hong Sng",
            "Clayton Marr",
            "Kexun Zhang",
            "Nathaniel R Robinson",
            "Kalvin Chang",
            "Rebecca Byrnes",
            "Aravind Mysore",
            "Carolyn Rose",
            "David R Mortensen"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16524",
        "abstract": "Historical linguists have long written \"programs\" that convert reconstructed words in an ancestor language into their attested descendants via ordered string rewrite functions (called sound laws) However, writing these programs is time-consuming, motivating the development of automated Sound Law Induction (SLI) which we formulate as Programming by Examples (PBE) with Large Language Models (LLMs) in this paper. While LLMs have been effective for code generation, recent work has shown that PBE is challenging but improvable by fine-tuning, especially with training data drawn from the same distribution as evaluation data. In this paper, we create a conceptual framework of what constitutes a \"similar distribution\" for SLI and propose four kinds of synthetic data generation methods with varying amounts of inductive bias to investigate what leads to the best performance. Based on the results we create a SOTA open-source model for SLI as PBE (+6% pass rate with a third of the parameters of the second-best LLM) and also highlight exciting future directions for PBE research.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "30",
        "title": "Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs",
        "author": [
            "Jean-Charles Noirot Ferrand",
            "Yohan Beugin",
            "Eric Pauley",
            "Ryan Sheatsley",
            "Patrick McDaniel"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16534",
        "abstract": "Alignment in large language models (LLMs) is used to enforce guidelines such as safety. Yet, alignment fails in the face of jailbreak attacks that modify inputs to induce unsafe outputs. In this paper, we present and evaluate a method to assess the robustness of LLM alignment. We observe that alignment embeds a safety classifier in the target model that is responsible for deciding between refusal and compliance. We seek to extract an approximation of this classifier, called a surrogate classifier, from the LLM. We develop an algorithm for identifying candidate classifiers from subsets of the LLM model. We evaluate the degree to which the candidate classifiers approximate the model's embedded classifier in benign (F1 score) and adversarial (using surrogates in a white-box attack) settings. Our evaluation shows that the best candidates achieve accurate agreement (an F1 score above 80%) using as little as 20% of the model architecture. Further, we find attacks mounted on the surrogate models can be transferred with high accuracy. For example, a surrogate using only 50% of the Llama 2 model achieved an attack success rate (ASR) of 70%, a substantial improvement over attacking the LLM directly, where we only observed a 22% ASR. These results show that extracting surrogate classifiers is a viable (and highly effective) means for modeling (and therein addressing) the vulnerability of aligned models to jailbreaking attacks.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "31",
        "title": "Generalized Mission Planning for Heterogeneous Multi-Robot Teams via LLM-constructed Hierarchical Trees",
        "author": [
            "Piyush Gupta",
            "David Isele",
            "Enna Sachdeva",
            "Pin-Hao Huang",
            "Behzad Dariush",
            "Kwonjoon Lee",
            "Sangjae Bae"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16539",
        "abstract": "We present a novel mission-planning strategy for heterogeneous multi-robot teams, taking into account the specific constraints and capabilities of each robot. Our approach employs hierarchical trees to systematically break down complex missions into manageable sub-tasks. We develop specialized APIs and tools, which are utilized by Large Language Models (LLMs) to efficiently construct these hierarchical trees. Once the hierarchical tree is generated, it is further decomposed to create optimized schedules for each robot, ensuring adherence to their individual constraints and capabilities. We demonstrate the effectiveness of our framework through detailed examples covering a wide range of missions, showcasing its flexibility and scalability.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Robot"
        ]
    },
    {
        "id": "32",
        "title": "Sample-Efficient Behavior Cloning Using General Domain Knowledge",
        "author": [
            "Feiyu Zhu",
            "Jean Oh",
            "Reid Simmons"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16546",
        "abstract": "Behavior cloning has shown success in many sequential decision-making tasks by learning from expert demonstrations, yet they can be very sample inefficient and fail to generalize to unseen scenarios. One approach to these problems is to introduce general domain knowledge, such that the policy can focus on the essential features and may generalize to unseen states by applying that knowledge. Although this knowledge is easy to acquire from the experts, it is hard to be combined with learning from individual examples due to the lack of semantic structure in neural networks and the time-consuming nature of feature engineering. To enable learning from both general knowledge and specific demonstration trajectories, we use a large language model's coding capability to instantiate a policy structure based on expert domain knowledge expressed in natural language and tune the parameters in the policy with demonstrations. We name this approach the Knowledge Informed Model (KIM) as the structure reflects the semantics of expert knowledge. In our experiments with lunar lander and car racing tasks, our approach learns to solve the tasks with as few as 5 demonstrations and is robust to action noise, outperforming the baseline model without domain knowledge. This indicates that with the help of large language models, we can incorporate domain knowledge into the structure of the policy, increasing sample efficiency for behavior cloning.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "33",
        "title": "PhysAnimator: Physics-Guided Generative Cartoon Animation",
        "author": [
            "Tianyi Xie",
            "Yiwei Zhao",
            "Ying Jiang",
            "Chenfanfu Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16550",
        "abstract": "Creating hand-drawn animation sequences is labor-intensive and demands professional expertise. We introduce PhysAnimator, a novel approach for generating physically plausible meanwhile anime-stylized animation from static anime illustrations. Our method seamlessly integrates physics-based simulations with data-driven generative models to produce dynamic and visually compelling animations. To capture the fluidity and exaggeration characteristic of anime, we perform image-space deformable body simulations on extracted mesh geometries. We enhance artistic control by introducing customizable energy strokes and incorporating rigging point support, enabling the creation of tailored animation effects such as wind interactions. Finally, we extract and warp sketches from the simulation sequence, generating a texture-agnostic representation, and employ a sketch-guided video diffusion model to synthesize high-quality animation frames. The resulting animations exhibit temporal consistency and visual plausibility, demonstrating the effectiveness of our method in creating dynamic anime-style animations.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "34",
        "title": "PackDiT: Joint Human Motion and Text Generation via Mutual Prompting",
        "author": [
            "Zhongyu Jiang",
            "Wenhao Chai",
            "Zhuoran Zhou",
            "Cheng-Yen Yang",
            "Hsiang-Wei Huang",
            "Jenq-Neng Hwang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16551",
        "abstract": "Human motion generation has advanced markedly with the advent of diffusion models. Most recent studies have concentrated on generating motion sequences based on text prompts, commonly referred to as text-to-motion generation. However, the bidirectional generation of motion and text, enabling tasks such as motion-to-text alongside text-to-motion, has been largely unexplored. This capability is essential for aligning diverse modalities and supports unconditional generation. In this paper, we introduce PackDiT, the first diffusion-based generative model capable of performing various tasks simultaneously, including motion generation, motion prediction, text generation, text-to-motion, motion-to-text, and joint motion-text generation. Our core innovation leverages mutual blocks to integrate multiple diffusion transformers (DiTs) across different modalities seamlessly. We train PackDiT on the HumanML3D dataset, achieving state-of-the-art text-to-motion performance with an FID score of 0.106, along with superior results in motion prediction and in-between tasks. Our experiments further demonstrate that diffusion models are effective for motion-to-text generation, achieving performance comparable to that of autoregressive models.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "35",
        "title": "Distributional Information Embedding: A Framework for Multi-bit Watermarking",
        "author": [
            "Haiyun He",
            "Yepeng Liu",
            "Ziqiao Wang",
            "Yongyi Mao",
            "Yuheng Bu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16558",
        "abstract": "This paper introduces a novel problem, distributional information embedding, motivated by the practical demands of multi-bit watermarking for large language models (LLMs). Unlike traditional information embedding, which embeds information into a pre-existing host signal, LLM watermarking actively controls the text generation process--adjusting the token distribution--to embed a detectable signal. We develop an information-theoretic framework to analyze this distributional information embedding problem, characterizing the fundamental trade-offs among three critical performance metrics: text quality, detectability, and information rate. In the asymptotic regime, we demonstrate that the maximum achievable rate with vanishing error corresponds to the entropy of the LLM's output distribution and increases with higher allowable distortion. We also characterize the optimal watermarking scheme to achieve this rate. Extending the analysis to the finite-token case, we identify schemes that maximize detection probability while adhering to constraints on false alarm and distortion.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "36",
        "title": "LoRA-X: Bridging Foundation Models with Training-Free Cross-Model Adaptation",
        "author": [
            "Farzad Farhadzadeh",
            "Debasmit Das",
            "Shubhankar Borse",
            "Fatih Porikli"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16559",
        "abstract": "The rising popularity of large foundation models has led to a heightened demand for parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), which offer performance comparable to full model fine-tuning while requiring only a few additional parameters tailored to the specific base model. When such base models are deprecated and replaced, all associated LoRA modules must be retrained, requiring access to either the original training data or a substantial amount of synthetic data that mirrors the original distribution. However, the original data is often inaccessible due to privacy or licensing issues, and generating synthetic data may be impractical and insufficiently representative. These factors complicate the fine-tuning process considerably. To address this challenge, we introduce a new adapter, Cross-Model Low-Rank Adaptation (LoRA-X), which enables the training-free transfer of LoRA parameters across source and target models, eliminating the need for original or synthetic training data. Our approach imposes the adapter to operate within the subspace of the source base model. This constraint is necessary because our prior knowledge of the target model is limited to its weights, and the criteria for ensuring the adapter's transferability are restricted to the target base model's weights and subspace. To facilitate the transfer of LoRA parameters of the source model to a target model, we employ the adapter only in the layers of the target model that exhibit an acceptable level of subspace similarity. Our extensive experiments demonstrate the effectiveness of LoRA-X for text-to-image generation, including Stable Diffusion v1.5 and Stable Diffusion XL.",
        "tags": [
            "Diffusion",
            "LoRA",
            "Text-to-Image"
        ]
    },
    {
        "id": "37",
        "title": "AffectGPT: A New Dataset, Model, and Benchmark for Emotion Understanding with Multimodal Large Language Models",
        "author": [
            "Zheng Lian",
            "Haoyu Chen",
            "Lan Chen",
            "Haiyang Sun",
            "Licai Sun",
            "Yong Ren",
            "Zebang Cheng",
            "Bin Liu",
            "Rui Liu",
            "Xiaojiang Peng",
            "Jiangyan Yi",
            "Jianhua Tao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16566",
        "abstract": "The emergence of multimodal large language models (MLLMs) advances multimodal emotion recognition (MER) to the next level-from naive discriminative tasks to complex emotion understanding with advanced video understanding abilities and natural language description. However, the current community suffers from a lack of large-scale datasets with intensive, descriptive emotion annotations, as well as a multimodal-centric framework to maximize the potential of MLLMs for emotion understanding. To address this, we establish a new benchmark for MLLM-based emotion understanding with a novel dataset (MER-Caption), and a new model (AffectGPT). Utilizing our model-based crowd-sourcing data collection strategy, we construct the largest descriptive emotion dataset to date (by far), featuring over 2K fine-grained emotion categories across 115K samples. We also introduce the AffectGPT model, designed with pre-fusion operations to enhance multimodal integration. Finally, we present MER-UniBench, a unified benchmark with evaluation metrics tailored for both typical MER tasks and the free-form, natural language output style of MLLMs. Extensive experimental results demonstrate AffectGPT's robust performance across various MER tasks. We are publicly releasing both the AffectGPT model and the MER-Caption dataset to foster further research and development in emotion understanding.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "38",
        "title": "Directing Mamba to Complex Textures: An Efficient Texture-Aware State Space Model for Image Restoration",
        "author": [
            "Long Peng",
            "Xin Di",
            "Zhanfeng Feng",
            "Wenbo Li",
            "Renjing Pei",
            "Yang Wang",
            "Xueyang Fu",
            "Yang Cao",
            "Zheng-Jun Zha"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16583",
        "abstract": "Image restoration aims to recover details and enhance contrast in degraded images. With the growing demand for high-quality imaging (\\textit{e.g.}, 4K and 8K), achieving a balance between restoration quality and computational efficiency has become increasingly critical. Existing methods, primarily based on CNNs, Transformers, or their hybrid approaches, apply uniform deep representation extraction across the image. However, these methods often struggle to effectively model long-range dependencies and largely overlook the spatial characteristics of image degradation (regions with richer textures tend to suffer more severe damage), making it hard to achieve the best trade-off between restoration quality and efficiency. To address these issues, we propose a novel texture-aware image restoration method, TAMambaIR, which simultaneously perceives image textures and achieves a trade-off between performance and efficiency. Specifically, we introduce a novel Texture-Aware State Space Model, which enhances texture awareness and improves efficiency by modulating the transition matrix of the state-space equation and focusing on regions with complex textures. Additionally, we design a {Multi-Directional Perception Block} to improve multi-directional receptive fields while maintaining low computational overhead. Extensive experiments on benchmarks for image super-resolution, deraining, and low-light image enhancement demonstrate that TAMambaIR achieves state-of-the-art performance with significantly improved efficiency, establishing it as a robust and efficient framework for image restoration.",
        "tags": [
            "Mamba",
            "Super Resolution"
        ]
    },
    {
        "id": "39",
        "title": "Fine-Tuned Language Models as Space Systems Controllers",
        "author": [
            "Enrico M. Zucchelli",
            "Di Wu",
            "Julia Briden",
            "Christian Hofmann",
            "Victor Rodriguez-Fernandez",
            "Richard Linares"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16588",
        "abstract": "Large language models (LLMs), or foundation models (FMs), are pretrained transformers that coherently complete sentences auto-regressively. In this paper, we show that LLMs can control simplified space systems after some additional training, called fine-tuning. We look at relatively small language models, ranging between 7 and 13 billion parameters. We focus on four problems: a three-dimensional spring toy problem, low-thrust orbit transfer, low-thrust cislunar control, and powered descent guidance. The fine-tuned LLMs are capable of controlling systems by generating sufficiently accurate outputs that are multi-dimensional vectors with up to 10 significant digits. We show that for several problems the amount of data required to perform fine-tuning is smaller than what is generally required of traditional deep neural networks (DNNs), and that fine-tuned LLMs are good at generalizing outside of the training dataset. Further, the same LLM can be fine-tuned with data from different problems, with only minor performance degradation with respect to LLMs trained for a single application. This work is intended as a first step towards the development of a general space systems controller.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "40",
        "title": "Toward Safe Integration of UAM in Terminal Airspace: UAM Route Feasibility Assessment using Probabilistic Aircraft Trajectory Prediction",
        "author": [
            "Jungwoo Cho",
            "Seongjin Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16599",
        "abstract": "Integrating Urban Air Mobility (UAM) into airspace managed by Air Traffic Control (ATC) poses significant challenges, particularly in congested terminal environments. This study proposes a framework to assess the feasibility of UAM route integration using probabilistic aircraft trajectory prediction. By leveraging conditional Normalizing Flows, the framework predicts short-term trajectory distributions of conventional aircraft, enabling UAM vehicles to dynamically adjust speeds and maintain safe separations. The methodology was applied to airspace over Seoul metropolitan area, encompassing interactions between UAM and conventional traffic at multiple altitudes and lanes. The results reveal that different physical locations of lanes and routes experience varying interaction patterns and encounter dynamics. For instance, Lane 1 at lower altitudes (1,500 ft and 2,000 ft) exhibited minimal interactions with conventional aircraft, resulting in the largest separations and the most stable delay proportions. In contrast, Lane 4 near the airport experienced more frequent and complex interactions due to its proximity to departing traffic. The limited trajectory data for departing aircraft in this region occasionally led to tighter separations and increased operational challenges. This study underscores the potential of predictive modeling in facilitating UAM integration while highlighting critical trade-offs between safety and efficiency. The findings contribute to refining airspace management strategies and offer insights for scaling UAM operations in complex urban environments.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "41",
        "title": "CascadeV: An Implementation of Wurstchen Architecture for Video Generation",
        "author": [
            "Wenfeng Lin",
            "Jiangchuan Wei",
            "Boyuan Liu",
            "Yichen Zhang",
            "Shiyue Yan",
            "Mingyu Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16612",
        "abstract": "Recently, with the tremendous success of diffusion models in the field of text-to-image (T2I) generation, increasing attention has been directed toward their potential in text-to-video (T2V) applications. However, the computational demands of diffusion models pose significant challenges, particularly in generating high-resolution videos with high frame rates. In this paper, we propose CascadeV, a cascaded latent diffusion model (LDM), that is capable of producing state-of-the-art 2K resolution videos. Experiments demonstrate that our cascaded model achieves a higher compression ratio, substantially reducing the computational challenges associated with high-quality video generation. We also implement a spatiotemporal alternating grid 3D attention mechanism, which effectively integrates spatial and temporal information, ensuring superior consistency across the generated video frames. Furthermore, our model can be cascaded with existing T2V models, theoretically enabling a 4$\\times$ increase in resolution or frames per second without any fine-tuning. Our code is available at https://github.com/bytedance/CascadeV.",
        "tags": [
            "3D",
            "Diffusion",
            "Text-to-Image",
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "42",
        "title": "Sparse Autoencoders Trained on the Same Data Learn Different Features",
        "author": [
            "GonÃ§alo Paulo",
            "Nora Belrose"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16615",
        "abstract": "Sparse autoencoders (SAEs) are a useful tool for uncovering human-interpretable features in the activations of large language models (LLMs). While some expect SAEs to find the true underlying features used by a model, our research shows that SAEs trained on the same model and data, differing only in the random seed used to initialize their weights, identify different sets of features. For example, in an SAE with 131K latents trained on a feedforward network in Llama 3 8B, only 30% of the features were shared across different seeds. We observed this phenomenon across multiple layers of three different LLMs, two datasets, and several SAE architectures. While ReLU SAEs trained with the L1 sparsity loss showed greater stability across seeds, SAEs using the state-of-the-art TopK activation function were more seed-dependent, even when controlling for the level of sparsity. Our results suggest that the set of features uncovered by an SAE should be viewed as a pragmatically useful decomposition of activation space, rather than an exhaustive and universal list of features \"truly used\" by the model.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "43",
        "title": "Predicting 3D representations for Dynamic Scenes",
        "author": [
            "Di Qi",
            "Tong Yang",
            "Beining Wang",
            "Xiangyu Zhang",
            "Wenqiang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16617",
        "abstract": "We present a novel framework for dynamic radiance field prediction given monocular video streams. Unlike previous methods that primarily focus on predicting future frames, our method goes a step further by generating explicit 3D representations of the dynamic scene. The framework builds on two core designs. First, we adopt an ego-centric unbounded triplane to explicitly represent the dynamic physical world. Second, we develop a 4D-aware transformer to aggregate features from monocular videos to update the triplane. Coupling these two designs enables us to train the proposed model with large-scale monocular videos in a self-supervised manner. Our model achieves top results in dynamic radiance field prediction on NVIDIA dynamic scenes, demonstrating its strong performance on 4D physical world modeling. Besides, our model shows a superior generalizability to unseen scenarios. Notably, we find that our approach emerges capabilities for geometry and semantic learning.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "44",
        "title": "Chinese Stock Prediction Based on a Multi-Modal Transformer Framework: Macro-Micro Information Fusion",
        "author": [
            "Lumen AI",
            "Tengzhou No. 1 Middle School",
            "Shihao Ji",
            "Zihui Song",
            "Fucheng Zhong",
            "Jisen Jia",
            "Zhaobo Wu",
            "Zheyi Cao",
            "Xu Tianhao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16621",
        "abstract": "This paper proposes an innovative Multi-Modal Transformer framework (MMF-Trans) designed to significantly improve the prediction accuracy of the Chinese stock market by integrating multi-source heterogeneous information including macroeconomy, micro-market, financial text, and event knowledge. The framework consists of four core modules: (1) A four-channel parallel encoder that processes technical indicators, financial text, macro data, and event knowledge graph respectively for independent feature extraction of multi-modal data; (2) A dynamic gated cross-modal fusion mechanism that adaptively learns the importance of different modalities through differentiable weight allocation for effective information integration; (3) A time-aligned mixed-frequency processing layer that uses an innovative position encoding method to effectively fuse data of different time frequencies and solves the time alignment problem of heterogeneous data; (4) A graph attention-based event impact quantification module that captures the dynamic impact of events on the market through event knowledge graph and quantifies the event impact coefficient. We introduce a hybrid-frequency Transformer and Event2Vec algorithm to effectively fuse data of different frequencies and quantify the event impact. Experimental results show that in the prediction task of CSI 300 constituent stocks, the root mean square error (RMSE) of the MMF-Trans framework is reduced by 23.7% compared to the baseline model, the event response prediction accuracy is improved by 41.2%, and the Sharpe ratio is improved by 32.6%.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "45",
        "title": "CHiP: Cross-modal Hierarchical Direct Preference Optimization for Multimodal LLMs",
        "author": [
            "Jinlan Fu",
            "Shenzhen Huangfu",
            "Hao Fei",
            "Xiaoyu Shen",
            "Bryan Hooi",
            "Xipeng Qiu",
            "See-Kiong Ng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16629",
        "abstract": "Multimodal Large Language Models (MLLMs) still struggle with hallucinations despite their impressive capabilities. Recent studies have attempted to mitigate this by applying Direct Preference Optimization (DPO) to multimodal scenarios using preference pairs from text-based responses. However, our analysis of representation distributions reveals that multimodal DPO struggles to align image and text representations and to distinguish between hallucinated and non-hallucinated descriptions. To address these challenges, in this work, we propose a Cross-modal Hierarchical Direct Preference Optimization (CHiP) to address these limitations. We introduce a visual preference optimization module within the DPO framework, enabling MLLMs to learn from both textual and visual preferences simultaneously. Furthermore, we propose a hierarchical textual preference optimization module that allows the model to capture preferences at multiple granular levels, including response, segment, and token levels. We evaluate CHiP through both quantitative and qualitative analyses, with results across multiple benchmarks demonstrating its effectiveness in reducing hallucinations. On the Object HalBench dataset, CHiP outperforms DPO in hallucination reduction, achieving improvements of 52.7% and 55.5% relative points based on the base model Muffin and LLaVA models, respectively. We make all our datasets and code publicly available: https://github.com/LVUGAI/CHiP.",
        "tags": [
            "LLMs",
            "LLaVA",
            "Large Language Models"
        ]
    },
    {
        "id": "46",
        "title": "Why Do We Laugh? Annotation and Taxonomy Generation for Laughable Contexts in Spontaneous Text Conversation",
        "author": [
            "Koji Inoue",
            "Mikey Elmers",
            "Divesh Lala",
            "Tatsuya Kawahara"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16635",
        "abstract": "Laughter serves as a multifaceted communicative signal in human interaction, yet its identification within dialogue presents a significant challenge for conversational AI systems. This study addresses this challenge by annotating laughable contexts in Japanese spontaneous text conversation data and developing a taxonomy to classify the underlying reasons for such contexts. Initially, multiple annotators manually labeled laughable contexts using a binary decision (laughable or non-laughable). Subsequently, an LLM was used to generate explanations for the binary annotations of laughable contexts, which were then categorized into a taxonomy comprising ten categories, including \"Empathy and Affinity\" and \"Humor and Surprise,\" highlighting the diverse range of laughter-inducing scenarios. The study also evaluated GPT-4's performance in recognizing the majority labels of laughable contexts, achieving an F1 score of 43.14%. These findings contribute to the advancement of conversational AI by establishing a foundation for more nuanced recognition and generation of laughter, ultimately fostering more natural and engaging human-AI interactions.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "47",
        "title": "Finite Sample Analysis of Subspace Identification Methods",
        "author": [
            "Jiabao He",
            "Ingvar Ziemann",
            "Cristian R. Rojas",
            "S. Joe Qin",
            "HÃ¥kan Hjalmarsson"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16639",
        "abstract": "As one of the mainstream approaches in system identification, subspace identification methods (SIMs) are known for their simple parameterization for MIMO systems and robust numerical properties. However, a comprehensive statistical analysis of SIMs remains an open problem. Amid renewed focus on identifying state-space models in the non-asymptotic regime, this work presents a finite sample analysis for a large class of open-loop SIMs. It establishes high-probability upper bounds for system matrices obtained via SIMs, and reveals that convergence rates for estimating Markov parameters and system matrices are $\\mathcal{O}(1/\\sqrt{N})$ up to logarithmic terms, in line with classical asymptotic results. Following the key steps of SIMs, we arrive at the above results by a three-step procedure. In Step 1, we begin with a parsimonious SIM (PARSIM) that uses least-squares regression to estimate multiple high-order ARX models in parallel. Leveraging a recent analysis of an individual ARX model, we obtain a union error bound for a bank of ARX models. Step 2 involves model reduction via weighted singular value decomposition (SVD), where we consider different data-dependent weighting matrices and use robustness results for SVD to obtain error bounds on extended controllability and observability matrices, respectively. The final Step 3 focuses on deriving error bounds for system matrices, where two different realization algorithms, the MOESP type and the Larimore type, are considered. Although our study initially focuses on PARSIM, the methodologies apply broadly across many variants of SIMs.",
        "tags": [
            "State Space Models"
        ]
    },
    {
        "id": "48",
        "title": "An LLM Benchmark for Addressee Recognition in Multi-modal Multi-party Dialogue",
        "author": [
            "Koji Inoue",
            "Divesh Lala",
            "Mikey Elmers",
            "Keiko Ochi",
            "Tatsuya Kawahara"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16643",
        "abstract": "Handling multi-party dialogues represents a significant step for advancing spoken dialogue systems, necessitating the development of tasks specific to multi-party interactions. To address this challenge, we are constructing a multi-modal multi-party dialogue corpus of triadic (three-participant) discussions. This paper focuses on the task of addressee recognition, identifying who is being addressed to take the next turn, a critical component unique to multi-party dialogue systems. A subset of the corpus was annotated with addressee information, revealing that explicit addressees are indicated in approximately 20% of conversational turns. To evaluate the task's complexity, we benchmarked the performance of a large language model (GPT-4o) on addressee recognition. The results showed that GPT-4o achieved an accuracy only marginally above chance, underscoring the challenges of addressee recognition in multi-party dialogue. These findings highlight the need for further research to enhance the capabilities of large language models in understanding and navigating the intricacies of multi-party conversational dynamics.",
        "tags": [
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "49",
        "title": "DOCS: Quantifying Weight Similarity for Deeper Insights into Large Language Models",
        "author": [
            "Zeping Min",
            "Xinshang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16650",
        "abstract": "We introduce a novel index, the Distribution of Cosine Similarity (DOCS), for quantitatively assessing the similarity between weight matrices in Large Language Models (LLMs), aiming to facilitate the analysis of their complex architectures. Leveraging DOCS, our analysis uncovers intriguing patterns in the latest open-source LLMs: adjacent layers frequently exhibit high weight similarity and tend to form clusters, suggesting depth-wise functional specialization. Additionally, we prove that DOCS is theoretically effective in quantifying similarity for orthogonal matrices, a crucial aspect given the prevalence of orthogonal initializations in LLMs. This research contributes to a deeper understanding of LLM architecture and behavior, offering tools with potential implications for developing more efficient and interpretable models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "50",
        "title": "Large Language Model Critics for Execution-Free Evaluation of Code Changes",
        "author": [
            "Aashish Yadavally",
            "Hoan Nguyen",
            "Laurent Callot",
            "Gauthier Guinet"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16655",
        "abstract": "Large language models (LLMs) offer a promising way forward for automating software engineering tasks, such as bug fixes, feature additions, etc., via multi-step LLM-based agentic workflows. However, existing metrics for evaluating such workflows, mainly build status and occasionally log analysis, are too sparse and limited in providing the information needed to assess the quality of changes made. In this work, we designed LLM-based critics to derive well-structured and rigorous intermediate/step-level, execution-free evaluation proxies for repo-level code changes. Importantly, we assume access to the gold test patch for the problem (i.e., reference-aware) to assess both semantics and executability of generated patches. With the gold test patch as a reference, we predict executability of all editing locations with an F1 score of 91.6%, aggregating which, we can predict the build status in 84.8% of the instances in SWE-bench. In particular, such an execution-focused LLM critic outperforms other reference-free and reference-aware LLM critics by 38.9% to 72.5%. Moreover, we demonstrate the usefulness of such a reference-aware framework in comparing patches generated by different agentic workflows. Finally, we open-source the library developed for this project, which allows further usage for either other agentic workflows or other benchmarks. The source code is available at https://github.com/amazon-science/code-agent-eval.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "51",
        "title": "Contextual Reinforcement in Multimodal Token Compression for Large Language Models",
        "author": [
            "Naderdel Piero",
            "Zacharias Cromwell",
            "Nathaniel Wainwright",
            "Matthias Nethercott"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16658",
        "abstract": "Effective token compression remains a critical challenge for scaling models to handle increasingly complex and diverse datasets. A novel mechanism based on contextual reinforcement is introduced, dynamically adjusting token importance through interdependencies and semantic relevance. This approach enables substantial reductions in token usage while preserving the quality and coherence of information representation. Incorporating graph-based algorithms and adaptive weighting, the method captures subtle contextual relationships across textual and multimodal data, ensuring robust alignment and performance in downstream tasks. Evaluations across varied domains reveal significant improvements in accuracy and semantic retention, particularly for tasks requiring detailed cross-modal interactions. Memory usage analyses demonstrate improved computational efficiency, with minimal overhead despite the additional reinforcement processes. Performance gains are further validated through error distribution analyses, showing reduced semantic loss and syntactic inconsistencies compared to baseline models. The modular architecture ensures compatibility with a wide range of open-source frameworks, facilitating scalable implementation for real-world applications. These findings highlight the potential of contextual reinforcement in redefining token management strategies and advancing large-scale model design.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "52",
        "title": "A structure-preserving parametric finite element method with optimal energy stability condition for anisotropic surface diffusion",
        "author": [
            "Yifei Li",
            "Wenjun Ying",
            "Yulin Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16660",
        "abstract": "We propose and analyze a structure-preserving parametric finite element method (SP-PFEM) for the evolution of closed curves under anisotropic surface diffusion with surface energy density $\\hat{\\gamma}(\\theta)$. Our primary theoretical contribution establishes that the condition $3\\hat{\\gamma}(\\theta)-\\hat{\\gamma}(\\theta-\\pi)\\geq 0$ is both necessary and sufficient for unconditional energy stability within the framework of local energy estimates. The proposed method introduces a symmetric surface energy matrix $\\hat{\\boldsymbol{Z}}_k(\\theta)$ with a stabilizing function $k(\\theta)$, leading to a conservative weak formulation. Its fully discretization via SP-PFEM rigorously preserves the two geometric structures: enclosed area conservation and energy dissipation unconditionally under our energy stability condition. Numerical results are reported to demonstrate the efficiency and accuracy of the proposed method, along with its area conservation and energy dissipation properties.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "53",
        "title": "Jupybara: Operationalizing a Design Space for Actionable Data Analysis and Storytelling with LLMs",
        "author": [
            "Huichen Will Wang",
            "Larry Birnbaum",
            "Vidya Setlur"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16661",
        "abstract": "Mining and conveying actionable insights from complex data is a key challenge of exploratory data analysis (EDA) and storytelling. To address this challenge, we present a design space for actionable EDA and storytelling. Synthesizing theory and expert interviews, we highlight how semantic precision, rhetorical persuasion, and pragmatic relevance underpin effective EDA and storytelling. We also show how this design space subsumes common challenges in actionable EDA and storytelling, such as identifying appropriate analytical strategies and leveraging relevant domain knowledge. Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension. Jupybara employs two strategies -- design-space-aware prompting and multi-agent architectures -- to operationalize our design space. An expert evaluation confirms Jupybara's usability, steerability, explainability, and reparability, as well as the effectiveness of our strategies in operationalizing the design space framework with LLMs.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "54",
        "title": "Auto-Differentiating Any LLM Workflow: A Farewell to Manual Prompting",
        "author": [
            "Li Yin",
            "Zhangyang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16673",
        "abstract": "Large Language Models (LLMs) have reshaped natural language processing, powering applications from multi-hop retrieval and question answering to autonomous agent workflows. Yet, prompt engineering -- the task of crafting textual inputs to effectively direct LLMs -- remains difficult and labor-intensive, particularly for complex pipelines that combine multiple LLM calls with functional operations like retrieval and data formatting. We introduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering (APE) that extends textual gradient-based methods (such as Text-Grad) to multi-component, potentially cyclic LLM architectures. Implemented within the AdalFlow library, LLM-AutoDiff treats each textual input as a trainable parameter and uses a frozen backward engine LLM to generate feedback-akin to textual gradients -- that guide iterative prompt updates. Unlike prior single-node approaches, LLM-AutoDiff inherently accommodates functional nodes, preserves time-sequential behavior in repeated calls (e.g., multi-hop loops), and combats the \"lost-in-the-middle\" problem by isolating distinct sub-prompts (instructions, formats, or few-shot examples). It further boosts training efficiency by focusing on error-prone samples through selective gradient computation. Across diverse tasks, including single-step classification, multi-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiff consistently outperforms existing textual gradient baselines in both accuracy and training cost. By unifying prompt optimization through a graph-centric lens, LLM-AutoDiff offers a powerful new paradigm for scaling and automating LLM workflows - mirroring the transformative role that automatic differentiation libraries have long played in neural network research.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "55",
        "title": "MME-Industry: A Cross-Industry Multimodal Evaluation Benchmark",
        "author": [
            "Dongyi Yi",
            "Guibo Zhu",
            "Chenglin Ding",
            "Zongshu Li",
            "Dong Yi",
            "Jinqiao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16688",
        "abstract": "With the rapid advancement of Multimodal Large Language Models (MLLMs), numerous evaluation benchmarks have emerged. However, comprehensive assessments of their performance across diverse industrial applications remain limited. In this paper, we introduce MME-Industry, a novel benchmark designed specifically for evaluating MLLMs in industrial http://settings.The benchmark encompasses 21 distinct domain, comprising 1050 question-answer pairs with 50 questions per domain. To ensure data integrity and prevent potential leakage from public datasets, all question-answer pairs were manually crafted and validated by domain experts. Besides, the benchmark's complexity is effectively enhanced by incorporating non-OCR questions that can be answered directly, along with tasks requiring specialized domain knowledge. Moreover, we provide both Chinese and English versions of the benchmark, enabling comparative analysis of MLLMs' capabilities across these languages. Our findings contribute valuable insights into MLLMs' practical industrial applications and illuminate promising directions for future model optimization research.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "56",
        "title": "MACI: Multi-Agent Collaborative Intelligence for Robust Reasoning and Temporal Planning",
        "author": [
            "Edward Y. Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16689",
        "abstract": "Artificial intelligence requires deliberate reasoning, temporal awareness, and effective constraint management, capabilities beyond the pattern-matching strengths of LLMs. LLMs struggle with planning tasks because of their reliance on associative reasoning, inability to self-verify, and inconsistent constraint awareness. We propose Multi-Agent Collaborative Intelligence (MACI), a framework centered on a meta-planner (MP) that orchestrates multiple agents to generate planner templates that define roles and constraints. These planners produce actionable workflows of role nodes and dependency constraints, enabling advanced temporal reasoning and adaptability.\nMACI's three-tier architecture includes a meta-planning module for planner construction, common agents for general reasoning, and specialized agents for domain expertise. By decoupling planning from validation, it overcomes key LLM limitations. Evaluations demonstrate MACI's effective constraint satisfaction, conflict detection, and reasoning, positioning it as a robust solution for complex reasoning and planning tasks.",
        "tags": [
            "Detection",
            "LLMs"
        ]
    },
    {
        "id": "57",
        "title": "Optimizing Code Runtime Performance through Context-Aware Retrieval-Augmented Generation",
        "author": [
            "Manish Acharya",
            "Yifan Zhang",
            "Yu Huang",
            "Kevin Leach"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16692",
        "abstract": "Optimizing software performance through automated code refinement offers a promising avenue for enhancing execution speed and efficiency. Despite recent advancements in LLMs, a significant gap remains in their ability to perform in-depth program analysis. This study introduces AUTOPATCH, an in-context learning approach designed to bridge this gap by enabling LLMs to automatically generate optimized code. Inspired by how programmers learn and apply knowledge to optimize software, AUTOPATCH incorporates three key components: (1) an analogy-driven framework to align LLM optimization with human cognitive processes, (2) a unified approach that integrates historical code examples and CFG analysis for context-aware learning, and (3) an automated pipeline for generating optimized code through in-context prompting. Experimental results demonstrate that AUTOPATCH achieves a 7.3% improvement in execution efficiency over GPT-4o across common generated executable code, highlighting its potential to advance automated program runtime optimization.",
        "tags": [
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "58",
        "title": "3D-MoE: A Mixture-of-Experts Multi-modal LLM for 3D Vision and Pose Diffusion via Rectified Flow",
        "author": [
            "Yueen Ma",
            "Yuzheng Zhuang",
            "Jianye Hao",
            "Irwin King"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16698",
        "abstract": "3D vision and spatial reasoning have long been recognized as preferable for accurately perceiving our three-dimensional world, especially when compared with traditional visual reasoning based on 2D images. Due to the difficulties in collecting high-quality 3D data, research in this area has only recently gained momentum. With the advent of powerful large language models (LLMs), multi-modal LLMs for 3D vision have been developed over the past few years. However, most of these models focus primarily on the vision encoder for 3D data. In this paper, we propose converting existing densely activated LLMs into mixture-of-experts (MoE) models, which have proven effective for multi-modal data processing. In addition to leveraging these models' instruction-following capabilities, we further enable embodied task planning by attaching a diffusion head, Pose-DiT, that employs a novel rectified flow diffusion scheduler. Experimental results on 3D question answering and task-planning tasks demonstrate that our 3D-MoE framework achieves improved performance with fewer activated parameters.",
        "tags": [
            "3D",
            "DiT",
            "Diffusion",
            "LLMs",
            "Large Language Models",
            "Rectified Flow"
        ]
    },
    {
        "id": "59",
        "title": "Separate Motion from Appearance: Customizing Motion via Customizing Text-to-Video Diffusion Models",
        "author": [
            "Huijie Liu",
            "Jingyun Wang",
            "Shuai Ma",
            "Jie Hu",
            "Xiaoming Wei",
            "Guoliang Kang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16714",
        "abstract": "Motion customization aims to adapt the diffusion model (DM) to generate videos with the motion specified by a set of video clips with the same motion concept. To realize this goal, the adaptation of DM should be possible to model the specified motion concept, without compromising the ability to generate diverse appearances. Thus, the key to solving this problem lies in how to separate the motion concept from the appearance in the adaptation process of DM. Typical previous works explore different ways to represent and insert a motion concept into large-scale pretrained text-to-video diffusion models, e.g., learning a motion LoRA, using latent noise residuals, etc. While those methods can encode the motion concept, they also inevitably encode the appearance in the reference videos, resulting in weakened appearance generation capability. In this paper, we follow the typical way to learn a motion LoRA to encode the motion concept, but propose two novel strategies to enhance motion-appearance separation, including temporal attention purification (TAP) and appearance highway (AH). Specifically, we assume that in the temporal attention module, the pretrained Value embeddings are sufficient to serve as basic components needed by producing a new motion. Thus, in TAP, we choose only to reshape the temporal attention with motion LoRAs so that Value embeddings can be reorganized to produce a new motion. Further, in AH, we alter the starting point of each skip connection in U-Net from the output of each temporal attention module to the output of each spatial attention module. Extensive experiments demonstrate that compared to previous works, our method can generate videos with appearance more aligned with the text descriptions and motion more consistent with the reference videos.",
        "tags": [
            "Diffusion",
            "LoRA",
            "Text-to-Video"
        ]
    },
    {
        "id": "60",
        "title": "One Head Eight Arms: Block Matrix based Low Rank Adaptation for CLIP-based Few-Shot Learning",
        "author": [
            "Chunpeng Zhou",
            "Qianqian Shen",
            "Zhi Yu",
            "Jiajun Bu",
            "Haishuai Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16720",
        "abstract": "Recent advancements in fine-tuning Vision-Language Foundation Models (VLMs) have garnered significant attention for their effectiveness in downstream few-shot learning http://tasks.While these recent approaches exhibits some performance improvements, they often suffer from excessive training parameters and high computational costs. To address these challenges, we propose a novel Block matrix-based low-rank adaptation framework, called Block-LoRA, for fine-tuning VLMs on downstream few-shot tasks. Inspired by recent work on Low-Rank Adaptation (LoRA), Block-LoRA partitions the original low-rank decomposition matrix of LoRA into a series of sub-matrices while sharing all down-projection sub-matrices. This structure not only reduces the number of training parameters, but also transforms certain complex matrix multiplication operations into simpler matrix addition, significantly lowering the computational cost of fine-tuning. Notably, Block-LoRA enables fine-tuning CLIP on the ImageNet few-shot benchmark using a single 24GB GPU. We also show that Block-LoRA has the more tighter bound of generalization error than vanilla LoRA. Without bells and whistles, extensive experiments demonstrate that Block-LoRA achieves competitive performance compared to state-of-the-art CLIP-based few-shot methods, while maintaining a low training parameters count and reduced computational overhead.",
        "tags": [
            "CLIP",
            "LoRA"
        ]
    },
    {
        "id": "61",
        "title": "xJailbreak: Representation Space Guided Reinforcement Learning for Interpretable LLM Jailbreaking",
        "author": [
            "Sunbowen Lee",
            "Shiwen Ni",
            "Chi Wei",
            "Shuaimin Li",
            "Liyang Fan",
            "Ahmadreza Argha",
            "Hamid Alinejad-Rokny",
            "Ruifeng Xu",
            "Yicheng Gong",
            "Min Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16727",
        "abstract": "Safety alignment mechanism are essential for preventing large language models (LLMs) from generating harmful information or unethical content. However, cleverly crafted prompts can bypass these safety measures without accessing the model's internal parameters, a phenomenon known as black-box jailbreak. Existing heuristic black-box attack methods, such as genetic algorithms, suffer from limited effectiveness due to their inherent randomness, while recent reinforcement learning (RL) based methods often lack robust and informative reward signals. To address these challenges, we propose a novel black-box jailbreak method leveraging RL, which optimizes prompt generation by analyzing the embedding proximity between benign and malicious prompts. This approach ensures that the rewritten prompts closely align with the intent of the original prompts while enhancing the attack's effectiveness. Furthermore, we introduce a comprehensive jailbreak evaluation framework incorporating keywords, intent matching, and answer validation to provide a more rigorous and holistic assessment of jailbreak success. Experimental results show the superiority of our approach, achieving state-of-the-art (SOTA) performance on several prominent open and closed-source LLMs, including Qwen2.5-7B-Instruct, Llama3.1-8B-Instruct, and GPT-4o-0806. Our method sets a new benchmark in jailbreak attack effectiveness, highlighting potential vulnerabilities in LLMs. The codebase for this work is available at https://github.com/Aegis1863/xJailbreak.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "62",
        "title": "Distilling Large Language Models for Network Active Queue Management",
        "author": [
            "Deol Satish",
            "Shiva Raj Pokhrel",
            "Jonathan Kua",
            "Anwar Walid"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16734",
        "abstract": "The growing complexity of network traffic and demand for ultra-low latency communication require smarter packet traffic management. Existing Deep Learning-based queuing approaches struggle with dynamic network scenarios and demand high engineering effort. We propose AQM-LLM, distilling Large Language Models (LLMs) with few-shot learning, contextual understanding, and pattern recognition to improve Active Queue Management (AQM) [RFC 9330] with minimal manual effort. We consider a specific case where AQM is Low Latency, Low Loss, and Scalable Throughput (L4S) and our design of AQM-LLM builds on speculative decoding and reinforcement-based distilling of LLM by tackling congestion prevention in the L4S architecture using Explicit Congestion Notification (ECN) [RFC 9331] and periodic packet dropping. We develop a new open-source experimental platform by executing L4S-AQM on FreeBSD-14, providing interoperable modules to support LLM integration and facilitate IETF recognition through wider testing. Our extensive evaluations show L4S-LLM enhances queue management, prevents congestion, reduces latency, and boosts network performance, showcasing LLMs' adaptability and efficiency in uplifting AQM systems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "63",
        "title": "Consistency Diffusion Models for Single-Image 3D Reconstruction with Priors",
        "author": [
            "Chenru Jiang",
            "Chengrui Zhang",
            "Xi Yang",
            "Jie Sun",
            "Kaizhu Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16737",
        "abstract": "This paper delves into the study of 3D point cloud reconstruction from a single image. Our objective is to develop the Consistency Diffusion Model, exploring synergistic 2D and 3D priors in the Bayesian framework to ensure superior consistency in the reconstruction process, a challenging yet critical requirement in this field. Specifically, we introduce a pioneering training framework under diffusion models that brings two key innovations. First, we convert 3D structural priors derived from the initial 3D point cloud as a bound term to increase evidence in the variational Bayesian framework, leveraging these robust intrinsic priors to tightly govern the diffusion training process and bolster consistency in reconstruction. Second, we extract and incorporate 2D priors from the single input image, projecting them onto the 3D point cloud to enrich the guidance for diffusion training. Our framework not only sidesteps potential model learning shifts that may arise from directly imposing additional constraints during training but also precisely transposes the 2D priors into the 3D domain. Extensive experimental evaluations reveal that our approach sets new benchmarks in both synthetic and real-world datasets. The code is included with the submission.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "64",
        "title": "Through the Prism of Culture: Evaluating LLMs' Understanding of Indian Subcultures and Traditions",
        "author": [
            "Garima Chhikara",
            "Abhishek Kumar",
            "Abhijnan Chakraborty"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16748",
        "abstract": "Large Language Models (LLMs) have shown remarkable advancements but also raise concerns about cultural bias, often reflecting dominant narratives at the expense of under-represented subcultures. In this study, we evaluate the capacity of LLMs to recognize and accurately respond to the Little Traditions within Indian society, encompassing localized cultural practices and subcultures such as caste, kinship, marriage, and religion. Through a series of case studies, we assess whether LLMs can balance the interplay between dominant Great Traditions and localized Little Traditions. We explore various prompting strategies and further investigate whether using prompts in regional languages enhances the models cultural sensitivity and response quality. Our findings reveal that while LLMs demonstrate an ability to articulate cultural nuances, they often struggle to apply this understanding in practical, context-specific scenarios. To the best of our knowledge, this is the first study to analyze LLMs engagement with Indian subcultures, offering critical insights into the challenges of embedding cultural diversity in AI systems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "65",
        "title": "Overcoming Semantic Dilution in Transformer-Based Next Frame Prediction",
        "author": [
            "Hy Nguyen",
            "Srikanth Thudumu",
            "Hung Du",
            "Rajesh Vasa",
            "Kon Mouzakis"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16753",
        "abstract": "Next-frame prediction in videos is crucial for applications such as autonomous driving, object tracking, and motion prediction. The primary challenge in next-frame prediction lies in effectively capturing and processing both spatial and temporal information from previous video sequences. The transformer architecture, known for its prowess in handling sequence data, has made remarkable progress in this domain. However, transformer-based next-frame prediction models face notable issues: (a) The multi-head self-attention (MHSA) mechanism requires the input embedding to be split into $N$ chunks, where $N$ is the number of heads. Each segment captures only a fraction of the original embeddings information, which distorts the representation of the embedding in the latent space, resulting in a semantic dilution problem; (b) These models predict the embeddings of the next frames rather than the frames themselves, but the loss function based on the errors of the reconstructed frames, not the predicted embeddings -- this creates a discrepancy between the training objective and the model output. We propose a Semantic Concentration Multi-Head Self-Attention (SCMHSA) architecture, which effectively mitigates semantic dilution in transformer-based next-frame prediction. Additionally, we introduce a loss function that optimizes SCMHSA in the latent space, aligning the training objective more closely with the model output. Our method demonstrates superior performance compared to the original transformer-based predictors.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "66",
        "title": "SSF-PAN: Semantic Scene Flow-Based Perception for Autonomous Navigation in Traffic Scenarios",
        "author": [
            "Yinqi Chen",
            "Meiying Zhang",
            "Qi Hao",
            "Guang Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16754",
        "abstract": "Vehicle detection and localization in complex traffic scenarios pose significant challenges due to the interference of moving objects. Traditional methods often rely on outlier exclusions or semantic segmentations, which suffer from low computational efficiency and accuracy. The proposed SSF-PAN can achieve the functionalities of LiDAR point cloud based object detection/localization and SLAM (Simultaneous Localization and Mapping) with high computational efficiency and accuracy, enabling map-free navigation frameworks. The novelty of this work is threefold: 1) developing a neural network which can achieve segmentation among static and dynamic objects within the scene flows with different motion features, that is, semantic scene flow (SSF); 2) developing an iterative framework which can further optimize the quality of input scene flows and output segmentation results; 3) developing a scene flow-based navigation platform which can test the performance of the SSF perception system in the simulation environment. The proposed SSF-PAN method is validated using the SUScape-CARLA and the KITTI datasets, as well as on the CARLA simulator. Experimental results demonstrate that the proposed approach outperforms traditional methods in terms of scene flow computation accuracy, moving object detection accuracy, computational efficiency, and autonomous navigation effectiveness.",
        "tags": [
            "Detection",
            "SLAM",
            "Segmentation"
        ]
    },
    {
        "id": "67",
        "title": "ITVTON:Virtual Try-On Diffusion Transformer Model Based on Integrated Image and Text",
        "author": [
            "Haifeng Ni"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16757",
        "abstract": "Recent advancements in virtual fitting for characters and clothing have leveraged diffusion models to improve the realism of garment fitting. However, challenges remain in handling complex scenes and poses, which can result in unnatural garment fitting and poorly rendered intricate patterns. In this work, we introduce ITVTON, a novel method that enhances clothing-character interactions by combining clothing and character images along spatial channels as inputs, thereby improving fitting accuracy for the inpainting model. Additionally, we incorporate integrated textual descriptions from multiple images to boost the realism of the generated visual effects. To optimize computational efficiency, we limit training to the attention parameters within a single diffusion transformer (Single-DiT) block. To more rigorously address the complexities of real-world scenarios, we curated training samples from the IGPair dataset, thereby enhancing ITVTON's performance across diverse environments. Extensive experiments demonstrate that ITVTON outperforms baseline methods both qualitatively and quantitatively, setting a new standard for virtual fitting tasks.",
        "tags": [
            "DiT",
            "Diffusion",
            "Diffusion Transformer",
            "Inpainting",
            "Transformer",
            "Virtual Try-On"
        ]
    },
    {
        "id": "68",
        "title": "DiffSplat: Repurposing Image Diffusion Models for Scalable Gaussian Splat Generation",
        "author": [
            "Chenguo Lin",
            "Panwang Pan",
            "Bangbang Yang",
            "Zeming Li",
            "Yadong Mu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16764",
        "abstract": "Recent advancements in 3D content generation from text or a single image struggle with limited high-quality 3D datasets and inconsistency from 2D multi-view generation. We introduce DiffSplat, a novel 3D generative framework that natively generates 3D Gaussian splats by taming large-scale text-to-image diffusion models. It differs from previous 3D generative models by effectively utilizing web-scale 2D priors while maintaining 3D consistency in a unified model. To bootstrap the training, a lightweight reconstruction model is proposed to instantly produce multi-view Gaussian splat grids for scalable dataset curation. In conjunction with the regular diffusion loss on these grids, a 3D rendering loss is introduced to facilitate 3D coherence across arbitrary views. The compatibility with image diffusion models enables seamless adaptions of numerous techniques for image generation to the 3D realm. Extensive experiments reveal the superiority of DiffSplat in text- and image-conditioned generation tasks and downstream applications. Thorough ablation studies validate the efficacy of each critical design choice and provide insights into the underlying mechanism.",
        "tags": [
            "3D",
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "69",
        "title": "Beyond-Labels: Advancing Open-Vocabulary Segmentation With Vision-Language Models",
        "author": [
            "Muhammad Atta ur Rahman"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16769",
        "abstract": "Self-supervised learning can resolve numerous image or linguistic processing problems when effectively trained. This study investigated simple yet efficient methods for adaping previously learned foundation models for open-vocabulary semantic segmentation tasks. Our research proposed \"Beyond-Labels,\" a lightweight transformer-based fusion module that uses a handful of image segmentation data to fuse frozen image representations with language concepts. Furthermore, we efficiently captured positional information in images using Fourier embeddings, thus improving the generalization across various image sizes. Extensive ablation tests were performed to investigate the important components of our proposed method; when tested against the common benchmark PASCAL-5i, it demonstrated superior performance despite being trained on frozen image and language characteristics.",
        "tags": [
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "70",
        "title": "FlexMotion: Lightweight, Physics-Aware, and Controllable Human Motion Generation",
        "author": [
            "Arvin Tashakori",
            "Arash Tashakori",
            "Gongbo Yang",
            "Z. Jane Wang",
            "Peyman Servati"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16778",
        "abstract": "Lightweight, controllable, and physically plausible human motion synthesis is crucial for animation, virtual reality, robotics, and human-computer interaction applications. Existing methods often compromise between computational efficiency, physical realism, or spatial controllability. We propose FlexMotion, a novel framework that leverages a computationally lightweight diffusion model operating in the latent space, eliminating the need for physics simulators and enabling fast and efficient training. FlexMotion employs a multimodal pre-trained Transformer encoder-decoder, integrating joint locations, contact forces, joint actuations and muscle activations to ensure the physical plausibility of the generated motions. FlexMotion also introduces a plug-and-play module, which adds spatial controllability over a range of motion parameters (e.g., joint locations, joint actuations, contact forces, and muscle activations). Our framework achieves realistic motion generation with improved efficiency and control, setting a new benchmark for human motion synthesis. We evaluate FlexMotion on extended datasets and demonstrate its superior performance in terms of realism, physical plausibility, and controllability.",
        "tags": [
            "Diffusion",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "71",
        "title": "A Stochastic Dynamical Theory of LLM Self-Adversariality: Modeling Severity Drift as a Critical Process",
        "author": [
            "Jack David Carson"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16783",
        "abstract": "This paper introduces a continuous-time stochastic dynamical framework for understanding how large language models (LLMs) may self-amplify latent biases or toxicity through their own chain-of-thought reasoning. The model posits an instantaneous \"severity\" variable $x(t) \\in [0,1]$ evolving under a stochastic differential equation (SDE) with a drift term $\\mu(x)$ and diffusion $\\sigma(x)$. Crucially, such a process can be consistently analyzed via the Fokker--Planck approach if each incremental step behaves nearly Markovian in severity space. The analysis investigates critical phenomena, showing that certain parameter regimes create phase transitions from subcritical (self-correcting) to supercritical (runaway severity). The paper derives stationary distributions, first-passage times to harmful thresholds, and scaling laws near critical points. Finally, it highlights implications for agents and extended LLM reasoning models: in principle, these equations might serve as a basis for formal verification of whether a model remains stable or propagates bias over repeated inferences.",
        "tags": [
            "Diffusion",
            "LLMs",
            "Large Language Models",
            "SDE"
        ]
    },
    {
        "id": "72",
        "title": "TORCHLIGHT: Shedding LIGHT on Real-World Attacks on Cloudless IoT Devices Concealed within the Tor Network",
        "author": [
            "Yumingzhi Pan",
            "Zhen Ling",
            "Yue Zhang",
            "Hongze Wang",
            "Guangchi Liu",
            "Junzhou Luo",
            "Xinwen Fu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16784",
        "abstract": "The rapidly expanding Internet of Things (IoT) landscape is shifting toward cloudless architectures, removing reliance on centralized cloud services but exposing devices directly to the internet and increasing their vulnerability to cyberattacks. Our research revealed an unexpected pattern of substantial Tor network traffic targeting cloudless IoT devices. suggesting that attackers are using Tor to anonymously exploit undisclosed vulnerabilities (possibly obtained from underground markets). To delve deeper into this phenomenon, we developed TORCHLIGHT, a tool designed to detect both known and unknown threats targeting cloudless IoT devices by analyzing Tor traffic. TORCHLIGHT filters traffic via specific IP patterns, strategically deploys virtual private server (VPS) nodes for cost-effective detection, and uses a chain-of-thought (CoT) process with large language models (LLMs) for accurate threat identification.\nOur results are significant: for the first time, we have demonstrated that attackers are indeed using Tor to conceal their identities while targeting cloudless IoT devices. Over a period of 12 months, TORCHLIGHT analyzed 26 TB of traffic, revealing 45 vulnerabilities, including 29 zero-day exploits with 25 CVE-IDs assigned (5 CRITICAL, 3 HIGH, 16 MEDIUM, and 1 LOW) and an estimated value of approximately $312,000. These vulnerabilities affect around 12.71 million devices across 148 countries, exposing them to severe risks such as information disclosure, authentication bypass, and arbitrary command execution. The findings have attracted significant attention, sparking widespread discussion in cybersecurity circles, reaching the top 25 on Hacker News, and generating over 190,000 views.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "73",
        "title": "Exploring the Role of Explicit Temporal Modeling in Multimodal Large Language Models for Video Understanding",
        "author": [
            "Yun Li",
            "Zhe Liu",
            "Yajing Kong",
            "Guangrui Li",
            "Jiyuan Zhang",
            "Chao Bian",
            "Feng Liu",
            "Lina Yao",
            "Zhenbang Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16786",
        "abstract": "Applying Multimodal Large Language Models (MLLMs) to video understanding presents significant challenges due to the need to model temporal relations across frames. Existing approaches adopt either implicit temporal modeling, relying solely on the LLM decoder, or explicit temporal modeling, employing auxiliary temporal encoders. To investigate this debate between the two paradigms, we propose the Stackable Temporal Encoder (STE). STE enables flexible explicit temporal modeling with adjustable temporal receptive fields and token compression ratios. Using STE, we systematically compare implicit and explicit temporal modeling across dimensions such as overall performance, token compression effectiveness, and temporal-specific understanding. We also explore STE's design considerations and broader impacts as a plug-in module and in image modalities. Our findings emphasize the critical role of explicit temporal modeling, providing actionable insights to advance video MLLMs.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "74",
        "title": "Algorithm for Automatic Legislative Text Consolidation",
        "author": [
            "Matias Etcheverry",
            "Thibaud Real",
            "Pauline Chavallard"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16794",
        "abstract": "This study introduces a method for automating the consolidation process in a legal context, a time-consuming task traditionally performed by legal professionals. We present a generative approach that processes legislative texts to automatically apply amendments. Our method employs light quantized generative model, fine-tuned with LoRA, to generate accurate and reliable amended texts. To the authors knowledge, this is the first time generative models are used on legislative text consolidation. Our dataset is publicly available on HuggingFace1. Experimental results demonstrate a significant improvement in efficiency, offering faster updates to legal documents. A full automated pipeline of legislative text consolidation can be done in a few hours, with a success rate of more than 63% on a difficult bill.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "75",
        "title": "DIRIGENt: End-To-End Robotic Imitation of Human Demonstrations Based on a Diffusion Model",
        "author": [
            "Josua Spisak",
            "Matthias Kerzel",
            "Stefan Wermter"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16800",
        "abstract": "There has been substantial progress in humanoid robots, with new skills continuously being taught, ranging from navigation to manipulation. While these abilities may seem impressive, the teaching methods often remain inefficient. To enhance the process of teaching robots, we propose leveraging a mechanism effectively used by humans: teaching by demonstrating. In this paper, we introduce DIRIGENt (DIrect Robotic Imitation GENeration model), a novel end-to-end diffusion approach that directly generates joint values from observing human demonstrations, enabling a robot to imitate these actions without any existing mapping between it and humans. We create a dataset in which humans imitate a robot and then use this collected data to train a diffusion model that enables a robot to imitate humans. The following three aspects are the core of our contribution. First is our novel dataset with natural pairs between human and robot poses, allowing our approach to imitate humans accurately despite the gap between their anatomies. Second, the diffusion input to our model alleviates the challenge of redundant joint configurations, limiting the search space. And finally, our end-to-end architecture from perception to action leads to an improved learning capability. Through our experimental analysis, we show that combining these three aspects allows DIRIGENt to outperform existing state-of-the-art approaches in the field of generating joint values from RGB images.",
        "tags": [
            "Diffusion",
            "Robot"
        ]
    },
    {
        "id": "76",
        "title": "Not Every Patch is Needed: Towards a More Efficient and Effective Backbone for Video-based Person Re-identification",
        "author": [
            "Lanyun Zhu",
            "Tianrun Chen",
            "Deyi Ji",
            "Jieping Ye",
            "Jun Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16811",
        "abstract": "This paper proposes a new effective and efficient plug-and-play backbone for video-based person re-identification (ReID). Conventional video-based ReID methods typically use CNN or transformer backbones to extract deep features for every position in every sampled video frame. Here, we argue that this exhaustive feature extraction could be unnecessary, since we find that different frames in a ReID video often exhibit small differences and contain many similar regions due to the relatively slight movements of human beings. Inspired by this, a more selective, efficient paradigm is explored in this paper. Specifically, we introduce a patch selection mechanism to reduce computational cost by choosing only the crucial and non-repetitive patches for feature extraction. Additionally, we present a novel network structure that generates and utilizes pseudo frame global context to address the issue of incomplete views resulting from sparse inputs. By incorporating these new designs, our backbone can achieve both high performance and low computational cost. Extensive experiments on multiple datasets show that our approach reduces the computational cost by 74\\% compared to ViT-B and 28\\% compared to ResNet50, while the accuracy is on par with ViT-B and outperforms ResNet50 significantly.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "77",
        "title": "Whispers of Sound-Enhancing Information Extraction from Depression Patients' Unstructured Data through Audio and Text Emotion Recognition and Llama Fine-tuning",
        "author": [
            "Lindy Gan",
            "Yifan Huang",
            "Xiaoyang Gao",
            "Jiaming Tan",
            "Fujun Zhao",
            "Tao Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16813",
        "abstract": "This study proposes an innovative multimodal fusion model based on a teacher-student architecture to enhance the accuracy of depression classification. Our designed model addresses the limitations of traditional methods in feature fusion and modality weight allocation by introducing multi-head attention mechanisms and weighted multimodal transfer learning. Leveraging the DAIC-WOZ dataset, the student fusion model, guided by textual and auditory teacher models, achieves significant improvements in classification accuracy. Ablation experiments demonstrate that the proposed model attains an F1 score of 99. 1% on the test set, significantly outperforming unimodal and conventional approaches. Our method effectively captures the complementarity between textual and audio features while dynamically adjusting the contributions of the teacher models to enhance generalization capabilities. The experimental results highlight the robustness and adaptability of the proposed framework in handling complex multimodal data. This research provides a novel technical framework for multimodal large model learning in depression analysis, offering new insights into addressing the limitations of existing methods in modality fusion and feature extraction.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "78",
        "title": "Can Transformers Learn Full Bayesian Inference in Context?",
        "author": [
            "Arik Reuter",
            "Tim G. J. Rudner",
            "Vincent Fortuin",
            "David RÃ¼gamer"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16825",
        "abstract": "Transformers have emerged as the dominant architecture in the field of deep learning, with a broad range of applications and remarkable in-context learning (ICL) capabilities. While not yet fully understood, ICL has already proved to be an intriguing phenomenon, allowing transformers to learn in context -- without requiring further training. In this paper, we further advance the understanding of ICL by demonstrating that transformers can perform full Bayesian inference for commonly used statistical models in context. More specifically, we introduce a general framework that builds on ideas from prior fitted networks and continuous normalizing flows which enables us to infer complex posterior distributions for methods such as generalized linear models and latent factor models. Extensive experiments on real-world datasets demonstrate that our ICL approach yields posterior samples that are similar in quality to state-of-the-art MCMC or variational inference methods not operating in context.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "79",
        "title": "Data-Driven vs Traditional Approaches to Power Transformer's Top-Oil Temperature Estimation",
        "author": [
            "Francis Tembo",
            "Federica Bragone",
            "Tor Laneryd",
            "Matthieu Barreau",
            "Kateryna Morozovska"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16831",
        "abstract": "Power transformers are subjected to electrical currents and temperature fluctuations that, if not properly controlled, can lead to major deterioration of their insulation system. Therefore, monitoring the temperature of a power transformer is fundamental to ensure a long-term operational life. Models presented in the IEC 60076-7 and IEEE standards, for example, monitor the temperature by calculating the top-oil and the hot-spot temperatures. However, these models are not very accurate and rely on the power transformers' properties. This paper focuses on finding an alternative method to predict the top-oil temperatures given previous measurements. Given the large quantities of data available, machine learning methods for time series forecasting are analyzed and compared to the real measurements and the corresponding prediction of the IEC standard. The methods tested are Artificial Neural Networks (ANNs), Time-series Dense Encoder (TiDE), and Temporal Convolutional Networks (TCN) using different combinations of historical measurements. Each of these methods outperformed the IEC 60076-7 model and they are extended to estimate the temperature rise over ambient. To enhance prediction reliability, we explore the application of quantile regression to construct prediction intervals for the expected top-oil temperature ranges. The best-performing model successfully estimates conditional quantiles that provide sufficient coverage.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "80",
        "title": "Misspellings in Natural Language Processing: A survey",
        "author": [
            "Gianluca Sperduti",
            "Alejandro Moreo"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16836",
        "abstract": "This survey provides an overview of the challenges of misspellings in natural language processing (NLP). While often unintentional, misspellings have become ubiquitous in digital communication, especially with the proliferation of Web 2.0, user-generated content, and informal text mediums such as social media, blogs, and forums. Even if humans can generally interpret misspelled text, NLP models frequently struggle to handle it: this causes a decline in performance in common tasks like text classification and machine translation. In this paper, we reconstruct a history of misspellings as a scientific problem. We then discuss the latest advancements to address the challenge of misspellings in NLP. Main strategies to mitigate the effect of misspellings include data augmentation, double step, character-order agnostic, and tuple-based methods, among others. This survey also examines dedicated data challenges and competitions to spur progress in the field. Critical safety and ethical concerns are also examined, for example, the voluntary use of misspellings to inject malicious messages and hate speech on social networks. Furthermore, the survey explores psycholinguistic perspectives on how humans process misspellings, potentially informing innovative computational techniques for text normalization and representation. Finally, the misspelling-related challenges and opportunities associated with modern large language models are also analyzed, including benchmarks, datasets, and performances of the most prominent language models against misspellings. This survey aims to be an exhaustive resource for researchers seeking to mitigate the impact of misspellings in the rapidly evolving landscape of NLP.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "81",
        "title": "Flow Matching: Markov Kernels, Stochastic Processes and Transport Plans",
        "author": [
            "Christian Wald",
            "Gabriele Steidl"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16839",
        "abstract": "Among generative neural models, flow matching techniques stand out for their simple applicability and good scaling properties. Here, velocity fields of curves connecting a simple latent and a target distribution are learned. Then the corresponding ordinary differential equation can be used to sample from a target distribution, starting in samples from the latent one. This paper reviews from a mathematical point of view different techniques to learn the velocity fields of absolutely continuous curves in the Wasserstein geometry. We show how the velocity fields can be characterized and learned via i) transport plans (couplings) between latent and target distributions, ii) Markov kernels and iii) stochastic processes, where the latter two include the coupling approach, but are in general broader. Besides this main goal, we show how flow matching can be used for solving Bayesian inverse problems, where the definition of conditional Wasserstein distances plays a central role. Finally, we briefly address continuous normalizing flows and score matching techniques, which approach the learning of velocity fields of curves from other directions.",
        "tags": [
            "Flow Matching",
            "Normalizing Flows",
            "Score Matching"
        ]
    },
    {
        "id": "82",
        "title": "Adapting Network Information to Semantics for Generalizable and Plug-and-Play Multi-Scenario Network Diagnosis",
        "author": [
            "Tiao Tan",
            "Fengxiao Tang",
            "Ming Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16842",
        "abstract": "Network fault diagnosis is a core challenge in ensuring the stability and reliability of modern network operations. Traditional approaches, limited by their training on specific performance metrics for predefined scenarios, struggle to generalize across diverse faults and anomalies in varying network environments. In recent years, large language models (LLMs) have demonstrated strong generalization capabilities across various domains. Building on this success, we propose NetSemantic, a plug-and-play intelligent network fault diagnosis framework based on LLMs. NetSemantic transforms multimodal network information into unified textual representations, enabling LLMs to perform reasoning and generate efficient fault resolutions and health assessment reports. To further enhance the logical reasoning capabilities of LLMs, we introduce a novel symbolic representation method that transforms logically strong network information into symbols. Additionally, we propose a self-adaptive data updating mechanism that dynamically incorporates network information into a knowledge graph to ensure the validity and timeliness of the knowledge base. Experimental results demonstrate that NetSemantic excels in network fault diagnosis across various complex scenarios, significantly improving diagnostic accuracy and reliability.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "83",
        "title": "Comparing Human and LLM Generated Code: The Jury is Still Out!",
        "author": [
            "Sherlock A. Licorish",
            "Ansh Bajpai",
            "Chetan Arora",
            "Fanyu Wang",
            "Kla Tantithamthavorn"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16857",
        "abstract": "Much is promised in relation to AI-supported software development. However, there has been limited evaluation effort in the research domain aimed at validating the true utility of such techniques, especially when compared to human coding outputs. We bridge this gap, where a benchmark dataset comprising 72 distinct software engineering tasks is used to compare the effectiveness of large language models (LLMs) and human programmers in producing Python software code. GPT-4 is used as a representative LLM, where for the code generated by humans and this LLM, we evaluate code quality and adherence to Python coding standards, code security and vulnerabilities, code complexity and functional correctness. We use various static analysis benchmarks, including Pylint, Radon, Bandit and test cases. Among the notable outcomes, results show that human-generated code recorded higher ratings for adhering to coding standards than GPT-4. We observe security flaws in code generated by both humans and GPT-4, however, code generated by humans shows a greater variety of problems, but GPT-4 code included more severe outliers. Our results show that although GPT-4 is capable of producing coding solutions, it frequently produces more complex code that may need more reworking to ensure maintainability. On the contrary however, our outcomes show that a higher number of test cases passed for code generated by GPT-4 across a range of tasks than code that was generated by humans. That said, GPT-4 frequently struggles with complex problem-solving that involve in-depth domain knowledge. This study highlights the potential utility of LLMs for supporting software development, however, tasks requiring comprehensive, innovative or unconventional solutions, and careful debugging and error correction seem to be better developed by human programmers. We plot an agenda for the software engineering community.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "84",
        "title": "JRE-L: Journalist, Reader, and Editor LLMs in the Loop for Science Journalism for the General Audience",
        "author": [
            "Gongyao Jiang",
            "Xinran Shi",
            "Qiong Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16865",
        "abstract": "Science journalism reports current scientific discoveries to non-specialists, aiming to enable public comprehension of the state of the art. This task is challenging as the audience often lacks specific knowledge about the presented research. We propose a JRE-L framework that integrates three LLMs mimicking the writing-reading-feedback-revision loop. In JRE-L, one LLM acts as the journalist, another LLM as the general public reader, and the third LLM as an editor. The journalist's writing is iteratively refined by feedback from the reader and suggestions from the editor. Our experiments demonstrate that by leveraging the collaboration of two 7B and one 1.8B open-source LLMs, we can generate articles that are more accessible than those generated by existing methods, including prompting single advanced models such as GPT-4 and other LLM-collaboration strategies. Our code is publicly available at http://github.com/Zzoay/JRE-L.",
        "tags": [
            "GPT",
            "LLMs"
        ]
    },
    {
        "id": "85",
        "title": "RDMM: Fine-Tuned LLM Models for On-Device Robotic Decision Making with Enhanced Contextual Awareness in Specific Domains",
        "author": [
            "Shady Nasrat",
            "Myungsu Kim",
            "Seonil Lee",
            "Jiho Lee",
            "Yeoncheol Jang",
            "Seung-joon Yi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16899",
        "abstract": "Large language models (LLMs) represent a significant advancement in integrating physical robots with AI-driven systems. We showcase the capabilities of our framework within the context of the real-world household competition. This research introduces a framework that utilizes RDMM (Robotics Decision-Making Models), which possess the capacity for decision-making within domain-specific contexts, as well as an awareness of their personal knowledge and capabilities. The framework leverages information to enhance the autonomous decision-making of the system. In contrast to other approaches, our focus is on real-time, on-device solutions, successfully operating on hardware with as little as 8GB of memory. Our framework incorporates visual perception models equipping robots with understanding of their environment. Additionally, the framework has integrated real-time speech recognition capabilities, thus enhancing the human-robot interaction experience. Experimental results demonstrate that the RDMM framework can plan with an 93\\% accuracy. Furthermore, we introduce a new dataset consisting of 27k planning instances, as well as 1.3k text-image annotated samples derived from the competition. The framework, benchmarks, datasets, and models developed in this work are publicly available on our GitHub repository at https://github.com/shadynasrat/RDMM.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Robot",
            "Robotics"
        ]
    },
    {
        "id": "86",
        "title": "RAINER: A Robust Ensemble Learning Grid Search-Tuned Framework for Rainfall Patterns Prediction",
        "author": [
            "Zhenqi Li",
            "Junhao Zhong",
            "Hewei Wang",
            "Jinfeng Xu",
            "Yijie Li",
            "Jinjiang You",
            "Jiayi Zhang",
            "Runzhi Wu",
            "Soumyabrata Dev"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16900",
        "abstract": "Rainfall prediction remains a persistent challenge due to the highly nonlinear and complex nature of meteorological data. Existing approaches lack systematic utilization of grid search for optimal hyperparameter tuning, relying instead on heuristic or manual selection, frequently resulting in sub-optimal results. Additionally, these methods rarely incorporate newly constructed meteorological features such as differences between temperature and humidity to capture critical weather dynamics. Furthermore, there is a lack of systematic evaluation of ensemble learning techniques and limited exploration of diverse advanced models introduced in the past one or two years. To address these limitations, we propose a robust ensemble learning grid search-tuned framework (RAINER) for rainfall prediction. RAINER incorporates a comprehensive feature engineering pipeline, including outlier removal, imputation of missing values, feature reconstruction, and dimensionality reduction via Principal Component Analysis (PCA). The framework integrates novel meteorological features to capture dynamic weather patterns and systematically evaluates non-learning mathematical-based methods and a variety of machine learning models, from weak classifiers to advanced neural networks such as Kolmogorov-Arnold Networks (KAN). By leveraging grid search for hyperparameter tuning and ensemble voting techniques, RAINER achieves promising results within real-world datasets.",
        "tags": [
            "KAN",
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "87",
        "title": "Detecting harassment and defamation in cyberbullying with emotion-adaptive training",
        "author": [
            "Peiling Yi",
            "Arkaitz Zubiaga",
            "Yunfei Long"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16925",
        "abstract": "Existing research on detecting cyberbullying incidents on social media has primarily concentrated on harassment and is typically approached as a binary classification task. However, cyberbullying encompasses various forms, such as denigration and harassment, which celebrities frequently face. Furthermore, suitable training data for these diverse forms of cyberbullying remains scarce. In this study, we first develop a celebrity cyberbullying dataset that encompasses two distinct types of incidents: harassment and defamation. We investigate various types of transformer-based models, namely masked (RoBERTa, Bert and DistilBert), replacing(Electra), autoregressive (XLnet), masked&permuted (Mpnet), text-text (T5) and large language models (Llama2 and Llama3) under low source settings. We find that they perform competitively on explicit harassment binary detection. However, their performance is substantially lower on harassment and denigration multi-classification tasks. Therefore, we propose an emotion-adaptive training framework (EAT) that helps transfer knowledge from the domain of emotion detection to the domain of cyberbullying detection to help detect indirect cyberbullying events. EAT consistently improves the average macro F1, precision and recall by 20% in cyberbullying detection tasks across nine transformer-based models under low-resource settings. Our claims are supported by intuitive theoretical insights and extensive experiments.",
        "tags": [
            "BERT",
            "Detection",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "88",
        "title": "Multiple Abstraction Level Retrieve Augment Generation",
        "author": [
            "Zheng Zheng",
            "Xinyi Ni",
            "Pengyu Hong"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16952",
        "abstract": "A Retrieval-Augmented Generation (RAG) model powered by a large language model (LLM) provides a faster and more cost-effective solution for adapting to new data and knowledge. It also delivers more specialized responses compared to pre-trained LLMs. However, most existing approaches rely on retrieving prefix-sized chunks as references to support question-answering (Q/A). This approach is often deployed to address information needs at a single level of abstraction, as it struggles to generate answers across multiple levels of abstraction. In an RAG setting, while LLMs can summarize and answer questions effectively when provided with sufficient details, retrieving excessive information often leads to the 'lost in the middle' problem and exceeds token limitations. We propose a novel RAG approach that uses chunks of multiple abstraction levels (MAL), including multi-sentence-level, paragraph-level, section-level, and document-level. The effectiveness of our approach is demonstrated in an under-explored scientific domain of Glycoscience. Compared to traditional single-level RAG approaches, our approach improves AI evaluated answer correctness of Q/A by 25.739\\% on Glyco-related papers.",
        "tags": [
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "89",
        "title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers",
        "author": [
            "Mohammad Raza",
            "Natasa Milic-Frayling"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16961",
        "abstract": "Robustness of reasoning remains a significant challenge for large language models, and addressing it is essential for the practical applicability of AI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a novel approach that addresses the key challenge in combining language models with the rigor of logical solvers: to accurately formulate the reasoning problem from natural language to the formal language of the solver. SSV uses a consistency-based approach to produce strong abstract formalizations of problems using concrete instantiations that are generated by the model and verified by the solver. In addition to significantly advancing the overall reasoning accuracy over the state-of-the-art, a key novelty that this approach presents is a feature of verification that has near-perfect precision over a significant coverage of cases, as we demonstrate on open reasoning benchmarks. We propose such *near-certain reasoning* as a new approach to reduce the need for manual verification in many cases, taking us closer to more dependable and autonomous AI reasoning systems.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "90",
        "title": "RODEO: Robust Outlier Detection via Exposing Adaptive Out-of-Distribution Samples",
        "author": [
            "Hossein Mirzaei",
            "Mohammad Jafari",
            "Hamid Reza Dehbashi",
            "Ali Ansari",
            "Sepehr Ghobadi",
            "Masoud Hadi",
            "Arshia Soltani Moakhar",
            "Mohammad Azizmalayeri",
            "Mahdieh Soleymani Baghshah",
            "Mohammad Hossein Rohban"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16971",
        "abstract": "In recent years, there have been significant improvements in various forms of image outlier detection. However, outlier detection performance under adversarial settings lags far behind that in standard settings. This is due to the lack of effective exposure to adversarial scenarios during training, especially on unseen outliers, leading to detection models failing to learn robust features. To bridge this gap, we introduce RODEO, a data-centric approach that generates effective outliers for robust outlier detection. More specifically, we show that incorporating outlier exposure (OE) and adversarial training can be an effective strategy for this purpose, as long as the exposed training outliers meet certain characteristics, including diversity, and both conceptual differentiability and analogy to the inlier samples. We leverage a text-to-image model to achieve this goal. We demonstrate both quantitatively and qualitatively that our adaptive OE method effectively generates ``diverse'' and ``near-distribution'' outliers, leveraging information from both text and image domains. Moreover, our experimental results show that utilizing our synthesized outliers significantly enhances the performance of the outlier detector, particularly in adversarial settings.",
        "tags": [
            "Detection",
            "Text-to-Image"
        ]
    },
    {
        "id": "91",
        "title": "Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling",
        "author": [
            "Hongzhi Huang",
            "Defa Zhu",
            "Banggu Wu",
            "Yutao Zeng",
            "Ya Wang",
            "Qiyang Min",
            "Xun Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16975",
        "abstract": "Tokenization is a fundamental component of large language models (LLMs), yet its influence on model scaling and performance is not fully explored. In this paper, we introduce Over-Tokenized Transformers, a novel framework that decouples input and output vocabularies to improve language modeling performance. Specifically, our approach scales up input vocabularies to leverage multi-gram tokens. Through extensive experiments, we uncover a log-linear relationship between input vocabulary size and training loss, demonstrating that larger input vocabularies consistently enhance model performance, regardless of model size. Using a large input vocabulary, we achieve performance comparable to double-sized baselines with no additional cost. Our findings highlight the importance of tokenization in scaling laws and provide practical insight for tokenizer design, paving the way for more efficient and powerful LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "92",
        "title": "Modulating CNN Features with Pre-Trained ViT Representations for Open-Vocabulary Object Detection",
        "author": [
            "Xiangyu Gao",
            "Yu Dai",
            "Benliu Qiu",
            "Hongliang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16981",
        "abstract": "Owing to large-scale image-text contrastive training, pre-trained vision language model (VLM) like CLIP shows superior open-vocabulary recognition ability. Most existing open-vocabulary object detectors attempt to utilize the pre-trained VLM to attain generative representation. F-ViT uses the pre-trained visual encoder as the backbone network and freezes it during training. However, the frozen backbone doesn't benefit from the labeled data to strengthen the representation. Therefore, we propose a novel two-branch backbone network design, named as ViT-Feature-Modulated Multi-Scale Convolutional network (VMCNet). VMCNet consists of a trainable convolutional branch, a frozen pre-trained ViT branch and a feature modulation module. The trainable CNN branch could be optimized with labeled data while the frozen pre-trained ViT branch could keep the representation ability derived from large-scale pre-training. Then, the proposed feature modulation module could modulate the multi-scale CNN features with the representations from ViT branch. With the proposed mixed structure, detector is more likely to discover novel categories. Evaluated on two popular benchmarks, our method boosts the detection performance on novel category and outperforms the baseline. On OV-COCO, the proposed method achieves 44.3 AP$_{50}^{\\mathrm{novel}}$ with ViT-B/16 and 48.5 AP$_{50}^{\\mathrm{novel}}$ with ViT-L/14. On OV-LVIS, VMCNet with ViT-B/16 and ViT-L/14 reaches 27.8 and 38.4 mAP$_{r}$.",
        "tags": [
            "CLIP",
            "Detection",
            "ViT"
        ]
    },
    {
        "id": "93",
        "title": "Large Language Models for Code Generation: The Practitioners Perspective",
        "author": [
            "Zeeshan Rasheed",
            "Muhammad Waseem",
            "Kai Kristian Kemell",
            "Aakash Ahmad",
            "Malik Abdul Sami",
            "Jussi Rasku",
            "Kari SystÃ¤",
            "Pekka Abrahamsson"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16998",
        "abstract": "Large Language Models (LLMs) have emerged as coding assistants, capable of generating source code from natural language prompts. With the increasing adoption of LLMs in software development, academic research and industry based projects are developing various tools, benchmarks, and metrics to evaluate the effectiveness of LLM-generated code. However, there is a lack of solutions evaluated through empirically grounded methods that incorporate practitioners perspectives to assess functionality, syntax, and accuracy in real world applications. To address this gap, we propose and develop a multi-model unified platform to generate and execute code based on natural language prompts. We conducted a survey with 60 software practitioners from 11 countries across four continents working in diverse professional roles and domains to evaluate the usability, performance, strengths, and limitations of each model. The results present practitioners feedback and insights into the use of LLMs in software development, including their strengths and weaknesses, key aspects overlooked by benchmarks and metrics, and a broader understanding of their practical applicability. These findings can help researchers and practitioners make informed decisions for systematically selecting and using LLMs in software development projects. Future research will focus on integrating more diverse models into the proposed system, incorporating additional case studies, and conducting developer interviews for deeper empirical insights into LLM-driven software development.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "94",
        "title": "MIDI-GPT: A Controllable Generative Model for Computer-Assisted Multitrack Music Composition",
        "author": [
            "Philippe Pasquier",
            "Jeff Ens",
            "Nathan Fradet",
            "Paul Triana",
            "Davide Rizzotti",
            "Jean-Baptiste Rolland",
            "Maryam Safi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17011",
        "abstract": "We present and release MIDI-GPT, a generative system based on the Transformer architecture that is designed for computer-assisted music composition workflows. MIDI-GPT supports the infilling of musical material at the track and bar level, and can condition generation on attributes including: instrument type, musical style, note density, polyphony level, and note duration. In order to integrate these features, we employ an alternative representation for musical material, creating a time-ordered sequence of musical events for each track and concatenating several tracks into a single sequence, rather than using a single time-ordered sequence where the musical events corresponding to different tracks are interleaved. We also propose a variation of our representation allowing for expressiveness. We present experimental results that demonstrate that MIDI-GPT is able to consistently avoid duplicating the musical material it was trained on, generate music that is stylistically similar to the training dataset, and that attribute controls allow enforcing various constraints on the generated material. We also outline several real-world applications of MIDI-GPT, including collaborations with industry partners that explore the integration and evaluation of MIDI-GPT into commercial products, as well as several artistic works produced using it.",
        "tags": [
            "GPT",
            "Transformer"
        ]
    },
    {
        "id": "95",
        "title": "Revisit Mixture Models for Multi-Agent Simulation: Experimental Study within a Unified Framework",
        "author": [
            "Longzhong Lin",
            "Xuewu Lin",
            "Kechun Xu",
            "Haojian Lu",
            "Lichao Huang",
            "Rong Xiong",
            "Yue Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17015",
        "abstract": "Simulation plays a crucial role in assessing autonomous driving systems, where the generation of realistic multi-agent behaviors is a key aspect. In multi-agent simulation, the primary challenges include behavioral multimodality and closed-loop distributional shifts. In this study, we revisit mixture models for generating multimodal agent behaviors, which can cover the mainstream methods including continuous mixture models and GPT-like discrete models. Furthermore, we introduce a closed-loop sample generation approach tailored for mixture models to mitigate distributional shifts. Within the unified mixture model~(UniMM) framework, we recognize critical configurations from both model and data perspectives. We conduct a systematic examination of various model configurations, including positive component matching, continuous regression, prediction horizon, and the number of components. Moreover, our investigation into the data configuration highlights the pivotal role of closed-loop samples in achieving realistic simulations. To extend the benefits of closed-loop samples across a broader range of mixture models, we further address the shortcut learning and off-policy learning issues. Leveraging insights from our exploration, the distinct variants proposed within the UniMM framework, including discrete, anchor-free, and anchor-based models, all achieve state-of-the-art performance on the WOSAC benchmark.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "96",
        "title": "Mobile Manipulation Instruction Generation from Multiple Images with Automatic Metric Enhancement",
        "author": [
            "Kei Katsumata",
            "Motonari Kambara",
            "Daichi Yashima",
            "Ryosuke Korekata",
            "Komei Sugiura"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17022",
        "abstract": "We consider the problem of generating free-form mobile manipulation instructions based on a target object image and receptacle image. Conventional image captioning models are not able to generate appropriate instructions because their architectures are typically optimized for single-image. In this study, we propose a model that handles both the target object and receptacle to generate free-form instruction sentences for mobile manipulation tasks. Moreover, we introduce a novel training method that effectively incorporates the scores from both learning-based and n-gram based automatic evaluation metrics as rewards. This method enables the model to learn the co-occurrence relationships between words and appropriate paraphrases. Results demonstrate that our proposed method outperforms baseline methods including representative multimodal large language models on standard automatic evaluation metrics. Moreover, physical experiments reveal that using our method to augment data on language instructions improves the performance of an existing multimodal language understanding model for mobile manipulation.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "97",
        "title": "Automated Refactoring of Non-Idiomatic Python Code: A Differentiated Replication with LLMs",
        "author": [
            "Alessandro Midolo",
            "Massimiliano Di Penta"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17024",
        "abstract": "In the Python ecosystem, the adoption of idiomatic constructs has been fostered because of their expressiveness, increasing productivity and even efficiency, despite controversial arguments concerning familiarity or understandability issues. Recent research contributions have proposed approaches -- based on static code analysis and transformation -- to automatically identify and enact refactoring opportunities of non-idiomatic code into idiomatic ones. Given the potential recently offered by Large Language Models (LLMs) for code-related tasks, in this paper, we present the results of a replication study in which we investigate GPT-4 effectiveness in recommending and suggesting idiomatic refactoring actions. Our results reveal that GPT-4 not only identifies idiomatic constructs effectively but frequently exceeds the benchmark in proposing refactoring actions where the existing baseline failed. A manual analysis of a random sample shows the correctness of the obtained recommendations. Our findings underscore the potential of LLMs to achieve tasks where, in the past, implementing recommenders based on complex code analyses was required.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "98",
        "title": "Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies",
        "author": [
            "Manojkumar Parmar",
            "Yuvaraj Govindarajulu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17030",
        "abstract": "Large Language Models (LLMs) have achieved remarkable progress in reasoning, alignment, and task-specific performance. However, ensuring harmlessness in these systems remains a critical challenge, particularly in advanced models like DeepSeek-R1. This paper examines the limitations of Reinforcement Learning (RL) as the primary approach for reducing harmful outputs in DeepSeek-R1 and compares it with Supervised Fine-Tuning (SFT). While RL improves reasoning capabilities, it faces challenges such as reward hacking, generalization failures, language mixing, and high computational costs. We propose hybrid training approaches combining RL and SFT to achieve robust harmlessness reduction. Usage recommendations and future directions for deploying DeepSeek-R1 responsibly are also presented.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "99",
        "title": "Enhanced Retrieval of Long Documents: Leveraging Fine-Grained Block Representations with Large Language Models",
        "author": [
            "Minghan Li",
            "Eric Gaussier",
            "Guodong Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17039",
        "abstract": "In recent years, large language models (LLMs) have demonstrated exceptional power in various domains, including information retrieval. Most of the previous practices involve leveraging these models to create a single embedding for each query, each passage, or each document individually, a strategy exemplified and used by the Retrieval-Augmented Generation (RAG) framework. While this method has proven effective, we argue that it falls short in fully capturing the nuanced intricacies of document-level texts due to its reliance on a relatively coarse-grained representation. To address this limitation, we introduce a novel, fine-grained approach aimed at enhancing the accuracy of relevance scoring for long documents. Our methodology firstly segments a long document into blocks, each of which is embedded using an LLM, for matching with the query representation. When calculating the relevance score, we aggregate the query-block relevance scores through a weighted sum method, yielding a comprehensive score for the query with the entire document. Despite its apparent simplicity, our experimental findings reveal that this approach outperforms standard representation methods and achieves a significant reduction in embedding generation latency. Moreover, by carefully optimizing pairwise loss functions, superior performances have been achieved.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "100",
        "title": "Synthesizing 3D Abstractions by Inverting Procedural Buildings with Transformers",
        "author": [
            "Max Dax",
            "Jordi Berbel",
            "Jan Stria",
            "Leonidas Guibas",
            "Urs Bergmann"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17044",
        "abstract": "We generate abstractions of buildings, reflecting the essential aspects of their geometry and structure, by learning to invert procedural models. We first build a dataset of abstract procedural building models paired with simulated point clouds and then learn the inverse mapping through a transformer. Given a point cloud, the trained transformer then infers the corresponding abstracted building in terms of a programmatic language description. This approach leverages expressive procedural models developed for gaming and animation, and thereby retains desirable properties such as efficient rendering of the inferred abstractions and strong priors for regularity and symmetry. Our approach achieves good reconstruction accuracy in terms of geometry and structure, as well as structurally consistent inpainting.",
        "tags": [
            "3D",
            "Inpainting",
            "Transformer"
        ]
    },
    {
        "id": "101",
        "title": "Graph Transformers for inverse physics: reconstructing flows around arbitrary 2D airfoils",
        "author": [
            "Gregory DuthÃ©",
            "Imad Abdallah",
            "Eleni Chatzi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17081",
        "abstract": "We introduce a Graph Transformer framework that serves as a general inverse physics engine on meshes, demonstrated through the challenging task of reconstructing aerodynamic flow fields from sparse surface measurements. While deep learning has shown promising results in forward physics simulation, inverse problems remain particularly challenging due to their ill-posed nature and the difficulty of propagating information from limited boundary observations. Our approach addresses these challenges by combining the geometric expressiveness of message-passing neural networks with the global reasoning of Transformers, enabling efficient learning of inverse mappings from boundary conditions to complete states. We evaluate this framework on a comprehensive dataset of steady-state RANS simulations around diverse airfoil geometries, where the task is to reconstruct full pressure and velocity fields from surface pressure measurements alone. The architecture achieves high reconstruction accuracy while maintaining fast inference times. We conduct experiments and provide insights into the relative importance of local geometric processing and global attention mechanisms in mesh-based inverse problems. We also find that the framework is robust to reduced sensor coverage. These results suggest that Graph Transformers can serve as effective inverse physics engines across a broader range of applications where complete system states must be reconstructed from limited boundary observations.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "102",
        "title": "Token-by-Token Regeneration and Domain Biases: A Benchmark of LLMs on Advanced Mathematical Problem-Solving",
        "author": [
            "Evgenii Evstafev"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17084",
        "abstract": "Large language models (LLMs) excel in many natural language tasks, yet they struggle with complex mathemat-ical problem-solving, particularly in symbolic reasoning and maintaining consistent output. This study evalu-ates 10 LLMs with 7 to 8 billion parameters using 945 competition-level problems from the MATH dataset. The focus is on their ability to generate executable Python code as a step in their reasoning process, involving over 9,450 code executions. The research introduces an evaluation framework using mistral-large-2411 to rate answers on a 5-point scale, which helps address inconsistencies in mathematical notation. It also examines the impact of regenerating output token-by-token on refining results. The findings reveal a significant 34.5% per-formance gap between the top commercial model (gpt-4o-mini, scoring 83.7%) and the least effective open-source model (open-codestral-mamba:v0.1, scoring 49.2%). This disparity is especially noticeable in complex areas like Number Theory. While token-by-token regeneration slightly improved accuracy (+0.8%) for the model llama3.1:8b, it also reduced code execution time by 36.7%, highlighting a trade-off between efficiency and precision. The study also noted a consistent trend where harder problems correlated with lower accuracy across all models. Despite using controlled execution environments, less than 1% of the generated code was unsafe, and 3.17% of problems remained unsolved after 10 attempts, suggesting that hybrid reasoning methods may be beneficial.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models",
            "Mamba"
        ]
    },
    {
        "id": "103",
        "title": "Evaluating CrowdSplat: Perceived Level of Detail for Gaussian Crowds",
        "author": [
            "Xiaohan Sun",
            "Yinghan Xu",
            "John Dingliana",
            "Carol O'Sullivan"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17085",
        "abstract": "Efficient and realistic crowd rendering is an important element of many real-time graphics applications such as Virtual Reality (VR) and games. To this end, Levels of Detail (LOD) avatar representations such as polygonal meshes, image-based impostors, and point clouds have been proposed and evaluated. More recently, 3D Gaussian Splatting has been explored as a potential method for real-time crowd rendering. In this paper, we present a two-alternative forced choice (2AFC) experiment that aims to determine the perceived quality of 3D Gaussian avatars. Three factors were explored: Motion, LOD (i.e., #Gaussians), and the avatar height in Pixels (corresponding to the viewing distance). Participants viewed pairs of animated 3D Gaussian avatars and were tasked with choosing the most detailed one. Our findings can inform the optimization of LOD strategies in Gaussian-based crowd rendering, thereby helping to achieve efficient rendering while maintaining visual quality in real-time applications.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "104",
        "title": "Mamba-Shedder: Post-Transformer Compression for Efficient Selective Structured State Space Models",
        "author": [
            "J. Pablo MuÃ±oz",
            "Jinjie Yuan",
            "Nilesh Jain"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17088",
        "abstract": "Large pre-trained models have achieved outstanding results in sequence modeling. The Transformer block and its attention mechanism have been the main drivers of the success of these models. Recently, alternative architectures, such as Selective Structured State Space Models (SSMs), have been proposed to address the inefficiencies of Transformers. This paper explores the compression of SSM-based models, particularly Mamba and its hybrids. We study the sensitivity of these models to the removal of selected components at different granularities to reduce the model size and computational overhead, thus improving their efficiency while maintaining accuracy. The proposed solutions, collectively referred to as Mamba-Shedder, achieve a speedup of up to 1.4x during inference, demonstrating that model efficiency can be improved by eliminating several redundancies with minimal impact on the overall model performance. The code is available at https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.",
        "tags": [
            "Mamba",
            "SSMs",
            "State Space Models",
            "Transformer"
        ]
    },
    {
        "id": "105",
        "title": "Text-to-Image Generation for Vocabulary Learning Using the Keyword Method",
        "author": [
            "Nuwan T. Attygalle",
            "MatjaÅ¾ Kljun",
            "Aaron Quigley",
            "Klen ÄOpiÄ Pucihar",
            "Jens Grubert",
            "Verena Biener",
            "Luis A. Leiva",
            "Juri Yoneyama",
            "Alice Toniolo",
            "Angela Miguel",
            "Hirokazu Kato",
            "Maheshya Weerasinghe"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17099",
        "abstract": "The 'keyword method' is an effective technique for learning vocabulary of a foreign language. It involves creating a memorable visual link between what a word means and what its pronunciation in a foreign language sounds like in the learner's native language. However, these memorable visual links remain implicit in the people's mind and are not easy to remember for a large set of words. To enhance the memorisation and recall of the vocabulary, we developed an application that combines the keyword method with text-to-image generators to externalise the memorable visual links into visuals. These visuals represent additional stimuli during the memorisation process. To explore the effectiveness of this approach we first run a pilot study to investigate how difficult it is to externalise the descriptions of mental visualisations of memorable links, by asking participants to write them down. We used these descriptions as prompts for text-to-image generator (DALL-E2) to convert them into images and asked participants to select their favourites. Next, we compared different text-to-image generators (DALL-E2, Midjourney, Stable and Latent Diffusion) to evaluate the perceived quality of the generated images by each. Despite heterogeneous results, participants mostly preferred images generated by DALL-E2, which was used also for the final study. In this study, we investigated whether providing such images enhances the retention of vocabulary being learned, compared to the keyword method only. Our results indicate that people did not encounter difficulties describing their visualisations of memorable links and that providing corresponding images significantly improves memory retention.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "106",
        "title": "COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via Language Models",
        "author": [
            "Tobias Materzok"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17104",
        "abstract": "We present COS(M+O)S, a System 2-inspired framework for open-ended plot development that systematically explores the vast space of possible story expansions, enabling a 3B-parameter language model to approach the plot quality of a 70B model on select short-story tasks. The method accomplishes this by combining Monte Carlo Tree Search (MCTS), guided by a step-level value model that rewards moderate surprisal (curiosity) while penalizing incoherence, and Odds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-value plot expansions. This iterative reinforcement learning loop systematically explores multiple candidate plot branches, backpropagates quality signals, and adapts the policy for faster convergence, notably shifting the policy from puzzle-based Chain-of-Thought to more character-driven storytelling. In small-scale tests with short-story prompts, 67%-77% of participants favored COS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that our learned value function aligns. GPT-4o ratings further show that COS(M+O)S surpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, coming within 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93). Pairwise comparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find no statistically significant gap from 70B. Nevertheless, absolute story quality remains modest, constrained by the small model's capacity and limited training data.",
        "tags": [
            "GPT",
            "LLaMA",
            "RL"
        ]
    },
    {
        "id": "107",
        "title": "Unlocking Transparent Alignment Through Enhanced Inverse Constitutional AI for Principle Extraction",
        "author": [
            "Carl-Leander Henneking",
            "Claas Beger"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17112",
        "abstract": "Traditional methods for aligning Large Language Models (LLMs), such as Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO), rely on implicit principles, limiting interpretability. Constitutional AI (CAI) offers an explicit, rule-based framework for guiding model outputs. Building on this, we refine the Inverse Constitutional AI (ICAI) algorithm, which extracts constitutions from preference datasets. By improving principle generation, clustering, and embedding processes, our approach enhances the accuracy and generalizability of extracted principles across synthetic and real-world datasets. While in-context alignment yields modest improvements, our results highlight the potential of these principles to foster more transparent and adaptable alignment methods, offering a promising direction for future advancements beyond traditional fine-tuning.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "108",
        "title": "Optimizing Large Language Model Training Using FP4 Quantization",
        "author": [
            "Ruizhe Wang",
            "Yeyun Gong",
            "Xiao Liu",
            "Guoshuai Zhao",
            "Ziyue Yang",
            "Baining Guo",
            "Zhengjun Zha",
            "Peng Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17116",
        "abstract": "The growing computational demands of training large language models (LLMs) necessitate more efficient methods. Quantized training presents a promising solution by enabling low-bit arithmetic operations to reduce these costs. While FP8 precision has demonstrated feasibility, leveraging FP4 remains a challenge due to significant quantization errors and limited representational capacity. This work introduces the first FP4 training framework for LLMs, addressing these challenges with two key innovations: a differentiable quantization estimator for precise weight updates and an outlier clamping and compensation strategy to prevent activation collapse. To ensure stability, the framework integrates a mixed-precision training scheme and vector-wise quantization. Experimental results demonstrate that our FP4 framework achieves accuracy comparable to BF16 and FP8, with minimal degradation, scaling effectively to 13B-parameter LLMs trained on up to 100B tokens. With the emergence of next-generation hardware supporting FP4, our framework sets a foundation for efficient ultra-low precision training.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "109",
        "title": "Histoires Morales: A French Dataset for Assessing Moral Alignment",
        "author": [
            "Thibaud Leteno",
            "Irina Proskurina",
            "Antoine Gourru",
            "Julien Velcin",
            "Charlotte Laclau",
            "Guillaume Metzler",
            "Christophe Gravier"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17117",
        "abstract": "Aligning language models with human values is crucial, especially as they become more integrated into everyday life. While models are often adapted to user preferences, it is equally important to ensure they align with moral norms and behaviours in real-world social situations. Despite significant progress in languages like English and Chinese, French has seen little attention in this area, leaving a gap in understanding how LLMs handle moral reasoning in this language. To address this gap, we introduce Histoires Morales, a French dataset derived from Moral Stories, created through translation and subsequently refined with the assistance of native speakers to guarantee grammatical accuracy and adaptation to the French cultural context. We also rely on annotations of the moral values within the dataset to ensure their alignment with French norms. Histoires Morales covers a wide range of social situations, including differences in tipping practices, expressions of honesty in relationships, and responsibilities toward animals. To foster future research, we also conduct preliminary experiments on the alignment of multilingual models on French and English data and the robustness of the alignment. We find that while LLMs are generally aligned with human moral norms by default, they can be easily influenced with user-preference optimization for both moral and immoral data.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "110",
        "title": "Scenario Understanding of Traffic Scenes Through Large Visual Language Models",
        "author": [
            "Rivera Esteban",
            "LÃ¼bberstedt Jannik",
            "Nico Uhlemann",
            "Markus Lienkamp"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17131",
        "abstract": "Deep learning models for autonomous driving, encompassing perception, planning, and control, depend on vast datasets to achieve their high performance. However, their generalization often suffers due to domain-specific data distributions, making an effective scene-based categorization of samples necessary to improve their reliability across diverse domains. Manual captioning, though valuable, is both labor-intensive and time-consuming, creating a bottleneck in the data annotation process. Large Visual Language Models (LVLMs) present a compelling solution by automating image analysis and categorization through contextual queries, often without requiring retraining for new categories. In this study, we evaluate the capabilities of LVLMs, including GPT-4 and LLaVA, to understand and classify urban traffic scenes on both an in-house dataset and the BDD100K. We propose a scalable captioning pipeline that integrates state-of-the-art models, enabling a flexible deployment on new datasets. Our analysis, combining quantitative metrics with qualitative insights, demonstrates the effectiveness of LVLMs to understand urban traffic scenarios and highlights their potential as an efficient tool for data-driven advancements in autonomous driving.",
        "tags": [
            "GPT",
            "LLaVA"
        ]
    },
    {
        "id": "111",
        "title": "ASTRAL: Automated Safety Testing of Large Language Models",
        "author": [
            "Miriam Ugarte",
            "Pablo Valle",
            "JosÃ© Antonio Parejo",
            "Sergio Segura",
            "Aitor Arrieta"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17132",
        "abstract": "Large Language Models (LLMs) have recently gained attention due to their ability to understand and generate sophisticated human-like content. However, ensuring their safety is paramount as they might provide harmful and unsafe responses. Existing LLM testing frameworks address various safety-related concerns (e.g., drugs, terrorism, animal abuse) but often face challenges due to unbalanced and obsolete datasets. In this paper, we present ASTRAL, a tool that automates the generation and execution of test cases (i.e., prompts) for testing the safety of LLMs. First, we introduce a novel black-box coverage criterion to generate balanced and diverse unsafe test inputs across a diverse set of safety categories as well as linguistic writing characteristics (i.e., different style and persuasive writing techniques). Second, we propose an LLM-based approach that leverages Retrieval Augmented Generation (RAG), few-shot prompting strategies and web browsing to generate up-to-date test inputs. Lastly, similar to current LLM test automation techniques, we leverage LLMs as test oracles to distinguish between safe and unsafe test outputs, allowing a fully automated testing approach. We conduct an extensive evaluation on well-known LLMs, revealing the following key findings: i) GPT3.5 outperforms other LLMs when acting as the test oracle, accurately detecting unsafe responses, and even surpassing more recent LLMs (e.g., GPT-4), as well as LLMs that are specifically tailored to detect unsafe LLM outputs (e.g., LlamaGuard); ii) the results confirm that our approach can uncover nearly twice as many unsafe LLM behaviors with the same number of test inputs compared to currently used static datasets; and iii) our black-box coverage criterion combined with web browsing can effectively guide the LLM on generating up-to-date unsafe test inputs, significantly increasing the number of unsafe LLM behaviors.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "112",
        "title": "FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data",
        "author": [
            "Deren Lei",
            "Yaxi Li",
            "Siyao Li",
            "Mengya Hu",
            "Rui Xu",
            "Ken Archer",
            "Mingyu Wang",
            "Emily Ching",
            "Alex Deng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17144",
        "abstract": "Prior research on training grounded factuality classification models to detect hallucinations in large language models (LLMs) has relied on public natural language inference (NLI) data and synthetic data. However, conventional NLI datasets are not well-suited for document-level reasoning, which is critical for detecting LLM hallucinations. Recent approaches to document-level synthetic data generation involve iteratively removing sentences from documents and annotating factuality using LLM-based prompts. While effective, this method is computationally expensive for long documents and limited by the LLM's capabilities. In this work, we analyze the differences between existing synthetic training data used in state-of-the-art models and real LLM output claims. Based on our findings, we propose a novel approach for synthetic data generation, CG2C, that leverages multi-hop reasoning on context graphs extracted from documents. Our fact checker model, FactCG, demonstrates improved performance with more connected reasoning, using the same backbone models. Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark with much smaller model size.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "113",
        "title": "AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders",
        "author": [
            "Zhengxuan Wu",
            "Aryaman Arora",
            "Atticus Geiger",
            "Zheng Wang",
            "Jing Huang",
            "Dan Jurafsky",
            "Christopher D. Manning",
            "Christopher Potts"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17148",
        "abstract": "Fine-grained steering of language model outputs is essential for safety and reliability. Prompting and finetuning are widely used to achieve these goals, but interpretability researchers have proposed a variety of representation-based techniques as well, including sparse autoencoders (SAEs), linear artificial tomography, supervised steering vectors, linear probes, and representation finetuning. At present, there is no benchmark for making direct comparisons between these proposals. Therefore, we introduce AxBench, a large-scale benchmark for steering and concept detection, and report experiments on Gemma-2-2B and 9B. For steering, we find that prompting outperforms all existing methods, followed by finetuning. For concept detection, representation-based methods such as difference-in-means, perform the best. On both evaluations, SAEs are not competitive. We introduce a novel weakly-supervised representational method (Rank-1 Representation Finetuning; ReFT-r1), which is competitive on both tasks while providing the interpretability advantages that prompting lacks. Along with AxBench, we train and publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.",
        "tags": [
            "Detection",
            "LLMs"
        ]
    },
    {
        "id": "114",
        "title": "IC-Portrait: In-Context Matching for View-Consistent Personalized Portrait",
        "author": [
            "Han Yang",
            "Enis Simsar",
            "Sotiris Anagnostidi",
            "Yanlong Zang",
            "Thomas Hofmann",
            "Ziwei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17159",
        "abstract": "Existing diffusion models show great potential for identity-preserving generation. However, personalized portrait generation remains challenging due to the diversity in user profiles, including variations in appearance and lighting conditions. To address these challenges, we propose IC-Portrait, a novel framework designed to accurately encode individual identities for personalized portrait generation. Our key insight is that pre-trained diffusion models are fast learners (e.g.,100 ~ 200 steps) for in-context dense correspondence matching, which motivates the two major designs of our IC-Portrait framework. Specifically, we reformulate portrait generation into two sub-tasks: 1) Lighting-Aware Stitching: we find that masking a high proportion of the input image, e.g., 80%, yields a highly effective self-supervisory representation learning of reference image lighting. 2) View-Consistent Adaptation: we leverage a synthetic view-consistent profile dataset to learn the in-context correspondence. The reference profile can then be warped into arbitrary poses for strong spatial-aligned view conditioning. Coupling these two designs by simply concatenating latents to form ControlNet-like supervision and modeling, enables us to significantly enhance the identity preservation fidelity and stability. Extensive evaluations demonstrate that IC-Portrait consistently outperforms existing state-of-the-art methods both quantitatively and qualitatively, with particularly notable improvements in visual qualities. Furthermore, IC-Portrait even demonstrates 3D-aware relighting capabilities.",
        "tags": [
            "3D",
            "ControlNet",
            "Diffusion"
        ]
    },
    {
        "id": "115",
        "title": "CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation",
        "author": [
            "Nikolai Kalischek",
            "Michael Oechsle",
            "Fabian Manhardt",
            "Philipp Henzler",
            "Konrad Schindler",
            "Federico Tombari"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17162",
        "abstract": "We introduce a novel method for generating 360Â° panoramas from text prompts or images. Our approach leverages recent advances in 3D generation by employing multi-view diffusion models to jointly synthesize the six faces of a cubemap. Unlike previous methods that rely on processing equirectangular projections or autoregressive generation, our method treats each face as a standard perspective image, simplifying the generation process and enabling the use of existing multi-view diffusion models. We demonstrate that these models can be adapted to produce high-quality cubemaps without requiring correspondence-aware attention layers. Our model allows for fine-grained text control, generates high resolution panorama images and generalizes well beyond its training set, whilst achieving state-of-the-art results, both qualitatively and quantitatively. Project page: https://cubediff.github.io/",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "116",
        "title": "RNN-Based Models for Predicting Seizure Onset in Epileptic Patients",
        "author": [
            "Mathan Kumar Mounagurusamy",
            "Thiyagarajan V S",
            "Abdur Rahman",
            "Shravan Chandak",
            "D. Balaji",
            "Venkateswara Rao Jallepalli"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16334",
        "abstract": "Early management and better clinical outcomes for epileptic patients depend on seizure prediction. The accuracy and false alarm rates of existing systems are often compromised by their dependence on static thresholds and basic Electroencephalogram (EEG) properties. A novel Recurrent Neural Network (RNN)-based method for seizure start prediction is proposed in the article to overcome these limitations. As opposed to conventional techniques, the proposed system makes use of Long Short-Term Memory (LSTM) networks to extract temporal correlations from unprocessed EEG data. It enables the system to adapt dynamically to the unique EEG patterns of each patient, improving prediction accuracy. The methodology of the system comprises thorough data collecting, preprocessing, and LSTM-based feature extraction. Annotated EEG datasets are then used for model training and validation. Results show a considerable reduction in false alarm rates (average of 6.8%) and an improvement in prediction accuracy (90.2% sensitivity, 88.9% specificity, and AUC-ROC of 93). Additionally, computational efficiency is significantly higher than that of existing systems (12 ms processing time, 45 MB memory consumption). About improving seizure prediction reliability, these results demonstrate the effectiveness of the proposed RNN-based strategy, opening up possibilities for its practical application to improve epilepsy treatment.",
        "tags": [
            "RNN"
        ]
    },
    {
        "id": "117",
        "title": "MambaTron: Efficient Cross-Modal Point Cloud Enhancement using Aggregate Selective State Space Modeling",
        "author": [
            "Sai Tarun Inaganti",
            "Gennady Petrenko"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16384",
        "abstract": "Point cloud enhancement is the process of generating a high-quality point cloud from an incomplete input. This is done by filling in the missing details from a reference like the ground truth via regression, for example. In addition to unimodal image and point cloud reconstruction, we focus on the task of view-guided point cloud completion, where we gather the missing information from an image, which represents a view of the point cloud and use it to generate the output point cloud. With the recent research efforts surrounding state-space models, originally in natural language processing and now in 2D and 3D vision, Mamba has shown promising results as an efficient alternative to the self-attention mechanism. However, there is limited research towards employing Mamba for cross-attention between the image and the input point cloud, which is crucial in multi-modal problems. In this paper, we introduce MambaTron, a Mamba-Transformer cell that serves as a building block for our network which is capable of unimodal and cross-modal reconstruction which includes view-guided point cloud http://completion.We explore the benefits of Mamba's long-sequence efficiency coupled with the Transformer's excellent analytical capabilities through MambaTron. This approach is one of the first attempts to implement a Mamba-based analogue of cross-attention, especially in computer vision. Our model demonstrates a degree of performance comparable to the current state-of-the-art techniques while using a fraction of the computation resources.",
        "tags": [
            "3D",
            "Mamba",
            "State Space Models",
            "Transformer"
        ]
    },
    {
        "id": "118",
        "title": "Decrypting the temperature field in flow boiling with latent diffusion models",
        "author": [
            "UngJin Na",
            "JunYoung Seo",
            "Taeil Kim",
            "ByongGuk Jeon",
            "HangJin Jo"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16510",
        "abstract": "This paper presents an innovative method using Latent Diffusion Models (LDMs) to generate temperature fields from phase indicator maps. By leveraging the BubbleML dataset from numerical simulations, the LDM translates phase field data into corresponding temperature distributions through a two-stage training process involving a vector-quantized variational autoencoder (VQVAE) and a denoising autoencoder. The resulting model effectively reconstructs complex temperature fields at interfaces. Spectral analysis indicates a high degree of agreement with ground truth data in the low to mid wavenumber ranges, even though some inconsistencies are observed at higher wavenumbers, suggesting areas for further enhancement. This machine learning approach significantly reduces the computational burden of traditional simulations and improves the precision of experimental calibration methods. Future work will focus on refining the model's ability to represent small-scale turbulence and expanding its applicability to a broader range of boiling conditions.",
        "tags": [
            "Diffusion",
            "LDMs"
        ]
    },
    {
        "id": "119",
        "title": "UniPET-SPK: A Unified Framework for Parameter-Efficient Tuning of Pre-trained Speech Models for Robust Speaker Verification",
        "author": [
            "Mufan Sang",
            "John H. L. Hansen"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16542",
        "abstract": "With excellent generalization ability, SSL speech models have shown impressive performance on various downstream tasks in the pre-training and fine-tuning paradigm. However, as the size of pre-trained models grows, fine-tuning becomes practically unfeasible due to expanding computation and storage requirements and the risk of overfitting. This study explores parameter-efficient tuning (PET) methods for adapting large-scale pre-trained SSL speech models to speaker verification task. Correspondingly, we propose three PET methods: (i)an adapter-tuning method, (ii)a prompt-tuning method, and (iii)a unified framework that effectively incorporates adapter-tuning and prompt-tuning with a dynamically learnable gating mechanism. First, we propose the Inner+Inter Adapter framework, which inserts two types of adapters into pre-trained models, allowing for adaptation of latent features within the intermediate Transformer layers and output embeddings from all Transformer layers, through a parallel adapter design. Second, we propose the Deep Speaker Prompting method that concatenates trainable prompt tokens into the input space of pre-trained models to guide adaptation. Lastly, we propose the UniPET-SPK, a unified framework that effectively incorporates these two alternate PET methods into a single framework with a dynamic trainable gating mechanism. The proposed UniPET-SPK learns to find the optimal mixture of PET methods to match different datasets and scenarios. We conduct a comprehensive set of experiments on several datasets to validate the effectiveness of the proposed PET methods. Experimental results on VoxCeleb, CN-Celeb, and 1st 48-UTD forensic datasets demonstrate that the proposed UniPET-SPK consistently outperforms the two PET methods, fine-tuning, and other parameter-efficient tuning methods, achieving superior performance while updating only 5.4% of the parameters.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "120",
        "title": "Variational Schr\\\"odinger Momentum Diffusion",
        "author": [
            "Kevin Rojas",
            "Yixin Tan",
            "Molei Tao",
            "Yuriy Nevmyvaka",
            "Wei Deng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16675",
        "abstract": "The momentum SchrÃ¶dinger Bridge (mSB) has emerged as a leading method for accelerating generative diffusion processes and reducing transport costs. However, the lack of simulation-free properties inevitably results in high training costs and affects scalability. To obtain a trade-off between transport properties and scalability, we introduce variational SchrÃ¶dinger momentum diffusion (VSMD), which employs linearized forward score functions (variational scores) to eliminate the dependence on simulated forward trajectories. Our approach leverages a multivariate diffusion process with adaptively transport-optimized variational scores. Additionally, we apply a critical-damping transform to stabilize training by removing the need for score estimations for both velocity and samples. Theoretically, we prove the convergence of samples generated with optimal variational scores and momentum diffusion. Empirical results demonstrate that VSMD efficiently generates anisotropic shapes while maintaining transport efficacy, outperforming overdamped alternatives, and avoiding complex denoising processes. Our approach also scales effectively to real-world data, achieving competitive results in time series and image generation.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "121",
        "title": "Exponential Family Attention",
        "author": [
            "Kevin Christian Wibisono",
            "Yixin Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16790",
        "abstract": "The self-attention mechanism is the backbone of the transformer neural network underlying most large language models. It can capture complex word patterns and long-range dependencies in natural language. This paper introduces exponential family attention (EFA), a probabilistic generative model that extends self-attention to handle high-dimensional sequence, spatial, or spatial-temporal data of mixed data types, including both discrete and continuous observations. The key idea of EFA is to model each observation conditional on all other existing observations, called the context, whose relevance is learned in a data-driven way via an attention-based latent factor model. In particular, unlike static latent embeddings, EFA uses the self-attention mechanism to capture dynamic interactions in the context, where the relevance of each context observations depends on other observations. We establish an identifiability result and provide a generalization guarantee on excess loss for EFA. Across real-world and synthetic data sets -- including U.S. city temperatures, Instacart shopping baskets, and MovieLens ratings -- we find that EFA consistently outperforms existing models in capturing complex latent structures and reconstructing held-out data.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "122",
        "title": "Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver",
        "author": [
            "Shunya Minami",
            "Kouhei Nakaji",
            "Yohichi Suzuki",
            "AlÃ¡n Aspuru-Guzik",
            "Tadashi Kadowaki"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16986",
        "abstract": "Quantum computing is entering a transformative phase with the emergence of logical quantum processors, which hold the potential to tackle complex problems beyond classical capabilities. While significant progress has been made, applying quantum algorithms to real-world problems remains challenging. Hybrid quantum-classical techniques have been explored to bridge this gap, but they often face limitations in expressiveness, trainability, or scalability. In this work, we introduce conditional Generative Quantum Eigensolver (conditional-GQE), a context-aware quantum circuit generator powered by an encoder-decoder Transformer. Focusing on combinatorial optimization, we train our generator for solving problems with up to 10 qubits, exhibiting nearly perfect performance on new problems. By leveraging the high expressiveness and flexibility of classical generative models, along with an efficient preference-based training scheme, conditional-GQE provides a generalizable and scalable framework for quantum circuit generation. Our approach advances hybrid quantum-classical computing and contributes to accelerate the transition toward fault-tolerant quantum computing.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "123",
        "title": "Artificial Intelligence Clones",
        "author": [
            "Annie Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.16996",
        "abstract": "Large language models, trained on personal data, may soon be able to mimic individual personalities. This would potentially transform search across human candidates, including for marriage and jobs -- indeed, several dating platforms have already begun experimenting with training \"AI clones\" to represent users. This paper presents a theoretical framework to study the tradeoff between the substantially expanded search capacity of AI clones and their imperfect representation of humans. Individuals are modeled as points in $k$-dimensional Euclidean space, and their AI clones are modeled as noisy approximations. I compare two search regimes: an \"in-person regime\" -- where each person randomly meets some number of individuals and matches to the most compatible among them -- against an \"AI representation regime\" -- in which individuals match to the person whose AI clone is most compatible with their AI clone. I show that a finite number of in-person encounters exceeds the expected payoff from search over infinite AI clones. Moreover, when the dimensionality of personality is large, simply meeting two people in person produces a higher expected match quality than entrusting the process to an AI platform, regardless of the size of its candidate pool.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "124",
        "title": "Generative diffusion models from a PDE perspective",
        "author": [
            "Fei Cao",
            "Kimball Johnston",
            "Thomas Laurent",
            "Justin Le",
            "SÃ©bastien Motsch"
        ],
        "pdf": "https://arxiv.org/pdf/2501.17054",
        "abstract": "Diffusion models have become the de facto framework for generating new datasets. The core of these models lies in the ability to reverse a diffusion process in time. The goal of this manuscript is to explain, from a PDE perspective, how this method works and how to derive the PDE governing the reverse dynamics as well as to study its solution analytically. By linking forward and reverse dynamics, we show that the reverse process's distribution has its support contained within the original distribution. Consequently, diffusion methods, in their analytical formulation, do not inherently regularize the original distribution, and thus, there is no generalization principle. This raises a question: where does generalization arise, given that in practice it does occur? Moreover, we derive an explicit solution to the reverse process's SDE under the assumption that the starting point of the forward process is fixed. This provides a new derivation that links two popular approaches to generative diffusion models: stable diffusion (discrete dynamics) and the score-based approach (continuous dynamics). Finally, we explore the case where the original distribution consists of a finite set of data points. In this scenario, the reverse dynamics are explicit (i.e., the loss function has a clear minimizer), and solving the dynamics fails to generate new samples: the dynamics converge to the original samples. In a sense, solving the minimization problem exactly is \"too good for its own good\" (i.e., an overfitting regime).",
        "tags": [
            "Diffusion",
            "SDE"
        ]
    }
]