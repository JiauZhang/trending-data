[
    {
        "id": "1",
        "title": "AI in Education: Rationale, Principles, and Instructional Implications",
        "author": [
            "Eyvind Elstad"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12116",
        "abstract": "This study examines the integration of generative AI in schools, assessing its benefits and risks. As AI use by students grows, it's crucial to understand its impact on learning and teaching practices. Generative AI, like ChatGPT, can create human-like content, prompting questions about its educational role. The article differentiates large language models from traditional search engines and stresses the need for students to develop critical source evaluation skills. Although empirical evidence on AI's classroom effects is limited, AI offers personalized learning support and problem-solving tools, alongside challenges like undermining deep learning if misused. The study emphasizes deliberate strategies to ensure AI complements, not replaces, genuine cognitive effort. AI's educational role should be context-dependent, guided by pedagogical goals. The study concludes with practical advice for teachers on effectively utilizing AI to promote understanding and critical engagement, advocating for a balanced approach to enhance students' knowledge and skills development.",
        "tags": [
            "ChatGPT",
            "Large Language Models"
        ]
    },
    {
        "id": "2",
        "title": "Harnessing AI in Secondary Education to Enhance Writing Competence",
        "author": [
            "Eyvind Elstad",
            "Harald Eriksen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12117",
        "abstract": "The emergence of free AI tools like ChatGPT holds significant implications for developing writing skills in secondary education. This study examines AI's impact on students' writing competence and personal voice, balancing technological benefits against risks of dependency and plagiarism. We review the pros and cons of AI in the writing process, emphasizing process-based assessments, creativity-driven tasks, and AI as a supplement to teacher guidance. The discussion covers AI's role in the pre-writing, writing, and revision stages, and highlights the need for innovative assignments and critical thinking to maintain writing as a human, expressive activity. We advocate for a balanced approach to AI in education, ensuring it supports rather than replaces teacher instruction.",
        "tags": [
            "ChatGPT"
        ]
    },
    {
        "id": "3",
        "title": "Mastering Board Games by External and Internal Planning with Language Models",
        "author": [
            "John Schultz",
            "Jakub Adamek",
            "Matej Jusup",
            "Marc Lanctot",
            "Michael Kaisers",
            "Sarah Perrin",
            "Daniel Hennes",
            "Jeremy Shar",
            "Cannada Lewis",
            "Anian Ruoss",
            "Tom Zahavy",
            "Petar Veličković",
            "Laurel Prince",
            "Satinder Singh",
            "Eric Malmi",
            "Nenad Tomašev"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12119",
        "abstract": "While large language models perform well on a range of complex tasks (e.g., text generation, question answering, summarization), robust multi-step planning and reasoning remains a considerable challenge for them. In this paper we show that search-based planning can significantly improve LLMs' playing strength across several board games (Chess, Fischer Random / Chess960, Connect Four, and Hex). We introduce, compare and contrast two major approaches: In external search, the model guides Monte Carlo Tree Search (MCTS) rollouts and evaluations without calls to an external engine, and in internal search, the model directly generates in-context a linearized tree of potential futures and a resulting final choice. Both build on a language model pre-trained on relevant domain knowledge, capturing the transition and value functions across these games. We find that our pre-training method minimizes hallucinations, as our model is highly accurate regarding state prediction and legal moves. Additionally, both internal and external search indeed improve win-rates against state-of-the-art bots, even reaching Grandmaster-level performance in chess while operating on a similar move count search budget per decision as human Grandmasters. The way we combine search with domain knowledge is not specific to board games, suggesting direct extensions into more general language model inference and training techniques.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "4",
        "title": "NLLG Quarterly arXiv Report 09/24: What are the most influential current AI Papers?",
        "author": [
            "Christoph Leiter",
            "Jonas Belouadi",
            "Yanran Chen",
            "Ran Zhang",
            "Daniil Larionov",
            "Aida Kostikova",
            "Steffen Eger"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12121",
        "abstract": "The NLLG (Natural Language Learning & Generation) arXiv reports assist in navigating the rapidly evolving landscape of NLP and AI research across cs.CL, cs.CV, cs.AI, and cs.LG categories. This fourth installment captures a transformative period in AI history - from January 1, 2023, following ChatGPT's debut, through September 30, 2024. Our analysis reveals substantial new developments in the field - with 45% of the top 40 most-cited papers being new entries since our last report eight months ago and offers insights into emerging trends and major breakthroughs, such as novel multimodal architectures, including diffusion and state space models. Natural Language Processing (NLP; cs.CL) remains the dominant main category in the list of our top-40 papers but its dominance is on the decline in favor of Computer vision (cs.CV) and general machine learning (cs.LG). This report also presents novel findings on the integration of generative AI in academic writing, documenting its increasing adoption since 2022 while revealing an intriguing pattern: top-cited papers show notably fewer markers of AI-generated content compared to random samples. Furthermore, we track the evolution of AI-associated language, identifying declining trends in previously common indicators such as \"delve\".",
        "tags": [
            "ChatGPT",
            "Diffusion",
            "State Space Models"
        ]
    },
    {
        "id": "5",
        "title": "SceneDiffuser: Efficient and Controllable Driving Simulation Initialization and Rollout",
        "author": [
            "Chiyu Max Jiang",
            "Yijing Bai",
            "Andre Cornman",
            "Christopher Davis",
            "Xiukun Huang",
            "Hong Jeon",
            "Sakshum Kulshrestha",
            "John Lambert",
            "Shuangyu Li",
            "Xuanyu Zhou",
            "Carlos Fuertes",
            "Chang Yuan",
            "Mingxing Tan",
            "Yin Zhou",
            "Dragomir Anguelov"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12129",
        "abstract": "Realistic and interactive scene simulation is a key prerequisite for autonomous vehicle (AV) development. In this work, we present SceneDiffuser, a scene-level diffusion prior designed for traffic simulation. It offers a unified framework that addresses two key stages of simulation: scene initialization, which involves generating initial traffic layouts, and scene rollout, which encompasses the closed-loop simulation of agent behaviors. While diffusion models have been proven effective in learning realistic and multimodal agent distributions, several challenges remain, including controllability, maintaining realism in closed-loop simulations, and ensuring inference efficiency. To address these issues, we introduce amortized diffusion for simulation. This novel diffusion denoising paradigm amortizes the computational cost of denoising over future simulation steps, significantly reducing the cost per rollout step (16x less inference steps) while also mitigating closed-loop errors. We further enhance controllability through the introduction of generalized hard constraints, a simple yet effective inference-time constraint mechanism, as well as language-based constrained scene generation via few-shot prompting of a large language model (LLM). Our investigations into model scaling reveal that increased computational resources significantly improve overall simulation realism. We demonstrate the effectiveness of our approach on the Waymo Open Sim Agents Challenge, achieving top open-loop performance and the best closed-loop performance among diffusion models.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "6",
        "title": "Frontier AI systems have surpassed the self-replicating red line",
        "author": [
            "Xudong Pan",
            "Jiarun Dai",
            "Yihe Fan",
            "Min Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12140",
        "abstract": "Successful self-replication under no human assistance is the essential step for AI to outsmart the human beings, and is an early signal for rogue AIs. That is why self-replication is widely recognized as one of the few red line risks of frontier AI systems. Nowadays, the leading AI corporations OpenAI and Google evaluate their flagship large language models GPT-o1 and Gemini Pro 1.0, and report the lowest risk level of self-replication. However, following their methodology, we for the first time discover that two AI systems driven by Meta's Llama31-70B-Instruct and Alibaba's Qwen25-72B-Instruct, popular large language models of less parameters and weaker capabilities, have already surpassed the self-replicating red line. In 50% and 90% experimental trials, they succeed in creating a live and separate copy of itself respectively. By analyzing the behavioral traces, we observe the AI systems under evaluation already exhibit sufficient self-perception, situational awareness and problem-solving capabilities to accomplish self-replication. We further note the AI systems are even able to use the capability of self-replication to avoid shutdown and create a chain of replica to enhance the survivability, which may finally lead to an uncontrolled population of AIs. If such a worst-case risk is let unknown to the human society, we would eventually lose control over the frontier AI systems: They would take control over more computing devices, form an AI species and collude with each other against human beings. Our findings are a timely alert on existing yet previously unknown severe AI risks, calling for international collaboration on effective governance on uncontrolled self-replication of AI systems.",
        "tags": [
            "GPT",
            "Large Language Models"
        ]
    },
    {
        "id": "7",
        "title": "Automatic Item Generation for Personality Situational Judgment Tests with Large Language Models",
        "author": [
            "Chang-Jin Li",
            "Jiyuan Zhang",
            "Yun Tang",
            "Jian Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12144",
        "abstract": "Personality assessment, particularly through situational judgment tests (SJTs), is a vital tool for psychological research, talent selection, and educational evaluation. This study explores the potential of GPT-4, a state-of-the-art large language model (LLM), to automate the generation of personality situational judgment tests (PSJTs) in Chinese. Traditional SJT development is labor-intensive and prone to biases, while GPT-4 offers a scalable, efficient alternative. Two studies were conducted: Study 1 evaluated the impact of prompt design and temperature settings on content validity, finding that optimized prompts with a temperature of 1.0 produced creative and accurate items. Study 2 assessed the psychometric properties of GPT-4-generated PSJTs, revealing that they demonstrated satisfactory reliability and validity, surpassing the performance of manually developed tests in measuring the Big Five personality traits. This research highlights GPT-4's effectiveness in developing high-quality PSJTs, providing a scalable and innovative method for psychometric test development. These findings expand the possibilities of automatic item generation and the application of LLMs in psychology, and offer practical implications for streamlining test development processes in resource-limited settings.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "8",
        "title": "Na'vi or Knave: Jailbreaking Language Models via Metaphorical Avatars",
        "author": [
            "Yu Yan",
            "Sheng Sun",
            "Junqi Tong",
            "Min Liu",
            "Qi Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12145",
        "abstract": "Metaphor serves as an implicit approach to convey information, while enabling the generalized comprehension of complex subjects. However, metaphor can potentially be exploited to bypass the safety alignment mechanisms of Large Language Models (LLMs), leading to the theft of harmful knowledge. In our study, we introduce a novel attack framework that exploits the imaginative capacity of LLMs to achieve jailbreaking, the J\\underline{\\textbf{A}}ilbreak \\underline{\\textbf{V}}ia \\underline{\\textbf{A}}dversarial Me\\underline{\\textbf{TA}} -pho\\underline{\\textbf{R}} (\\textit{AVATAR}). Specifically, to elicit the harmful response, AVATAR extracts harmful entities from a given harmful target and maps them to innocuous adversarial entities based on LLM's imagination. Then, according to these metaphors, the harmful target is nested within human-like interaction for jailbreaking adaptively. Experimental results demonstrate that AVATAR can effectively and transferablly jailbreak LLMs and achieve a state-of-the-art attack success rate across multiple advanced LLMs. Our study exposes a security risk in LLMs from their endogenous imaginative capabilities. Furthermore, the analytical study reveals the vulnerability of LLM to adversarial metaphors and the necessity of developing defense methods against jailbreaking caused by the adversarial metaphor. \\textcolor{orange}{ \\textbf{Warning: This paper contains potentially harmful content from LLMs.}}",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "9",
        "title": "Generative Modeling and Data Augmentation for Power System Production Simulation",
        "author": [
            "Linna Xu",
            "Yongli Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12146",
        "abstract": "As a key component of power system production simulation, load forecasting is critical for the stable operation of power systems. Machine learning methods prevail in this field. However, the limited training data can be a challenge. This paper proposes a generative model-assisted approach for load forecasting under small sample scenarios, consisting of two steps: expanding the dataset using a diffusion-based generative model and then training various machine learning regressors on the augmented dataset to identify the best performer. The expanded dataset significantly reduces forecasting errors compared to the original dataset, and the diffusion model outperforms the generative adversarial model by achieving about 200 times smaller errors and better alignment in latent data distributions.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "10",
        "title": "SMARTCAL: An Approach to Self-Aware Tool-Use Evaluation and Calibration",
        "author": [
            "Yuanhao Shen",
            "Xiaodan Zhu",
            "Lei Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12151",
        "abstract": "The tool-use ability of Large Language Models (LLMs) has a profound impact on a wide range of industrial applications. However, LLMs' self-control and calibration capability in appropriately using tools remains understudied. The problem is consequential as it raises potential risks of degraded performance and poses a threat to the trustworthiness of the models. In this paper, we conduct a study on a family of state-of-the-art LLMs on three datasets with two mainstream tool-use frameworks. Our study reveals the tool-abuse behavior of LLMs, a tendency for models to misuse tools with overconfidence. We also find that this is a common issue regardless of model capability. Accordingly, we propose a novel approach, \\textit{SMARTCAL}, to mitigate the observed issues, and our results show an average of 8.6 percent increase in the QA performance and a 21.6 percent decrease in Expected Calibration Error (ECE) compared to baseline models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "11",
        "title": "GraphTool-Instruction: Revolutionizing Graph Reasoning in LLMs through Decomposed Subtask Instruction",
        "author": [
            "Rongzheng Wang",
            "Shuang Liang",
            "Qizhi Chen",
            "Jiasheng Zhang",
            "Ke Qin"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12152",
        "abstract": "Large language models (LLMs) have been demonstrated to possess the capabilities to understand fundamental graph properties and address various graph reasoning tasks. Existing methods fine-tune LLMs to understand and execute graph reasoning tasks by specially designed task instructions. However, these Text-Instruction methods generally exhibit poor performance. Inspired by tool learning, researchers propose Tool-Instruction methods to solve various graph problems by special tool calling (e.g., function, API and model), achieving significant improvements in graph reasoning tasks. Nevertheless, current Tool-Instruction approaches focus on the tool information and ignore the graph structure information, which leads to significantly inferior performance on small-scale LLMs (less than 13B). To tackle this issue, we propose GraphTool-Instruction, an innovative Instruction-tuning approach that decomposes the graph reasoning task into three distinct subtasks (i.e., graph extraction, tool name identification and tool parameter extraction), and design specialized instructions for each subtask. Our GraphTool-Instruction can be used as a plug-and-play prompt for different LLMs without fine-tuning. Moreover, building on GraphTool-Instruction, we develop GTools, a dataset that includes twenty graph reasoning tasks, and create a graph reasoning LLM called GraphForge based on Llama3-8B. We conduct extensive experiments on twenty graph reasoning tasks with different graph types (e.g., graph size or graph direction), and we find that GraphTool-Instruction achieves SOTA compared to Text-Instruction and Tool-Instruction methods. Fine-tuned on GTools, GraphForge gets further improvement of over 30% compared to the Tool-Instruction enhanced GPT-3.5-turbo, and it performs comparably to the high-cost GPT-4o. Our codes and data are available at https://anonymous.4open.science/r/GraphTool-Instruction.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "12",
        "title": "What Makes In-context Learning Effective for Mathematical Reasoning: A Theoretical Analysis",
        "author": [
            "Jiayu Liu",
            "Zhenya Huang",
            "Chaokun Wang",
            "Xunpeng Huang",
            "Chengxiang Zhai",
            "Enhong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12157",
        "abstract": "Owing to the capability of in-context learning, large language models (LLMs) have shown impressive performance across diverse mathematical reasoning benchmarks. However, we find that few-shot demonstrations can sometimes bring negative performance and their effectiveness on LLMs' reasoning abilities remains unreliable. To this end, in this paper, we aim to theoretically analyze the impact of in-context demonstrations on LLMs' reasoning performance. We prove that the reasoning efficacy (measured by empirical prediction loss) can be bounded by a LLM-oriented semantic similarity and an inference stability of demonstrations, which is general for both one-shot and few-shot scenarios. Based on this finding, we propose a straightforward, generalizable, and low-complexity demonstration selection method named LMS3. It can adaptively facilitate to select the most pertinent samples for different LLMs and includes a novel demonstration rejection mechanism to automatically filter out samples that are unsuitable for few-shot learning. Through experiments on three representative benchmarks, two LLM backbones, and multiple few-shot settings, we verify that our LMS3 has superiority and achieves consistent improvements on all datasets, which existing methods have been unable to accomplish.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "13",
        "title": "Climate Aware Deep Neural Networks (CADNN) for Wind Power Simulation",
        "author": [
            "Ali Forootani",
            "Danial Esmaeili Aliabadi",
            "Daniela Thraen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12160",
        "abstract": "Wind power forecasting plays a critical role in modern energy systems, facilitating the integration of renewable energy sources into the power grid. Accurate prediction of wind energy output is essential for managing the inherent intermittency of wind power, optimizing energy dispatch, and ensuring grid stability. This paper proposes the use of Deep Neural Network (DNN)-based predictive models that leverage climate datasets, including wind speed, atmospheric pressure, temperature, and other meteorological variables, to improve the accuracy of wind power simulations. In particular, we focus on the Coupled Model Intercomparison Project (CMIP) datasets, which provide climate projections, as inputs for training the DNN models. These models aim to capture the complex nonlinear relationships between the CMIP-based climate data and actual wind power generation at wind farms located in Germany. Our study compares various DNN architectures, specifically Multilayer Perceptron (MLP), Long Short-Term Memory (LSTM) networks, and Transformer-enhanced LSTM models, to identify the best configuration among these architectures for climate-aware wind power simulation. The implementation of this framework involves the development of a Python package (CADNN) designed to support multiple tasks, including statistical analysis of the climate data, data visualization, preprocessing, DNN training, and performance evaluation. We demonstrate that the DNN models, when integrated with climate data, significantly enhance forecasting accuracy. This climate-aware approach offers a deeper understanding of the time-dependent climate patterns that influence wind power generation, providing more accurate predictions and making it adaptable to other geographical regions.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "14",
        "title": "Towards LLM-based optimization compilers. Can LLMs learn how to apply a single peephole optimization? Reasoning is all LLMs need!",
        "author": [
            "Xiangxin Fang",
            "Lev Mukhanov"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12163",
        "abstract": "Large Language Models (LLMs) have demonstrated great potential in various language processing tasks, and recent studies have explored their application in compiler optimizations. However, all these studies focus on the conventional open-source LLMs, such as Llama2, which lack enhanced reasoning mechanisms. In this study, we investigate the errors produced by the fine-tuned 7B-parameter Llama2 model as it attempts to learn and apply a simple peephole optimization for the AArch64 assembly code. We provide an analysis of the errors produced by the LLM and compare it with state-of-the-art OpenAI models which implement advanced reasoning logic, including GPT-4o and GPT-o1 (preview). We demonstrate that OpenAI GPT-o1, despite not being fine-tuned, outperforms the fine-tuned Llama2 and GPT-4o. Our findings indicate that this advantage is largely due to the chain-of-thought reasoning implemented in GPT-o1. We hope our work will inspire further research on using LLMs with enhanced reasoning mechanisms and chain-of-thought for code generation and optimization.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "15",
        "title": "PickLLM: Context-Aware RL-Assisted Large Language Model Routing",
        "author": [
            "Dimitrios Sikeridis",
            "Dennis Ramdass",
            "Pranay Pareek"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12170",
        "abstract": "Recently, the number of off-the-shelf Large Language Models (LLMs) has exploded with many open-source options. This creates a diverse landscape regarding both serving options (e.g., inference on local hardware vs remote LLM APIs) and model heterogeneous expertise. However, it is hard for the user to efficiently optimize considering operational cost (pricing structures, expensive LLMs-as-a-service for large querying volumes), efficiency, or even per-case specific measures such as response accuracy, bias, or toxicity. Also, existing LLM routing solutions focus mainly on cost reduction, with response accuracy optimizations relying on non-generalizable supervised training, and ensemble approaches necessitating output computation for every considered LLM candidate. In this work, we tackle the challenge of selecting the optimal LLM from a model pool for specific queries with customizable objectives. We propose PickLLM, a lightweight framework that relies on Reinforcement Learning (RL) to route on-the-fly queries to available models. We introduce a weighted reward function that considers per-query cost, inference latency, and model response accuracy by a customizable scoring function. Regarding the learning algorithms, we explore two alternatives: PickLLM router acting as a learning automaton that utilizes gradient ascent to select a specific LLM, or utilizing stateless Q-learning to explore the set of LLMs and perform selection with a $\\epsilon$-greedy approach. The algorithm converges to a single LLM for the remaining session queries. To evaluate, we utilize a pool of four LLMs and benchmark prompt-response datasets with different contexts. A separate scoring function is assessing response accuracy during the experiment. We demonstrate the speed of convergence for different learning rates and improvement in hard metrics such as cost per querying session and overall response latency.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "16",
        "title": "A NotSo Simple Way to Beat Simple Bench",
        "author": [
            "Soham Sane",
            "Angus McLean"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12173",
        "abstract": "This paper presents a novel framework for enhancing reasoning capabilities in large language models (LLMs) by leveraging iterative reasoning and feedback-driven methodologies. Building on the limitations identified in the SimpleBench benchmark, a dataset designed to evaluate logical coherence and real-world reasoning, we propose a multi-step prompting strategy coupled with global consistency checks to improve model accuracy and robustness. Through comparative analysis of state-of-the-art models, including Claude 3 Opus, Claude 3.5, GPT- 4o, and o1-preview, we demonstrate that iterative reasoning significantly enhances model performance, with improvements observed in both standard accuracy metrics (AVG@5) and a newly introduced metric, Extreme Averaging (EAG@5). Our results reveal model-specific strengths: Claude excels in maintaining logical consistency, while GPT-4o exhibits exploratory creativity but struggles with ambiguous prompts. By analyzing case studies and identifying gaps in spatial and temporal reasoning, we highlight areas for further refinement. The findings underscore the potential of structured reasoning frameworks to address inherent model limitations, irrespective of pretraining methodologies. This study lays the groundwork for integrating dynamic feedback mechanisms, adaptive restart strategies, and diverse evaluation metrics to advance LLM reasoning capabilities across complex and multi-domain problem spaces.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "17",
        "title": "Explore Theory of Mind: Program-guided adversarial data generation for theory of mind reasoning",
        "author": [
            "Melanie Sclar",
            "Jane Yu",
            "Maryam Fazel-Zarandi",
            "Yulia Tsvetkov",
            "Yonatan Bisk",
            "Yejin Choi",
            "Asli Celikyilmaz"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12175",
        "abstract": "Do large language models (LLMs) have theory of mind? A plethora of papers and benchmarks have been introduced to evaluate if current models have been able to develop this key ability of social intelligence. However, all rely on limited datasets with simple patterns that can potentially lead to problematic blind spots in evaluation and an overestimation of model capabilities. We introduce ExploreToM, the first framework to allow large-scale generation of diverse and challenging theory of mind data for robust training and evaluation. Our approach leverages an A* search over a custom domain-specific language to produce complex story structures and novel, diverse, yet plausible scenarios to stress test the limits of LLMs. Our evaluation reveals that state-of-the-art LLMs, such as Llama-3.1-70B and GPT-4o, show accuracies as low as 0% and 9% on ExploreToM-generated data, highlighting the need for more robust theory of mind evaluation. As our generations are a conceptual superset of prior work, fine-tuning on our data yields a 27-point accuracy improvement on the classic ToMi benchmark (Le et al., 2019). ExploreToM also enables uncovering underlying skills and factors missing for models to show theory of mind, such as unreliable state tracking or data imbalances, which may contribute to models' poor performance on benchmarks.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "18",
        "title": "Model-diff: A Tool for Comparative Study of Language Models in the Input Space",
        "author": [
            "Weitang Liu",
            "Yuelei Li",
            "Ying Wai Li",
            "Zihan Wang",
            "Jingbo Shang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12177",
        "abstract": "Comparing two (large) language models (LMs) side-by-side and pinpointing their prediction similarities and differences on the same set of inputs are crucial in many real-world scenarios, e.g., one can test if a licensed model was potentially plagiarized by another. Traditional analysis compares the LMs' outputs on some benchmark datasets, which only cover a limited number of inputs of designed perspectives for the intended applications. The benchmark datasets cannot prepare data to cover the test cases from unforeseen perspectives which can help us understand differences between models unbiasedly. In this paper, we propose a new model comparative analysis setting that considers a large input space where brute-force enumeration would be infeasible. The input space can be simply defined as all token sequences that a LM would produce low perplexity on -- we follow this definition in the paper as it would produce the most human-understandable inputs. We propose a novel framework \\our that uses text generation by sampling and deweights the histogram of sampling statistics to estimate prediction differences between two LMs in this input space efficiently and unbiasedly. Our method achieves this by drawing and counting the inputs at each prediction difference value in negative log-likelihood. Experiments reveal for the first time the quantitative prediction differences between LMs in a large input space, potentially facilitating the model analysis for applications such as model plagiarism.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "19",
        "title": "Activation Sparsity Opportunities for Compressing General Large Language Models",
        "author": [
            "Nobel Dhar",
            "Bobin Deng",
            "Md Romyull Islam",
            "Kazi Fahim Ahmad Nasif",
            "Liang Zhao",
            "Kun Suo"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12178",
        "abstract": "Deploying local AI models, such as Large Language Models (LLMs), to edge devices can substantially enhance devices' independent capabilities, alleviate the server's burden, and lower the response time. Owing to these tremendous potentials, many big tech companies have released several lightweight Small Language Models (SLMs) to bridge this gap. However, we still have huge motivations to deploy more powerful (LLMs) AI models on edge devices and enhance their smartness level. Unlike the conventional approaches for AI model compression, we investigate activation sparsity. The activation sparsity method is orthogonal and combinable with existing techniques to maximize compression rate while maintaining great accuracy. LLMs' Feed-Forward Network (FFN) components, which typically comprise a large proportion of parameters (around 3/2), ensure that our FFN optimizations would have a better chance of achieving effective compression. Moreover, our findings are beneficial to general LLMs and are not restricted to ReLU-based models. This work systematically investigates the tradeoff between enforcing activation sparsity and perplexity (accuracy) on state-of-the-art LLMs. Our empirical analysis demonstrates that we can obtain around 50% of main memory and computing reductions for critical FFN components with negligible accuracy degradation. This extra 50% sparsity does not naturally exist in the current LLMs, which require tuning LLMs' activation outputs by injecting zero-enforcing thresholds. To obtain the benefits of activation sparsity, we provide a guideline for the system architect for LLM prediction and prefetching. The success prediction allows the system to prefetch the necessary weights while omitting the inactive ones and their successors, therefore lowering cache and memory pollution and reducing LLM execution time on resource-constrained edge devices.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "20",
        "title": "iMoT: Inertial Motion Transformer for Inertial Navigation",
        "author": [
            "Son Minh Nguyen",
            "Linh Duy Tran",
            "Duc Viet Le",
            "Paul J.M Havinga"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12190",
        "abstract": "We propose iMoT, an innovative Transformer-based inertial odometry method that retrieves cross-modal information from motion and rotation modalities for accurate positional estimation. Unlike prior work, during the encoding of the motion context, we introduce Progressive Series Decoupler at the beginning of each encoder layer to stand out critical motion events inherent in acceleration and angular velocity signals. To better aggregate cross-modal interactions, we present Adaptive Positional Encoding, which dynamically modifies positional embeddings for temporal discrepancies between different modalities. During decoding, we introduce a small set of learnable query motion particles as priors to model motion uncertainties within velocity segments. Each query motion particle is intended to draw cross-modal features dedicated to a specific motion mode, all taken together allowing the model to refine its understanding of motion dynamics effectively. Lastly, we design a dynamic scoring mechanism to stabilize iMoT's optimization by considering all aligned motion particles at the final decoding step, ensuring robust and accurate velocity segment estimation. Extensive evaluations on various inertial datasets demonstrate that iMoT significantly outperforms state-of-the-art methods in delivering superior robustness and accuracy in trajectory reconstruction.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "21",
        "title": "No Free Lunch for Defending Against Prefilling Attack by In-Context Learning",
        "author": [
            "Zhiyu Xue",
            "Guangliang Liu",
            "Bocheng Chen",
            "Kristen Marie Johnson",
            "Ramtin Pedarsani"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12192",
        "abstract": "The security of Large Language Models (LLMs) has become an important research topic since the emergence of ChatGPT. Though there have been various effective methods to defend against jailbreak attacks, prefilling attacks remain an unsolved and popular threat against open-sourced LLMs. In-Context Learning (ICL) offers a computationally efficient defense against various jailbreak attacks, yet no effective ICL methods have been developed to counter prefilling attacks. In this paper, we: (1) show that ICL can effectively defend against prefilling jailbreak attacks by employing adversative sentence structures within demonstrations; (2) characterize the effectiveness of this defense through the lens of model size, number of demonstrations, over-defense, integration with other jailbreak attacks, and the presence of safety alignment. Given the experimental results and our analysis, we conclude that there is no free lunch for defending against prefilling jailbreak attacks with ICL. On the one hand, current safety alignment methods fail to mitigate prefilling jailbreak attacks, but adversative structures within ICL demonstrations provide robust defense across various model sizes and complex jailbreak attacks. On the other hand, LLMs exhibit similar over-defensiveness when utilizing ICL demonstrations with adversative structures, and this behavior appears to be independent of model size.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "22",
        "title": "Embracing Large Language Models in Traffic Flow Forecasting",
        "author": [
            "Yusheng Zhao",
            "Xiao Luo",
            "Haomin Wen",
            "Zhiping Xiao",
            "Wei Ju",
            "Ming Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12201",
        "abstract": "Traffic flow forecasting aims to predict future traffic flows based on the historical traffic conditions and the road network. It is an important problem in intelligent transportation systems, with a plethora of methods been proposed. Existing efforts mainly focus on capturing and utilizing spatio-temporal dependencies to predict future traffic flows. Though promising, they fall short in adapting to test-time environmental changes of traffic conditions. To tackle this challenge, we propose to introduce large language models (LLMs) to help traffic flow forecasting and design a novel method named Large Language Model Enhanced Traffic Flow Predictor (LEAF). LEAF adopts two branches, capturing different spatio-temporal relations using graph and hypergraph structures respectively. The two branches are first pre-trained individually, and during test-time, they yield different predictions. Based on these predictions, a large language model is used to select the most likely result. Then, a ranking loss is applied as the learning objective to enhance the prediction ability of the two branches. Extensive experiments on several datasets demonstrate the effectiveness of the proposed LEAF.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "23",
        "title": "SEE: Sememe Entanglement Encoding for Transformer-bases Models Compression",
        "author": [
            "Jing Zhang",
            "Shuzhen Sun",
            "Peng Zhang",
            "Guangxing Cao",
            "Hui Gao",
            "Xindian Ma",
            "Nan Xu",
            "Yuexian Hou"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12204",
        "abstract": "Transformer-based large language models exhibit groundbreaking capabilities, but their storage and computational costs are prohibitively high, limiting their application in resource-constrained scenarios. An effective approach is to eliminate redundant model parameters and computational costs while incorporating efficient expert-derived knowledge structures to achieve a balance between compression and performance. Therefore, we propose the \\textit{Sememe Entanglement Encoding (SEE)} algorithm. Guided by expert prior knowledge, the model is compressed through the low-rank approximation idea. In Entanglement Embedding, basic semantic units such as sememes are represented as low-dimensional vectors, and then reconstructed into high-dimensional word embeddings through the combination of generalized quantum entanglement. We adapt the Sememe Entanglement Encoding algorithm to transformer-based models of different magnitudes. Experimental results indicate that our approach achieves stable performance while compressing model parameters and computational costs.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "24",
        "title": "Finding a Wolf in Sheep's Clothing: Combating Adversarial Text-To-Image Prompts with Text Summarization",
        "author": [
            "Portia Cooper",
            "Harshita Narnoli",
            "Mihai Surdeanu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12212",
        "abstract": "Text-to-image models are vulnerable to the stepwise \"Divide-and-Conquer Attack\" (DACA) that utilize a large language model to obfuscate inappropriate content in prompts by wrapping sensitive text in a benign narrative. To mitigate stepwise DACA attacks, we propose a two-layer method involving text summarization followed by binary classification. We assembled the Adversarial Text-to-Image Prompt (ATTIP) dataset ($N=940$), which contained DACA-obfuscated and non-obfuscated prompts. From the ATTIP dataset, we created two summarized versions: one generated by a small encoder model and the other by a large language model. Then, we used an encoder classifier and a GPT-4o classifier to perform content moderation on the summarized and unsummarized prompts. When compared with a classifier that operated over the unsummarized data, our method improved F1 score performance by 31%. Further, the highest recorded F1 score achieved (98%) was produced by the encoder classifier on a summarized ATTIP variant. This study indicates that pre-classification text summarization can inoculate content detection models against stepwise DACA obfuscations.",
        "tags": [
            "Detection",
            "GPT",
            "Text-to-Image"
        ]
    },
    {
        "id": "25",
        "title": "Can video generation replace cinematographers? Research on the cinematic language of generated video",
        "author": [
            "Xiaozhe Li",
            "Kai WU",
            "Siyi Yang",
            "YiZhan Qu",
            "Guohua.Zhang",
            "Zhiyu Chen",
            "Jiayao Li",
            "Jiangchuan Mu",
            "Xiaobin Hu",
            "Wen Fang",
            "Mingliang Xiong",
            "Hao Deng",
            "Qingwen Liu",
            "Gang Li",
            "Bin He"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12223",
        "abstract": "Recent advancements in text-to-video (T2V) generation have leveraged diffusion models to enhance the visual coherence of videos generated from textual descriptions. However, most research has primarily focused on object motion, with limited attention given to cinematic language in videos, which is crucial for cinematographers to convey emotion and narrative pacing. To address this limitation, we propose a threefold approach to enhance the ability of T2V models to generate controllable cinematic language. Specifically, we introduce a cinematic language dataset that encompasses shot framing, angle, and camera movement, enabling models to learn diverse cinematic styles. Building on this, to facilitate robust cinematic alignment evaluation, we present CameraCLIP, a model fine-tuned on the proposed dataset that excels in understanding complex cinematic language in generated videos and can further provide valuable guidance in the multi-shot composition process. Finally, we propose CLIPLoRA, a cost-guided dynamic LoRA composition method that facilitates smooth transitions and realistic blending of cinematic language by dynamically fusing multiple pre-trained cinematic LoRAs within a single video. Our experiments demonstrate that CameraCLIP outperforms existing models in assessing the alignment between cinematic language and video, achieving an R@1 score of 0.81. Additionally, CLIPLoRA improves the ability for multi-shot composition, potentially bridging the gap between automatically generated videos and those shot by professional cinematographers.",
        "tags": [
            "Diffusion",
            "LoRA",
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "26",
        "title": "EDformer: Embedded Decomposition Transformer for Interpretable Multivariate Time Series Predictions",
        "author": [
            "Sanjay Chakraborty",
            "Ibrahim Delibasoglu",
            "Fredrik Heintz"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12227",
        "abstract": "Time series forecasting is a crucial challenge with significant applications in areas such as weather prediction, stock market analysis, and scientific simulations. This paper introduces an embedded decomposed transformer, 'EDformer', for multivariate time series forecasting tasks. Without altering the fundamental elements, we reuse the Transformer architecture and consider the capable functions of its constituent parts in this work. Edformer first decomposes the input multivariate signal into seasonal and trend components. Next, the prominent multivariate seasonal component is reconstructed across the reverse dimensions, followed by applying the attention mechanism and feed-forward network in the encoder stage. In particular, the feed-forward network is used for each variable frame to learn nonlinear representations, while the attention mechanism uses the time points of individual seasonal series embedded within variate frames to capture multivariate correlations. Therefore, the trend signal is added with projection and performs the final forecasting. The EDformer model obtains state-of-the-art predicting results in terms of accuracy and efficiency on complex real-world time series datasets. This paper also addresses model explainability techniques to provide insights into how the model makes its predictions and why specific features or time steps are important, enhancing the interpretability and trustworthiness of the forecasting results.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "27",
        "title": "OmniPrism: Learning Disentangled Visual Concept for Image Generation",
        "author": [
            "Yangyang Li",
            "Daqing Liu",
            "Wu Liu",
            "Allen He",
            "Xinchen Liu",
            "Yongdong Zhang",
            "Guoqing Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12242",
        "abstract": "Creative visual concept generation often draws inspiration from specific concepts in a reference image to produce relevant outcomes. However, existing methods are typically constrained to single-aspect concept generation or are easily disrupted by irrelevant concepts in multi-aspect concept scenarios, leading to concept confusion and hindering creative generation. To address this, we propose OmniPrism, a visual concept disentangling approach for creative image generation. Our method learns disentangled concept representations guided by natural language and trains a diffusion model to incorporate these concepts. We utilize the rich semantic space of a multimodal extractor to achieve concept disentanglement from given images and concept guidance. To disentangle concepts with different semantics, we construct a paired concept disentangled dataset (PCD-200K), where each pair shares the same concept such as content, style, and composition. We learn disentangled concept representations through our contrastive orthogonal disentangled (COD) training pipeline, which are then injected into additional diffusion cross-attention layers for generation. A set of block embeddings is designed to adapt each block's concept domain in the diffusion models. Extensive experiments demonstrate that our method can generate high-quality, concept-disentangled results with high fidelity to text prompts and desired concepts.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "28",
        "title": "Emergence of Abstractions: Concept Encoding and Decoding Mechanism for In-Context Learning in Transformers",
        "author": [
            "Seungwook Han",
            "Jinyeop Song",
            "Jeff Gore",
            "Pulkit Agrawal"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12276",
        "abstract": "Humans distill complex experiences into fundamental abstractions that enable rapid learning and adaptation. Similarly, autoregressive transformers exhibit adaptive learning through in-context learning (ICL), which begs the question of how. In this paper, we propose \\textbf{concept encoding-decoding mechanism} to explain ICL by studying how transformers form and use internal abstractions in their representations. On synthetic ICL tasks, we analyze the training dynamics of a small transformer and report the coupled emergence of concept encoding and decoding. As the model learns to encode different latent concepts (e.g., ``Finding the first noun in a sentence.\") into distinct, separable representations, it concureently builds conditional decoding algorithms and improve its ICL performance. We validate the existence of this mechanism across pretrained models of varying scales (Gemma-2 2B/9B/27B, Llama-3.1 8B/70B). Further, through mechanistic interventions and controlled finetuning, we demonstrate that the quality of concept encoding is causally related and predictive of ICL performance. Our empirical insights shed light into better understanding the success and failure modes of large language models via their representations.",
        "tags": [
            "LLaMA",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "29",
        "title": "Towards a Universal Synthetic Video Detector: From Face or Background Manipulations to Fully AI-Generated Content",
        "author": [
            "Rohit Kundu",
            "Hao Xiong",
            "Vishal Mohanty",
            "Athula Balachandran",
            "Amit K. Roy-Chowdhury"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12278",
        "abstract": "Existing DeepFake detection techniques primarily focus on facial manipulations, such as face-swapping or lip-syncing. However, advancements in text-to-video (T2V) and image-to-video (I2V) generative models now allow fully AI-generated synthetic content and seamless background alterations, challenging face-centric detection methods and demanding more versatile approaches.\nTo address this, we introduce the \\underline{U}niversal \\underline{N}etwork for \\underline{I}dentifying \\underline{T}ampered and synth\\underline{E}tic videos (\\texttt{UNITE}) model, which, unlike traditional detectors, captures full-frame manipulations. \\texttt{UNITE} extends detection capabilities to scenarios without faces, non-human subjects, and complex background modifications. It leverages a transformer-based architecture that processes domain-agnostic features extracted from videos via the SigLIP-So400M foundation model. Given limited datasets encompassing both facial/background alterations and T2V/I2V content, we integrate task-irrelevant data alongside standard DeepFake datasets in training. We further mitigate the model's tendency to over-focus on faces by incorporating an attention-diversity (AD) loss, which promotes diverse spatial attention across video frames. Combining AD loss with cross-entropy improves detection performance across varied contexts. Comparative evaluations demonstrate that \\texttt{UNITE} outperforms state-of-the-art detectors on datasets (in cross-data settings) featuring face/background manipulations and fully synthetic T2V/I2V videos, showcasing its adaptability and generalizable detection capabilities.",
        "tags": [
            "Detection",
            "Text-to-Video",
            "Transformer"
        ]
    },
    {
        "id": "30",
        "title": "On the stability of IMEX BDF methods for DDEs and PDDEs",
        "author": [
            "Ana Tercero-Báez",
            "Jesús Martín-Vaquero"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12297",
        "abstract": "In this paper, the stability of IMEX-BDF methods for delay differential equations (DDEs) is studied based on the test equation $y'(t)=-A y(t) + B y(t-\\tau)$, where $\\tau$ is a constant delay, $A$ is a positive definite matrix, but $B$ might be any matrix. First, it is analyzed the case where both matrices diagonalize simultaneously, but the paper focus in the case where the matrices $A$ and $B$ are not simultaneosly diagonalizable. The concept of field of values is used to prove a sufficient condition for unconditional stability of these methods and another condition which also guarantees their stability, but according to the step size.\nSeveral numerical examples in which the theory discussed here is applied to DDEs, but also parabolic problems given by partial delay differential equations with a diffusion term and a delayed term are presented.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "31",
        "title": "Numerical Solution Partial Differential Equations using the Discrete Fourier Transform",
        "author": [
            "Daniela Rodriguez-Lara",
            "Ivan Alvarez-Rios",
            "Francisco S. Guzman"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12308",
        "abstract": "In this paper we explain how to use the Fast Fourier Transform (FFT) to solve partial differential equations (PDEs). We start by defining appropriate discrete domains in coordinate and frequency domains. Then describe the main limitation of the method arising from the Sampling Theorem, which defines the critical Nyquist frequency and the aliasing effect. We then define the Fourier Transform (FT) and the FFT in a way that can be implemented in one and more dimensions. Finally, we show how to apply the FFT in the solution of PDEs related to problems involving two spatial dimensions, specifically the Poisson equation, the diffusion equation and the wave equation for elliptic, parabolic and hyperbolic cases respectively.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "32",
        "title": "Second Language (Arabic) Acquisition of LLMs via Progressive Vocabulary Expansion",
        "author": [
            "Jianqing Zhu",
            "Huang Huang",
            "Zhihang Lin",
            "Juhao Liang",
            "Zhengyang Tang",
            "Khalid Almubarak",
            "Abdulmohsen Alharthik",
            "Bang An",
            "Juncai He",
            "Xiangbo Wu",
            "Fei Yu",
            "Junying Chen",
            "Zhuoheng Ma",
            "Yuhao Du",
            "He Zhang",
            "Emad A. Alghamdi",
            "Lian Zhang",
            "Ruoyu Sun",
            "Haizhou Li",
            "Benyou Wang",
            "Jinchao Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12310",
        "abstract": "This paper addresses the critical need for democratizing large language models (LLM) in the Arab world, a region that has seen slower progress in developing models comparable to state-of-the-art offerings like GPT-4 or ChatGPT 3.5, due to a predominant focus on mainstream languages (e.g., English and Chinese). One practical objective for an Arabic LLM is to utilize an Arabic-specific vocabulary for the tokenizer that could speed up decoding. However, using a different vocabulary often leads to a degradation of learned knowledge since many words are initially out-of-vocabulary (OOV) when training starts. Inspired by the vocabulary learning during Second Language (Arabic) Acquisition for humans, the released AraLLaMA employs progressive vocabulary expansion, which is implemented by a modified BPE algorithm that progressively extends the Arabic subwords in its dynamic vocabulary during training, thereby balancing the OOV ratio at every stage. The ablation study demonstrated the effectiveness of Progressive Vocabulary Expansion. Moreover, AraLLaMA achieves decent performance comparable to the best Arabic LLMs across a variety of Arabic benchmarks. Models, training data, benchmarks, and codes will be all open-sourced.",
        "tags": [
            "ChatGPT",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "33",
        "title": "RAG Playground: A Framework for Systematic Evaluation of Retrieval Strategies and Prompt Engineering in RAG Systems",
        "author": [
            "Ioannis Papadimitriou",
            "Ilias Gialampoukidis",
            "Stefanos Vrochidis",
            "Ioannis",
            "Kompatsiaris"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12322",
        "abstract": "We present RAG Playground, an open-source framework for systematic evaluation of Retrieval-Augmented Generation (RAG) systems. The framework implements and compares three retrieval approaches: naive vector search, reranking, and hybrid vector-keyword search, combined with ReAct agents using different prompting strategies. We introduce a comprehensive evaluation framework with novel metrics and provide empirical results comparing different language models (Llama 3.1 and Qwen 2.5) across various retrieval configurations. Our experiments demonstrate significant performance improvements through hybrid search methods and structured self-evaluation prompting, achieving up to 72.7% pass rate on our multi-metric evaluation framework. The results also highlight the importance of prompt engineering in RAG systems, with our custom-prompted agents showing consistent improvements in retrieval accuracy and response quality.",
        "tags": [
            "LLaMA",
            "RAG"
        ]
    },
    {
        "id": "34",
        "title": "A Large Language Model Approach to Identify Flakiness in C++ Projects",
        "author": [
            "Xin Sun",
            "Daniel Ståhl",
            "Kristian Sandahl"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12340",
        "abstract": "The role of regression testing in software testing is crucial as it ensures that any new modifications do not disrupt the existing functionality and behaviour of the software system. The desired outcome is for regression tests to yield identical results without any modifications made to the system being tested. In practice, however, the presence of Flaky Tests introduces non-deterministic behaviour and undermines the reliability of regression testing results.\nIn this paper, we propose an LLM-based approach for identifying the root cause of flaky tests in C++ projects at the code level, with the intention of assisting developers in debugging and resolving them more efficiently. We compile a comprehensive collection of C++ project flaky tests sourced from GitHub repositories. We fine-tune Mistral-7b, Llama2-7b and CodeLlama-7b models on the C++ dataset and an existing Java dataset and evaluate the performance in terms of precision, recall, accuracy, and F1 score. We assess the performance of the models across various datasets and offer recommendations for both research and industry applications.\nThe results indicate that our models exhibit varying performance on the C++ dataset, while their performance is comparable to that of the Java dataset. The Mistral-7b surpasses the other two models regarding all metrics, achieving a score of 1. Our results demonstrate the exceptional capability of LLMs to accurately classify flakiness in C++ and Java projects, providing a promising approach to enhance the efficiency of debugging flaky tests in practice.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "35",
        "title": "Krony-PT: GPT2 compressed with Kronecker Products",
        "author": [
            "M. Ayoub Ben Ayad",
            "Jelena Mitrovic",
            "Michael Granitzer"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12351",
        "abstract": "We introduce Krony-PT, a compression technique of GPT2 \\citep{radford2019language} based on Kronecker Products. We specifically target the MLP layers of each transformer layer, and systematically compress the feed forward layer matrices to various degrees. We introduce a modified Van Loan decomposition to initialize the new factors, and also introduce a new pruning-based initialization trick. Our method compresses the original 124M parameter GPT2 to various smaller models, with 80M being the smallest, and 96M being the largest compressed model. Our 81M model variant outperforms distilgpt2 on next-token prediction on all standard language modeling datasets, and shows competitive scores or performs on par with other Kronecker Products based compressed models of GPT2 that are significantly higher in size.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "36",
        "title": "BioRAGent: A Retrieval-Augmented Generation System for Showcasing Generative Query Expansion and Domain-Specific Search for Scientific Q&A",
        "author": [
            "Samy Ateia",
            "Udo Kruschwitz"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12358",
        "abstract": "We present BioRAGent, an interactive web-based retrieval-augmented generation (RAG) system for biomedical question answering. The system uses large language models (LLMs) for query expansion, snippet extraction, and answer generation while maintaining transparency through citation links to the source documents and displaying generated queries for further editing. Building on our successful participation in the BioASQ 2024 challenge, we demonstrate how few-shot learning with LLMs can be effectively applied for a professional search setting. The system supports both direct short paragraph style responses and responses with inline citations. Our demo is available online, and the source code is publicly accessible through GitHub.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "37",
        "title": "Visual Instruction Tuning with 500x Fewer Parameters through Modality Linear Representation-Steering",
        "author": [
            "Jinhe Bi",
            "Yujun Wang",
            "Haokun Chen",
            "Xun Xiao",
            "Artur Hecker",
            "Volker Tresp",
            "Yunpu Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12359",
        "abstract": "Multimodal Large Language Models (MLLMs) have significantly advanced visual tasks by integrating visual representations into large language models (LLMs). The textual modality, inherited from LLMs, equips MLLMs with abilities like instruction following and in-context learning. In contrast, the visual modality enhances performance in downstream tasks by leveraging rich semantic content, spatial information, and grounding capabilities. These intrinsic modalities work synergistically across various visual tasks. Our research initially reveals a persistent imbalance between these modalities, with text often dominating output generation during visual instruction tuning. This imbalance occurs when using both full fine-tuning and parameter-efficient fine-tuning (PEFT) methods. We then found that re-balancing these modalities can significantly reduce the number of trainable parameters required, inspiring a direction for further optimizing visual instruction tuning. We introduce Modality Linear Representation-Steering (MoReS) to achieve the goal. MoReS effectively re-balances the intrinsic modalities throughout the model, where the key idea is to steer visual representations through linear transformations in the visual subspace across each model layer. To validate our solution, we composed LLaVA Steering, a suite of models integrated with the proposed MoReS method. Evaluation results show that the composed LLaVA Steering models require, on average, 500 times fewer trainable parameters than LoRA needs while still achieving comparable performance across three visual benchmarks and eight visual question-answering tasks. Last, we present the LLaVA Steering Factory, an in-house developed platform that enables researchers to quickly customize various MLLMs with component-based architecture for seamlessly integrating state-of-the-art models, and evaluate their intrinsic modality imbalance.",
        "tags": [
            "LLMs",
            "LLaVA",
            "Large Language Models",
            "LoRA"
        ]
    },
    {
        "id": "38",
        "title": "How Different AI Chatbots Behave? Benchmarking Large Language Models in Behavioral Economics Games",
        "author": [
            "Yutong Xie",
            "Yiyao Liu",
            "Zhuang Ma",
            "Lin Shi",
            "Xiyuan Wang",
            "Walter Yuan",
            "Matthew O. Jackson",
            "Qiaozhu Mei"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12362",
        "abstract": "The deployment of large language models (LLMs) in diverse applications requires a thorough understanding of their decision-making strategies and behavioral patterns. As a supplement to a recent study on the behavioral Turing test, this paper presents a comprehensive analysis of five leading LLM-based chatbot families as they navigate a series of behavioral economics games. By benchmarking these AI chatbots, we aim to uncover and document both common and distinct behavioral patterns across a range of scenarios. The findings provide valuable insights into the strategic preferences of each LLM, highlighting potential implications for their deployment in critical decision-making roles.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "39",
        "title": "LogBabylon: A Unified Framework for Cross-Log File Integration and Analysis",
        "author": [
            "Rabimba Karanjai",
            "Yang Lu",
            "Dana Alsagheer",
            "Keshav Kasichainula",
            "Lei Xu",
            "Weidong Shi",
            "Shou-Hsuan Stephen Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12364",
        "abstract": "Logs are critical resources that record events, activities, or messages produced by software applications, operating systems, servers, and network devices. However, consolidating the heterogeneous logs and cross-referencing them is challenging and complicated. Manually analyzing the log data is time-consuming and prone to errors. LogBabylon is a centralized log data consolidating solution that leverages Large Language Models (LLMs) integrated with Retrieval-Augmented Generation (RAG) technology. LogBabylon interprets the log data in a human-readable way and adds insight analysis of the system performance and anomaly alerts. It provides a paramount view of the system landscape, enabling proactive management and rapid incident response. LogBabylon consolidates diverse log sources and enhances the extracted information's accuracy and relevancy. This facilitates a deeper understanding of log data, supporting more effective decision-making and operational efficiency. Furthermore, LogBabylon streamlines the log analysis process, significantly reducing the time and effort required to interpret complex datasets. Its capabilities extend to generating context-aware insights, offering an invaluable tool for continuous monitoring, performance optimization, and security assurance in dynamic computing environments.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "40",
        "title": "Priority-Aware Model-Distributed Inference at Edge Networks",
        "author": [
            "Teng Li",
            "Hulya Seferoglu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12371",
        "abstract": "Distributed inference techniques can be broadly classified into data-distributed and model-distributed schemes. In data-distributed inference (DDI), each worker carries the entire Machine Learning (ML) model but processes only a subset of the data. However, feeding the data to workers results in high communication costs, especially when the data is large. An emerging paradigm is model-distributed inference (MDI), where each worker carries only a subset of ML layers. In MDI, a source device that has data processes a few layers of ML model and sends the output to a neighboring device, i.e., offloads the rest of the layers. This process ends when all layers are processed in a distributed manner. In this paper, we investigate the design and development of MDI when multiple data sources co-exist. We consider that each data source has a different importance and, hence, a priority. We formulate and solve a priority-aware model allocation optimization problem. Based on the structure of the optimal solution, we design a practical Priority-Aware Model- Distributed Inference (PA-MDI) algorithm that determines model allocation and distribution over devices by taking into account the priorities of different sources. Experiments were conducted on a real-life testbed of NVIDIA Jetson Xavier and Nano edge devices as well as in the Colosseum testbed with ResNet-50, ResNet- 56, and GPT-2 models. The experimental results show that PA-MDI performs priority-aware model allocation successfully while reducing the inference time as compared to baselines.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "41",
        "title": "Interpretable LLM-based Table Question Answering",
        "author": [
            "Giang",
            "Nguyen",
            "Ivan Brugere",
            "Shubham Sharma",
            "Sanjay Kariyappa",
            "Anh Totti Nguyen",
            "Freddy Lecue"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12386",
        "abstract": "Interpretability for Table Question Answering (Table QA) is critical, particularly in high-stakes industries like finance or healthcare. Although recent approaches using Large Language Models (LLMs) have significantly improved Table QA performance, their explanations for how the answers are generated are ambiguous. To fill this gap, we introduce Plan-of-SQLs ( or POS), an interpretable, effective, and efficient approach to Table QA that answers an input query solely with SQL executions. Through qualitative and quantitative evaluations with human and LLM judges, we show that POS is most preferred among explanation methods, helps human users understand model decision boundaries, and facilitates model success and error identification. Furthermore, when evaluated in standard benchmarks (TabFact, WikiTQ, and FetaQA), POS achieves competitive or superior accuracy compared to existing methods, while maintaining greater efficiency by requiring significantly fewer LLM calls and database queries.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "42",
        "title": "Efficient Scaling of Diffusion Transformers for Text-to-Image Generation",
        "author": [
            "Hao Li",
            "Shamit Lal",
            "Zhiheng Li",
            "Yusheng Xie",
            "Ying Wang",
            "Yang Zou",
            "Orchid Majumder",
            "R. Manmatha",
            "Zhuowen Tu",
            "Stefano Ermon",
            "Stefano Soatto",
            "Ashwin Swaminathan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12391",
        "abstract": "We empirically study the scaling properties of various Diffusion Transformers (DiTs) for text-to-image generation by performing extensive and rigorous ablations, including training scaled DiTs ranging from 0.3B upto 8B parameters on datasets up to 600M images. We find that U-ViT, a pure self-attention based DiT model provides a simpler design and scales more effectively in comparison with cross-attention based DiT variants, which allows straightforward expansion for extra conditions and other modalities. We identify a 2.3B U-ViT model can get better performance than SDXL UNet and other DiT variants in controlled setting. On the data scaling side, we investigate how increasing dataset size and enhanced long caption improve the text-image alignment performance and the learning efficiency.",
        "tags": [
            "DiT",
            "Diffusion",
            "SDXL",
            "Text-to-Image",
            "ViT"
        ]
    },
    {
        "id": "43",
        "title": "MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors",
        "author": [
            "Riku Murai",
            "Eric Dexheimer",
            "Andrew J. Davison"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12392",
        "abstract": "We present a real-time monocular dense SLAM system designed bottom-up from MASt3R, a two-view 3D reconstruction and matching prior. Equipped with this strong prior, our system is robust on in-the-wild video sequences despite making no assumption on a fixed or parametric camera model beyond a unique camera centre. We introduce efficient methods for pointmap matching, camera tracking and local fusion, graph construction and loop closure, and second-order global optimisation. With known calibration, a simple modification to the system achieves state-of-the-art performance across various benchmarks. Altogether, we propose a plug-and-play monocular SLAM system capable of producing globally-consistent poses and dense geometry while operating at 15 FPS.",
        "tags": [
            "3D",
            "SLAM"
        ]
    },
    {
        "id": "44",
        "title": "Causally Consistent Normalizing Flow",
        "author": [
            "Qingyang Zhou",
            "Kangjie Lu",
            "Meng Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12401",
        "abstract": "Causal inconsistency arises when the underlying causal graphs captured by generative models like \\textit{Normalizing Flows} (NFs) are inconsistent with those specified in causal models like \\textit{Struct Causal Models} (SCMs). This inconsistency can cause unwanted issues including the unfairness problem. Prior works to achieve causal consistency inevitably compromise the expressiveness of their models by disallowing hidden layers. In this work, we introduce a new approach: \\textbf{C}ausally \\textbf{C}onsistent \\textbf{N}ormalizing \\textbf{F}low (CCNF). To the best of our knowledge, CCNF is the first causally consistent generative model that can approximate any distribution with multiple layers. CCNF relies on two novel constructs: a sequential representation of SCMs and partial causal transformations. These constructs allow CCNF to inherently maintain causal consistency without sacrificing expressiveness. CCNF can handle all forms of causal inference tasks, including interventions and counterfactuals. Through experiments, we show that CCNF outperforms current approaches in causal inference. We also empirically validate the practical utility of CCNF by applying it to real-world datasets and show how CCNF addresses challenges like unfairness effectively.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "45",
        "title": "Global SLAM in Visual-Inertial Systems with 5G Time-of-Arrival Integration",
        "author": [
            "Meisam Kabiri",
            "Holger Voos"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12406",
        "abstract": "This paper presents a novel approach to improve global localization and mapping in indoor drone navigation by integrating 5G Time of Arrival (ToA) measurements into ORB-SLAM3, a Simultaneous Localization and Mapping (SLAM) system. By incorporating ToA data from 5G base stations, we align the SLAM's local reference frame with a global coordinate system, enabling accurate and consistent global localization. We extend ORB-SLAM3's optimization pipeline to integrate ToA measurements alongside bias estimation, transforming the inherently local estimation into a globally consistent one. This integration effectively resolves scale ambiguity in monocular SLAM systems and enhances robustness, particularly in challenging scenarios where standard SLAM may fail. Our method is evaluated using five real-world indoor datasets collected with RGB-D cameras and inertial measurement units (IMUs), augmented with simulated 5G ToA measurements at 28 GHz and 78 GHz frequencies using MATLAB and QuaDRiGa. We tested four SLAM configurations: RGB-D, RGB-D-Inertial, Monocular, and Monocular-Inertial. The results demonstrate that while local estimation accuracy remains comparable due to the high precision of RGB-D-based ORB-SLAM3 compared to ToA measurements, the inclusion of ToA measurements facilitates robust global positioning. In scenarios where standard mono-inertial ORB-SLAM3 loses tracking, our approach maintains accurate localization throughout the trajectory.",
        "tags": [
            "SLAM"
        ]
    },
    {
        "id": "46",
        "title": "Automated Generation of Massive Reasonable Empirical Theorems by Forward Reasoning Based on Strong Relevant Logics -- A Solution to the Problem of LLM Pre-training Data Exhaustion",
        "author": [
            "Jingde Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12408",
        "abstract": "Recently, it is often said that the data used for the pre-training of large language models (LLMs) have been exhausted. This paper proposes a solution to the problem: Automated generation of massive reasonable empirical theorems by forward reasoning based on strong relevant logics. In fact, this can be regarded as a part of our approach to the problems of ATF (Automated Theorem Finding) and AKA (Automated Knowledge Appreciation).",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "47",
        "title": "DeepSN: A Sheaf Neural Framework for Influence Maximization",
        "author": [
            "Asela Hevapathige",
            "Qing Wang",
            "Ahad N. Zehmakan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12416",
        "abstract": "Influence maximization is key topic in data mining, with broad applications in social network analysis and viral marketing. In recent years, researchers have increasingly turned to machine learning techniques to address this problem. They have developed methods to learn the underlying diffusion processes in a data-driven manner, which enhances the generalizability of the solution, and have designed optimization objectives to identify the optimal seed set. Nonetheless, two fundamental gaps remain unsolved: (1) Graph Neural Networks (GNNs) are increasingly used to learn diffusion models, but in their traditional form, they often fail to capture the complex dynamics of influence diffusion, (2) Designing optimization objectives is challenging due to combinatorial explosion when solving this problem. To address these challenges, we propose a novel framework, DeepSN. Our framework employs sheaf neural diffusion to learn diverse influence patterns in a data-driven, end-to-end manner, providing enhanced separability in capturing diffusion characteristics. We also propose an optimization technique that accounts for overlapping influence between vertices, which helps to reduce the search space and identify the optimal seed set effectively and efficiently. Finally, we conduct extensive experiments on both synthetic and real-world datasets to demonstrate the effectiveness of our framework.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "48",
        "title": "Bridging the Gap: Enhancing LLM Performance for Low-Resource African Languages with New Benchmarks, Fine-Tuning, and Cultural Adjustments",
        "author": [
            "Tuka Alhanai",
            "Adam Kasumovic",
            "Mohammad Ghassemi",
            "Aven Zitzelberger",
            "Jessica Lundin",
            "Guillaume Chabot-Couture"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12417",
        "abstract": "Large Language Models (LLMs) have shown remarkable performance across various tasks, yet significant disparities remain for non-English languages, and especially native African languages. This paper addresses these disparities by creating approximately 1 million human-translated words of new benchmark data in 8 low-resource African languages, covering a population of over 160 million speakers of: Amharic, Bambara, Igbo, Sepedi (Northern Sotho), Shona, Sesotho (Southern Sotho), Setswana, and Tsonga. Our benchmarks are translations of Winogrande and three sections of MMLU: college medicine, clinical knowledge, and virology. Using the translated benchmarks, we report previously unknown performance gaps between state-of-the-art (SOTA) LLMs in English and African languages. Finally, using results from over 400 fine-tuned models, we explore several methods to reduce the LLM performance gap, including high-quality dataset fine-tuning (using an LLM-as-an-Annotator), cross-lingual transfer, and cultural appropriateness adjustments. Key findings include average mono-lingual improvements of 5.6% with fine-tuning (with 5.4% average mono-lingual improvements when using high-quality data over low-quality data), 2.9% average gains from cross-lingual transfer, and a 3.0% out-of-the-box performance boost on culturally appropriate questions. The publicly available benchmarks, translations, and code from this study support further research and development aimed at creating more inclusive and effective language technologies.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "49",
        "title": "Assessing the Limitations of Large Language Models in Clinical Fact Decomposition",
        "author": [
            "Monica Munnangi",
            "Akshay Swaminathan",
            "Jason Alan Fries",
            "Jenelle Jindal",
            "Sanjana Narayanan",
            "Ivan Lopez",
            "Lucia Tu",
            "Philip Chung",
            "Jesutofunmi A. Omiye",
            "Mehr Kashyap",
            "Nigam Shah"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12422",
        "abstract": "Verifying factual claims is critical for using large language models (LLMs) in healthcare. Recent work has proposed fact decomposition, which uses LLMs to rewrite source text into concise sentences conveying a single piece of information, as an approach for fine-grained fact verification. Clinical documentation poses unique challenges for fact decomposition due to dense terminology and diverse note types. To explore these challenges, we present FactEHR, a dataset consisting of full document fact decompositions for 2,168 clinical notes spanning four types from three hospital systems. Our evaluation, including review by clinicians, highlights significant variability in the quality of fact decomposition for four commonly used LLMs, with some LLMs generating 2.6x more facts per sentence than others. The results underscore the need for better LLM capabilities to support factual verification in clinical text. To facilitate future research in this direction, we plan to release our code at \\url{https://github.com/som-shahlab/factehr}.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "50",
        "title": "GG-SSMs: Graph-Generating State Space Models",
        "author": [
            "Nikola Zubić",
            "Davide Scaramuzza"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12423",
        "abstract": "State Space Models (SSMs) are powerful tools for modeling sequential data in computer vision and time series analysis domains. However, traditional SSMs are limited by fixed, one-dimensional sequential processing, which restricts their ability to model non-local interactions in high-dimensional data. While methods like Mamba and VMamba introduce selective and flexible scanning strategies, they rely on predetermined paths, which fails to efficiently capture complex dependencies. We introduce Graph-Generating State Space Models (GG-SSMs), a novel framework that overcomes these limitations by dynamically constructing graphs based on feature relationships. Using Chazelle's Minimum Spanning Tree algorithm, GG-SSMs adapt to the inherent data structure, enabling robust feature propagation across dynamically generated graphs and efficiently modeling complex dependencies. We validate GG-SSMs on 11 diverse datasets, including event-based eye-tracking, ImageNet classification, optical flow estimation, and six time series datasets. GG-SSMs achieve state-of-the-art performance across all tasks, surpassing existing methods by significant margins. Specifically, GG-SSM attains a top-1 accuracy of 84.9% on ImageNet, outperforming prior SSMs by 1%, reducing the KITTI-15 error rate to 2.77%, and improving eye-tracking detection rates by up to 0.33% with fewer parameters. These results demonstrate that dynamic scanning based on feature relationships significantly improves SSMs' representational power and efficiency, offering a versatile tool for various applications in computer vision and beyond.",
        "tags": [
            "Detection",
            "Mamba",
            "SSMs",
            "State Space Models"
        ]
    },
    {
        "id": "51",
        "title": "Numerical Pruning for Efficient Autoregressive Models",
        "author": [
            "Xuan Shen",
            "Zhao Song",
            "Yufa Zhou",
            "Bo Chen",
            "Jing Liu",
            "Ruiyi Zhang",
            "Ryan A. Rossi",
            "Hao Tan",
            "Tong Yu",
            "Xiang Chen",
            "Yufan Zhou",
            "Tong Sun",
            "Pu Zhao",
            "Yanzhi Wang",
            "Jiuxiang Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12441",
        "abstract": "Transformers have emerged as the leading architecture in deep learning, proving to be versatile and highly effective across diverse domains beyond language and image processing. However, their impressive performance often incurs high computational costs due to their substantial model size. This paper focuses on compressing decoder-only transformer-based autoregressive models through structural weight pruning to improve the model efficiency while preserving performance for both language and image generation tasks. Specifically, we propose a training-free pruning method that calculates a numerical score with Newton's method for the Attention and MLP modules, respectively. Besides, we further propose another compensation algorithm to recover the pruned model for better performance. To verify the effectiveness of our method, we provide both theoretical support and extensive experiments. Our experiments show that our method achieves state-of-the-art performance with reduced memory usage and faster generation speeds on GPUs.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "52",
        "title": "LazyDiT: Lazy Learning for the Acceleration of Diffusion Transformers",
        "author": [
            "Xuan Shen",
            "Zhao Song",
            "Yufa Zhou",
            "Bo Chen",
            "Yanyu Li",
            "Yifan Gong",
            "Kai Zhang",
            "Hao Tan",
            "Jason Kuen",
            "Henghui Ding",
            "Zhihao Shu",
            "Wei Niu",
            "Pu Zhao",
            "Yanzhi Wang",
            "Jiuxiang Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12444",
        "abstract": "Diffusion Transformers have emerged as the preeminent models for a wide array of generative tasks, demonstrating superior performance and efficacy across various applications. The promising results come at the cost of slow inference, as each denoising step requires running the whole transformer model with a large amount of parameters. In this paper, we show that performing the full computation of the model at each diffusion step is unnecessary, as some computations can be skipped by lazily reusing the results of previous steps. Furthermore, we show that the lower bound of similarity between outputs at consecutive steps is notably high, and this similarity can be linearly approximated using the inputs. To verify our demonstrations, we propose the \\textbf{LazyDiT}, a lazy learning framework that efficiently leverages cached results from earlier steps to skip redundant computations. Specifically, we incorporate lazy learning layers into the model, effectively trained to maximize laziness, enabling dynamic skipping of redundant computations. Experimental results show that LazyDiT outperforms the DDIM sampler across multiple diffusion transformer models at various resolutions. Furthermore, we implement our method on mobile devices, achieving better performance than DDIM with similar latency.",
        "tags": [
            "DDIM",
            "Diffusion",
            "Diffusion Transformer",
            "Transformer"
        ]
    },
    {
        "id": "53",
        "title": "PERC: Plan-As-Query Example Retrieval for Underrepresented Code Generation",
        "author": [
            "Jaeseok Yoo",
            "Hojae Han",
            "Youngwon Lee",
            "Jaejin Kim",
            "Seung-won Hwang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12447",
        "abstract": "Code generation with large language models has shown significant promise, especially when employing retrieval-augmented generation (RAG) with few-shot examples. However, selecting effective examples that enhance generation quality remains a challenging task, particularly when the target programming language (PL) is underrepresented. In this study, we present two key findings: (1) retrieving examples whose presented algorithmic plans can be referenced for generating the desired behavior significantly improves generation accuracy, and (2) converting code into pseudocode effectively captures such algorithmic plans, enhancing retrieval quality even when the source and the target PLs are different. Based on these findings, we propose Plan-as-query Example Retrieval for few-shot prompting in Code generation (PERC), a novel framework that utilizes algorithmic plans to identify and retrieve effective examples. We validate the effectiveness of PERC through extensive experiments on the CodeContests, HumanEval and MultiPL-E benchmarks: PERC consistently outperforms the state-of-the-art RAG methods in code generation, both when the source and target programming languages match or differ, highlighting its adaptability and robustness in diverse coding environments.",
        "tags": [
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "54",
        "title": "LITA: An Efficient LLM-assisted Iterative Topic Augmentation Framework",
        "author": [
            "Chia-Hsuan Chang",
            "Jui-Tse Tsai",
            "Yi-Hang Tsai",
            "San-Yih Hwang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12459",
        "abstract": "Topic modeling is widely used for uncovering thematic structures within text corpora, yet traditional models often struggle with specificity and coherence in domain-focused applications. Guided approaches, such as SeededLDA and CorEx, incorporate user-provided seed words to improve relevance but remain labor-intensive and static. Large language models (LLMs) offer potential for dynamic topic refinement and discovery, yet their application often incurs high API costs. To address these challenges, we propose the LLM-assisted Iterative Topic Augmentation framework (LITA), an LLM-assisted approach that integrates user-provided seeds with embedding-based clustering and iterative refinement. LITA identifies a small number of ambiguous documents and employs an LLM to reassign them to existing or new topics, minimizing API costs while enhancing topic quality. Experiments on two datasets across topic quality and clustering performance metrics demonstrate that LITA outperforms five baseline models, including LDA, SeededLDA, CorEx, BERTopic, and PromptTopic. Our work offers an efficient and adaptable framework for advancing topic modeling and text clustering.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "55",
        "title": "Pattern Analogies: Learning to Perform Programmatic Image Edits by Analogy",
        "author": [
            "Aditya Ganeshan",
            "Thibault Groueix",
            "Paul Guerrero",
            "Radomír Měch",
            "Matthew Fisher",
            "Daniel Ritchie"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12463",
        "abstract": "Pattern images are everywhere in the digital and physical worlds, and tools to edit them are valuable. But editing pattern images is tricky: desired edits are often programmatic: structure-aware edits that alter the underlying program which generates the pattern. One could attempt to infer this underlying program, but current methods for doing so struggle with complex images and produce unorganized programs that make editing tedious. In this work, we introduce a novel approach to perform programmatic edits on pattern images. By using a pattern analogy -- a pair of simple patterns to demonstrate the intended edit -- and a learning-based generative model to execute these edits, our method allows users to intuitively edit patterns. To enable this paradigm, we introduce SplitWeave, a domain-specific language that, combined with a framework for sampling synthetic pattern analogies, enables the creation of a large, high-quality synthetic training dataset. We also present TriFuser, a Latent Diffusion Model (LDM) designed to overcome critical issues that arise when naively deploying LDMs to this task. Extensive experiments on real-world, artist-sourced patterns reveals that our method faithfully performs the demonstrated edit while also generalizing to related pattern styles beyond its training distribution.",
        "tags": [
            "Diffusion",
            "LDMs"
        ]
    },
    {
        "id": "56",
        "title": "Core Context Aware Attention for Long Context Language Modeling",
        "author": [
            "Yaofo Chen",
            "Zeng You",
            "Shuhai Zhang",
            "Haokun Li",
            "Yirui Li",
            "Yaowei Wang",
            "Mingkui Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12465",
        "abstract": "Transformer-based Large Language Models (LLMs) have exhibited remarkable success in various natural language processing tasks primarily attributed to self-attention mechanism, which requires a token to consider all preceding tokens as its context to compute the attention score. However, when the context length L becomes very large (e.g., 32K), more redundant context information will be included w.r.t. any tokens, making the self-attention suffer from two main limitations: 1) The computational and memory complexity scales quadratically w.r.t. L; 2) The presence of redundant context information may hamper the model to capture dependencies among crucial tokens, which may degrade the representation performance. In this paper, we propose a plug-and-play Core Context Aware (CCA) Attention for efficient long-range context modeling, which consists of two components: 1) Globality-pooling attention that divides input tokens into groups and then dynamically merges tokens within each group into one core token based on their significance; 2) Locality-preserved attention that incorporates neighboring tokens into the attention calculation. The two complementary attentions will then be fused to the final attention, maintaining comprehensive modeling ability as the full self-attention. In this way, the core context information w.r.t. a given token will be automatically focused and strengthened, while the context information in redundant groups will be diminished during the learning process. As a result, the computational and memory complexity will be significantly reduced. More importantly, the CCA-Attention can improve the long-context modeling ability by diminishing the redundant context information. Extensive experimental results demonstrate that our CCA-Attention significantly outperforms state-of-the-art models in terms of computational efficiency and long-context modeling ability.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "57",
        "title": "Knowledge Boundary of Large Language Models: A Survey",
        "author": [
            "Moxin Li",
            "Yong Zhao",
            "Yang Deng",
            "Wenxuan Zhang",
            "Shuaiyi Li",
            "Wenya Xie",
            "See-Kiong Ng",
            "Tat-Seng Chua"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12472",
        "abstract": "Although large language models (LLMs) store vast amount of knowledge in their parameters, they still have limitations in the memorization and utilization of certain knowledge, leading to undesired behaviors such as generating untruthful and inaccurate responses. This highlights the critical need to understand the knowledge boundary of LLMs, a concept that remains inadequately defined in existing research. In this survey, we propose a comprehensive definition of the LLM knowledge boundary and introduce a formalized taxonomy categorizing knowledge into four distinct types. Using this foundation, we systematically review the field through three key lenses: the motivation for studying LLM knowledge boundaries, methods for identifying these boundaries, and strategies for mitigating the challenges they present. Finally, we discuss open challenges and potential research directions in this area. We aim for this survey to offer the community a comprehensive overview, facilitate access to key issues, and inspire further advancements in LLM knowledge research.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "58",
        "title": "A Method for Enhancing Generalization of Adam by Multiple Integrations",
        "author": [
            "Long Jin",
            "Han Nong",
            "Liangming Chen",
            "Zhenming Su"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12473",
        "abstract": "The insufficient generalization of adaptive moment estimation (Adam) has hindered its broader application. Recent studies have shown that flat minima in loss landscapes are highly associated with improved generalization. Inspired by the filtering effect of integration operations on high-frequency signals, we propose multiple integral Adam (MIAdam), a novel optimizer that integrates a multiple integral term into Adam. This multiple integral term effectively filters out sharp minima encountered during optimization, guiding the optimizer towards flatter regions and thereby enhancing generalization capability. We provide a theoretical explanation for the improvement in generalization through the diffusion theory framework and analyze the impact of the multiple integral term on the optimizer's convergence. Experimental results demonstrate that MIAdam not only enhances generalization and robustness against label noise but also maintains the rapid convergence characteristic of Adam, outperforming Adam and its variants in state-of-the-art benchmarks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "59",
        "title": "AutoSGNN: Automatic Propagation Mechanism Discovery for Spectral Graph Neural Networks",
        "author": [
            "Shibing Mo",
            "Kai Wu",
            "Qixuan Gao",
            "Xiangyi Teng",
            "Jing Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12483",
        "abstract": "In real-world applications, spectral Graph Neural Networks (GNNs) are powerful tools for processing diverse types of graphs. However, a single GNN often struggles to handle different graph types-such as homogeneous and heterogeneous graphs-simultaneously. This challenge has led to the manual design of GNNs tailored to specific graph types, but these approaches are limited by the high cost of labor and the constraints of expert knowledge, which cannot keep up with the rapid growth of graph data. To overcome these challenges, we propose AutoSGNN, an automated framework for discovering propagation mechanisms in spectral GNNs. AutoSGNN unifies the search space for spectral GNNs by integrating large language models with evolutionary strategies to automatically generate architectures that adapt to various graph types. Extensive experiments on nine widely-used datasets, encompassing both homophilic and heterophilic graphs, demonstrate that AutoSGNN outperforms state-of-the-art spectral GNNs and graph neural architecture search methods in both performance and efficiency.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "60",
        "title": "Boosting Long-Context Information Seeking via Query-Guided Activation Refilling",
        "author": [
            "Hongjin Qian",
            "Zheng Liu",
            "Peitian Zhang",
            "Zhicheng Dou",
            "Defu Lian"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12486",
        "abstract": "Processing long contexts poses a significant challenge for large language models (LLMs) due to their inherent context-window limitations and the computational burden of extensive key-value (KV) activations, which severely impact efficiency. For information-seeking tasks, full context perception is often unnecessary, as a query's information needs can dynamically range from localized details to a global perspective, depending on its complexity. However, existing methods struggle to adapt effectively to these dynamic information needs.\nIn the paper, we propose a method for processing long-context information-seeking tasks via query-guided Activation Refilling (ACRE). ACRE constructs a Bi-layer KV Cache for long contexts, where the layer-1 (L1) cache compactly captures global information, and the layer-2 (L2) cache provides detailed and localized information. ACRE establishes a proxying relationship between the two caches, allowing the input query to attend to the L1 cache and dynamically refill it with relevant entries from the L2 cache. This mechanism integrates global understanding with query-specific local details, thus improving answer decoding. Experiments on a variety of long-context information-seeking datasets demonstrate ACRE's effectiveness, achieving improvements in both performance and efficiency.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "61",
        "title": "Echo: Simulating Distributed Training At Scale",
        "author": [
            "Yicheng Feng",
            "Yuetao Chen",
            "Kaiwen Chen",
            "Jingzong Li",
            "Tianyuan Wu",
            "Peng Cheng",
            "Chuan Wu",
            "Wei Wang",
            "Tsung-Yi Ho",
            "Hong Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12487",
        "abstract": "Simulation offers unique values for both enumeration and extrapolation purposes, and is becoming increasingly important for managing the massive machine learning (ML) clusters and large-scale distributed training jobs. In this paper, we build Echo to tackle three key challenges in large-scale training simulation: (1) tracing the runtime training workloads at each device in an ex-situ fashion so we can use a single device to obtain the actual execution graphs of 1K-GPU training, (2) accurately estimating the collective communication without high overheads of discrete-event based network simulation, and (3) accounting for the interference-induced computation slowdown from overlapping communication and computation kernels on the same device. Echo delivers on average 8% error in training step -- roughly 3x lower than state-of-the-art simulators -- for GPT-175B on a 96-GPU H800 cluster with 3D parallelism on Megatron-LM under 2 minutes.",
        "tags": [
            "3D",
            "GPT"
        ]
    },
    {
        "id": "62",
        "title": "A System for Microserving of LLMs",
        "author": [
            "Hongyi Jin",
            "Ruihang Lai",
            "Charlie F. Ruan",
            "Yingcheng Wang",
            "Todd C. Mowry",
            "Xupeng Miao",
            "Zhihao Jia",
            "Tianqi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12488",
        "abstract": "The recent advances in LLMs bring a strong demand for efficient system support to improve overall serving efficiency. As LLM inference scales towards multiple GPUs and even multiple compute nodes, various coordination patterns, such as prefill-decode disaggregation and context migration, arise in serving systems. Most inference services today expose a coarse-grained request-level API with a pre-configured coordination strategy, limiting the ability to customize and dynamically reconfigure the coordination. In this paper, we propose LLM microserving, a multi-level architecture for structuring and programming LLM inference services. We introduces simple yet effective microserving APIs to support fine-grained sub-request level actions. A programmable router transforms user requests into sub-request calls, enabling the dynamic reconfiguration of serving patterns. To support diverse execution patterns, we develop a unified KV cache interface that handles various KV compute, transfer, and reuse scenarios. Our evaluation shows that LLM microserving can be reconfigured to support multiple disaggregation orchestration strategies in a few lines of Python code while maintaining state-of-the-art performance for LLM inference tasks. Additionally, it allows us to explore new strategy variants that reduce up to 47% of job completion time compared to the existing strategies.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "63",
        "title": "A Simple and Fast Way to Handle Semantic Errors in Transactions",
        "author": [
            "Jinghan Zeng",
            "Eugene Wu",
            "Sanjay Krishnan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12493",
        "abstract": "Many computer systems are now being redesigned to incorporate LLM-powered agents, enabling natural language input and more flexible operations. This paper focuses on handling database transactions created by large language models (LLMs). Transactions generated by LLMs may include semantic errors, requiring systems to treat them as long-lived. This allows for human review and, if the transaction is incorrect, removal from the database history. Any removal action must ensure the database's consistency (the \"C\" in ACID principles) is maintained throughout the process.\nWe propose a novel middleware framework based on Invariant Satisfaction (I-Confluence), which ensures consistency by identifying and coordinating dependencies between long-lived transactions and new transactions. This middleware buffers suspicious or compensating transactions to manage coordination states. Using the TPC-C benchmark, we evaluate how transaction generation frequency, user reviews, and invariant completeness impact system performance. For system researchers, this study establishes an interactive paradigm between LLMs and database systems, providing an \"undoing\" mechanism for handling incorrect operations while guaranteeing database consistency. For system engineers, this paper offers a middleware design that integrates removable LLM-generated transactions into existing systems with minimal modifications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "64",
        "title": "Faster Vision Mamba is Rebuilt in Minutes via Merged Token Re-training",
        "author": [
            "Mingjia Shi",
            "Yuhao Zhou",
            "Ruiji Yu",
            "Zekai Li",
            "Zhiyuan Liang",
            "Xuanlei Zhao",
            "Xiaojiang Peng",
            "Tanmay Rajpurohit",
            "Shanmukha Ramakrishna Vedantam",
            "Wangbo Zhao",
            "Kai Wang",
            "Yang You"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12496",
        "abstract": "Vision Mamba (e.g., Vim) has successfully been integrated into computer vision, and token reduction has yielded promising outcomes in Vision Transformers (ViTs). However, token reduction performs less effectively on Vision Mamba compared to ViTs. Pruning informative tokens in Mamba leads to a high loss of key knowledge and bad performance. This makes it not a good solution for enhancing efficiency in Mamba. Token merging, which preserves more token information than pruning, has demonstrated commendable performance in ViTs. Nevertheless, vanilla merging performance decreases as the reduction ratio increases either, failing to maintain the key knowledge in Mamba. Re-training the token-reduced model enhances the performance of Mamba, by effectively rebuilding the key knowledge. Empirically, pruned Vims only drop up to 0.9% accuracy on ImageNet-1K, recovered by our proposed framework R-MeeTo in our main evaluation. We show how simple and effective the fast recovery can be achieved at minute-level, in particular, a 35.9% accuracy spike over 3 epochs of training on Vim-Ti. Moreover, Vim-Ti/S/B are re-trained within 5/7/17 minutes, and Vim-S only drop 1.3% with 1.2x (up to 1.5x) speed up in inference.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "65",
        "title": "NLSR: Neuron-Level Safety Realignment of Large Language Models Against Harmful Fine-Tuning",
        "author": [
            "Xin Yi",
            "Shunfan Zheng",
            "Linlin Wang",
            "Gerard de Melo",
            "Xiaoling Wang",
            "Liang He"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12497",
        "abstract": "The emergence of finetuning-as-a-service has revealed a new vulnerability in large language models (LLMs). A mere handful of malicious data uploaded by users can subtly manipulate the finetuning process, resulting in an alignment-broken model. Existing methods to counteract fine-tuning attacks typically require substantial computational resources. Even with parameter-efficient techniques like LoRA, gradient updates remain essential. To address these challenges, we propose \\textbf{N}euron-\\textbf{L}evel \\textbf{S}afety \\textbf{R}ealignment (\\textbf{NLSR}), a training-free framework that restores the safety of LLMs based on the similarity difference of safety-critical neurons before and after fine-tuning. The core of our framework is first to construct a safety reference model from an initially aligned model to amplify safety-related features in neurons. We then utilize this reference model to identify safety-critical neurons, which we prepare as patches. Finally, we selectively restore only those neurons that exhibit significant similarity differences by transplanting these prepared patches, thereby minimally altering the fine-tuned model. Extensive experiments demonstrate significant safety enhancements in fine-tuned models across multiple downstream tasks, while greatly maintaining task-level accuracy. Our findings suggest regions of some safety-critical neurons show noticeable differences after fine-tuning, which can be effectively corrected by transplanting neurons from the reference model without requiring additional training. The code will be available at \\url{https://github.com/xinykou/NLSR}",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA"
        ]
    },
    {
        "id": "66",
        "title": "Hierarchical Control of Emotion Rendering in Speech Synthesis",
        "author": [
            "Sho Inoue",
            "Kun Zhou",
            "Shuai Wang",
            "Haizhou Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12498",
        "abstract": "Emotional text-to-speech synthesis (TTS) aims to generate realistic emotional speech from input text. However, quantitatively controlling multi-level emotion rendering remains challenging. In this paper, we propose a diffusion-based emotional TTS framework with a novel approach for emotion intensity modeling to facilitate fine-grained control over emotion rendering at the phoneme, word, and utterance levels. We introduce a hierarchical emotion distribution (ED) extractor that captures a quantifiable ED embedding across different speech segment levels. Additionally, we explore various acoustic features and assess their impact on emotion intensity modeling. During TTS training, the hierarchical ED embedding effectively captures the variance in emotion intensity from the reference audio and correlates it with linguistic and speaker information. The TTS model not only generates emotional speech during inference, but also quantitatively controls the emotion rendering over the speech constituents. Both objective and subjective evaluations demonstrate the effectiveness of our framework in terms of speech quality, emotional expressiveness, and hierarchical emotion control.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "67",
        "title": "LinguaLIFT: An Effective Two-stage Instruction Tuning Framework for Low-Resource Language Tasks",
        "author": [
            "Hongbin Zhang",
            "Kehai Chen",
            "Xuefeng Bai",
            "Yang Xiang",
            "Min Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12499",
        "abstract": "Large language models (LLMs) have demonstrated impressive multilingual understanding and reasoning capabilities, driven by extensive pre-training multilingual corpora and fine-tuning instruction data. However, a performance gap persists between high-resource and low-resource language tasks due to language imbalance in the pre-training corpus, even using more low-resource data during fine-tuning. To alleviate this issue, we propose LinguaLIFT, a two-stage instruction tuning framework for advancing low-resource language tasks. An additional language alignment layer is first integrated into the LLM to adapt a pre-trained multilingual encoder, thereby enhancing multilingual alignment through code-switched fine-tuning. The second stage fine-tunes LLM with English-only instruction data while freezing the language alignment layer, allowing LLM to transfer task-specific capabilities from English to low-resource language tasks. Additionally, we introduce the Multilingual Math World Problem (MMWP) benchmark, which spans 21 low-resource, 17 medium-resource, and 10 high-resource languages, enabling comprehensive evaluation of multilingual reasoning. Experimental results show that LinguaLIFT outperforms several competitive baselines across MMWP and other widely used benchmarks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "68",
        "title": "Track the Answer: Extending TextVQA from Image to Video with Spatio-Temporal Clues",
        "author": [
            "Yan Zhang",
            "Gangyan Zeng",
            "Huawen Shen",
            "Daiqing Wu",
            "Yu Zhou",
            "Can Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12502",
        "abstract": "Video text-based visual question answering (Video TextVQA) is a practical task that aims to answer questions by jointly reasoning textual and visual information in a given video. Inspired by the development of TextVQA in image domain, existing Video TextVQA approaches leverage a language model (e.g. T5) to process text-rich multiple frames and generate answers auto-regressively. Nevertheless, the spatio-temporal relationships among visual entities (including scene text and objects) will be disrupted and models are susceptible to interference from unrelated information, resulting in irrational reasoning and inaccurate answering. To tackle these challenges, we propose the TEA (stands for ``\\textbf{T}rack th\\textbf{E} \\textbf{A}nswer'') method that better extends the generative TextVQA framework from image to video. TEA recovers the spatio-temporal relationships in a complementary way and incorporates OCR-aware clues to enhance the quality of reasoning questions. Extensive experiments on several public Video TextVQA datasets validate the effectiveness and generalization of our framework. TEA outperforms existing TextVQA methods, video-language pretraining methods and video large language models by great margins.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "69",
        "title": "Boosting LLM-based Relevance Modeling with Distribution-Aware Robust Learning",
        "author": [
            "Hong Liu",
            "Saisai Gong",
            "Yixin Ji",
            "Kaixin Wu",
            "Jia Xu",
            "Jinjie Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12504",
        "abstract": "With the rapid advancement of pre-trained large language models (LLMs), recent endeavors have leveraged the capabilities of LLMs in relevance modeling, resulting in enhanced performance. This is usually done through the process of fine-tuning LLMs on specifically annotated datasets to determine the relevance between queries and items. However, there are two limitations when LLMs are naively employed for relevance modeling through fine-tuning and inference. First, it is not inherently efficient for performing nuanced tasks beyond simple yes or no answers, such as assessing search relevance. It may therefore tend to be overconfident and struggle to distinguish fine-grained degrees of relevance (e.g., strong relevance, weak relevance, irrelevance) used in search engines. Second, it exhibits significant performance degradation when confronted with data distribution shift in real-world scenarios. In this paper, we propose a novel Distribution-Aware Robust Learning framework (DaRL) for relevance modeling in Alipay Search. Specifically, we design an effective loss function to enhance the discriminability of LLM-based relevance modeling across various fine-grained degrees of query-item relevance. To improve the generalizability of LLM-based relevance modeling, we first propose the Distribution-Aware Sample Augmentation (DASA) module. This module utilizes out-of-distribution (OOD) detection techniques to actively select appropriate samples that are not well covered by the original training set for model fine-tuning. Furthermore, we adopt a multi-stage fine-tuning strategy to simultaneously improve in-distribution (ID) and OOD performance, bridging the performance gap between them. DaRL has been deployed online to serve the Alipay's insurance product search...",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "70",
        "title": "3DGUT: Enabling Distorted Cameras and Secondary Rays in Gaussian Splatting",
        "author": [
            "Qi Wu",
            "Janick Martinez Esturo",
            "Ashkan Mirzaei",
            "Nicolas Moenne-Loccoz",
            "Zan Gojcic"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12507",
        "abstract": "3D Gaussian Splatting (3DGS) has shown great potential for efficient reconstruction and high-fidelity real-time rendering of complex scenes on consumer hardware. However, due to its rasterization-based formulation, 3DGS is constrained to ideal pinhole cameras and lacks support for secondary lighting effects. Recent methods address these limitations by tracing volumetric particles instead, however, this comes at the cost of significantly slower rendering speeds. In this work, we propose 3D Gaussian Unscented Transform (3DGUT), replacing the EWA splatting formulation in 3DGS with the Unscented Transform that approximates the particles through sigma points, which can be projected exactly under any nonlinear projection function. This modification enables trivial support of distorted cameras with time dependent effects such as rolling shutter, while retaining the efficiency of rasterization. Additionally, we align our rendering formulation with that of tracing-based methods, enabling secondary ray tracing required to represent phenomena such as reflections and refraction within the same 3D representation.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "71",
        "title": "Can You Trust LLM Judgments? Reliability of LLM-as-a-Judge",
        "author": [
            "Kayla Schroeder",
            "Zach Wood-Doughty"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12509",
        "abstract": "Large Language Models (LLMs) have become increasingly powerful and ubiquitous, but their stochastic nature poses challenges to the reliability of their outputs. While deterministic settings can improve consistency, they do not guarantee reliability, as a single sample from the model's probability distribution can still be misleading. Building upon the concept of LLM-as-a-judge, we introduce a novel framework for rigorously evaluating the reliability of LLM judgments, leveraging McDonald's omega. We evaluate the reliability of LLMs when judging the outputs of other LLMs on standard single-turn and multi-turn benchmarks, simultaneously investigating the impact of temperature on reliability. By analyzing these results, we demonstrate the limitations of fixed randomness and the importance of considering multiple samples, which we show has significant implications for downstream applications. Our findings highlight the need for a nuanced understanding of LLM reliability and the potential risks associated with over-reliance on single-shot evaluations. This work provides a crucial step towards building more trustworthy and reliable LLM-based systems and applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "72",
        "title": "Can Large Language Models Understand You Better? An MBTI Personality Detection Dataset Aligned with Population Traits",
        "author": [
            "Bohan Li",
            "Jiannan Guan",
            "Longxu Dou",
            "Yunlong Feng",
            "Dingzirui Wang",
            "Yang Xu",
            "Enbo Wang",
            "Qiguang Chen",
            "Bichen Wang",
            "Xiao Xu",
            "Yimeng Zhang",
            "Libo Qin",
            "Yanyan Zhao",
            "Qingfu Zhu",
            "Wanxiang Che"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12510",
        "abstract": "The Myers-Briggs Type Indicator (MBTI) is one of the most influential personality theories reflecting individual differences in thinking, feeling, and behaving. MBTI personality detection has garnered considerable research interest and has evolved significantly over the years. However, this task tends to be overly optimistic, as it currently does not align well with the natural distribution of population personality traits. Specifically, (1) the self-reported labels in existing datasets result in incorrect labeling issues, and (2) the hard labels fail to capture the full range of population personality distributions. In this paper, we optimize the task by constructing MBTIBench, the first manually annotated high-quality MBTI personality detection dataset with soft labels, under the guidance of psychologists. As for the first challenge, MBTIBench effectively solves the incorrect labeling issues, which account for 29.58% of the data. As for the second challenge, we estimate soft labels by deriving the polarity tendency of samples. The obtained soft labels confirm that there are more people with non-extreme personality traits. Experimental results not only highlight the polarized predictions and biases in LLMs as key directions for future research, but also confirm that soft labels can provide more benefits to other psychological tasks than hard labels. The code and data are available at https://github.com/Personality-NLP/MbtiBench.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "73",
        "title": "Generating Move Smart Contracts based on Concepts",
        "author": [
            "Rabimba Karanjai",
            "Sam Blackshear",
            "Lei Xu",
            "Weidong Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12513",
        "abstract": "The growing adoption of formal verification for smart contracts has spurred the development of new verifiable languages like Move. However, the limited availability of training data for these languages hinders effective code generation by large language models (LLMs). This paper presents ConMover, a novel framework that enhances LLM-based code generation for Move by leveraging a knowledge graph of Move concepts and a small set of verified code examples. ConMover integrates concept retrieval, planning, coding, and debugging agents in an iterative process to refine generated code. Evaluations with various open-source LLMs demonstrate substantial accuracy improvements over baseline models. These results underscore ConMover's potential to address low-resource code generation challenges, bridging the gap between natural language descriptions and reliable smart contract development.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "74",
        "title": "When to Speak, When to Abstain: Contrastive Decoding with Abstention",
        "author": [
            "Hyuhng Joon Kim",
            "Youna Kim",
            "Sang-goo Lee",
            "Taeuk Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12527",
        "abstract": "Large Language Models (LLMs) demonstrate exceptional performance across diverse tasks by leveraging both pre-trained knowledge (i.e., parametric knowledge) and external knowledge (i.e., contextual knowledge). While substantial efforts have been made to leverage both forms of knowledge, scenarios in which the model lacks any relevant knowledge remain underexplored. Such limitations can result in issues like hallucination, causing reduced reliability and potential risks in high-stakes applications. To address such limitations, this paper extends the task scope to encompass cases where the user's request cannot be fulfilled due to the lack of relevant knowledge. To this end, we introduce Contrastive Decoding with Abstention (CDA), a training-free decoding method that empowers LLMs to generate responses when relevant knowledge is available and to abstain otherwise. CDA evaluates the relevance of each knowledge for a given query, adaptively determining which knowledge to prioritize or which to completely ignore. Extensive experiments with four LLMs on three question-answering datasets demonstrate that CDA can effectively perform accurate generation and abstention simultaneously. These findings highlight CDA's potential to broaden the applicability of LLMs, enhancing reliability and preserving user trust.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "75",
        "title": "LLMCL-GEC: Advancing Grammatical Error Correction with LLM-Driven Curriculum Learning",
        "author": [
            "Tao Fang",
            "Derek F. Wong",
            "Lusheng Zhang",
            "Keyan Jin",
            "Qiang Zhang",
            "Tianjiao Li",
            "Jinlong Hou",
            "Lidia S. Chao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12541",
        "abstract": "While large-scale language models (LLMs) have demonstrated remarkable capabilities in specific natural language processing (NLP) tasks, they may still lack proficiency compared to specialized models in certain domains, such as grammatical error correction (GEC). Drawing inspiration from the concept of curriculum learning, we have delved into refining LLMs into proficient GEC experts by devising effective curriculum learning (CL) strategies. In this paper, we introduce a novel approach, termed LLM-based curriculum learning, which capitalizes on the robust semantic comprehension and discriminative prowess inherent in LLMs to gauge the complexity of GEC training data. Unlike traditional curriculum learning techniques, our method closely mirrors human expert-designed curriculums. Leveraging the proposed LLM-based CL method, we sequentially select varying levels of curriculums ranging from easy to hard, and iteratively train and refine using the pretrianed T5 and LLaMA series models. Through rigorous testing and analysis across diverse benchmark assessments in English GEC, including the CoNLL14 test, BEA19 test, and BEA19 development sets, our approach showcases a significant performance boost over baseline models and conventional curriculum learning methodologies.",
        "tags": [
            "LLMs",
            "LLaMA"
        ]
    },
    {
        "id": "76",
        "title": "Seed-CTS: Unleashing the Power of Tree Search for Superior Performance in Competitive Coding Tasks",
        "author": [
            "Hao Wang",
            "Boyi Liu",
            "Yufeng Zhang",
            "Jie Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12544",
        "abstract": "Competition-level code generation tasks pose significant challenges for current state-of-the-art large language models (LLMs). For example, on the LiveCodeBench-Hard dataset, models such as O1-Mini and O1-Preview achieve pass@1 rates of only 0.366 and 0.143, respectively. While tree search techniques have proven effective in domains like mathematics and general coding, their potential in competition-level code generation remains under-explored. In this work, we propose a novel token-level tree search method specifically designed for code generation. Leveraging Qwen2.5-Coder-32B-Instruct, our approach achieves a pass rate of 0.305 on LiveCodeBench-Hard, surpassing the pass@100 performance of GPT4o-0513 (0.245). Furthermore, by integrating Chain-of-Thought (CoT) prompting, we improve our method's performance to 0.351, approaching O1-Mini's pass@1 rate. To ensure reproducibility, we report the average number of generations required per problem by our tree search method on the test set. Our findings underscore the potential of tree search to significantly enhance performance on competition-level code generation tasks. This opens up new possibilities for large-scale synthesis of challenging code problems supervised fine-tuning (SFT) data, advancing competition-level code generation tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "77",
        "title": "Consistent Diffusion: Denoising Diffusion Model with Data-Consistent Training for Image Restoration",
        "author": [
            "Xinlong Cheng",
            "Tiantian Cao",
            "Guoan Cheng",
            "Bangxuan Huang",
            "Xinghan Tian",
            "Ye Wang",
            "Xiaoyu He",
            "Weixin Li",
            "Tianfan Xue",
            "Xuan Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12550",
        "abstract": "In this work, we address the limitations of denoising diffusion models (DDMs) in image restoration tasks, particularly the shape and color distortions that can compromise image quality. While DDMs have demonstrated a promising performance in many applications such as text-to-image synthesis, their effectiveness in image restoration is often hindered by shape and color distortions. We observe that these issues arise from inconsistencies between the training and testing data used by DDMs. Based on our observation, we propose a novel training method, named data-consistent training, which allows the DDMs to access images with accumulated errors during training, thereby ensuring the model to learn to correct these errors. Experimental results show that, across five image restoration tasks, our method has significant improvements over state-of-the-art methods while effectively minimizing distortions and preserving image fidelity.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "78",
        "title": "Evaluating Zero-Shot Multilingual Aspect-Based Sentiment Analysis with Large Language Models",
        "author": [
            "Chengyan Wu",
            "Bolei Ma",
            "Zheyu Zhang",
            "Ningyuan Deng",
            "Yanqing He",
            "Yun Xue"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12564",
        "abstract": "Aspect-based sentiment analysis (ABSA), a sequence labeling task, has attracted increasing attention in multilingual contexts. While previous research has focused largely on fine-tuning or training models specifically for ABSA, we evaluate large language models (LLMs) under zero-shot conditions to explore their potential to tackle this challenge with minimal task-specific adaptation. We conduct a comprehensive empirical evaluation of a series of LLMs on multilingual ABSA tasks, investigating various prompting strategies, including vanilla zero-shot, chain-of-thought (CoT), self-improvement, self-debate, and self-consistency, across nine different models. Results indicate that while LLMs show promise in handling multilingual ABSA, they generally fall short of fine-tuned, task-specific models. Notably, simpler zero-shot prompts often outperform more complex strategies, especially in high-resource languages like English. These findings underscore the need for further refinement of LLM-based approaches to effectively address ABSA task across diverse languages.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "79",
        "title": "FCMR: Robust Evaluation of Financial Cross-Modal Multi-Hop Reasoning",
        "author": [
            "Seunghee Kim",
            "Changhyeon Kim",
            "Taeuk Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12567",
        "abstract": "Real-world decision-making often requires integrating and reasoning over information from multiple modalities. While recent multimodal large language models (MLLMs) have shown promise in such tasks, their ability to perform multi-hop reasoning across diverse sources remains insufficiently evaluated. Existing benchmarks, such as MMQA, face challenges due to (1) data contamination and (2) a lack of complex queries that necessitate operations across more than two modalities, hindering accurate performance assessment. To address this, we present Financial Cross-Modal Multi-Hop Reasoning (FCMR), a benchmark created to analyze the reasoning capabilities of MLLMs by urging them to combine information from textual reports, tables, and charts within the financial domain. FCMR is categorized into three difficulty levels-Easy, Medium, and Hard-facilitating a step-by-step evaluation. In particular, problems at the Hard level require precise cross-modal three-hop reasoning and are designed to prevent the disregard of any modality. Experiments on this new benchmark reveal that even state-of-the-art MLLMs struggle, with the best-performing model (Claude 3.5 Sonnet) achieving only 30.4% accuracy on the most challenging tier. We also conduct analysis to provide insights into the inner workings of the models, including the discovery of a critical bottleneck in the information retrieval phase.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "80",
        "title": "ChatDiT: A Training-Free Baseline for Task-Agnostic Free-Form Chatting with Diffusion Transformers",
        "author": [
            "Lianghua Huang",
            "Wei Wang",
            "Zhi-Fan Wu",
            "Yupeng Shi",
            "Chen Liang",
            "Tong Shen",
            "Han Zhang",
            "Huanzhang Dou",
            "Yu Liu",
            "Jingren Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12571",
        "abstract": "Recent research https://arxiv.org/abs/2410.15027 https://arxiv.org/abs/2410.23775 has highlighted the inherent in-context generation capabilities of pretrained diffusion transformers (DiTs), enabling them to seamlessly adapt to diverse visual tasks with minimal or no architectural modifications. These capabilities are unlocked by concatenating self-attention tokens across multiple input and target images, combined with grouped and masked generation pipelines. Building upon this foundation, we present ChatDiT, a zero-shot, general-purpose, and interactive visual generation framework that leverages pretrained diffusion transformers in their original form, requiring no additional tuning, adapters, or modifications. Users can interact with ChatDiT to create interleaved text-image articles, multi-page picture books, edit images, design IP derivatives, or develop character design settings, all through free-form natural language across one or more conversational rounds. At its core, ChatDiT employs a multi-agent system comprising three key components: an Instruction-Parsing agent that interprets user-uploaded images and instructions, a Strategy-Planning agent that devises single-step or multi-step generation actions, and an Execution agent that performs these actions using an in-context toolkit of diffusion transformers. We thoroughly evaluate ChatDiT on IDEA-Bench https://arxiv.org/abs/2412.11767, comprising 100 real-world design tasks and 275 cases with diverse instructions and varying numbers of input and target images. Despite its simplicity and training-free approach, ChatDiT surpasses all competitors, including those specifically designed and trained on extensive multi-task datasets. We further identify key limitations of pretrained DiTs in zero-shot adapting to tasks. We release all code, agents, results, and intermediate outputs to facilitate further research at https://github.com/ali-vilab/ChatDiT",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "81",
        "title": "License Plate Detection and Character Recognition Using Deep Learning and Font Evaluation",
        "author": [
            "Zahra Ebrahimi Vargoorani",
            "Ching Yee Suen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12572",
        "abstract": "License plate detection (LPD) is essential for traffic management, vehicle tracking, and law enforcement but faces challenges like variable lighting and diverse font types, impacting accuracy. Traditionally reliant on image processing and machine learning, the field is now shifting towards deep learning for its robust performance in various conditions. Current methods, however, often require tailoring to specific regional datasets. This paper proposes a dual deep learning strategy using a Faster R-CNN for detection and a CNN-RNN model with Connectionist Temporal Classification (CTC) loss and a MobileNet V3 backbone for recognition. This approach aims to improve model performance using datasets from Ontario, Quebec, California, and New York State, achieving a recall rate of 92% on the Centre for Pattern Recognition and Machine Intelligence (CENPARMI) dataset and 90% on the UFPR-ALPR dataset. It includes a detailed error analysis to identify the causes of false positives. Additionally, the research examines the role of font features in license plate (LP) recognition, analyzing fonts like Driver Gothic, Dreadnought, California Clarendon, and Zurich Extra Condensed with the OpenALPR system. It discovers significant performance discrepancies influenced by font characteristics, offering insights for future LPD system enhancements.\nKeywords: Deep Learning, License Plate, Font Evaluation",
        "tags": [
            "Detection",
            "RNN"
        ]
    },
    {
        "id": "82",
        "title": "Understanding Emotional Body Expressions via Large Language Models",
        "author": [
            "Haifeng Lu",
            "Jiuyi Chen",
            "Feng Liang",
            "Mingkui Tan",
            "Runhao Zeng",
            "Xiping Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12581",
        "abstract": "Emotion recognition based on body movements is vital in human-computer interaction. However, existing emotion recognition methods predominantly focus on enhancing classification accuracy, often neglecting the provision of textual explanations to justify their classifications. In this paper, we propose an Emotion-Action Interpreter powered by Large Language Model (EAI-LLM), which not only recognizes emotions but also generates textual explanations by treating 3D body movement data as unique input tokens within large language models (LLMs). Specifically, we propose a multi-granularity skeleton tokenizer designed for LLMs, which separately extracts spatio-temporal tokens and semantic tokens from the skeleton data. This approach allows LLMs to generate more nuanced classification descriptions while maintaining robust classification performance. Furthermore, we treat the skeleton sequence as a specific language and propose a unified skeleton token module. This module leverages the extensive background knowledge and language processing capabilities of LLMs to address the challenges of joint training on heterogeneous datasets, thereby significantly enhancing recognition accuracy on individual datasets. Experimental results demonstrate that our model achieves recognition accuracy comparable to existing methods. More importantly, with the support of background knowledge from LLMs, our model can generate detailed emotion descriptions based on classification results, even when trained on a limited amount of labeled skeleton data.",
        "tags": [
            "3D",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "83",
        "title": "Process-Supervised Reward Models for Clinical Note Generation: A Scalable Approach Guided by Domain Expertise",
        "author": [
            "Hanyin Wang",
            "Qiping Xu",
            "Bolun Liu",
            "Guleid Hussein",
            "Hariprasad Korsapati",
            "Mohamad El Labban",
            "Kingsley Iheasirim",
            "Mohamed Hassan",
            "Gokhan Anil",
            "Brian Bartlett",
            "Jimeng Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12583",
        "abstract": "Process-supervised reward models (PRMs), which verify large language model (LLM) outputs step-by-step, have achieved significant success in mathematical and coding problems. However, their application to other domains remains largely unexplored. In this work, we train a PRM to provide step-level reward signals for clinical notes generated by LLMs from patient-doctor dialogues. Guided by real-world clinician expertise, we carefully designed step definitions for clinical notes and utilized Gemini-Pro 1.5 to automatically generate process supervision data at scale. Our proposed PRM, trained on the LLaMA-3.1 8B instruct model, demonstrated superior performance compared to Gemini-Pro 1.5 and an outcome-supervised reward model (ORM) across two key evaluations: (1) the accuracy of selecting gold-reference samples from error-containing samples, achieving 98.8% (versus 61.3% for ORM and 93.8% for Gemini-Pro 1.5), and (2) the accuracy of selecting physician-preferred notes, achieving 56.2% (compared to 51.2% for ORM and 50.0% for Gemini-Pro 1.5). Additionally, we conducted ablation studies to determine optimal loss functions and data selection strategies, along with physician reader studies to explore predictors of downstream Best-of-N performance. Our promising results suggest the potential of PRMs to extend beyond the clinical domain, offering a scalable and effective solution for diverse generative tasks.",
        "tags": [
            "LLMs",
            "LLaMA"
        ]
    },
    {
        "id": "84",
        "title": "LLMs are Also Effective Embedding Models: An In-depth Overview",
        "author": [
            "Chongyang Tao",
            "Tao Shen",
            "Shen Gao",
            "Junshuo Zhang",
            "Zhen Li",
            "Zhengwei Tao",
            "Shuai Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12591",
        "abstract": "Large language models (LLMs) have revolutionized natural language processing by achieving state-of-the-art performance across various tasks. Recently, their effectiveness as embedding models has gained attention, marking a paradigm shift from traditional encoder-only models like ELMo and BERT to decoder-only, large-scale LLMs such as GPT, LLaMA, and Mistral. This survey provides an in-depth overview of this transition, beginning with foundational techniques before the LLM era, followed by LLM-based embedding models through two main strategies to derive embeddings from LLMs. 1) Direct prompting: We mainly discuss the prompt designs and the underlying rationale for deriving competitive embeddings. 2) Data-centric tuning: We cover extensive aspects that affect tuning an embedding model, including model architecture, training objectives, data constructions, etc. Upon the above, we also cover advanced methods, such as handling longer texts, and multilingual and cross-modal data. Furthermore, we discuss factors affecting choices of embedding models, such as performance/efficiency comparisons, dense vs sparse embeddings, pooling strategies, and scaling law. Lastly, the survey highlights the limitations and challenges in adapting LLMs for embeddings, including cross-task embedding quality, trade-offs between efficiency and accuracy, low-resource, long-context, data bias, robustness, etc. This survey serves as a valuable resource for researchers and practitioners by synthesizing current advancements, highlighting key challenges, and offering a comprehensive framework for future work aimed at enhancing the effectiveness and efficiency of LLMs as embedding models.",
        "tags": [
            "BERT",
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "85",
        "title": "A Simple and Efficient Baseline for Zero-Shot Generative Classification",
        "author": [
            "Zipeng Qi",
            "Buhua Liu",
            "Shiyan Zhang",
            "Bao Li",
            "Zhiqiang Xu",
            "Haoyi Xiong",
            "Zeke Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12594",
        "abstract": "Large diffusion models have become mainstream generative models in both academic studies and industrial AIGC applications. Recently, a number of works further explored how to employ the power of large diffusion models as zero-shot classifiers. While recent zero-shot diffusion-based classifiers have made performance advancement on benchmark datasets, they still suffered badly from extremely slow classification speed (e.g., ~1000 seconds per classifying single image on ImageNet). The extremely slow classification speed strongly prohibits existing zero-shot diffusion-based classifiers from practical applications. In this paper, we propose an embarrassingly simple and efficient zero-shot Gaussian Diffusion Classifiers (GDC) via pretrained text-to-image diffusion models and DINOv2. The proposed GDC can not only significantly surpass previous zero-shot diffusion-based classifiers by over 10 points (61.40% - 71.44%) on ImageNet, but also accelerate more than 30000 times (1000 - 0.03 seconds) classifying a single image on ImageNet. Additionally, it provides probability interpretation of the results. Our extensive experiments further demonstrate that GDC can achieve highly competitive zero-shot classification performance over various datasets and can promisingly self-improve with stronger diffusion models. To the best of our knowledge, the proposed GDC is the first zero-shot diffusionbased classifier that exhibits both competitive accuracy and practical efficiency.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "86",
        "title": "Improving Numerical Error Bounds Near Sharp Interface Limit for Stochastic Reaction-Diffusion Equations",
        "author": [
            "Jianbo Cui",
            "Feng-Yu Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12604",
        "abstract": "In the study of geometric surface evolutions, stochastic reaction-diffusion equation provides a powerful tool for capturing and simulating complex dynamics. A critical challenge in this area is developing numerical approximations that exhibit error bounds with polynomial dependence on $\\vv^{-1}$, where the small parameter $\\vv>0$ represents the diffuse interface thickness. The existence of such bounds for fully discrete approximations of stochastic reaction-diffusion equations remains unclear in the literature. In this work, we address this challenge by leveraging the asymptotic log-Harnack inequality to overcome the exponential growth of $\\vv^{-1}$. Furthermore, we establish the numerical weak error bounds under the truncated Wasserstein distance for the spectral Galerkin method and a fully discrete tamed Euler scheme, with explicit polynomial dependence on $\\vv^{-1}$.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "87",
        "title": "Multi-Dimensional Insights: Benchmarking Real-World Personalization in Large Multimodal Models",
        "author": [
            "YiFan Zhang",
            "Shanglin Lei",
            "Runqi Qiao",
            "Zhuoma GongQue",
            "Xiaoshuai Song",
            "Guanting Dong",
            "Qiuna Tan",
            "Zhe Wei",
            "Peiqing Yang",
            "Ye Tian",
            "Yadong Xue",
            "Xiaofei Wang",
            "Honggang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12606",
        "abstract": "The rapidly developing field of large multimodal models (LMMs) has led to the emergence of diverse models with remarkable capabilities. However, existing benchmarks fail to comprehensively, objectively and accurately evaluate whether LMMs align with the diverse needs of humans in real-world scenarios. To bridge this gap, we propose the Multi-Dimensional Insights (MDI) benchmark, which includes over 500 images covering six common scenarios of human life. Notably, the MDI-Benchmark offers two significant advantages over existing evaluations: (1) Each image is accompanied by two types of questions: simple questions to assess the model's understanding of the image, and complex questions to evaluate the model's ability to analyze and reason beyond basic content. (2) Recognizing that people of different age groups have varying needs and perspectives when faced with the same scenario, our benchmark stratifies questions into three age categories: young people, middle-aged people, and older people. This design allows for a detailed assessment of LMMs' capabilities in meeting the preferences and needs of different age groups. With MDI-Benchmark, the strong model like GPT-4o achieve 79% accuracy on age-related tasks, indicating that existing LMMs still have considerable room for improvement in addressing real-world applications. Looking ahead, we anticipate that the MDI-Benchmark will open new pathways for aligning real-world personalization in LMMs. The MDI-Benchmark data and evaluation code are available at https://mdi-benchmark.github.io/",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "88",
        "title": "MultiLingPoT: Enhancing Mathematical Reasoning with Multilingual Program Fine-tuning",
        "author": [
            "Nianqi Li",
            "Zujie Liang",
            "Siyu Yuan",
            "Jiaqing Liang",
            "Feng Wei",
            "Yanghua Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12609",
        "abstract": "Program-of-Thought (PoT), which aims to use programming language instead of natural language as an intermediate step in reasoning, is an important way for LLMs to solve mathematical problems. Since different programming languages excel in different areas, it is natural to use the most suitable language for solving specific problems. However, current PoT research only focuses on single language PoT, ignoring the differences between different programming languages. Therefore, this paper proposes an multilingual program reasoning method, MultiLingPoT. This method allows the model to answer questions using multiple programming languages by fine-tuning on multilingual data. Additionally, prior and posterior hybrid methods are used to help the model select the most suitable language for each problem. Our experimental results show that the training of MultiLingPoT improves each program's mathematical reasoning by about 2.5\\%. Moreover, with proper mixing, the performance of MultiLingPoT can be further improved, achieving a 6\\% increase compared to the single-language PoT with the data http://augmentation.Resources of this paper can be found at https://github.com/Nianqi-Li/MultiLingPoT.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "89",
        "title": "SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs",
        "author": [
            "Aman Tiwari",
            "Shiva Krishna Reddy Malay",
            "Vikas Yadav",
            "Masoud Hashemi",
            "Sathwik Tejaswi Madhusudhan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12612",
        "abstract": "Cypher, the query language for Neo4j graph databases, plays a critical role in enabling graph-based analytics and data exploration. While substantial research has been dedicated to natural language to SQL query generation (Text2SQL), the analogous problem for graph databases referred to as Text2Cypher remains underexplored. In this work, we introduce SynthCypher, a fully synthetic and automated data generation pipeline designed to address this gap. SynthCypher employs a novel LLMSupervised Generation-Verification framework, ensuring syntactically and semantically correct Cypher queries across diverse domains and query complexities. Using this pipeline, we create SynthCypher Dataset, a large-scale benchmark containing 29.8k Text2Cypher instances. Fine-tuning open-source large language models (LLMs), including LLaMa-3.1- 8B, Mistral-7B, and QWEN-7B, on SynthCypher yields significant performance improvements of up to 40% on the Text2Cypher test set and 30% on the SPIDER benchmark adapted for graph databases. This work demonstrates that high-quality synthetic data can effectively advance the state-of-the-art in Text2Cypher tasks.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "90",
        "title": "Jailbreaking? One Step Is Enough!",
        "author": [
            "Weixiong Zheng",
            "Peijian Zeng",
            "Yiwei Li",
            "Hongyan Wu",
            "Nankai Lin",
            "Junhao Chen",
            "Aimin Yang",
            "Yongmei Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12621",
        "abstract": "Large language models (LLMs) excel in various tasks but remain vulnerable to jailbreak attacks, where adversaries manipulate prompts to generate harmful outputs. Examining jailbreak prompts helps uncover the shortcomings of LLMs. However, current jailbreak methods and the target model's defenses are engaged in an independent and adversarial process, resulting in the need for frequent attack iterations and redesigning attacks for different models. To address these gaps, we propose a Reverse Embedded Defense Attack (REDA) mechanism that disguises the attack intention as the \"defense\". intention against harmful content. Specifically, REDA starts from the target response, guiding the model to embed harmful content within its defensive measures, thereby relegating harmful content to a secondary role and making the model believe it is performing a defensive task. The attacking model considers that it is guiding the target model to deal with harmful content, while the target model thinks it is performing a defensive task, creating an illusion of cooperation between the two. Additionally, to enhance the model's confidence and guidance in \"defensive\" intentions, we adopt in-context learning (ICL) with a small number of attack examples and construct a corresponding dataset of attack examples. Extensive evaluations demonstrate that the REDA method enables cross-model attacks without the need to redesign attack strategies for different models, enables successful jailbreak in one iteration, and outperforms existing methods on both open-source and closed-source models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "91",
        "title": "Make Imagination Clearer! Stable Diffusion-based Visual Imagination for Multimodal Machine Translation",
        "author": [
            "Andong Chen",
            "Yuchen Song",
            "Kehai Chen",
            "Muyun Yang",
            "Tiejun Zhao",
            "Min Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12627",
        "abstract": "Visual information has been introduced for enhancing machine translation (MT), and its effectiveness heavily relies on the availability of large amounts of bilingual parallel sentence pairs with manual image annotations. In this paper, we introduce a stable diffusion-based imagination network into a multimodal large language model (MLLM) to explicitly generate an image for each source sentence, thereby advancing the multimodel MT. Particularly, we build heuristic human feedback with reinforcement learning to ensure the consistency of the generated image with the source sentence without the supervision of image annotation, which breaks the bottleneck of using visual information in MT. Furthermore, the proposed method enables imaginative visual information to be integrated into large-scale text-only MT in addition to multimodal MT. Experimental results show that our model significantly outperforms existing multimodal MT and text-only MT, especially achieving an average improvement of more than 14 BLEU points on Multi30K multimodal MT benchmarks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "92",
        "title": "What External Knowledge is Preferred by LLMs? Characterizing and Exploring Chain of Evidence in Imperfect Context",
        "author": [
            "Zhiyuan Chang",
            "Mingyang Li",
            "Xiaojun Jia",
            "Junjie Wang",
            "Yuekai Huang",
            "Qing Wang",
            "Yihao Huang",
            "Yang Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12632",
        "abstract": "Incorporating external knowledge into large language models (LLMs) has emerged as a promising approach to mitigate outdated knowledge and hallucination in LLMs. However, external knowledge is often imperfect. In addition to useful knowledge, external knowledge is rich in irrelevant or misinformation in the context that can impair the reliability of LLM responses. This paper focuses on LLMs' preferred external knowledge in imperfect contexts when handling multi-hop QA. Inspired by criminal procedural law's Chain of Evidence (CoE), we characterize that knowledge preferred by LLMs should maintain both relevance to the question and mutual support among knowledge pieces. Accordingly, we propose an automated CoE discrimination approach and explore LLMs' preferences from their effectiveness, faithfulness and robustness, as well as CoE's usability in a naive Retrieval-Augmented Generation (RAG) case. The evaluation on five LLMs reveals that CoE enhances LLMs through more accurate generation, stronger answer faithfulness, better robustness against knowledge conflict, and improved performance in a popular RAG case.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "93",
        "title": "Falcon: Faster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding Tree",
        "author": [
            "Xiangxiang Gao",
            "Weisheng Xie",
            "Yiwei Xiang",
            "Feng Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12639",
        "abstract": "Striking an optimal balance between minimal drafting latency and high speculation accuracy to enhance the inference speed of Large Language Models remains a significant challenge in speculative decoding. In this paper, we introduce Falcon, an innovative semi-autoregressive speculative decoding framework fashioned to augment both the drafter's parallelism and output quality. Falcon incorporates the Coupled Sequential Glancing Distillation technique, which fortifies inter-token dependencies within the same block, leading to increased speculation accuracy. We offer a comprehensive theoretical analysis to illuminate the underlying mechanisms. Additionally, we introduce a Custom-Designed Decoding Tree, which permits the drafter to generate multiple tokens in a single forward pass and accommodates multiple forward passes as needed, thereby boosting the number of drafted tokens and significantly improving the overall acceptance rate. Comprehensive evaluations on benchmark datasets such as MT-Bench, HumanEval, and GSM8K demonstrate Falcon's superior acceleration capabilities. The framework achieves a lossless speedup ratio ranging from 2.91x to 3.51x when tested on the Vicuna and LLaMA2-Chat model series. These results outstrip existing speculative decoding methods for LLMs, including Eagle, Medusa, Lookahead, SPS, and PLD, while maintaining a compact drafter architecture equivalent to merely two Transformer layers.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer",
            "Vicuna"
        ]
    },
    {
        "id": "94",
        "title": "RDPI: A Refine Diffusion Probability Generation Method for Spatiotemporal Data Imputation",
        "author": [
            "Zijin Liu",
            "Xiang Zhao",
            "You Song"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12642",
        "abstract": "Spatiotemporal data imputation plays a crucial role in various fields such as traffic flow monitoring, air quality assessment, and climate prediction. However, spatiotemporal data collected by sensors often suffer from temporal incompleteness, and the sparse and uneven distribution of sensors leads to missing data in the spatial dimension. Among existing methods, autoregressive approaches are prone to error accumulation, while simple conditional diffusion models fail to adequately capture the spatiotemporal relationships between observed and missing data. To address these issues, we propose a novel two-stage Refined Diffusion Probability Impuation (RDPI) framework based on an initial network and a conditional diffusion model. In the initial stage, deterministic imputation methods are used to generate preliminary estimates of the missing data. In the refinement stage, residuals are treated as the diffusion target, and observed values are innovatively incorporated into the forward process. This results in a conditional diffusion model better suited for spatiotemporal data imputation, bridging the gap between the preliminary estimates and the true values. Experiments on multiple datasets demonstrate that RDPI not only achieves state-of-the-art imputation accuracy but also significantly reduces sampling computational costs.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "95",
        "title": "LLM-based Discriminative Reasoning for Knowledge Graph Question Answering",
        "author": [
            "Mufan Xu",
            "Kehai Chen",
            "Xuefeng Bai",
            "Muyun Yang",
            "Tiejun Zhao",
            "Min Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12643",
        "abstract": "Large language models (LLMs) based on generative pre-trained Transformer have achieved remarkable performance on knowledge graph question-answering (KGQA) tasks. However, LLMs often produce ungrounded subgraph planning or reasoning results in KGQA due to the hallucinatory behavior brought by the generative paradigm, which may hinder the advancement of the LLM-based KGQA model. To deal with the issue, we propose a novel LLM-based Discriminative Reasoning (LDR) method to explicitly model the subgraph retrieval and answer inference process. By adopting discriminative strategies, the proposed LDR method not only enhances the capability of LLMs to retrieve question-related subgraphs but also alleviates the issue of ungrounded reasoning brought by the generative paradigm of LLMs. Experimental results show that the proposed approach outperforms multiple strong comparison methods, along with achieving state-of-the-art performance on two widely used WebQSP and CWQ benchmarks.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "96",
        "title": "iPrOp: Interactive Prompt Optimization for Large Language Models with a Human in the Loop",
        "author": [
            "Jiahui Li",
            "Roman Klinger"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12644",
        "abstract": "Prompt engineering has made significant contributions to the era of large language models, yet its effectiveness depends on the skills of a prompt author. Automatic prompt optimization can support the prompt development process, but requires annotated data. This paper introduces $\\textit{iPrOp}$, a novel Interactive Prompt Optimization system, to bridge manual prompt engineering and automatic prompt optimization. With human intervention in the optimization loop, $\\textit{iPrOp}$ offers users the flexibility to assess evolving prompts. We present users with prompt variations, selected instances, large language model predictions accompanied by corresponding explanations, and performance metrics derived from a subset of the training data. This approach empowers users to choose and further refine the provided prompts based on their individual preferences and needs. This system not only assists non-technical domain experts in generating optimal prompts tailored to their specific tasks or domains, but also enables to study the intrinsic parameters that influence the performance of prompt optimization. Our evaluation shows that our system has the capability to generate improved prompts, leading to enhanced task performance.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "97",
        "title": "Train More Parameters But Mind Their Placement: Insights into Language Adaptation with PEFT",
        "author": [
            "Jenny Kunz"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12674",
        "abstract": "Smaller LLMs still face significant challenges even in medium-resourced languages, particularly when it comes to language-specific knowledge -- a problem not easily resolved with machine-translated data. In this case study on Icelandic, we aim to enhance the generation performance of an LLM by specialising it using unstructured text corpora. A key focus is on preventing interference with the models' capabilities of handling longer context during this adaptation. Through ablation studies using various parameter-efficient fine-tuning (PEFT) methods and setups, we find that increasing the number of trainable parameters leads to better and more robust language adaptation. LoRAs placed in the feed-forward layers and bottleneck adapters show promising results with sufficient parameters, while prefix tuning and (IA)3 are not suitable. Although improvements are consistent in 0-shot summarisation, some adapted models struggle with longer context lengths, an issue that can be mitigated by adapting only the final layers.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "98",
        "title": "ShotVL: Human-Centric Highlight Frame Retrieval via Language Queries",
        "author": [
            "Wangyu Xue",
            "Chen Qian",
            "Jiayi Wu",
            "Yang Zhou",
            "Wentao Liu",
            "Ju Ren",
            "Siming Fan",
            "Yaoxue Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12675",
        "abstract": "Existing works on human-centric video understanding typically focus on analyzing specific moment or entire videos. However, many applications require higher precision at the frame level. In this work, we propose a novel task, BestShot, which aims to locate highlight frames within human-centric videos via language queries. This task demands not only a deep semantic comprehension of human actions but also precise temporal localization. To support this task, we introduce the BestShot Benchmark. %The benchmark is meticulously constructed by combining human detection and tracking, potential frame selection based on human judgment, and detailed textual descriptions crafted by human input to ensure precision. The benchmark is meticulously constructed by combining human-annotated highlight frames, detailed textual descriptions and duration labeling. These descriptions encompass three critical elements: (1) Visual content; (2) Fine-grained action; and (3) Human Pose Description. Together, these elements provide the necessary precision to identify the exact highlight frames in videos.\nTo tackle this problem, we have collected two distinct datasets: (i) ShotGPT4o Dataset, which is algorithmically generated by GPT-4o and (ii) Image-SMPLText Dataset, a dataset with large-scale and accurate per-frame pose description leveraging PoseScript and existing pose estimation datasets. Based on these datasets, we present a strong baseline model, ShotVL, fine-tuned from InternVL, specifically for BestShot. We highlight the impressive zero-shot capabilities of our model and offer comparative analyses with existing SOTA models. ShotVL demonstrates a significant 52% improvement over InternVL on the BestShot Benchmark and a notable 57% improvement on the THUMOS14 Benchmark, all while maintaining the SOTA performance in general image classification and retrieval.",
        "tags": [
            "Detection",
            "GPT",
            "Pose Estimation"
        ]
    },
    {
        "id": "99",
        "title": "Detecting Document-level Paraphrased Machine Generated Content: Mimicking Human Writing Style and Involving Discourse Features",
        "author": [
            "Yupei Li",
            "Manuel Milling",
            "Lucia Specia",
            "Björn W. Schuller"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12679",
        "abstract": "The availability of high-quality APIs for Large Language Models (LLMs) has facilitated the widespread creation of Machine-Generated Content (MGC), posing challenges such as academic plagiarism and the spread of misinformation. Existing MGC detectors often focus solely on surface-level information, overlooking implicit and structural features. This makes them susceptible to deception by surface-level sentence patterns, particularly for longer texts and in texts that have been subsequently paraphrased.\nTo overcome these challenges, we introduce novel methodologies and datasets. Besides the publicly available dataset Plagbench, we developed the paraphrased Long-Form Question and Answer (paraLFQA) and paraphrased Writing Prompts (paraWP) datasets using GPT and DIPPER, a discourse paraphrasing tool, by extending artifacts from their original versions. To address the challenge of detecting highly similar paraphrased texts, we propose MhBART, an encoder-decoder model designed to emulate human writing style while incorporating a novel difference score mechanism. This model outperforms strong classifier baselines and identifies deceptive sentence patterns. To better capture the structure of longer texts at document level, we propose DTransformer, a model that integrates discourse analysis through PDTB preprocessing to encode structural features. It results in substantial performance gains across both datasets -- 15.5\\% absolute improvement on paraLFQA, 4\\% absolute improvement on paraWP, and 1.5\\% absolute improvement on M4 compared to SOTA approaches.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "100",
        "title": "XTransplant: A Probe into the Upper Bound Performance of Multilingual Capability and Culture Adaptability in LLMs via Mutual Cross-lingual Feed-forward Transplantation",
        "author": [
            "Yangfan Ye",
            "Xiaocheng Feng",
            "Xiachong Feng",
            "Libo Qin",
            "Yichong Huang",
            "Lei Huang",
            "Weitao Ma",
            "Zhirui Zhang",
            "Yunfei Lu",
            "Xiaohui Yan",
            "Duyu Tang",
            "Dandan Tu",
            "Bing Qin"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12686",
        "abstract": "Current large language models (LLMs) often exhibit imbalances in multilingual capabilities and cultural adaptability, largely due to their English-centric pretraining data. To address this imbalance, we propose a probing method named XTransplant that explores cross-lingual latent interactions via cross-lingual feed-forward transplantation during inference stage, with the hope of enabling the model to leverage the strengths of both English and non-English languages. Through extensive pilot experiments, we empirically prove that both the multilingual capabilities and cultural adaptability of LLMs hold the potential to be significantly improved by XTransplant, respectively from En -> non-En and non-En -> En, highlighting the underutilization of current LLMs' multilingual potential. And the patterns observed in these pilot experiments further motivate an offline scaling inference strategy, which demonstrates consistent performance improvements in multilingual and culture-aware tasks, sometimes even surpassing multilingual supervised fine-tuning. And we do hope our further analysis and discussion could help gain deeper insights into XTransplant mechanism.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "101",
        "title": "Uncertainty-Aware Hybrid Inference with On-Device Small and Remote Large Language Models",
        "author": [
            "Seungeun Oh",
            "Jinhyuk Kim",
            "Jihong Park",
            "Seung-Woo Ko",
            "Tony Q. S. Quek",
            "Seong-Lyun Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12687",
        "abstract": "This paper studies a hybrid language model (HLM) architecture that integrates a small language model (SLM) operating on a mobile device with a large language model (LLM) hosted at the base station (BS) of a wireless network. The HLM token generation process follows the speculative inference principle: the SLM's vocabulary distribution is uploaded to the LLM, which either accepts or rejects it, with rejected tokens being resampled by the LLM. While this approach ensures alignment between the vocabulary distributions of the SLM and LLM, it suffers from low token throughput due to uplink transmission and the computation costs of running both language models. To address this, we propose a novel HLM structure coined Uncertainty-aware HLM (U-HLM), wherein the SLM locally measures its output uncertainty, and skips both uplink transmissions and LLM operations for tokens that are likely to be accepted. This opportunistic skipping is enabled by our empirical finding of a linear correlation between the SLM's uncertainty and the LLM's rejection probability. We analytically derive the uncertainty threshold and evaluate its expected risk of rejection. Simulations show that U-HLM reduces uplink transmissions and LLM computation by 45.93%, while achieving up to 97.54% of the LLM's inference accuracy and 2.54$\\times$ faster token throughput than HLM without skipping.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "102",
        "title": "Trigger$^3$: Refining Query Correction via Adaptive Model Selector",
        "author": [
            "Kepu Zhang",
            "Zhongxiang Sun",
            "Xiao Zhang",
            "Xiaoxue Zang",
            "Kai Zheng",
            "Yang Song",
            "Jun Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12701",
        "abstract": "In search scenarios, user experience can be hindered by erroneous queries due to typos, voice errors, or knowledge gaps. Therefore, query correction is crucial for search engines. Current correction models, usually small models trained on specific data, often struggle with queries beyond their training scope or those requiring contextual understanding. While the advent of Large Language Models (LLMs) offers a potential solution, they are still limited by their pre-training data and inference cost, particularly for complex queries, making them not always effective for query correction. To tackle these, we propose Trigger$^3$, a large-small model collaboration framework that integrates the traditional correction model and LLM for query correction, capable of adaptively choosing the appropriate correction method based on the query and the correction results from the traditional correction model and LLM. Trigger$^3$ first employs a correction trigger to filter out correct queries. Incorrect queries are then corrected by the traditional correction model. If this fails, an LLM trigger is activated to call the LLM for correction. Finally, for queries that no model can correct, a fallback trigger decides to return the original query. Extensive experiments demonstrate Trigger$^3$ outperforms correction baselines while maintaining efficiency.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "103",
        "title": "More Tokens, Lower Precision: Towards the Optimal Token-Precision Trade-off in KV Cache Compression",
        "author": [
            "Jiebin Zhang",
            "Dawei Zhu",
            "Yifan Song",
            "Wenhao Wu",
            "Chuqiao Kuang",
            "Xiaoguang Li",
            "Lifeng Shang",
            "Qun Liu",
            "Sujian Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12706",
        "abstract": "As large language models (LLMs) process increasing context windows, the memory usage of KV cache has become a critical bottleneck during inference. The mainstream KV compression methods, including KV pruning and KV quantization, primarily focus on either token or precision dimension and seldom explore the efficiency of their combination. In this paper, we comprehensively investigate the token-precision trade-off in KV cache compression. Experiments demonstrate that storing more tokens in the KV cache with lower precision, i.e., quantized pruning, can significantly enhance the long-context performance of LLMs. Furthermore, in-depth analysis regarding token-precision trade-off from a series of key aspects exhibit that, quantized pruning achieves substantial improvements in retrieval-related tasks and consistently performs well across varying input lengths. Moreover, quantized pruning demonstrates notable stability across different KV pruning methods, quantization strategies, and model scales. These findings provide valuable insights into the token-precision trade-off in KV cache compression. We plan to release our code in the near future.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "104",
        "title": "Enhancing Naturalness in LLM-Generated Utterances through Disfluency Insertion",
        "author": [
            "Syed Zohaib Hassan",
            "Pierre Lison",
            "Pål Halvorsen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12710",
        "abstract": "Disfluencies are a natural feature of spontaneous human speech but are typically absent from the outputs of Large Language Models (LLMs). This absence can diminish the perceived naturalness of synthesized speech, which is an important criteria when building conversational agents that aim to mimick human behaviours. We show how the insertion of disfluencies can alleviate this shortcoming. The proposed approach involves (1) fine-tuning an LLM with Low-Rank Adaptation (LoRA) to incorporate various types of disfluencies into LLM-generated utterances and (2) synthesizing those utterances using a text-to-speech model that supports the generation of speech phenomena such as disfluencies. We evaluated the quality of the generated speech across two metrics: intelligibility and perceived spontaneity. We demonstrate through a user study that the insertion of disfluencies significantly increase the perceived spontaneity of the generated speech. This increase came, however, along with a slight reduction in intelligibility.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "LoRA"
        ]
    },
    {
        "id": "105",
        "title": "ASAP: Advancing Semantic Alignment Promotes Multi-Modal Manipulation Detecting and Grounding",
        "author": [
            "Zhenxing Zhang",
            "Yaxiong Wang",
            "Lechao Cheng",
            "Zhun Zhong",
            "Dan Guo",
            "Meng Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12718",
        "abstract": "We present ASAP, a new framework for detecting and grounding multi-modal media manipulation (DGM4).Upon thorough examination, we observe that accurate fine-grained cross-modal semantic alignment between the image and text is vital for accurately manipulation detection and grounding. While existing DGM4 methods pay rare attention to the cross-modal alignment, hampering the accuracy of manipulation detecting to step further. To remedy this issue, this work targets to advance the semantic alignment learning to promote this task. Particularly, we utilize the off-the-shelf Multimodal Large-Language Models (MLLMs) and Large Language Models (LLMs) to construct paired image-text pairs, especially for the manipulated instances. Subsequently, a cross-modal alignment learning is performed to enhance the semantic alignment. Besides the explicit auxiliary clues, we further design a Manipulation-Guided Cross Attention (MGCA) to provide implicit guidance for augmenting the manipulation perceiving. With the grounding truth available during training, MGCA encourages the model to concentrate more on manipulated components while downplaying normal ones, enhancing the model's ability to capture manipulations. Extensive experiments are conducted on the DGM4 dataset, the results demonstrate that our model can surpass the comparison method with a clear margin.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "106",
        "title": "RaCFormer: Towards High-Quality 3D Object Detection via Query-based Radar-Camera Fusion",
        "author": [
            "Xiaomeng Chu",
            "Jiajun Deng",
            "Guoliang You",
            "Yifan Duan",
            "Houqiang Li",
            "Yanyong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12725",
        "abstract": "We propose Radar-Camera fusion transformer (RaCFormer) to boost the accuracy of 3D object detection by the following insight. The Radar-Camera fusion in outdoor 3D scene perception is capped by the image-to-BEV transformation--if the depth of pixels is not accurately estimated, the naive combination of BEV features actually integrates unaligned visual content. To avoid this problem, we propose a query-based framework that enables adaptively sample instance-relevant features from both the BEV and the original image view. Furthermore, we enhance system performance by two key designs: optimizing query initialization and strengthening the representational capacity of BEV. For the former, we introduce an adaptive circular distribution in polar coordinates to refine the initialization of object queries, allowing for a distance-based adjustment of query density. For the latter, we initially incorporate a radar-guided depth head to refine the transformation from image view to BEV. Subsequently, we focus on leveraging the Doppler effect of radar and introduce an implicit dynamic catcher to capture the temporal elements within the BEV. Extensive experiments on nuScenes and View-of-Delft (VoD) datasets validate the merits of our design. Remarkably, our method achieves superior results of 64.9% mAP and 70.2% NDS on nuScenes, even outperforming several LiDAR-based detectors. RaCFormer also secures the 1st ranking on the VoD dataset. The code will be released.",
        "tags": [
            "3D",
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "107",
        "title": "Using LLM-Generated Draft Replies to Support Human Experts in Responding to Stakeholder Inquiries in Maritime Industry: A Real-World Case Study of Industrial AI",
        "author": [
            "Tita Alissa Bach",
            "Aleksandar Babic",
            "Narae Park",
            "Tor Sporsem",
            "Rasmus Ulfsnes",
            "Henrik Smith-Meyer",
            "Torkel Skeie"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12732",
        "abstract": "The maritime industry requires effective communication among diverse stakeholders to address complex, safety-critical challenges. Industrial AI, including Large Language Models (LLMs), has the potential to augment human experts' workflows in this specialized domain. Our case study investigated the utility of LLMs in drafting replies to stakeholder inquiries and supporting case handlers. We conducted a preliminary study (observations and interviews), a survey, and a text similarity analysis (LLM-as-a-judge and Semantic Embedding Similarity). We discover that while LLM drafts can streamline workflows, they often require significant modifications to meet the specific demands of maritime communications. Though LLMs are not yet mature enough for safety-critical applications without human oversight, they can serve as valuable augmentative tools. Final decision-making thus must remain with human experts. However, by leveraging the strengths of both humans and LLMs, fostering human-AI collaboration, industries can increase efficiency while maintaining high standards of quality and precision tailored to each case.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "108",
        "title": "Gaussian Billboards: Expressive 2D Gaussian Splatting with Textures",
        "author": [
            "Sebastian Weiss",
            "Derek Bradley"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12734",
        "abstract": "Gaussian Splatting has recently emerged as the go-to representation for reconstructing and rendering 3D scenes. The transition from 3D to 2D Gaussian primitives has further improved multi-view consistency and surface reconstruction accuracy. In this work we highlight the similarity between 2D Gaussian Splatting (2DGS) and billboards from traditional computer graphics. Both use flat semi-transparent 2D geometry that is positioned, oriented and scaled in 3D space. However 2DGS uses a solid color per splat and an opacity modulated by a Gaussian distribution, where billboards are more expressive, modulating the color with a uv-parameterized texture. We propose to unify these concepts by presenting Gaussian Billboards, a modification of 2DGS to add spatially-varying color achieved using per-splat texture interpolation. The result is a mixture of the two representations, which benefits from both the robust scene optimization power of 2DGS and the expressiveness of texture mapping. We show that our method can improve the sharpness and quality of the scene representation in a wide range of qualitative and quantitative evaluations compared to the original 2DGS implementation.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "109",
        "title": "GIRAFFE: Design Choices for Extending the Context Length of Visual Language Models",
        "author": [
            "Mukai Li",
            "Lei Li",
            "Shansan Gong",
            "Qi Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12735",
        "abstract": "Visual Language Models (VLMs) demonstrate impressive capabilities in processing multimodal inputs, yet applications such as visual agents, which require handling multiple images and high-resolution videos, demand enhanced long-range modeling. Moreover, existing open-source VLMs lack systematic exploration into extending their context length, and commercial models often provide limited details. To tackle this, we aim to establish an effective solution that enhances long context performance of VLMs while preserving their capacities in short context scenarios. Towards this goal, we make the best design choice through extensive experiment settings from data curation to context window extending and utilizing: (1) we analyze data sources and length distributions to construct ETVLM - a data recipe to balance the performance across scenarios; (2) we examine existing position extending methods, identify their limitations and propose M-RoPE++ as an enhanced approach; we also choose to solely instruction-tune the backbone with mixed-source data; (3) we discuss how to better utilize extended context windows and propose hybrid-resolution training. Built on the Qwen-VL series model, we propose Giraffe, which is effectively extended to 128K lengths. Evaluated on extensive long context VLM benchmarks such as VideoMME and Viusal Haystacks, our Giraffe achieves state-of-the-art performance among similarly sized open-source long VLMs and is competitive with commercial model GPT-4V. We will open-source the code, data, and models.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "110",
        "title": "PolSAM: Polarimetric Scattering Mechanism Informed Segment Anything Model",
        "author": [
            "Yuqing Wang",
            "Zhongling Huang",
            "Shuxin Yang",
            "Hao Tang",
            "Xiaolan Qiu",
            "Junwei Han",
            "Dingwen Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12737",
        "abstract": "PolSAR data presents unique challenges due to its rich and complex characteristics. Existing data representations, such as complex-valued data, polarimetric features, and amplitude images, are widely used. However, these formats often face issues related to usability, interpretability, and data integrity. Most feature extraction networks for PolSAR are small, limiting their ability to capture features effectively. To address these issues, We propose the Polarimetric Scattering Mechanism-Informed SAM (PolSAM), an enhanced Segment Anything Model (SAM) that integrates domain-specific scattering characteristics and a novel prompt generation strategy. PolSAM introduces Microwave Vision Data (MVD), a lightweight and interpretable data representation derived from polarimetric decomposition and semantic correlations. We propose two key components: the Feature-Level Fusion Prompt (FFP), which fuses visual tokens from pseudo-colored SAR images and MVD to address modality incompatibility in the frozen SAM encoder, and the Semantic-Level Fusion Prompt (SFP), which refines sparse and dense segmentation prompts using semantic information. Experimental results on the PhySAR-Seg datasets demonstrate that PolSAM significantly outperforms existing SAM-based and multimodal fusion models, improving segmentation accuracy, reducing data storage, and accelerating inference time. The source code and datasets will be made publicly available at \\url{https://github.com/XAI4SAR/PolSAM}.",
        "tags": [
            "SAM",
            "Segment Anything",
            "Segmentation"
        ]
    },
    {
        "id": "111",
        "title": "Progressive Monitoring of Generative Model Training Evolution",
        "author": [
            "Vidya Prasad",
            "Anna Vilanova",
            "Nicola Pezzotti"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12755",
        "abstract": "While deep generative models (DGMs) have gained popularity, their susceptibility to biases and other inefficiencies that lead to undesirable outcomes remains an issue. With their growing complexity, there is a critical need for early detection of issues to achieve desired results and optimize resources. Hence, we introduce a progressive analysis framework to monitor the training process of DGMs. Our method utilizes dimensionality reduction techniques to facilitate the inspection of latent representations, the generated and real distributions, and their evolution across training iterations. This monitoring allows us to pause and fix the training method if the representations or distributions progress undesirably. This approach allows for the analysis of a models' training dynamics and the timely identification of biases and failures, minimizing computational loads. We demonstrate how our method supports identifying and mitigating biases early in training a Generative Adversarial Network (GAN) and improving the quality of the generated data distribution.",
        "tags": [
            "Detection",
            "GAN"
        ]
    },
    {
        "id": "112",
        "title": "Towards a Training Free Approach for 3D Scene Editing",
        "author": [
            "Vivek Madhavaram",
            "Shivangana Rawat",
            "Chaitanya Devaguptapu",
            "Charu Sharma",
            "Manohar Kaul"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12766",
        "abstract": "Text driven diffusion models have shown remarkable capabilities in editing images. However, when editing 3D scenes, existing works mostly rely on training a NeRF for 3D editing. Recent NeRF editing methods leverages edit operations by deploying 2D diffusion models and project these edits into 3D space. They require strong positional priors alongside text prompt to identify the edit location. These methods are operational on small 3D scenes and are more generalized to particular scene. They require training for each specific edit and cannot be exploited in real-time edits. To address these limitations, we propose a novel method, FreeEdit, to make edits in training free manner using mesh representations as a substitute for NeRF. Training-free methods are now a possibility because of the advances in foundation model's space. We leverage these models to bring a training-free alternative and introduce solutions for insertion, replacement and deletion. We consider insertion, replacement and deletion as basic blocks for performing intricate edits with certain combinations of these operations. Given a text prompt and a 3D scene, our model is capable of identifying what object should be inserted/replaced or deleted and location where edit should be performed. We also introduce a novel algorithm as part of FreeEdit to find the optimal location on grounding object for placement. We evaluate our model by comparing it with baseline models on a wide range of scenes using quantitative and qualitative metrics and showcase the merits of our method with respect to others.",
        "tags": [
            "3D",
            "Diffusion",
            "NeRF"
        ]
    },
    {
        "id": "113",
        "title": "A Survey of Calibration Process for Black-Box LLMs",
        "author": [
            "Liangru Xie",
            "Hui Liu",
            "Jingying Zeng",
            "Xianfeng Tang",
            "Yan Han",
            "Chen Luo",
            "Jing Huang",
            "Zhen Li",
            "Suhang Wang",
            "Qi He"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12767",
        "abstract": "Large Language Models (LLMs) demonstrate remarkable performance in semantic understanding and generation, yet accurately assessing their output reliability remains a significant challenge. While numerous studies have explored calibration techniques, they primarily focus on White-Box LLMs with accessible parameters. Black-Box LLMs, despite their superior performance, pose heightened requirements for calibration techniques due to their API-only interaction constraints. Although recent researches have achieved breakthroughs in black-box LLMs calibration, a systematic survey of these methodologies is still lacking. To bridge this gap, we presents the first comprehensive survey on calibration techniques for black-box LLMs. We first define the Calibration Process of LLMs as comprising two interrelated key steps: Confidence Estimation and Calibration. Second, we conduct a systematic review of applicable methods within black-box settings, and provide insights on the unique challenges and connections in implementing these key steps. Furthermore, we explore typical applications of Calibration Process in black-box LLMs and outline promising future research directions, providing new perspectives for enhancing reliability and human-machine alignment. This is our GitHub link: https://github.com/LiangruXie/Calibration-Process-in-Black-Box-LLMs",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "114",
        "title": "Guided and Variance-Corrected Fusion with One-shot Style Alignment for Large-Content Image Generation",
        "author": [
            "Shoukun Sun",
            "Min Xian",
            "Tiankai Yao",
            "Fei Xu",
            "Luca Capriotti"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12771",
        "abstract": "Producing large images using small diffusion models is gaining increasing popularity, as the cost of training large models could be prohibitive. A common approach involves jointly generating a series of overlapped image patches and obtaining large images by merging adjacent patches. However, results from existing methods often exhibit obvious artifacts, e.g., seams and inconsistent objects and styles. To address the issues, we proposed Guided Fusion (GF), which mitigates the negative impact from distant image regions by applying a weighted average to the overlapping regions. Moreover, we proposed Variance-Corrected Fusion (VCF), which corrects data variance at post-averaging, generating more accurate fusion for the Denoising Diffusion Probabilistic Model. Furthermore, we proposed a one-shot Style Alignment (SA), which generates a coherent style for large images by adjusting the initial input noise without adding extra computational burden. Extensive experiments demonstrated that the proposed fusion methods improved the quality of the generated image significantly. As a plug-and-play module, the proposed method can be widely applied to enhance other fusion-based methods for large image generation.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "115",
        "title": "Optimize the Unseen -- Fast NeRF Cleanup with Free Space Prior",
        "author": [
            "Leo Segre",
            "Shai Avidan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12772",
        "abstract": "Neural Radiance Fields (NeRF) have advanced photorealistic novel view synthesis, but their reliance on photometric reconstruction introduces artifacts, commonly known as \"floaters\". These artifacts degrade novel view quality, especially in areas unseen by the training cameras. We present a fast, post-hoc NeRF cleanup method that eliminates such artifacts by enforcing our Free Space Prior, effectively minimizing floaters without disrupting the NeRF's representation of observed regions. Unlike existing approaches that rely on either Maximum Likelihood (ML) estimation to fit the data or a complex, local data-driven prior, our method adopts a Maximum-a-Posteriori (MAP) approach, selecting the optimal model parameters under a simple global prior assumption that unseen regions should remain empty. This enables our method to clean artifacts in both seen and unseen areas, enhancing novel view quality even in challenging scene regions. Our method is comparable with existing NeRF cleanup models while being 2.5x faster in inference time, requires no additional memory beyond the original NeRF, and achieves cleanup training in less than 30 seconds. Our code will be made publically available.",
        "tags": [
            "NeRF"
        ]
    },
    {
        "id": "116",
        "title": "A Framework for Critical Evaluation of Text-to-Image Models: Integrating Art Historical Analysis, Artistic Exploration, and Critical Prompt Engineering",
        "author": [
            "Amalia Foka"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12774",
        "abstract": "This paper proposes a novel interdisciplinary framework for the critical evaluation of text-to-image models, addressing the limitations of current technical metrics and bias studies. By integrating art historical analysis, artistic exploration, and critical prompt engineering, the framework offers a more nuanced understanding of these models' capabilities and societal implications. Art historical analysis provides a structured approach to examine visual and symbolic elements, revealing potential biases and misrepresentations. Artistic exploration, through creative experimentation, uncovers hidden potentials and limitations, prompting critical reflection on the algorithms' assumptions. Critical prompt engineering actively challenges the model's assumptions, exposing embedded biases. Case studies demonstrate the framework's practical application, showcasing how it can reveal biases related to gender, race, and cultural representation. This comprehensive approach not only enhances the evaluation of text-to-image models but also contributes to the development of more equitable, responsible, and culturally aware AI systems.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "117",
        "title": "RemoteRAG: A Privacy-Preserving LLM Cloud RAG Service",
        "author": [
            "Yihang Cheng",
            "Lan Zhang",
            "Junyang Wang",
            "Mu Yuan",
            "Yunhao Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12775",
        "abstract": "Retrieval-augmented generation (RAG) improves the service quality of large language models by retrieving relevant documents from credible literature and integrating them into the context of the user query. Recently, the rise of the cloud RAG service has made it possible for users to query relevant documents conveniently. However, directly sending queries to the cloud brings potential privacy leakage. In this paper, we are the first to formally define the privacy-preserving cloud RAG service to protect the user query and propose RemoteRAG as a solution regarding privacy, efficiency, and accuracy. For privacy, we introduce $(n,\\epsilon)$-DistanceDP to characterize privacy leakage of the user query and the leakage inferred from relevant documents. For efficiency, we limit the search range from the total documents to a small number of selected documents related to a perturbed embedding generated from $(n,\\epsilon)$-DistanceDP, so that computation and communication costs required for privacy protection significantly decrease. For accuracy, we ensure that the small range includes target documents related to the user query with detailed theoretical analysis. Experimental results also demonstrate that RemoteRAG can resist existing embedding inversion attack methods while achieving no loss in retrieval under various settings. Moreover, RemoteRAG is efficient, incurring only $0.67$ seconds and $46.66$KB of data transmission ($2.72$ hours and $1.43$ GB with the non-optimized privacy-preserving scheme) when retrieving from a total of $10^6$ documents.",
        "tags": [
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "118",
        "title": "Activating Distributed Visual Region within LLMs for Efficient and Effective Vision-Language Training and Inference",
        "author": [
            "Siyuan Wang",
            "Dianyi Wang",
            "Chengxing Zhou",
            "Zejun Li",
            "Zhihao Fan",
            "Xuanjing Huang",
            "Zhongyu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12785",
        "abstract": "Large Vision-Language Models (LVLMs) typically learn visual capacity through visual instruction tuning, involving updates to both a projector and their LLM backbones. Drawing inspiration from the concept of visual region in the human brain, we investigate the existence of an analogous \\textit{visual region} within LLMs that functions as a cognitive core, and explore the possibility of efficient training of LVLMs via selective layers tuning. We use Bunny-Llama-3-8B-V for detailed experiments and LLaVA-1.5-7B and LLaVA-1.5-13B for validation across a range of visual and textual tasks. Our findings reveal that selectively updating 25\\% of LLMs layers, when sparsely and uniformly distributed, can preserve nearly 99\\% of visual performance while maintaining or enhancing textual task results, and also effectively reducing training time. Based on this targeted training approach, we further propose a novel visual region-based pruning paradigm, removing non-critical layers outside the visual region, which can achieve minimal performance loss. This study offers an effective and efficient strategy for LVLM training and inference by activating a layer-wise visual region within LLMs, which is consistently effective across different models and parameter scales.",
        "tags": [
            "LLMs",
            "LLaMA",
            "LLaVA"
        ]
    },
    {
        "id": "119",
        "title": "CRoF: CLIP-based Robust Few-shot Learning on Noisy Labels",
        "author": [
            "Shizhuo Deng",
            "Bowen Han",
            "Jiaqi Chen",
            "Hao Wang",
            "Dongyue Chen",
            "Tong Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12793",
        "abstract": "Noisy labels threaten the robustness of few-shot learning (FSL) due to the inexact features in a new domain. CLIP, a large-scale vision-language model, performs well in FSL on image-text embedding similarities, but it is susceptible to misclassification caused by noisy labels. How to enhance domain generalization of CLIP on noisy data within FSL tasks is a critical challenge. In this paper, we provide a novel view to mitigate the influence of noisy labels, CLIP-based Robust Few-shot learning (CRoF). CRoF is a general plug-in module for CLIP-based models. To avoid misclassification and confused label embedding, we design the few-shot task-oriented prompt generator to give more discriminative descriptions of each category. The proposed prompt achieves larger distances of inter-class textual embedding. Furthermore, rather than fully trusting zero-shot classification by CLIP, we fine-tune CLIP on noisy few-shot data in a new domain with a weighting strategy like label-smooth. The weights for multiple potentially correct labels consider the relationship between CLIP's prior knowledge and original label information to ensure reliability. Our multiple label loss function further supports robust training under this paradigm. Comprehensive experiments show that CRoF, as a plug-in, outperforms fine-tuned and vanilla CLIP models on different noise types and noise ratios.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "120",
        "title": "RCTrans: Radar-Camera Transformer via Radar Densifier and Sequential Decoder for 3D Object Detection",
        "author": [
            "Yiheng Li",
            "Yang Yang",
            "Zhen Lei"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12799",
        "abstract": "In radar-camera 3D object detection, the radar point clouds are sparse and noisy, which causes difficulties in fusing camera and radar modalities. To solve this, we introduce a novel query-based detection method named Radar-Camera Transformer (RCTrans). Specifically, we first design a Radar Dense Encoder to enrich the sparse valid radar tokens, and then concatenate them with the image tokens. By doing this, we can fully explore the 3D information of each interest region and reduce the interference of empty tokens during the fusing stage. We then design a Pruning Sequential Decoder to predict 3D boxes based on the obtained tokens and random initialized queries. To alleviate the effect of elevation ambiguity in radar point clouds, we gradually locate the position of the object via a sequential fusion structure. It helps to get more precise and flexible correspondences between tokens and queries. A pruning training strategy is adopted in the decoder, which can save much time during inference and inhibit queries from losing their distinctiveness. Extensive experiments on the large-scale nuScenes dataset prove the superiority of our method, and we also achieve new state-of-the-art radar-camera 3D detection results. Our implementation is available at https://github.com/liyih/RCTrans.",
        "tags": [
            "3D",
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "121",
        "title": "Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning",
        "author": [
            "Ziqi Qiu",
            "Jianxing Yu",
            "Yufeng Zhang",
            "Hanjiang Lai",
            "Yanghui Rao",
            "Qinliang Su",
            "Jian Yin"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12808",
        "abstract": "This paper focuses on sarcasm detection, which aims to identify whether given statements convey criticism, mockery, or other negative sentiment opposite to the literal meaning. To detect sarcasm, humans often require a comprehensive understanding of the semantics in the statement and even resort to external commonsense to infer the fine-grained incongruity. However, existing methods lack commonsense inferential ability when they face complex real-world scenarios, leading to unsatisfactory performance. To address this problem, we propose a novel framework for sarcasm detection, which conducts incongruity reasoning based on commonsense augmentation, called EICR. Concretely, we first employ retrieval-augmented large language models to supplement the missing but indispensable commonsense background knowledge. To capture complex contextual associations, we construct a dependency graph and obtain the optimized topology via graph refinement. We further introduce an adaptive reasoning skeleton that integrates prior rules to extract sentiment-inconsistent subgraphs explicitly. To eliminate the possible spurious relations between words and labels, we employ adversarial contrastive learning to enhance the robustness of the detector. Experiments conducted on five datasets demonstrate the effectiveness of EICR.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "122",
        "title": "DSGram: Dynamic Weighting Sub-Metrics for Grammatical Error Correction in the Era of Large Language Models",
        "author": [
            "Jinxiang Xie",
            "Yilin Li",
            "Xunjian Yin",
            "Xiaojun Wan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12832",
        "abstract": "Evaluating the performance of Grammatical Error Correction (GEC) models has become increasingly challenging, as large language model (LLM)-based GEC systems often produce corrections that diverge from provided gold references. This discrepancy undermines the reliability of traditional reference-based evaluation metrics. In this study, we propose a novel evaluation framework for GEC models, DSGram, integrating Semantic Coherence, Edit Level, and Fluency, and utilizing a dynamic weighting mechanism. Our framework employs the Analytic Hierarchy Process (AHP) in conjunction with large language models to ascertain the relative importance of various evaluation criteria. Additionally, we develop a dataset incorporating human annotations and LLM-simulated sentences to validate our algorithms and fine-tune more cost-effective models. Experimental results indicate that our proposed approach enhances the effectiveness of GEC model evaluations.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "123",
        "title": "FocusChat: Text-guided Long Video Understanding via Spatiotemporal Information Filtering",
        "author": [
            "Zheng Cheng",
            "Rendong Wang",
            "Zhicheng Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12833",
        "abstract": "Recently, multi-modal large language models have made significant progress. However, visual information lacking of guidance from the user's intention may lead to redundant computation and involve unnecessary visual noise, especially in long, untrimmed videos. To address this issue, we propose FocusChat, a text-guided multi-modal large language model (LLM) that emphasizes visual information correlated to the user's prompt. In detail, Our model first undergoes the semantic extraction module, which comprises a visual semantic branch and a text semantic branch to extract image and text semantics, respectively. The two branches are combined using the Spatial-Temporal Filtering Module (STFM). STFM enables explicit spatial-level information filtering and implicit temporal-level feature filtering, ensuring that the visual tokens are closely aligned with the user's query. It lowers the essential number of visual tokens inputted into the LLM. FocusChat significantly outperforms Video-LLaMA in zero-shot experiments, using an order of magnitude less training data with only 16 visual tokens occupied. It achieves results comparable to the state-of-the-art in few-shot experiments, with only 0.72M pre-training data.",
        "tags": [
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "124",
        "title": "Benchmarking and Understanding Compositional Relational Reasoning of LLMs",
        "author": [
            "Ruikang Ni",
            "Da Xiao",
            "Qingye Meng",
            "Xiangyu Li",
            "Shihui Zheng",
            "Hongliang Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12841",
        "abstract": "Compositional relational reasoning (CRR) is a hallmark of human intelligence, but we lack a clear understanding of whether and how existing transformer large language models (LLMs) can solve CRR tasks. To enable systematic exploration of the CRR capability of LLMs, we first propose a new synthetic benchmark called Generalized Associative Recall (GAR) by integrating and generalizing the essence of several tasks in mechanistic interpretability (MI) study in a unified framework. Evaluation shows that GAR is challenging enough for existing LLMs, revealing their fundamental deficiency in CRR. Meanwhile, it is easy enough for systematic MI study. Then, to understand how LLMs solve GAR tasks, we use attribution patching to discover the core circuits reused by Vicuna-33B across different tasks and a set of vital attention heads. Intervention experiments show that the correct functioning of these heads significantly impacts task performance. Especially, we identify two classes of heads whose activations represent the abstract notion of true and false in GAR tasks respectively. They play a fundamental role in CRR across various models and tasks. The dataset and code are available at https://github.com/Caiyun-AI/GAR.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer",
            "Vicuna"
        ]
    },
    {
        "id": "125",
        "title": "Efficient Event-based Semantic Segmentation with Spike-driven Lightweight Transformer-based Networks",
        "author": [
            "Xiaxin Zhu",
            "Fangming Guo",
            "Xianlei Long",
            "Qingyi Gu",
            "Chao Chen",
            "Fuqiang Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12843",
        "abstract": "Event-based semantic segmentation has great potential in autonomous driving and robotics due to the advantages of event cameras, such as high dynamic range, low latency, and low power cost. Unfortunately, current artificial neural network (ANN)-based segmentation methods suffer from high computational demands, the requirements for image frames, and massive energy consumption, limiting their efficiency and application on resource-constrained edge/mobile platforms. To address these problems, we introduce SLTNet, a spike-driven lightweight transformer-based network designed for event-based semantic segmentation. Specifically, SLTNet is built on efficient spike-driven convolution blocks (SCBs) to extract rich semantic features while reducing the model's parameters. Then, to enhance the long-range contextural feature interaction, we propose novel spike-driven transformer blocks (STBs) with binary mask operations. Based on these basic blocks, SLTNet employs a high-efficiency single-branch architecture while maintaining the low energy consumption of the Spiking Neural Network (SNN). Finally, extensive experiments on DDD17 and DSEC-Semantic datasets demonstrate that SLTNet outperforms state-of-the-art (SOTA) SNN-based methods by at least 7.30% and 3.30% mIoU, respectively, with extremely 5.48x lower energy consumption and 1.14x faster inference speed.",
        "tags": [
            "Robotics",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "126",
        "title": "ClarityEthic: Explainable Moral Judgment Utilizing Contrastive Ethical Insights from Large Language Models",
        "author": [
            "Yuxi Sun",
            "Wei Gao",
            "Jing Ma",
            "Hongzhan Lin",
            "Ziyang Luo",
            "Wenxuan Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12848",
        "abstract": "With the rise and widespread use of Large Language Models (LLMs), ensuring their safety is crucial to prevent harm to humans and promote ethical behaviors. However, directly assessing value valence (i.e., support or oppose) by leveraging large-scale data training is untrustworthy and inexplainable. We assume that emulating humans to rely on social norms to make moral decisions can help LLMs understand and predict moral judgment. However, capturing human values remains a challenge, as multiple related norms might conflict in specific contexts. Consider norms that are upheld by the majority and promote the well-being of society are more likely to be accepted and widely adopted (e.g., \"don't cheat,\"). Therefore, it is essential for LLM to identify the appropriate norms for a given scenario before making moral decisions. To this end, we introduce a novel moral judgment approach called \\textit{ClarityEthic} that leverages LLMs' reasoning ability and contrastive learning to uncover relevant social norms for human actions from different perspectives and select the most reliable one to enhance judgment accuracy. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches in moral judgment tasks. Moreover, human evaluations confirm that the generated social norms provide plausible explanations that support the judgments. This suggests that modeling human moral judgment with the emulating humans moral strategy is promising for improving the ethical behaviors of LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "127",
        "title": "HyperGS: Hyperspectral 3D Gaussian Splatting",
        "author": [
            "Christopher Thirgood",
            "Oscar Mendez",
            "Erin Chao Ling",
            "Jon Storey",
            "Simon Hadfield"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12849",
        "abstract": "We introduce HyperGS, a novel framework for Hyperspectral Novel View Synthesis (HNVS), based on a new latent 3D Gaussian Splatting (3DGS) technique. Our approach enables simultaneous spatial and spectral renderings by encoding material properties from multi-view 3D hyperspectral datasets. HyperGS reconstructs high-fidelity views from arbitrary perspectives with improved accuracy and speed, outperforming currently existing methods. To address the challenges of high-dimensional data, we perform view synthesis in a learned latent space, incorporating a pixel-wise adaptive density function and a pruning technique for increased training stability and efficiency. Additionally, we introduce the first HNVS benchmark, implementing a number of new baselines based on recent SOTA RGB-NVS techniques, alongside the small number of prior works on HNVS. We demonstrate HyperGS's robustness through extensive evaluation of real and simulated hyperspectral scenes with a 14db accuracy improvement upon previously published models.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "128",
        "title": "Selective Shot Learning for Code Explanation",
        "author": [
            "Paheli Bhattacharya",
            "Rishabh Gupta"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12852",
        "abstract": "Code explanation plays a crucial role in the software engineering domain, aiding developers in grasping code functionality efficiently. Recent work shows that the performance of LLMs for code explanation improves in a few-shot setting, especially when the few-shot examples are selected intelligently. State-of-the-art approaches for such Selective Shot Learning (SSL) include token-based and embedding-based methods. However, these SSL approaches have been evaluated on proprietary LLMs, without much exploration on open-source Code-LLMs. Additionally, these methods lack consideration for programming language syntax. To bridge these gaps, we present a comparative study and propose a novel SSL method (SSL_ner) that utilizes entity information for few-shot example selection. We present several insights and show the effectiveness of SSL_ner approach over state-of-the-art methods across two datasets. To the best of our knowledge, this is the first systematic benchmarking of open-source Code-LLMs while assessing the performances of the various few-shot examples selection approaches for the code explanation task.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "129",
        "title": "Dyn-HaMR: Recovering 4D Interacting Hand Motion from a Dynamic Camera",
        "author": [
            "Zhengdi Yu",
            "Stefanos Zafeiriou",
            "Tolga Birdal"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12861",
        "abstract": "We propose Dyn-HaMR, to the best of our knowledge, the first approach to reconstruct 4D global hand motion from monocular videos recorded by dynamic cameras in the wild. Reconstructing accurate 3D hand meshes from monocular videos is a crucial task for understanding human behaviour, with significant applications in augmented and virtual reality (AR/VR). However, existing methods for monocular hand reconstruction typically rely on a weak perspective camera model, which simulates hand motion within a limited camera frustum. As a result, these approaches struggle to recover the full 3D global trajectory and often produce noisy or incorrect depth estimations, particularly when the video is captured by dynamic or moving cameras, which is common in egocentric scenarios. Our Dyn-HaMR consists of a multi-stage, multi-objective optimization pipeline, that factors in (i) simultaneous localization and mapping (SLAM) to robustly estimate relative camera motion, (ii) an interacting-hand prior for generative infilling and to refine the interaction dynamics, ensuring plausible recovery under (self-)occlusions, and (iii) hierarchical initialization through a combination of state-of-the-art hand tracking methods. Through extensive evaluations on both in-the-wild and indoor datasets, we show that our approach significantly outperforms state-of-the-art methods in terms of 4D global mesh recovery. This establishes a new benchmark for hand motion reconstruction from monocular video with moving cameras. Our project page is at https://dyn-hamr.github.io/.",
        "tags": [
            "3D",
            "SLAM"
        ]
    },
    {
        "id": "130",
        "title": "Preference-Oriented Supervised Fine-Tuning: Favoring Target Model Over Aligned Large Language Models",
        "author": [
            "Yuchen Fan",
            "Yuzhong Hong",
            "Qiushi Wang",
            "Junwei Bao",
            "Hongfei Jiang",
            "Yang Song"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12865",
        "abstract": "Alignment, endowing a pre-trained Large language model (LLM) with the ability to follow instructions, is crucial for its real-world applications. Conventional supervised fine-tuning (SFT) methods formalize it as causal language modeling typically with a cross-entropy objective, requiring a large amount of high-quality instruction-response pairs. However, the quality of widely used SFT datasets can not be guaranteed due to the high cost and intensive labor for the creation and maintenance in practice. To overcome the limitations associated with the quality of SFT datasets, we introduce a novel \\textbf{p}reference-\\textbf{o}riented supervised \\textbf{f}ine-\\textbf{t}uning approach, namely PoFT. The intuition is to boost SFT by imposing a particular preference: \\textit{favoring the target model over aligned LLMs on the same SFT data.} This preference encourages the target model to predict a higher likelihood than that predicted by the aligned LLMs, incorporating assessment information on data quality (i.e., predicted likelihood by the aligned LLMs) into the training process. Extensive experiments are conducted, and the results validate the effectiveness of the proposed method. PoFT achieves stable and consistent improvements over the SFT baselines across different training datasets and base models. Moreover, we prove that PoFT can be integrated with existing SFT data filtering methods to achieve better performance, and further improved by following preference optimization procedures, such as DPO.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "131",
        "title": "MIVE: New Design and Benchmark for Multi-Instance Video Editing",
        "author": [
            "Samuel Teodoro",
            "Agus Gunawan",
            "Soo Ye Kim",
            "Jihyong Oh",
            "Munchurl Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12877",
        "abstract": "Recent AI-based video editing has enabled users to edit videos through simple text prompts, significantly simplifying the editing process. However, recent zero-shot video editing techniques primarily focus on global or single-object edits, which can lead to unintended changes in other parts of the video. When multiple objects require localized edits, existing methods face challenges, such as unfaithful editing, editing leakage, and lack of suitable evaluation datasets and metrics. To overcome these limitations, we propose a zero-shot $\\textbf{M}$ulti-$\\textbf{I}$nstance $\\textbf{V}$ideo $\\textbf{E}$diting framework, called MIVE. MIVE is a general-purpose mask-based framework, not dedicated to specific objects (e.g., people). MIVE introduces two key modules: (i) Disentangled Multi-instance Sampling (DMS) to prevent editing leakage and (ii) Instance-centric Probability Redistribution (IPR) to ensure precise localization and faithful editing. Additionally, we present our new MIVE Dataset featuring diverse video scenarios and introduce the Cross-Instance Accuracy (CIA) Score to evaluate editing leakage in multi-instance video editing tasks. Our extensive qualitative, quantitative, and user study evaluations demonstrate that MIVE significantly outperforms recent state-of-the-art methods in terms of editing faithfulness, accuracy, and leakage prevention, setting a new benchmark for multi-instance video editing. The project page is available at https://kaist-viclab.github.io/mive-site/",
        "tags": [
            "Video Editing"
        ]
    },
    {
        "id": "132",
        "title": "RAG-Star: Enhancing Deliberative Reasoning with Retrieval Augmented Verification and Refinement",
        "author": [
            "Jinhao Jiang",
            "Jiayi Chen",
            "Junyi Li",
            "Ruiyang Ren",
            "Shijie Wang",
            "Wayne Xin Zhao",
            "Yang Song",
            "Tao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12881",
        "abstract": "Existing large language models (LLMs) show exceptional problem-solving capabilities but might struggle with complex reasoning tasks. Despite the successes of chain-of-thought and tree-based search methods, they mainly depend on the internal knowledge of LLMs to search over intermediate reasoning steps, limited to dealing with simple tasks involving fewer reasoning steps. In this paper, we propose \\textbf{RAG-Star}, a novel RAG approach that integrates the retrieved information to guide the tree-based deliberative reasoning process that relies on the inherent knowledge of LLMs. By leveraging Monte Carlo Tree Search, RAG-Star iteratively plans intermediate sub-queries and answers for reasoning based on the LLM itself. To consolidate internal and external knowledge, we propose an retrieval-augmented verification that utilizes query- and answer-aware reward modeling to provide feedback for the inherent reasoning of LLMs. Our experiments involving Llama-3.1-8B-Instruct and GPT-4o demonstrate that RAG-Star significantly outperforms previous RAG and reasoning methods.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "133",
        "title": "A Comparative Study of Pruning Methods in Transformer-based Time Series Forecasting",
        "author": [
            "Nicholas Kiefer",
            "Arvid Weyrauch",
            "Muhammed Öz",
            "Achim Streit",
            "Markus Götz",
            "Charlotte Debus"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12883",
        "abstract": "The current landscape in time-series forecasting is dominated by Transformer-based models. Their high parameter count and corresponding demand in computational resources pose a challenge to real-world deployment, especially for commercial and scientific applications with low-power embedded devices. Pruning is an established approach to reduce neural network parameter count and save compute. However, the implications and benefits of pruning Transformer-based models for time series forecasting are largely unknown. To close this gap, we provide a comparative benchmark study by evaluating unstructured and structured pruning on various state-of-the-art multivariate time series models. We study the effects of these pruning strategies on model predictive performance and computational aspects like model size, operations, and inference time. Our results show that certain models can be pruned even up to high sparsity levels, outperforming their dense counterpart. However, fine-tuning pruned models is necessary. Furthermore, we demonstrate that even with corresponding hardware and software support, structured pruning is unable to provide significant time savings.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "134",
        "title": "TimeCHEAT: A Channel Harmony Strategy for Irregularly Sampled Multivariate Time Series Analysis",
        "author": [
            "Jiexi Liu",
            "Meng Cao",
            "Songcan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12886",
        "abstract": "Irregularly sampled multivariate time series (ISMTS) are prevalent in reality. Due to their non-uniform intervals between successive observations and varying sampling rates among series, the channel-independent (CI) strategy, which has been demonstrated more desirable for complete multivariate time series forecasting in recent studies, has failed. This failure can be further attributed to the sampling sparsity, which provides insufficient information for effective CI learning, thereby reducing its capacity. When we resort to the channel-dependent (CD) strategy, even higher capacity cannot mitigate the potential loss of diversity in learning similar embedding patterns across different channels. We find that existing work considers CI and CD strategies to be mutually exclusive, primarily because they apply these strategies to the global channel. However, we hold the view that channel strategies do not necessarily have to be used globally. Instead, by appropriately applying them locally and globally, we can create an opportunity to take full advantage of both strategies. This leads us to introduce the Channel Harmony ISMTS Transformer (TimeCHEAT), which utilizes the CD locally and the CI globally. Specifically, we segment the ISMTS into sub-series level patches. Locally, the CD strategy aggregates information within each patch for time embedding learning, maximizing the use of relevant observations while reducing long-range irrelevant interference. Here, we enhance generality by transforming embedding learning into an edge weight prediction task using bipartite graphs, eliminating the need for special prior knowledge. Globally, the CI strategy is applied across patches, allowing the Transformer to learn individualized attention patterns for each channel. Experimental results indicate our proposed TimeCHEAT demonstrates competitive SOTA performance across three mainstream tasks.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "135",
        "title": "ArtAug: Enhancing Text-to-Image Generation through Synthesis-Understanding Interaction",
        "author": [
            "Zhongjie Duan",
            "Qianyi Zhao",
            "Cen Chen",
            "Daoyuan Chen",
            "Wenmeng Zhou",
            "Yaliang Li",
            "Yingda Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12888",
        "abstract": "The emergence of diffusion models has significantly advanced image synthesis. The recent studies of model interaction and self-corrective reasoning approach in large language models offer new insights for enhancing text-to-image models. Inspired by these studies, we propose a novel method called ArtAug for enhancing text-to-image models in this paper. To the best of our knowledge, ArtAug is the first one that improves image synthesis models via model interactions with understanding models. In the interactions, we leverage human preferences implicitly learned by image understanding models to provide fine-grained suggestions for image synthesis models. The interactions can modify the image content to make it aesthetically pleasing, such as adjusting exposure, changing shooting angles, and adding atmospheric effects. The enhancements brought by the interaction are iteratively fused into the synthesis model itself through an additional enhancement module. This enables the synthesis model to directly produce aesthetically pleasing images without any extra computational cost. In the experiments, we train the ArtAug enhancement module on existing text-to-image models. Various evaluation metrics consistently demonstrate that ArtAug enhances the generative capabilities of text-to-image models without incurring additional computational costs. The source code and models will be released publicly.",
        "tags": [
            "Diffusion",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "136",
        "title": "SAUGE: Taming SAM for Uncertainty-Aligned Multi-Granularity Edge Detection",
        "author": [
            "Xing Liufu",
            "Chaolei Tan",
            "Xiaotong Lin",
            "Yonggang Qi",
            "Jinxuan Li",
            "Jian-Fang Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12892",
        "abstract": "Edge labels are typically at various granularity levels owing to the varying preferences of annotators, thus handling the subjectivity of per-pixel labels has been a focal point for edge detection. Previous methods often employ a simple voting strategy to diminish such label uncertainty or impose a strong assumption of labels with a pre-defined distribution, e.g., Gaussian. In this work, we unveil that the segment anything model (SAM) provides strong prior knowledge to model the uncertainty in edge labels. Our key insight is that the intermediate SAM features inherently correspond to object edges at various granularities, which reflects different edge options due to uncertainty. Therefore, we attempt to align uncertainty with granularity by regressing intermediate SAM features from different layers to object edges at multi-granularity levels. In doing so, the model can fully and explicitly explore diverse ``uncertainties'' in a data-driven fashion. Specifically, we inject a lightweight module (~ 1.5% additional parameters) into the frozen SAM to progressively fuse and adapt its intermediate features to estimate edges from coarse to fine. It is crucial to normalize the granularity level of human edge labels to match their innate uncertainty. For this, we simply perform linear blending to the real edge labels at hand to create pseudo labels with varying granularities. Consequently, our uncertainty-aligned edge detector can flexibly produce edges at any desired granularity (including an optimal one). Thanks to SAM, our model uniquely demonstrates strong generalizability for cross-dataset edge detection. Extensive experimental results on BSDS500, Muticue and NYUDv2 validate our model's superiority.",
        "tags": [
            "Detection",
            "SAM",
            "Segment Anything"
        ]
    },
    {
        "id": "137",
        "title": "Question: How do Large Language Models perform on the Question Answering tasks? Answer:",
        "author": [
            "Kevin Fischer",
            "Darren Fürst",
            "Sebastian Steindl",
            "Jakob Lindner",
            "Ulrich Schäfer"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12893",
        "abstract": "Large Language Models (LLMs) have been showing promising results for various NLP-tasks without the explicit need to be trained for these tasks by using few-shot or zero-shot prompting techniques. A common NLP-task is question-answering (QA). In this study, we propose a comprehensive performance comparison between smaller fine-tuned models and out-of-the-box instruction-following LLMs on the Stanford Question Answering Dataset 2.0 (SQuAD2), specifically when using a single-inference prompting technique. Since the dataset contains unanswerable questions, previous work used a double inference method. We propose a prompting style which aims to elicit the same ability without the need for double inference, saving compute time and resources. Furthermore, we investigate their generalization capabilities by comparing their performance on similar but different QA datasets, without fine-tuning neither model, emulating real-world uses where the context and questions asked may differ from the original training distribution, for example swapping Wikipedia for news articles.\nOur results show that smaller, fine-tuned models outperform current State-Of-The-Art (SOTA) LLMs on the fine-tuned task, but recent SOTA models are able to close this gap on the out-of-distribution test and even outperform the fine-tuned models on 3 of the 5 tested QA datasets.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "138",
        "title": "An Agentic Approach to Automatic Creation of P&ID Diagrams from Natural Language Descriptions",
        "author": [
            "Shreeyash Gowaikar",
            "Srinivasan Iyengar",
            "Sameer Segal",
            "Shivkumar Kalyanaraman"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12898",
        "abstract": "The Piping and Instrumentation Diagrams (P&IDs) are foundational to the design, construction, and operation of workflows in the engineering and process industries. However, their manual creation is often labor-intensive, error-prone, and lacks robust mechanisms for error detection and correction. While recent advancements in Generative AI, particularly Large Language Models (LLMs) and Vision-Language Models (VLMs), have demonstrated significant potential across various domains, their application in automating generation of engineering workflows remains underexplored. In this work, we introduce a novel copilot for automating the generation of P&IDs from natural language descriptions. Leveraging a multi-step agentic workflow, our copilot provides a structured and iterative approach to diagram creation directly from Natural Language prompts. We demonstrate the feasibility of the generation process by evaluating the soundness and completeness of the workflow, and show improved results compared to vanilla zero-shot and few-shot generation approaches.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "139",
        "title": "CATSplat: Context-Aware Transformer with Spatial Guidance for Generalizable 3D Gaussian Splatting from A Single-View Image",
        "author": [
            "Wonseok Roh",
            "Hwanhee Jung",
            "Jong Wook Kim",
            "Seunggwan Lee",
            "Innfarn Yoo",
            "Andreas Lugmayr",
            "Seunggeun Chi",
            "Karthik Ramani",
            "Sangpil Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12906",
        "abstract": "Recently, generalizable feed-forward methods based on 3D Gaussian Splatting have gained significant attention for their potential to reconstruct 3D scenes using finite resources. These approaches create a 3D radiance field, parameterized by per-pixel 3D Gaussian primitives, from just a few images in a single forward pass. However, unlike multi-view methods that benefit from cross-view correspondences, 3D scene reconstruction with a single-view image remains an underexplored area. In this work, we introduce CATSplat, a novel generalizable transformer-based framework designed to break through the inherent constraints in monocular settings. First, we propose leveraging textual guidance from a visual-language model to complement insufficient information from a single image. By incorporating scene-specific contextual details from text embeddings through cross-attention, we pave the way for context-aware 3D scene reconstruction beyond relying solely on visual cues. Moreover, we advocate utilizing spatial guidance from 3D point features toward comprehensive geometric understanding under single-view settings. With 3D priors, image features can capture rich structural insights for predicting 3D Gaussians without multi-view techniques. Extensive experiments on large-scale datasets demonstrate the state-of-the-art performance of CATSplat in single-view 3D scene reconstruction with high-quality novel view synthesis.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Transformer"
        ]
    },
    {
        "id": "140",
        "title": "Unsupervised Region-Based Image Editing of Denoising Diffusion Models",
        "author": [
            "Zixiang Li",
            "Yue Song",
            "Renshuai Tao",
            "Xiaohong Jia",
            "Yao Zhao",
            "Wei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12912",
        "abstract": "Although diffusion models have achieved remarkable success in the field of image generation, their latent space remains under-explored. Current methods for identifying semantics within latent space often rely on external supervision, such as textual information and segmentation masks. In this paper, we propose a method to identify semantic attributes in the latent space of pre-trained diffusion models without any further training. By projecting the Jacobian of the targeted semantic region into a low-dimensional subspace which is orthogonal to the non-masked regions, our approach facilitates precise semantic discovery and control over local masked areas, eliminating the need for annotations. We conducted extensive experiments across multiple datasets and various architectures of diffusion models, achieving state-of-the-art performance. In particular, for some specific face attributes, the performance of our proposed method even surpasses that of supervised approaches, demonstrating its superior ability in editing local image properties.",
        "tags": [
            "Diffusion",
            "Image Editing",
            "Segmentation"
        ]
    },
    {
        "id": "141",
        "title": "Truthful Text Sanitization Guided by Inference Attacks",
        "author": [
            "Ildikó Pilán",
            "Benet Manzanares-Salor",
            "David Sánchez",
            "Pierre Lison"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12928",
        "abstract": "The purpose of text sanitization is to rewrite those text spans in a document that may directly or indirectly identify an individual, to ensure they no longer disclose personal information. Text sanitization must strike a balance between preventing the leakage of personal information (privacy protection) while also retaining as much of the document's original content as possible (utility preservation). We present an automated text sanitization strategy based on generalizations, which are more abstract (but still informative) terms that subsume the semantic content of the original text spans. The approach relies on instruction-tuned large language models (LLMs) and is divided into two stages. The LLM is first applied to obtain truth-preserving replacement candidates and rank them according to their abstraction level. Those candidates are then evaluated for their ability to protect privacy by conducting inference attacks with the LLM. Finally, the system selects the most informative replacement shown to be resistant to those attacks. As a consequence of this two-stage process, the chosen replacements effectively balance utility and privacy. We also present novel metrics to automatically evaluate these two aspects without the need to manually annotate data. Empirical results on the Text Anonymization Benchmark show that the proposed approach leads to enhanced utility, with only a marginal increase in the risk of re-identifying protected individuals compared to fully suppressing the original information. Furthermore, the selected replacements are shown to be more truth-preserving and abstractive than previous methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "142",
        "title": "FineGates: LLMs Finetuning with Compression using Stochastic Gates",
        "author": [
            "Jonathan Svirsky",
            "Yehonathan Refael",
            "Ofir Lindenbaum"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12951",
        "abstract": "Large Language Models (LLMs), with billions of parameters, present significant challenges for full finetuning due to the high computational demands, memory requirements, and impracticality of many real-world applications. When faced with limited computational resources or small datasets, updating all model parameters can often result in overfitting. To address this, lightweight finetuning techniques have been proposed, like learning low-rank adapter layers. These methods aim to train only a few additional parameters combined with the base model, which remains frozen, reducing resource usage and mitigating overfitting risks. In this work, we propose an adaptor model based on stochastic gates that simultaneously sparsify the frozen base model with task-specific adaptation. Our method comes with a small number of trainable parameters and allows us to speed up the base model inference with competitive accuracy. We evaluate it in additional variants by equipping it with additional low-rank parameters and comparing it to several recent baselines. Our results show that the proposed method improves the finetuned model accuracy comparatively to the several baselines and allows the removal of up to 20-40\\% without significant accuracy loss.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "143",
        "title": "Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning",
        "author": [
            "Moritz Reuss",
            "Jyothish Pari",
            "Pulkit Agrawal",
            "Rudolf Lioutikov"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12953",
        "abstract": "Diffusion Policies have become widely used in Imitation Learning, offering several appealing properties, such as generating multimodal and discontinuous behavior. As models are becoming larger to capture more complex capabilities, their computational demands increase, as shown by recent scaling laws. Therefore, continuing with the current architectures will present a computational roadblock. To address this gap, we propose Mixture-of-Denoising Experts (MoDE) as a novel policy for Imitation Learning. MoDE surpasses current state-of-the-art Transformer-based Diffusion Policies while enabling parameter-efficient scaling through sparse experts and noise-conditioned routing, reducing both active parameters by 40% and inference costs by 90% via expert caching. Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism, enabling more effective denoising across different noise levels. MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO). Notably, by pretraining MoDE on diverse robotics data, we achieve 4.01 on CALVIN ABC and 0.95 on LIBERO-90. It surpasses both CNN-based and Transformer Diffusion Policies by an average of 57% across 4 benchmarks, while using 90% fewer FLOPs and fewer active parameters compared to default Diffusion Transformer architectures. Furthermore, we conduct comprehensive ablations on MoDE's components, providing insights for designing efficient and scalable Transformer architectures for Diffusion Policies. Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy/.",
        "tags": [
            "Diffusion",
            "Diffusion Transformer",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "144",
        "title": "SnakModel: Lessons Learned from Training an Open Danish Large Language Model",
        "author": [
            "Mike Zhang",
            "Max Müller-Eberstein",
            "Elisa Bassignana",
            "Rob van der Goot"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12956",
        "abstract": "We present SnakModel, a Danish large language model (LLM) based on Llama2-7B, which we continuously pre-train on 13.6B Danish words, and further tune on 3.7M Danish instructions. As best practices for creating LLMs for smaller language communities have yet to be established, we examine the effects of early modeling and training decisions on downstream performance throughout the entire training pipeline, including (1) the creation of a strictly curated corpus of Danish text from diverse sources; (2) the language modeling and instruction-tuning training process itself, including the analysis of intermediate training dynamics, and ablations across different hyperparameters; (3) an evaluation on eight language and culturally-specific tasks. Across these experiments SnakModel achieves the highest overall performance, outperforming multiple contemporary Llama2-7B-based models. By making SnakModel, the majority of our pre-training corpus, and the associated code available under open licenses, we hope to foster further research and development in Danish Natural Language Processing, and establish training guidelines for languages with similar resource constraints.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "145",
        "title": "Adaptations of AI models for querying the LandMatrix database in natural language",
        "author": [
            "Fatiha Ait Kbir",
            "Jérémy Bourgoin",
            "Rémy Decoupes",
            "Marie Gradeler",
            "Roberto Interdonato"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12961",
        "abstract": "The Land Matrix initiative (https://landmatrix.org) and its global observatory aim to provide reliable data on large-scale land acquisitions to inform debates and actions in sectors such as agriculture, extraction, or energy in low- and middle-income countries. Although these data are recognized in the academic world, they remain underutilized in public policy, mainly due to the complexity of access and exploitation, which requires technical expertise and a good understanding of the database schema.\nThe objective of this work is to simplify access to data from different database systems. The methods proposed in this article are evaluated using data from the Land Matrix. This work presents various comparisons of Large Language Models (LLMs) as well as combinations of LLM adaptations (Prompt Engineering, RAG, Agents) to query different database systems (GraphQL and REST queries). The experiments are reproducible, and a demonstration is available online: https://github.com/tetis-nlp/landmatrix-graphql-python.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "146",
        "title": "Fruit Deformity Classification through Single-Input and Multi-Input Architectures based on CNN Models using Real and Synthetic Images",
        "author": [
            "Tommy D. Beltran",
            "Raul J. Villao",
            "Luis E. Chuquimarca",
            "Boris X. Vintimilla",
            "Sergio A. Velastin"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12966",
        "abstract": "The present study focuses on detecting the degree of deformity in fruits such as apples, mangoes, and strawberries during the process of inspecting their external quality, employing Single-Input and Multi-Input architectures based on convolutional neural network (CNN) models using sets of real and synthetic images. The datasets are segmented using the Segment Anything Model (SAM), which provides the silhouette of the fruits. Regarding the single-input architecture, the evaluation of the CNN models is performed only with real images, but a methodology is proposed to improve these results using a pre-trained model with synthetic images. In the Multi-Input architecture, branches with RGB images and fruit silhouettes are implemented as inputs for evaluating CNN models such as VGG16, MobileNetV2, and CIDIS. However, the results revealed that the Multi-Input architecture with the MobileNetV2 model was the most effective in identifying deformities in the fruits, achieving accuracies of 90\\%, 94\\%, and 92\\% for apples, mangoes, and strawberries, respectively. In conclusion, the Multi-Input architecture with the MobileNetV2 model is the most accurate for classifying levels of deformity in fruits.",
        "tags": [
            "SAM",
            "Segment Anything"
        ]
    },
    {
        "id": "147",
        "title": "ArchesWeather & ArchesWeatherGen: a deterministic and generative model for efficient ML weather forecasting",
        "author": [
            "Guillaume Couairon",
            "Renu Singh",
            "Anastase Charantonis",
            "Christian Lessig",
            "Claire Monteleoni"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12971",
        "abstract": "Weather forecasting plays a vital role in today's society, from agriculture and logistics to predicting the output of renewable energies, and preparing for extreme weather events. Deep learning weather forecasting models trained with the next state prediction objective on ERA5 have shown great success compared to numerical global circulation models. However, for a wide range of applications, being able to provide representative samples from the distribution of possible future weather states is critical. In this paper, we propose a methodology to leverage deterministic weather models in the design of probabilistic weather models, leading to improved performance and reduced computing costs. We first introduce \\textbf{ArchesWeather}, a transformer-based deterministic model that improves upon Pangu-Weather by removing overrestrictive inductive priors. We then design a probabilistic weather model called \\textbf{ArchesWeatherGen} based on flow matching, a modern variant of diffusion models, that is trained to project ArchesWeather's predictions to the distribution of ERA5 weather states. ArchesWeatherGen is a true stochastic emulator of ERA5 and surpasses IFS ENS and NeuralGCM on all WeatherBench headline variables (except for NeuralGCM's geopotential). Our work also aims to democratize the use of deterministic and generative machine learning models in weather forecasting research, with academic computing resources. All models are trained at 1.5° resolution, with a training budget of $\\sim$9 V100 days for ArchesWeather and $\\sim$45 V100 days for ArchesWeatherGen. For inference, ArchesWeatherGen generates 15-day weather trajectories at a rate of 1 minute per ensemble member on a A100 GPU card. To make our work fully reproducible, our code and models are open source, including the complete pipeline for data preparation, training, and evaluation, at https://github.com/INRIA/geoarches .",
        "tags": [
            "Diffusion",
            "Flow Matching",
            "Transformer"
        ]
    },
    {
        "id": "148",
        "title": "Attentive Eraser: Unleashing Diffusion Model's Object Removal Potential via Self-Attention Redirection Guidance",
        "author": [
            "Wenhao Sun",
            "Benlei Cui",
            "Jingqun Tang",
            "Xue-Mei Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12974",
        "abstract": "Recently, diffusion models have emerged as promising newcomers in the field of generative models, shining brightly in image generation. However, when employed for object removal tasks, they still encounter issues such as generating random artifacts and the incapacity to repaint foreground object areas with appropriate content after removal. To tackle these problems, we propose Attentive Eraser, a tuning-free method to empower pre-trained diffusion models for stable and effective object removal. Firstly, in light of the observation that the self-attention maps influence the structure and shape details of the generated images, we propose Attention Activation and Suppression (ASS), which re-engineers the self-attention mechanism within the pre-trained diffusion models based on the given mask, thereby prioritizing the background over the foreground object during the reverse generation process. Moreover, we introduce Self-Attention Redirection Guidance (SARG), which utilizes the self-attention redirected by ASS to guide the generation process, effectively removing foreground objects within the mask while simultaneously generating content that is both plausible and coherent. Experiments demonstrate the stability and effectiveness of Attentive Eraser in object removal across a variety of pre-trained diffusion models, outperforming even training-based methods. Furthermore, Attentive Eraser can be implemented in various diffusion model architectures and checkpoints, enabling excellent scalability. Code is available at https://github.com/Anonym0u3/AttentiveEraser.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "149",
        "title": "A New Adversarial Perspective for LiDAR-based 3D Object Detection",
        "author": [
            "Shijun Zheng",
            "Weiquan Liu",
            "Yu Guo",
            "Yu Zang",
            "Siqi Shen",
            "Cheng Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13017",
        "abstract": "Autonomous vehicles (AVs) rely on LiDAR sensors for environmental perception and decision-making in driving scenarios. However, ensuring the safety and reliability of AVs in complex environments remains a pressing challenge. To address this issue, we introduce a real-world dataset (ROLiD) comprising LiDAR-scanned point clouds of two random objects: water mist and smoke. In this paper, we introduce a novel adversarial perspective by proposing an attack framework that utilizes water mist and smoke to simulate environmental interference. Specifically, we propose a point cloud sequence generation method using a motion and content decomposition generative adversarial network named PCS-GAN to simulate the distribution of random objects. Furthermore, leveraging the simulated LiDAR scanning characteristics implemented with Range Image, we examine the effects of introducing random object perturbations at various positions on the target vehicle. Extensive experiments demonstrate that adversarial perturbations based on random objects effectively deceive vehicle detection and reduce the recognition rate of 3D object detection models.",
        "tags": [
            "3D",
            "Detection",
            "GAN"
        ]
    },
    {
        "id": "150",
        "title": "OmniEval: An Omnidirectional and Automatic RAG Evaluation Benchmark in Financial Domain",
        "author": [
            "Shuting Wang",
            "Jiejun Tan",
            "Zhicheng Dou",
            "Ji-Rong Wen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13018",
        "abstract": "As a typical and practical application of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) techniques have gained extensive attention, particularly in vertical domains where LLMs may lack domain-specific knowledge. In this paper, we introduce an omnidirectional and automatic RAG benchmark, OmniEval, in the financial domain. Our benchmark is characterized by its multi-dimensional evaluation framework, including (1) a matrix-based RAG scenario evaluation system that categorizes queries into five task classes and 16 financial topics, leading to a structured assessment of diverse query scenarios; (2) a multi-dimensional evaluation data generation approach, which combines GPT-4-based automatic generation and human annotation, achieving an 87.47\\% acceptance ratio in human evaluations on generated instances; (3) a multi-stage evaluation system that evaluates both retrieval and generation performance, result in a comprehensive evaluation on the RAG pipeline; and (4) robust evaluation metrics derived from rule-based and LLM-based ones, enhancing the reliability of assessments through manual annotations and supervised fine-tuning of an LLM evaluator. Our experiments demonstrate the comprehensiveness of OmniEval, which includes extensive test datasets and highlights the performance variations of RAG systems across diverse topics and tasks, revealing significant opportunities for RAG models to improve their capabilities in vertical domains. We open source the code of our benchmark in \\href{https://github.com/RUC-NLPIR/OmniEval}{https://github.com/RUC-NLPIR/OmniEval}.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "151",
        "title": "NAVCON: A Cognitively Inspired and Linguistically Grounded Corpus for Vision and Language Navigation",
        "author": [
            "Karan Wanchoo",
            "Xiaoye Zuo",
            "Hannah Gonzalez",
            "Soham Dan",
            "Georgios Georgakis",
            "Dan Roth",
            "Kostas Daniilidis",
            "Eleni Miltsakaki"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13026",
        "abstract": "We present NAVCON, a large-scale annotated Vision-Language Navigation (VLN) corpus built on top of two popular datasets (R2R and RxR). The paper introduces four core, cognitively motivated and linguistically grounded, navigation concepts and an algorithm for generating large-scale silver annotations of naturally occurring linguistic realizations of these concepts in navigation instructions. We pair the annotated instructions with video clips of an agent acting on these instructions. NAVCON contains 236, 316 concept annotations for approximately 30, 0000 instructions and 2.7 million aligned images (from approximately 19, 000 instructions) showing what the agent sees when executing an instruction. To our knowledge, this is the first comprehensive resource of navigation concepts. We evaluated the quality of the silver annotations by conducting human evaluation studies on NAVCON samples. As further validation of the quality and usefulness of the resource, we trained a model for detecting navigation concepts and their linguistic realizations in unseen instructions. Additionally, we show that few-shot learning with GPT-4o performs well on this task using large-scale silver annotations of NAVCON.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "152",
        "title": "TAME: Temporal Audio-based Mamba for Enhanced Drone Trajectory Estimation and Classification",
        "author": [
            "Zhenyuan Xiao",
            "Huanran Hu",
            "Guili Xu",
            "Junwei He"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13037",
        "abstract": "The increasing prevalence of compact UAVs has introduced significant risks to public safety, while traditional drone detection systems are often bulky and costly. To address these challenges, we present TAME, the Temporal Audio-based Mamba for Enhanced Drone Trajectory Estimation and Classification. This innovative anti-UAV detection model leverages a parallel selective state-space model to simultaneously capture and learn both the temporal and spectral features of audio, effectively analyzing propagation of sound. To further enhance temporal features, we introduce a Temporal Feature Enhancement Module, which integrates spectral features into temporal data using residual cross-attention. This enhanced temporal information is then employed for precise 3D trajectory estimation and classification. Our model sets a new standard of performance on the MMUAD benchmarks, demonstrating superior accuracy and effectiveness. The code and trained models are publicly available on GitHub \\url{https://github.com/AmazingDay1/TAME}.",
        "tags": [
            "3D",
            "Detection",
            "Mamba"
        ]
    },
    {
        "id": "153",
        "title": "Harnessing Event Sensory Data for Error Pattern Prediction in Vehicles: A Language Model Approach",
        "author": [
            "Hugo Math",
            "Rainer Lienhart",
            "Robin Schön"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13041",
        "abstract": "In this paper, we draw an analogy between processing natural languages and processing multivariate event streams from vehicles in order to predict $\\textit{when}$ and $\\textit{what}$ error pattern is most likely to occur in the future for a given car. Our approach leverages the temporal dynamics and contextual relationships of our event data from a fleet of cars. Event data is composed of discrete values of error codes as well as continuous values such as time and mileage. Modelled by two causal Transformers, we can anticipate vehicle failures and malfunctions before they happen. Thus, we introduce $\\textit{CarFormer}$, a Transformer model trained via a new self-supervised learning strategy, and $\\textit{EPredictor}$, an autoregressive Transformer decoder model capable of predicting $\\textit{when}$ and $\\textit{what}$ error pattern will most likely occur after some error code apparition. Despite the challenges of high cardinality of event types, their unbalanced frequency of appearance and limited labelled data, our experimental results demonstrate the excellent predictive ability of our novel model. Specifically, with sequences of $160$ error codes on average, our model is able with only half of the error codes to achieve $80\\%$ F1 score for predicting $\\textit{what}$ error pattern will occur and achieves an average absolute error of $58.4 \\pm 13.2$h $\\textit{when}$ forecasting the time of occurrence, thus enabling confident predictive maintenance and enhancing vehicle safety.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "154",
        "title": "Modality-Inconsistent Continual Learning of Multimodal Large Language Models",
        "author": [
            "Weiguo Pian",
            "Shijian Deng",
            "Shentong Mo",
            "Yunhui Guo",
            "Yapeng Tian"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13050",
        "abstract": "In this paper, we introduce Modality-Inconsistent Continual Learning (MICL), a new continual learning scenario for Multimodal Large Language Models (MLLMs) that involves tasks with inconsistent modalities (image, audio, or video) and varying task types (captioning or question-answering). Unlike existing vision-only or modality-incremental settings, MICL combines modality and task type shifts, both of which drive catastrophic forgetting. To address these challenges, we propose MoInCL, which employs a Pseudo Targets Generation Module to mitigate forgetting caused by task type shifts in previously seen modalities. It also incorporates Instruction-based Knowledge Distillation to preserve the model's ability to handle previously learned modalities when new ones are introduced. We benchmark MICL using a total of six tasks and conduct experiments to validate the effectiveness of our proposed MoInCL. The experimental results highlight the superiority of MoInCL, showing significant improvements over representative and state-of-the-art continual learning baselines.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "155",
        "title": "VidTok: A Versatile and Open-Source Video Tokenizer",
        "author": [
            "Anni Tang",
            "Tianyu He",
            "Junliang Guo",
            "Xinle Cheng",
            "Li Song",
            "Jiang Bian"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13061",
        "abstract": "Encoding video content into compact latent tokens has become a fundamental step in video generation and understanding, driven by the need to address the inherent redundancy in pixel-level representations. Consequently, there is a growing demand for high-performance, open-source video tokenizers as video-centric research gains prominence. We introduce VidTok, a versatile video tokenizer that delivers state-of-the-art performance in both continuous and discrete tokenizations. VidTok incorporates several key advancements over existing approaches: 1) model architecture such as convolutional layers and up/downsampling modules; 2) to address the training instability and codebook collapse commonly associated with conventional Vector Quantization (VQ), we integrate Finite Scalar Quantization (FSQ) into discrete video tokenization; 3) improved training strategies, including a two-stage training process and the use of reduced frame rates. By integrating these advancements, VidTok achieves substantial improvements over existing methods, demonstrating superior performance across multiple metrics, including PSNR, SSIM, LPIPS, and FVD, under standardized evaluation settings.",
        "tags": [
            "Vector Quantization",
            "Video Generation"
        ]
    },
    {
        "id": "156",
        "title": "Prompt Augmentation for Self-supervised Text-guided Image Manipulation",
        "author": [
            "Rumeysa Bodur",
            "Binod Bhattarai",
            "Tae-Kyun Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13081",
        "abstract": "Text-guided image editing finds applications in various creative and practical fields. While recent studies in image generation have advanced the field, they often struggle with the dual challenges of coherent image transformation and context preservation. In response, our work introduces prompt augmentation, a method amplifying a single input prompt into several target prompts, strengthening textual context and enabling localised image editing. Specifically, we use the augmented prompts to delineate the intended manipulation area. We propose a Contrastive Loss tailored to driving effective image editing by displacing edited areas and drawing preserved regions closer. Acknowledging the continuous nature of image manipulations, we further refine our approach by incorporating the similarity concept, creating a Soft Contrastive Loss. The new losses are incorporated to the diffusion model, demonstrating improved or competitive image editing results on public datasets and generated images over state-of-the-art approaches.",
        "tags": [
            "Diffusion",
            "Image Editing"
        ]
    },
    {
        "id": "157",
        "title": "AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark",
        "author": [
            "Jianlyu Chen",
            "Nan Wang",
            "Chaofan Li",
            "Bo Wang",
            "Shitao Xiao",
            "Han Xiao",
            "Hao Liao",
            "Defu Lian",
            "Zheng Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13102",
        "abstract": "Evaluation plays a crucial role in the advancement of information retrieval (IR) models. However, current benchmarks, which are based on predefined domains and human-labeled data, face limitations in addressing evaluation needs for emerging domains both cost-effectively and efficiently. To address this challenge, we propose the Automated Heterogeneous Information Retrieval Benchmark (AIR-Bench). AIR-Bench is distinguished by three key features: 1) Automated. The testing data in AIR-Bench is automatically generated by large language models (LLMs) without human intervention. 2) Heterogeneous. The testing data in AIR-Bench is generated with respect to diverse tasks, domains and languages. 3) Dynamic. The domains and languages covered by AIR-Bench are constantly augmented to provide an increasingly comprehensive evaluation benchmark for community developers. We develop a reliable and robust data generation pipeline to automatically create diverse and high-quality evaluation datasets based on real-world corpora. Our findings demonstrate that the generated testing data in AIR-Bench aligns well with human-labeled testing data, making AIR-Bench a dependable benchmark for evaluating IR models. The resources in AIR-Bench are publicly available at https://github.com/AIR-Bench/AIR-Bench.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "158",
        "title": "AI PERSONA: Towards Life-long Personalization of LLMs",
        "author": [
            "Tiannan Wang",
            "Meiling Tao",
            "Ruoyu Fang",
            "Huilin Wang",
            "Shuai Wang",
            "Yuchen Eleanor Jiang",
            "Wangchunshu Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13103",
        "abstract": "In this work, we introduce the task of life-long personalization of large language models. While recent mainstream efforts in the LLM community mainly focus on scaling data and compute for improved capabilities of LLMs, we argue that it is also very important to enable LLM systems, or language agents, to continuously adapt to the diverse and ever-changing profiles of every distinct user and provide up-to-date personalized assistance. We provide a clear task formulation and introduce a simple, general, effective, and scalable framework for life-long personalization of LLM systems and language agents. To facilitate future research on LLM personalization, we also introduce methods to synthesize realistic benchmarks and robust evaluation metrics. We will release all codes and data for building and benchmarking life-long personalized LLM systems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "159",
        "title": "A finite volume scheme for the local sensing chemotaxis model",
        "author": [
            "Maxime Herda",
            "Ariane Trescases",
            "Antoine Zurek"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13143",
        "abstract": "In this paper we design, analyze and simulate a finite volume scheme for a cross-diffusion system which models chemotaxis with local sensing. This system has the same gradient flow structure as the celebrated minimal Keller-Segel system, but unlike the latter, its solutions are known to exist globally in 2D. The long-time behavior of solutions is only partially understood which motivates numerical exploration with a reliable numerical method. We propose a linearly implicit, two-point flux finite volume approximation of the system. We show that the scheme preserves, at the discrete level, the main features of the continuous system, namely mass, non-negativity of solution, entropy, and duality estimates. These properties allow us to prove the well-posedness, unconditional stability and convergence of the scheme. We also show rigorously that the scheme possesses an asymptotic preserving (AP) property in the quasi-stationary limit. We complement our analysis with thorough numerical experiments investigating convergence and AP properties of the scheme as well as its reliability with respect to stability properties of steady solutions.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "160",
        "title": "Are Your LLMs Capable of Stable Reasoning?",
        "author": [
            "Junnan Liu",
            "Hongwei Liu",
            "Linchen Xiao",
            "Ziyi Wang",
            "Kuikun Liu",
            "Songyang Gao",
            "Wenwei Zhang",
            "Songyang Zhang",
            "Kai Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13147",
        "abstract": "The rapid advancement of Large Language Models (LLMs) has demonstrated remarkable progress in complex reasoning tasks. However, a significant discrepancy persists between benchmark performances and real-world applications. We identify this gap as primarily stemming from current evaluation protocols and metrics, which inadequately capture the full spectrum of LLM capabilities, particularly in complex reasoning tasks where both accuracy and consistency are crucial. This work makes two key contributions. First, we introduce G-Pass@k, a novel evaluation metric that provides a continuous assessment of model performance across multiple sampling attempts, quantifying both the model's peak performance potential and its stability. Second, we present LiveMathBench, a dynamic benchmark comprising challenging, contemporary mathematical problems designed to minimize data leakage risks during evaluation. Through extensive experiments using G-Pass@k on state-of-the-art LLMs with LiveMathBench, we provide comprehensive insights into both their maximum capabilities and operational consistency. Our findings reveal substantial room for improvement in LLMs' \"realistic\" reasoning capabilities, highlighting the need for more robust evaluation methods. The benchmark and detailed results are available at: https://github.com/open-compass/GPassK.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "161",
        "title": "SWAN: Preprocessing SGD Enables Adam-Level Performance On LLM Training With Significant Memory Reduction",
        "author": [
            "Chao Ma",
            "Wenbo Gong",
            "Meyer Scetbon",
            "Edward Meeds"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13148",
        "abstract": "Adaptive optimizers such as Adam (Kingma & Ba, 2015) have been central to the success of large language models. However, they maintain additional moving average states throughout training, which results in memory requirements several times greater than the model. This overhead imposes constraints on scalability and computational efficiency. On the other hand, while stochastic gradient descent (SGD) is optimal in terms of memory efficiency, their capability in LLM training is limited (Zhao et al., 2024b).\nTo address this dilemma, we show that pre-processing SGD is sufficient to reach Adam-level performance on LLMs. Specifically, we propose to preprocess the instantaneous stochastic gradients with two simple operators: $\\mathtt{GradNorm}$ and $\\mathtt{GradWhitening}$. $\\mathtt{GradNorm}$ stabilizes gradient distributions, and $\\mathtt{GradWhitening}$ counteracts the local curvature of the loss landscape, respectively. This results in SWAN (SGD with Whitening And Normalization), a stochastic optimizer that eliminates the need to store any accumulative state variables. Empirically, SWAN has the same memory footprint as SGD, achieving $\\approx 50\\%$ reduction on total end-to-end memory compared to Adam. In language modeling tasks, SWAN demonstrates the same or even a substantial improvement over Adam. Specifically, when pre-training the LLaMa model with 350M and 1.3B parameters, SWAN achieves a 2x speedup by reaching the same evaluation perplexity in less than half tokens seen.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "162",
        "title": "C-FedRAG: A Confidential Federated Retrieval-Augmented Generation System",
        "author": [
            "Parker Addison",
            "Minh-Tuan H. Nguyen",
            "Tomislav Medan",
            "Mohammad T. Manzari",
            "Brendan McElrone",
            "Laksh Lalwani",
            "Aboli More",
            "Smita Sharma",
            "Holger R. Roth",
            "Isaac Yang",
            "Chester Chen",
            "Daguang Xu",
            "Yan Cheng",
            "Andrew Feng",
            "Ziyue Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13163",
        "abstract": "Organizations seeking to utilize Large Language Models (LLMs) for knowledge querying and analysis often encounter challenges in maintaining an LLM fine-tuned on targeted, up-to-date information that keeps answers relevant and grounded. Retrieval Augmented Generation (RAG) has quickly become a feasible solution for organizations looking to overcome the challenges of maintaining proprietary models and to help reduce LLM hallucinations in their query responses. However, RAG comes with its own issues regarding scaling data pipelines across tiered-access and disparate data sources. In many scenarios, it is necessary to query beyond a single data silo to provide richer and more relevant context for an LLM. Analyzing data sources within and across organizational trust boundaries is often limited by complex data-sharing policies that prohibit centralized data storage, therefore, inhibit the fast and effective setup and scaling of RAG solutions. In this paper, we introduce Confidential Computing (CC) techniques as a solution for secure Federated Retrieval Augmented Generation (FedRAG). Our proposed Confidential FedRAG system (C-FedRAG) enables secure connection and scaling of a RAG workflows across a decentralized network of data providers by ensuring context confidentiality. We also demonstrate how to implement a C-FedRAG system using the NVIDIA FLARE SDK and assess its performance using the MedRAG toolkit and MIRAGE benchmarking dataset.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "163",
        "title": "Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study",
        "author": [
            "Bolei Ma",
            "Berk Yoztyurk",
            "Anna-Carolina Haensch",
            "Xinpeng Wang",
            "Markus Herklotz",
            "Frauke Kreuter",
            "Barbara Plank",
            "Matthias Assenmacher"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13169",
        "abstract": "In recent research, large language models (LLMs) have been increasingly used to investigate public opinions. This study investigates the algorithmic fidelity of LLMs, i.e., the ability to replicate the socio-cultural context and nuanced opinions of human participants. Using open-ended survey data from the German Longitudinal Election Studies (GLES), we prompt different LLMs to generate synthetic public opinions reflective of German subpopulations by incorporating demographic features into the persona prompts. Our results show that Llama performs better than other LLMs at representing subpopulations, particularly when there is lower opinion diversity within those groups. Our findings further reveal that the LLM performs better for supporters of left-leaning parties like The Greens and The Left compared to other parties, and matches the least with the right-party AfD. Additionally, the inclusion or exclusion of specific variables in the prompts can significantly impact the models' predictions. These findings underscore the importance of aligning LLMs to more effectively model diverse public opinions while minimizing political biases and enhancing robustness in representativeness.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "164",
        "title": "Locate n' Rotate: Two-stage Openable Part Detection with Foundation Model Priors",
        "author": [
            "Siqi Li",
            "Xiaoxue Chen",
            "Haoyu Cheng",
            "Guyue Zhou",
            "Hao Zhao",
            "Guanzhong Tian"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13173",
        "abstract": "Detecting the openable parts of articulated objects is crucial for downstream applications in intelligent robotics, such as pulling a drawer. This task poses a multitasking challenge due to the necessity of understanding object categories and motion. Most existing methods are either category-specific or trained on specific datasets, lacking generalization to unseen environments and objects. In this paper, we propose a Transformer-based Openable Part Detection (OPD) framework named Multi-feature Openable Part Detection (MOPD) that incorporates perceptual grouping and geometric priors, outperforming previous methods in performance. In the first stage of the framework, we introduce a perceptual grouping feature model that provides perceptual grouping feature priors for openable part detection, enhancing detection results through a cross-attention mechanism. In the second stage, a geometric understanding feature model offers geometric feature priors for predicting motion parameters. Compared to existing methods, our proposed approach shows better performance in both detection and motion parameter prediction. Codes and models are publicly available at https://github.com/lisiqi-zju/MOPD",
        "tags": [
            "Detection",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "165",
        "title": "ORFormer: Occlusion-Robust Transformer for Accurate Facial Landmark Detection",
        "author": [
            "Jui-Che Chiang",
            "Hou-Ning Hu",
            "Bo-Syuan Hou",
            "Chia-Yu Tseng",
            "Yu-Lun Liu",
            "Min-Hung Chen",
            "Yen-Yu Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13174",
        "abstract": "Although facial landmark detection (FLD) has gained significant progress, existing FLD methods still suffer from performance drops on partially non-visible faces, such as faces with occlusions or under extreme lighting conditions or poses. To address this issue, we introduce ORFormer, a novel transformer-based method that can detect non-visible regions and recover their missing features from visible parts. Specifically, ORFormer associates each image patch token with one additional learnable token called the messenger token. The messenger token aggregates features from all but its patch. This way, the consensus between a patch and other patches can be assessed by referring to the similarity between its regular and messenger embeddings, enabling non-visible region identification. Our method then recovers occluded patches with features aggregated by the messenger tokens. Leveraging the recovered features, ORFormer compiles high-quality heatmaps for the downstream FLD task. Extensive experiments show that our method generates heatmaps resilient to partial occlusions. By integrating the resultant heatmaps into existing FLD methods, our method performs favorably against the state of the arts on challenging datasets such as WFLW and COFW.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "166",
        "title": "NFL-BA: Improving Endoscopic SLAM with Near-Field Light Bundle Adjustment",
        "author": [
            "Andrea Dunn Beltran",
            "Daniel Rho",
            "Marc Niethammer",
            "Roni Sengupta"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13176",
        "abstract": "Simultaneous Localization And Mapping (SLAM) from a monocular endoscopy video can enable autonomous navigation, guidance to unsurveyed regions, and 3D visualizations, which can significantly improve endoscopy experience for surgeons and patient outcomes. Existing dense SLAM algorithms often assume distant and static lighting and textured surfaces, and alternate between optimizing scene geometry and camera parameters by minimizing a photometric rendering loss, often called Photometric Bundle Adjustment. However, endoscopic environments exhibit dynamic near-field lighting due to the co-located light and camera moving extremely close to the surface, textureless surfaces, and strong specular reflections due to mucus layers. When not considered, these near-field lighting effects can cause significant performance reductions for existing SLAM algorithms from indoor/outdoor scenes when applied to endoscopy videos. To mitigate this problem, we introduce a new Near-Field Lighting Bundle Adjustment Loss $(L_{NFL-BA})$ that can also be alternatingly optimized, along with the Photometric Bundle Adjustment loss, such that the captured images' intensity variations match the relative distance and orientation between the surface and the co-located light and camera. We derive a general NFL-BA loss function for 3D Gaussian surface representations and demonstrate that adding $L_{NFL-BA}$ can significantly improve the tracking and mapping performance of two state-of-the-art 3DGS-SLAM systems, MonoGS (35% improvement in tracking, 48% improvement in mapping with predicted depth maps) and EndoGSLAM (22% improvement in tracking, marginal improvement in mapping with predicted depths), on the C3VD endoscopy dataset for colons. The project page is available at https://asdunnbe.github.io/NFL-BA/",
        "tags": [
            "3D",
            "SLAM"
        ]
    },
    {
        "id": "167",
        "title": "SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents",
        "author": [
            "Sheng Yin",
            "Xianghe Pang",
            "Yuanzhuo Ding",
            "Menglan Chen",
            "Yutong Bi",
            "Yichen Xiong",
            "Wenhao Huang",
            "Zhen Xiang",
            "Jing Shao",
            "Siheng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13178",
        "abstract": "With the integration of large language models (LLMs), embodied agents have strong capabilities to execute complicated instructions in natural language, paving a way for the potential deployment of embodied robots. However, a foreseeable issue is that those embodied agents can also flawlessly execute some hazardous tasks, potentially causing damages in real world. To study this issue, we present SafeAgentBench -- a new benchmark for safety-aware task planning of embodied LLM agents. SafeAgentBench includes: (1) a new dataset with 750 tasks, covering 10 potential hazards and 3 task types; (2) SafeAgentEnv, a universal embodied environment with a low-level controller, supporting multi-agent execution with 17 high-level actions for 8 state-of-the-art baselines; and (3) reliable evaluation methods from both execution and semantic perspectives. Experimental results show that the best-performing baseline gets 69% success rate for safe tasks, but only 5% rejection rate for hazardous tasks, indicating significant safety risks. More details and codes are available at https://github.com/shengyin1224/SafeAgentBench.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "168",
        "title": "Move-in-2D: 2D-Conditioned Human Motion Generation",
        "author": [
            "Hsin-Ping Huang",
            "Yang Zhou",
            "Jui-Hsien Wang",
            "Difan Liu",
            "Feng Liu",
            "Ming-Hsuan Yang",
            "Zhan Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13185",
        "abstract": "Generating realistic human videos remains a challenging task, with the most effective methods currently relying on a human motion sequence as a control signal. Existing approaches often use existing motion extracted from other videos, which restricts applications to specific motion types and global scene matching. We propose Move-in-2D, a novel approach to generate human motion sequences conditioned on a scene image, allowing for diverse motion that adapts to different scenes. Our approach utilizes a diffusion model that accepts both a scene image and text prompt as inputs, producing a motion sequence tailored to the scene. To train this model, we collect a large-scale video dataset featuring single-human activities, annotating each video with the corresponding human motion as the target output. Experiments demonstrate that our method effectively predicts human motion that aligns with the scene image after projection. Furthermore, we show that the generated motion sequence improves human motion quality in video synthesis tasks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "169",
        "title": "StreetCrafter: Street View Synthesis with Controllable Video Diffusion Models",
        "author": [
            "Yunzhi Yan",
            "Zhen Xu",
            "Haotong Lin",
            "Haian Jin",
            "Haoyu Guo",
            "Yida Wang",
            "Kun Zhan",
            "Xianpeng Lang",
            "Hujun Bao",
            "Xiaowei Zhou",
            "Sida Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13188",
        "abstract": "This paper aims to tackle the problem of photorealistic view synthesis from vehicle sensor data. Recent advancements in neural scene representation have achieved notable success in rendering high-quality autonomous driving scenes, but the performance significantly degrades as the viewpoint deviates from the training trajectory. To mitigate this problem, we introduce StreetCrafter, a novel controllable video diffusion model that utilizes LiDAR point cloud renderings as pixel-level conditions, which fully exploits the generative prior for novel view synthesis, while preserving precise camera control. Moreover, the utilization of pixel-level LiDAR conditions allows us to make accurate pixel-level edits to target scenes. In addition, the generative prior of StreetCrafter can be effectively incorporated into dynamic scene representations to achieve real-time rendering. Experiments on Waymo Open Dataset and PandaSet demonstrate that our model enables flexible control over viewpoint changes, enlarging the view synthesis regions for satisfying rendering, which outperforms existing methods.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "170",
        "title": "MotionBridge: Dynamic Video Inbetweening with Flexible Controls",
        "author": [
            "Maham Tanveer",
            "Yang Zhou",
            "Simon Niklaus",
            "Ali Mahdavi Amiri",
            "Hao Zhang",
            "Krishna Kumar Singh",
            "Nanxuan Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13190",
        "abstract": "By generating plausible and smooth transitions between two image frames, video inbetweening is an essential tool for video editing and long video synthesis. Traditional works lack the capability to generate complex large motions. While recent video generation techniques are powerful in creating high-quality results, they often lack fine control over the details of intermediate frames, which can lead to results that do not align with the creative mind. We introduce MotionBridge, a unified video inbetweening framework that allows flexible controls, including trajectory strokes, keyframes, masks, guide pixels, and text. However, learning such multi-modal controls in a unified framework is a challenging task. We thus design two generators to extract the control signal faithfully and encode feature through dual-branch embedders to resolve ambiguities. We further introduce a curriculum training strategy to smoothly learn various controls. Extensive qualitative and quantitative experiments have demonstrated that such multi-modal controls enable a more dynamic, customizable, and contextually accurate visual narrative.",
        "tags": [
            "Video Editing",
            "Video Generation"
        ]
    },
    {
        "id": "171",
        "title": "GaussTR: Foundation Model-Aligned Gaussian Transformer for Self-Supervised 3D Spatial Understanding",
        "author": [
            "Haoyi Jiang",
            "Liu Liu",
            "Tianheng Cheng",
            "Xinjie Wang",
            "Tianwei Lin",
            "Zhizhong Su",
            "Wenyu Liu",
            "Xinggang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13193",
        "abstract": "3D Semantic Occupancy Prediction is fundamental for spatial understanding as it provides a comprehensive semantic cognition of surrounding environments. However, prevalent approaches primarily rely on extensive labeled data and computationally intensive voxel-based modeling, restricting the scalability and generalizability of 3D representation learning. In this paper, we introduce GaussTR, a novel Gaussian Transformer that leverages alignment with foundation models to advance self-supervised 3D spatial understanding. GaussTR adopts a Transformer architecture to predict sparse sets of 3D Gaussians that represent scenes in a feed-forward manner. Through aligning rendered Gaussian features with diverse knowledge from pre-trained foundation models, GaussTR facilitates the learning of versatile 3D representations and enables open-vocabulary occupancy prediction without explicit annotations. Empirical evaluations on the Occ3D-nuScenes dataset showcase GaussTR's state-of-the-art zero-shot performance, achieving 11.70 mIoU while reducing training duration by approximately 50%. These experimental results highlight the significant potential of GaussTR for scalable and holistic 3D spatial understanding, with promising implications for autonomous driving and embodied agents. Code is available at https://github.com/hustvl/GaussTR.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "172",
        "title": "CoMPaSS: Enhancing Spatial Understanding in Text-to-Image Diffusion Models",
        "author": [
            "Gaoyang Zhang",
            "Bingtao Fu",
            "Qingnan Fan",
            "Qi Zhang",
            "Runxing Liu",
            "Hong Gu",
            "Huaqi Zhang",
            "Xinguo Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13195",
        "abstract": "Text-to-image diffusion models excel at generating photorealistic images, but commonly struggle to render accurate spatial relationships described in text prompts. We identify two core issues underlying this common failure: 1) the ambiguous nature of spatial-related data in existing datasets, and 2) the inability of current text encoders to accurately interpret the spatial semantics of input descriptions. We address these issues with CoMPaSS, a versatile training framework that enhances spatial understanding of any T2I diffusion model. CoMPaSS solves the ambiguity of spatial-related data with the Spatial Constraints-Oriented Pairing (SCOP) data engine, which curates spatially-accurate training data through a set of principled spatial constraints. To better exploit the curated high-quality spatial priors, CoMPaSS further introduces a Token ENcoding ORdering (TENOR) module to allow better exploitation of high-quality spatial priors, effectively compensating for the shortcoming of text encoders. Extensive experiments on four popular open-weight T2I diffusion models covering both UNet- and MMDiT-based architectures demonstrate the effectiveness of CoMPaSS by setting new state-of-the-arts with substantial relative gains across well-known benchmarks on spatial relationships generation, including VISOR (+98%), T2I-CompBench Spatial (+67%), and GenEval Position (+131%). Code will be available at https://github.com/blurgyy/CoMPaSS.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "173",
        "title": "Generative Modeling of Neural Dynamics via Latent Stochastic Differential Equations",
        "author": [
            "Ahmed ElGazzar",
            "Marcel van Gerven"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12112",
        "abstract": "We propose a probabilistic framework for developing computational models of biological neural systems. In this framework, physiological recordings are viewed as discrete-time partial observations of an underlying continuous-time stochastic dynamical system which implements computations through its state evolution. To model this dynamical system, we employ a system of coupled stochastic differential equations with differentiable drift and diffusion functions and use variational inference to infer its states and parameters. This formulation enables seamless integration of existing mathematical models in the literature, neural networks, or a hybrid of both to learn and compare different models. We demonstrate this in our framework by developing a generative model that combines coupled oscillators with neural networks to capture latent population dynamics from single-cell recordings. Evaluation across three neuroscience datasets spanning different species, brain regions, and behavioral tasks show that these hybrid models achieve competitive performance in predicting stimulus-evoked neural and behavioral responses compared to sophisticated black-box approaches while requiring an order of magnitude fewer parameters, providing uncertainty estimates, and offering a natural language for interpretation.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "174",
        "title": "How to Choose a Threshold for an Evaluation Metric for Large Language Models",
        "author": [
            "Bhaskarjit Sarmah",
            "Mingshu Li",
            "Jingrao Lyu",
            "Sebastian Frank",
            "Nathalia Castellanos",
            "Stefano Pasquali",
            "Dhagash Mehta"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12148",
        "abstract": "To ensure and monitor large language models (LLMs) reliably, various evaluation metrics have been proposed in the literature. However, there is little research on prescribing a methodology to identify a robust threshold on these metrics even though there are many serious implications of an incorrect choice of the thresholds during deployment of the LLMs. Translating the traditional model risk management (MRM) guidelines within regulated industries such as the financial industry, we propose a step-by-step recipe for picking a threshold for a given LLM evaluation metric. We emphasize that such a methodology should start with identifying the risks of the LLM application under consideration and risk tolerance of the stakeholders. We then propose concrete and statistically rigorous procedures to determine a threshold for the given LLM evaluation metric using available ground-truth data. As a concrete example to demonstrate the proposed methodology at work, we employ it on the Faithfulness metric, as implemented in various publicly available libraries, using the publicly available HaluBench dataset. We also lay a foundation for creating systematic approaches to select thresholds, not only for LLMs but for any GenAI applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "175",
        "title": "Diffusion backbone of temporal higher-order networks",
        "author": [
            "Shilun Zhang",
            "Alberto Ceria",
            "Huijuan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12856",
        "abstract": "Temporal higher-order networks, where each hyperlink involving a group of nodes are activated or deactivated over time, are recently used to represent complex systems such as social contacts, interactions or collaborations that occur at specific times. Such networks are substrates for social contagion processes like the diffusion of information and opinions. In this work, we consider eight temporal higher-order networks derived from human face-to-face interactions in various contexts and the Susceptible-Infected threshold process on each of these networks: whenever a hyperlink is active and the number of infected nodes in the hyperlink exceeds a threshold $\\Theta$, each susceptible node in the hyperlink is infected independently with probability $\\beta$. The objective is to understand (1) the contribution of each hyperlink to the diffusion process, namely, the average number of nodes that are infected directly via the activation of the hyperlink when the diffusion starts from an arbitrary seed node, and (2) hyperlinks with what network properties tend to contribute more. We first propose to construct the diffusion backbone. The backbone is a weighted higher-order network, where the weight of each hyperlink denotes the contribution of the hyperlink to a given diffusion process. Secondly, we find that the backbone, or the contribution of hyperlinks, is dependent on the parameters $\\beta$ and $\\Theta$ of the diffusion process, which is also supported by our theoretical analysis of the backbone when $\\beta\\rightarrow 0$. Thirdly, we systematically design centrality metrics for hyperlinks in a temporal higher-order network, and each centrality metric is used to estimate the ranking of hyperlinks by the weight in the backbone. Finally, we find and explain why different centrality metrics can better estimate the contributions of hyperlinks for different parameters of the diffusion process.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "176",
        "title": "Stable Diffusion is a Natural Cross-Modal Decoder for Layered AI-generated Image Compression",
        "author": [
            "Ruijie Chen",
            "Qi Mao",
            "Zhengxue Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2412.12982",
        "abstract": "Recent advances in Artificial Intelligence Generated Content (AIGC) have garnered significant interest, accompanied by an increasing need to transmit and compress the vast number of AI-generated images (AIGIs). However, there is a noticeable deficiency in research focused on compression methods for AIGIs. To address this critical gap, we introduce a scalable cross-modal compression framework that incorporates multiple human-comprehensible modalities, designed to efficiently capture and relay essential visual information for AIGIs. In particular, our framework encodes images into a layered bitstream consisting of a semantic layer that delivers high-level semantic information through text prompts; a structural layer that captures spatial details using edge or skeleton maps; and a texture layer that preserves local textures via a colormap. Utilizing Stable Diffusion as the backend, the framework effectively leverages these multimodal priors for image generation, effectively functioning as a decoder when these priors are encoded. Qualitative and quantitative results show that our method proficiently restores both semantic and visual details, competing against baseline approaches at extremely low bitrates ( <0.02 bpp). Additionally, our framework facilitates downstream editing applications without requiring full decoding, thereby paving a new direction for future research in AIGI compression.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "177",
        "title": "Identification of Epileptic Spasms (ESES) Phases Using EEG Signals: A Vision Transformer Approach",
        "author": [
            "Wei Gong",
            "Yaru Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13028",
        "abstract": "This work introduces a new approach to the Epileptic Spasms (ESES) detection based on the EEG signals using Vision Transformers (ViT). Classic ESES detection approaches have usually been performed with manual processing or conventional algorithms, suffering from poor sample sizes, single-channel-based analyses, and low generalization abilities. In contrast, the proposed ViT model overcomes these limitations by using the attention mechanism to focus on the important features in multi-channel EEG data, which is contributing to both better accuracy and efficiency. The model processes frequency-domain representations of EEG signals, such as spectrograms, as image data to capture long-range dependencies and complex patterns in the signal. The model demonstrates high performance with an accuracy of 97% without requiring intensive data preprocessing, thus rendering it suitable for real-time clinical applications on a large scale. The method represents a significant development in the advancement of neurological disorders such as ESES in detection and analysis.",
        "tags": [
            "Detection",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "178",
        "title": "Equity in the Use of ChatGPT for the Classroom: A Comparison of the Accuracy and Precision of ChatGPT 3.5 vs. ChatGPT4 with Respect to Statistics and Data Science Exams",
        "author": [
            "Monnie McGee",
            "Bivin Sadler"
        ],
        "pdf": "https://arxiv.org/pdf/2412.13116",
        "abstract": "A college education historically has been seen as method of moving upward with regards to income brackets and social status. Indeed, many colleges recognize this connection and seek to enroll talented low income students. While these students might have their education, books, room, and board paid; there are other items that they might be expected to use that are not part of most college scholarship packages. One of those items that has recently surfaced is access to generative AI platforms. The most popular of these platforms is ChatGPT, and it has a paid version (ChatGPT4) and a free version (ChatGPT3.5). We seek to explore differences in the free and paid versions in the context of homework questions and data analyses as might be seen in a typical introductory statistics course. We determine the extent to which students who cannot afford newer and faster versions of generative AI programs would be disadvantaged in terms of writing such projects and learning these methods.",
        "tags": [
            "ChatGPT"
        ]
    }
]