[
    {
        "id": "1",
        "title": "How Large Language Models (LLMs) Extrapolate: From Guided Missiles to Guided Prompts",
        "author": [
            "Xuenan Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10361",
        "abstract": "This paper argues that we should perceive LLMs as machines of extrapolation. Extrapolation is a statistical function for predicting the next value in a series. Extrapolation contributes to both GPT successes and controversies surrounding its hallucination. The term hallucination implies a malfunction, yet this paper contends that it in fact indicates the chatbot efficiency in extrapolation, albeit an excess of it. This article bears a historical dimension: it traces extrapolation to the nascent years of cybernetics. In 1941, when Norbert Wiener transitioned from missile science to communication engineering, the pivotal concept he adopted was none other than extrapolation. Soviet mathematician Andrey Kolmogorov, renowned for his compression logic that inspired OpenAI, had developed in 1939 another extrapolation project that Wiener later found rather like his own. This paper uncovers the connections between hot war science, Cold War cybernetics, and the contemporary debates on LLM performances.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "2",
        "title": "Can LLMs Identify Gaps and Misconceptions in Students' Code Explanations?",
        "author": [
            "Priti Oli",
            "Rabin Banjade",
            "Andrew M. Olney",
            "Vasile Rus"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10365",
        "abstract": "This paper investigates various approaches using Large Language Models (LLMs) to identify gaps and misconceptions in students' self-explanations of specific instructional material, in our case explanations of code examples. This research is a part of our larger effort to automate the assessment of students' freely generated responses, focusing specifically on their self-explanations of code examples during activities related to code comprehension. In this work, we experiment with zero-shot prompting, Supervised Fine-Tuning (SFT), and preference alignment of LLMs to identify gaps in students' self-explanation. With simple prompting, GPT-4 consistently outperformed LLaMA3 and Mistral in identifying gaps and misconceptions, as confirmed by human evaluations. Additionally, our results suggest that fine-tuned large language models are more effective at identifying gaps in students' explanations compared to zero-shot and few-shot prompting techniques. Furthermore, our findings show that the preference optimization approach using Odds Ratio Preference Optimization (ORPO) outperforms SFT in identifying gaps and misconceptions in students' code explanations.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "3",
        "title": "The Generative AI Ethics Playbook",
        "author": [
            "Jessie J. Smith",
            "Wesley Hanwen Deng",
            "William H. Smith",
            "Maarten Sap",
            "Nicole DeCario",
            "Jesse Dodge"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10383",
        "abstract": "The Generative AI Ethics Playbook provides guidance for identifying and mitigating risks of machine learning systems across various domains, including natural language processing, computer vision, and generative AI. This playbook aims to assist practitioners in diagnosing potential harms that may arise during the design, development, and deployment of datasets and models. It offers concrete strategies and resources for mitigating these risks, to help minimize negative impacts on users and society. Drawing on current best practices in both research and ethical considerations, this playbook aims to serve as a comprehensive resource for AI/ML practitioners. The intended audience of this playbook includes machine learning researchers, engineers, and practitioners who are involved in the creation and implementation of generative and multimodal models (e.g., text-to-text, image-to-image, text-to-image, text-to-video).\nSpecifically, we provide transparency/documentation checklists, topics of interest, common questions, examples of harms through case studies, and resources and strategies to mitigate harms throughout the Generative AI lifecycle. This playbook was made collaboratively over the course of 16 months through extensive literature review of over 100 resources and peer-reviewed articles, as well as through an initial group brainstorming session with 18 interdisciplinary AI ethics experts from industry and academia, and with additional feedback from 8 experts (5 of whom were in the initial brainstorming session).\nWe note that while this playbook provides examples, discussion, and harm mitigation strategies, research in this area is ongoing. Our playbook aims to be a practically useful survey, taking a high-level view rather than aiming for covering the entire existing body of research.",
        "tags": [
            "Text-to-Image",
            "Text-to-Video"
        ]
    },
    {
        "id": "4",
        "title": "Autonomous Microscopy Experiments through Large Language Model Agents",
        "author": [
            "Indrajeet Mandal",
            "Jitendra Soni",
            "Mohd Zaki",
            "Morten M. Smedskjaer",
            "Katrin Wondraczek",
            "Lothar Wondraczek",
            "Nitya Nand Gosvami",
            "N. M. Anoop Krishnan"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10385",
        "abstract": "The emergence of large language models (LLMs) has accelerated the development of self-driving laboratories (SDLs) for materials research. Despite their transformative potential, current SDL implementations rely on rigid, predefined protocols that limit their adaptability to dynamic experimental scenarios across different labs. A significant challenge persists in measuring how effectively AI agents can replicate the adaptive decision-making and experimental intuition of expert scientists. Here, we introduce AILA (Artificially Intelligent Lab Assistant), a framework that automates atomic force microscopy (AFM) through LLM-driven agents. Using AFM as an experimental testbed, we develop AFMBench-a comprehensive evaluation suite that challenges AI agents based on language models like GPT-4o and GPT-3.5 to perform tasks spanning the scientific workflow: from experimental design to results analysis. Our systematic assessment shows that state-of-the-art language models struggle even with basic tasks such as documentation retrieval, leading to a significant decline in performance in multi-agent coordination scenarios. Further, we observe that LLMs exhibit a tendency to not adhere to instructions or even divagate to additional tasks beyond the original request, raising serious concerns regarding safety alignment aspects of AI agents for SDLs. Finally, we demonstrate the application of AILA on increasingly complex experiments open-ended experiments: automated AFM calibration, high-resolution feature detection, and mechanical property measurement. Our findings emphasize the necessity for stringent benchmarking protocols before deploying AI agents as laboratory assistants across scientific disciplines.",
        "tags": [
            "Detection",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "5",
        "title": "Beyond the Sum: Unlocking AI Agents Potential Through Market Forces",
        "author": [
            "Jordi Montes Sanabria",
            "Pol Alvarez Vecino"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10388",
        "abstract": "The emergence of Large Language Models has fundamentally transformed the capabilities of AI agents, enabling a new class of autonomous agents capable of interacting with their environment through dynamic code generation and execution. These agents possess the theoretical capacity to operate as independent economic actors within digital markets, offering unprecedented potential for value creation through their distinct advantages in operational continuity, perfect replication, and distributed learning capabilities. However, contemporary digital infrastructure, architected primarily for human interaction, presents significant barriers to their participation.\nThis work presents a systematic analysis of the infrastructure requirements necessary for AI agents to function as autonomous participants in digital markets. We examine four key areas - identity and authorization, service discovery, interfaces, and payment systems - to show how existing infrastructure actively impedes agent participation. We argue that addressing these infrastructure challenges represents more than a technical imperative; it constitutes a fundamental step toward enabling new forms of economic organization. Much as traditional markets enable human intelligence to coordinate complex activities beyond individual capability, markets incorporating AI agents could dramatically enhance economic efficiency through continuous operation, perfect information sharing, and rapid adaptation to changing conditions. The infrastructure challenges identified in this work represent key barriers to realizing this potential.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "6",
        "title": "Transparency, Security, and Workplace Training & Awareness in the Age of Generative AI",
        "author": [
            "Lakshika Vaishnav",
            "Sakshi Singh",
            "Kimberly A. Cornell"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10389",
        "abstract": "This paper investigates the impacts of the rapidly evolving landscape of generative Artificial Intelligence (AI) development. Emphasis is given to how organizations grapple with a critical imperative: reevaluating their policies regarding AI usage in the workplace. As AI technologies advance, ethical considerations, transparency, data privacy, and their impact on human labor intersect with the drive for innovation and efficiency. Our research explores publicly accessible large language models (LLMs) that often operate on the periphery, away from mainstream scrutiny. These lesser-known models have received limited scholarly analysis and may lack comprehensive restrictions and safeguards. Specifically, we examine Gab AI, a platform that centers around unrestricted communication and privacy, allowing users to interact freely without censorship. Generative AI chatbots are increasingly prevalent, but cybersecurity risks have also escalated. Organizations must carefully navigate this evolving landscape by implementing transparent AI usage policies. Frequent training and policy updates are essential to adapt to emerging threats. Insider threats, whether malicious or unwitting, continue to pose one of the most significant cybersecurity challenges in the workplace. Our research is on the lesser-known publicly accessible LLMs and their implications for workplace policies. We contribute to the ongoing discourse on AI ethics, transparency, and security by emphasizing the need for well-thought-out guidelines and vigilance in policy maintenance.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "7",
        "title": "CodEv: An Automated Grading Framework Leveraging Large Language Models for Consistent and Constructive Feedback",
        "author": [
            "En-Qi Tseng",
            "Pei-Cing Huang",
            "Chan Hsu",
            "Peng-Yi Wu",
            "Chan-Tung Ku",
            "Yihuang Kang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10421",
        "abstract": "Grading programming assignments is crucial for guiding students to improve their programming skills and coding styles. This study presents an automated grading framework, CodEv, which leverages Large Language Models (LLMs) to provide consistent and constructive feedback. We incorporate Chain of Thought (CoT) prompting techniques to enhance the reasoning capabilities of LLMs and ensure that the grading is aligned with human evaluation. Our framework also integrates LLM ensembles to improve the accuracy and consistency of scores, along with agreement tests to deliver reliable feedback and code review comments. The results demonstrate that the framework can yield grading results comparable to human evaluators, by using smaller LLMs. Evaluation and consistency tests of the LLMs further validate our approach, confirming the reliability of the generated scores and feedback.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "8",
        "title": "Robust Hybrid Classical-Quantum Transfer Learning Model for Text Classification Using GPT-Neo 125M with LoRA & SMOTE Enhancement",
        "author": [
            "Santanam Wishal"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10435",
        "abstract": "This research introduces a hybrid classical-quantum framework for text classification, integrating GPT-Neo 125M with Low-Rank Adaptation (LoRA) and Synthetic Minority Over-sampling Technique (SMOTE) using quantum computing backends. While the GPT-Neo 125M baseline remains the best-performing model, the implementation of LoRA and SMOTE enhances the hybrid model, resulting in improved accuracy, faster convergence, and better generalization. Experiments on IBM's 127-qubit quantum backend and Pennylane's 32-qubit simulation demonstrate the viability of combining classical neural networks with quantum circuits. This framework underscores the potential of hybrid architectures for advancing natural language processing applications.",
        "tags": [
            "GPT",
            "LoRA"
        ]
    },
    {
        "id": "9",
        "title": "Towards Lightweight Time Series Forecasting: a Patch-wise Transformer with Weak Data Enriching",
        "author": [
            "Meng Wang",
            "Jintao Yang",
            "Bin Yang",
            "Hui Li",
            "Tongxin Gong",
            "Bo Yang",
            "Jiangtao Cui"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10448",
        "abstract": "Patch-wise Transformer based time series forecasting achieves superior accuracy. However, this superiority relies heavily on intricate model design with massive parameters, rendering both training and inference expensive, thus preventing their deployments on edge devices with limited resources and low latency requirements. In addition, existing methods often work in an autoregressive manner, which take into account only historical values, but ignore valuable, easy-to-obtain context information, such as weather forecasts, date and time of day. To contend with the two limitations, we propose LiPFormer, a novel Lightweight Patch-wise Transformer with weak data enriching. First, to simplify the Transformer backbone, LiPFormer employs a novel lightweight cross-patch attention and a linear transformation-based attention to eliminate Layer Normalization and Feed Forward Network, two heavy components in existing Transformers. Second, we propose a lightweight, weak data enriching module to provide additional, valuable weak supervision to the training. It enhances forecasting accuracy without significantly increasing model complexity as it does not involve expensive, human-labeling but using easily accessible context information. This facilitates the weak data enriching to plug-and-play on existing models. Extensive experiments on nine benchmark time series datasets demonstrate that LiPFormer outperforms state-of-the-art methods in accuracy, while significantly reducing parameter scale, training duration, and GPU memory usage. Deployment on an edge device reveals that LiPFormer takes only 1/3 inference time compared to classic Transformers. In addition, we demonstrate that the weak data enriching can integrate seamlessly into various Transformer based models to enhance their accuracy, suggesting its generality.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "10",
        "title": "Uncovering Bias in Foundation Models: Impact, Testing, Harm, and Mitigation",
        "author": [
            "Shuzhou Sun",
            "Li Liu",
            "Yongxiang Liu",
            "Zhen Liu",
            "Shuanghui Zhang",
            "Janne HeikkilÃ¤",
            "Xiang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10453",
        "abstract": "Bias in Foundation Models (FMs) - trained on vast datasets spanning societal and historical knowledge - poses significant challenges for fairness and equity across fields such as healthcare, education, and finance. These biases, rooted in the overrepresentation of stereotypes and societal inequalities in training data, exacerbate real-world discrimination, reinforce harmful stereotypes, and erode trust in AI systems. To address this, we introduce Trident Probe Testing (TriProTesting), a systematic testing method that detects explicit and implicit biases using semantically designed probes. Here we show that FMs, including CLIP, ALIGN, BridgeTower, and OWLv2, demonstrate pervasive biases across single and mixed social attributes (gender, race, age, and occupation). Notably, we uncover mixed biases when social attributes are combined, such as gender x race, gender x age, and gender x occupation, revealing deeper layers of discrimination. We further propose Adaptive Logit Adjustment (AdaLogAdjustment), a post-processing technique that dynamically redistributes probability power to mitigate these biases effectively, achieving significant improvements in fairness without retraining models. These findings highlight the urgent need for ethical AI practices and interdisciplinary solutions to address biases not only at the model level but also in societal structures. Our work provides a scalable and interpretable solution that advances fairness in AI systems while offering practical insights for future research on fair AI technologies.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "11",
        "title": "BloomScene: Lightweight Structured 3D Gaussian Splatting for Crossmodal Scene Generation",
        "author": [
            "Xiaolu Hou",
            "Mingcheng Li",
            "Dingkang Yang",
            "Jiawei Chen",
            "Ziyun Qian",
            "Xiao Zhao",
            "Yue Jiang",
            "Jinjie Wei",
            "Qingyao Xu",
            "Lihua Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10462",
        "abstract": "With the widespread use of virtual reality applications, 3D scene generation has become a new challenging research frontier. 3D scenes have highly complex structures and need to ensure that the output is dense, coherent, and contains all necessary structures. Many current 3D scene generation methods rely on pre-trained text-to-image diffusion models and monocular depth estimators. However, the generated scenes occupy large amounts of storage space and often lack effective regularisation methods, leading to geometric distortions. To this end, we propose BloomScene, a lightweight structured 3D Gaussian splatting for crossmodal scene generation, which creates diverse and high-quality 3D scenes from text or image inputs. Specifically, a crossmodal progressive scene generation framework is proposed to generate coherent scenes utilizing incremental point cloud reconstruction and 3D Gaussian splatting. Additionally, we propose a hierarchical depth prior-based regularization mechanism that utilizes multi-level constraints on depth accuracy and smoothness to enhance the realism and continuity of the generated scenes. Ultimately, we propose a structured context-guided compression mechanism that exploits structured hash grids to model the context of unorganized anchor attributes, which significantly eliminates structural redundancy and reduces storage overhead. Comprehensive experiments across multiple scenes demonstrate the significant potential and advantages of our framework compared with several baselines.",
        "tags": [
            "3D",
            "Diffusion",
            "Gaussian Splatting",
            "Text-to-Image"
        ]
    },
    {
        "id": "12",
        "title": "Poxel: Voxel Reconstruction for 3D Printing",
        "author": [
            "Ruixiang Cao",
            "Satoshi Yagi",
            "Satoshi Yamamori",
            "Jun Morimoto"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10474",
        "abstract": "Recent advancements in 3D reconstruction, especially through neural rendering approaches like Neural Radiance Fields (NeRF) and Plenoxel, have led to high-quality 3D visualizations. However, these methods are optimized for digital environments and employ view-dependent color models (RGB) and 2D splatting techniques, which do not translate well to physical 3D printing. This paper introduces \"Poxel\", which stands for Printable-Voxel, a voxel-based 3D reconstruction framework optimized for photopolymer jetting 3D printing, which allows for high-resolution, full-color 3D models using a CMYKWCl color model. Our framework directly outputs printable voxel grids by removing view-dependency and converting the digital RGB color space to a physical CMYKWCl color space suitable for multi-material jetting. The proposed system achieves better fidelity and quality in printed models, aligning with the requirements of physical 3D objects.",
        "tags": [
            "3D",
            "NeRF"
        ]
    },
    {
        "id": "13",
        "title": "Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude",
        "author": [
            "Yile Yan",
            "Yuqi Zhu",
            "Wentao Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10484",
        "abstract": "Recent advances in Large Language Models (LLMs) have enabled human-like responses across various tasks, raising questions about their ethical decision-making capabilities and potential biases. This study investigates protected attributes in LLMs through systematic evaluation of their responses to ethical dilemmas. Using two prominent models - GPT-3.5 Turbo and Claude 3.5 Sonnet - we analyzed their decision-making patterns across multiple protected attributes including age, gender, race, appearance, and disability status. Through 11,200 experimental trials involving both single-factor and two-factor protected attribute combinations, we evaluated the models' ethical preferences, sensitivity, stability, and clustering of preferences. Our findings reveal significant protected attributeses in both models, with consistent preferences for certain features (e.g., \"good-looking\") and systematic neglect of others. Notably, while GPT-3.5 Turbo showed stronger preferences aligned with traditional power structures, Claude 3.5 Sonnet demonstrated more diverse protected attribute choices. We also found that ethical sensitivity significantly decreases in more complex scenarios involving multiple protected attributes. Additionally, linguistic referents heavily influence the models' ethical evaluations, as demonstrated by differing responses to racial descriptors (e.g., \"Yellow\" versus \"Asian\"). These findings highlight critical concerns about the potential impact of LLM biases in autonomous decision-making systems and emphasize the need for careful consideration of protected attributes in AI development. Our study contributes to the growing body of research on AI ethics by providing a systematic framework for evaluating protected attributes in LLMs' ethical decision-making capabilities.",
        "tags": [
            "ChatGPT",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "14",
        "title": "4bit-Quantization in Vector-Embedding for RAG",
        "author": [
            "Taehee Jeong"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10534",
        "abstract": "Retrieval-augmented generation (RAG) is a promising technique that has shown great potential in addressing some of the limitations of large language models (LLMs). LLMs have two major limitations: they can contain outdated information due to their training data, and they can generate factually inaccurate responses, a phenomenon known as hallucinations. RAG aims to mitigate these issues by leveraging a database of relevant documents, which are stored as embedding vectors in a high-dimensional space. However, one of the challenges of using high-dimensional embeddings is that they require a significant amount of memory to store. This can be a major issue, especially when dealing with large databases of documents. To alleviate this problem, we propose the use of 4-bit quantization to store the embedding vectors. This involves reducing the precision of the vectors from 32-bit floating-point numbers to 4-bit integers, which can significantly reduce the memory requirements. Our approach has several benefits. Firstly, it significantly reduces the memory storage requirements of the high-dimensional vector database, making it more feasible to deploy RAG systems in resource-constrained environments. Secondly, it speeds up the searching process, as the reduced precision of the vectors allows for faster computation. Our code is available at https://github.com/taeheej/4bit-Quantization-in-Vector-Embedding-for-RAG",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "15",
        "title": "Improved IR-based Bug Localization with Intelligent Relevance Feedback",
        "author": [
            "Asif Mohammed Samir",
            "Mohammad Masudur Rahman"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10542",
        "abstract": "Software bugs pose a significant challenge during development and maintenance, and practitioners spend nearly 50% of their time dealing with bugs. Many existing techniques adopt Information Retrieval (IR) to localize a reported bug using textual and semantic relevance between bug reports and source code. However, they often struggle to bridge a critical gap between bug reports and code that requires in-depth contextual understanding, which goes beyond textual or semantic relevance. In this paper, we present a novel technique for bug localization - BRaIn - that addresses the contextual gaps by assessing the relevance between bug reports and code with Large Language Models (LLM). It then leverages the LLM's feedback (a.k.a., Intelligent Relevance Feedback) to reformulate queries and re-rank source documents, improving bug localization. We evaluate BRaIn using a benchmark dataset, Bench4BL, and three performance metrics and compare it against six baseline techniques from the literature. Our experimental results show that BRaIn outperforms baselines by 87.6%, 89.5%, and 48.8% margins in MAP, MRR, and HIT@K, respectively. Additionally, it can localize approximately 52% of bugs that cannot be localized by the baseline techniques due to the poor quality of corresponding bug reports. By addressing the contextual gaps and introducing Intelligent Relevance Feedback, BRaIn advances not only theory but also improves IR-based bug localization.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "16",
        "title": "An Empirical Study to Understand How Students Use ChatGPT for Writing Essays",
        "author": [
            "Andrew Jelson",
            "Daniel Manesh",
            "Alice Jang",
            "Daniel Dunlap",
            "Sang Won Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10551",
        "abstract": "As large language models (LLMs) advance and become widespread, students increasingly turn to systems like ChatGPT for assistance with writing tasks. Educators are concerned with students' usage of ChatGPT beyond cheating; using ChatGPT may reduce their critical engagement with writing, hindering students' learning processes. The negative or positive impact of using LLM-powered tools for writing will depend on how students use them; however, how students use ChatGPT remains largely unknown, resulting in a limited understanding of its impact on learning. To better understand how students use these tools, we conducted an online study $(n=70)$ where students were given an essay-writing task using a custom platform we developed to capture the queries they made to ChatGPT. To characterize their ChatGPT usage, we categorized each of the queries students made to ChatGPT. We then analyzed the relationship between ChatGPT usage and a variety of other metrics, including students' self-perception, attitudes towards AI, and the resulting essay itself. We found that factors such as gender, race, and perceived self-efficacy can help predict different AI usage patterns. Additionally, we found that different usage patterns were associated with varying levels of enjoyment and perceived ownership over the essay. The results of this study contribute to discussions about how writing education should incorporate generative AI-powered tools in the classroom.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "17",
        "title": "On the Benefits of Instance Decomposition in Video Prediction Models",
        "author": [
            "Eliyas Suleyman",
            "Paul Henderson",
            "Nicolas Pugeault"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10562",
        "abstract": "Video prediction is a crucial task for intelligent agents such as robots and autonomous vehicles, since it enables them to anticipate and act early on time-critical incidents. State-of-the-art video prediction methods typically model the dynamics of a scene jointly and implicitly, without any explicit decomposition into separate objects. This is challenging and potentially sub-optimal, as every object in a dynamic scene has their own pattern of movement, typically somewhat independent of others. In this paper, we investigate the benefit of explicitly modeling the objects in a dynamic scene separately within the context of latent-transformer video prediction models. We conduct detailed and carefully-controlled experiments on both synthetic and real-world datasets; our results show that decomposing a dynamic scene leads to higher quality predictions compared with models of a similar capacity that lack such decomposition.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "18",
        "title": "The Geometry of Tokens in Internal Representations of Large Language Models",
        "author": [
            "Karthik Viswanathan",
            "Yuri Gardinazzi",
            "Giada Panerai",
            "Alberto Cazzaniga",
            "Matteo Biagetti"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10573",
        "abstract": "We investigate the relationship between the geometry of token embeddings and their role in the next token prediction within transformer models. An important aspect of this connection uses the notion of empirical measure, which encodes the distribution of token point clouds across transformer layers and drives the evolution of token representations in the mean-field interacting picture. We use metrics such as intrinsic dimension, neighborhood overlap, and cosine similarity to observationally probe these empirical measures across layers. To validate our approach, we compare these metrics to a dataset where the tokens are shuffled, which disrupts the syntactic and semantic structure. Our findings reveal a correlation between the geometric properties of token embeddings and the cross-entropy loss of next token predictions, implying that prompts with higher loss values have tokens represented in higher-dimensional spaces.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "19",
        "title": "Adapting Large Language Models for Character-based Augmentative and Alternative Communication",
        "author": [
            "Dylan Gaines",
            "Keith Vertanen"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10582",
        "abstract": "Users of Augmentative and Alternative Communication (AAC) may write letter-by-letter via an interface that uses a character language model. However, most state-of-the-art large pretrained language models predict subword tokens of variable length. We investigate how to practically use such models to make accurate and efficient character predictions. We fine-tune models using a large dataset of sentences we curated in which each sentence is rated according to how useful it might be for spoken or written AAC communication. We find that using an algorithm to produce character predictions from a subword large language model provides more accurate predictions than adding a classification layer or using a byte-level model. We also find that our domain adaptation curriculum is effective at improving model performance on simple, conversational text.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "20",
        "title": "When language and vision meet road safety: leveraging multimodal large language models for video-based traffic accident analysis",
        "author": [
            "Ruixuan Zhang",
            "Beichen Wang",
            "Juexiao Zhang",
            "Zilin Bian",
            "Chen Feng",
            "Kaan Ozbay"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10604",
        "abstract": "The increasing availability of traffic videos functioning on a 24/7/365 time scale has the great potential of increasing the spatio-temporal coverage of traffic accidents, which will help improve traffic safety. However, analyzing footage from hundreds, if not thousands, of traffic cameras in a 24/7/365 working protocol remains an extremely challenging task, as current vision-based approaches primarily focus on extracting raw information, such as vehicle trajectories or individual object detection, but require laborious post-processing to derive actionable insights. We propose SeeUnsafe, a new framework that integrates Multimodal Large Language Model (MLLM) agents to transform video-based traffic accident analysis from a traditional extraction-then-explanation workflow to a more interactive, conversational approach. This shift significantly enhances processing throughput by automating complex tasks like video classification and visual grounding, while improving adaptability by enabling seamless adjustments to diverse traffic scenarios and user-defined queries. Our framework employs a severity-based aggregation strategy to handle videos of various lengths and a novel multimodal prompt to generate structured responses for review and evaluation and enable fine-grained visual grounding. We introduce IMS (Information Matching Score), a new MLLM-based metric for aligning structured responses with ground truth. We conduct extensive experiments on the Toyota Woven Traffic Safety dataset, demonstrating that SeeUnsafe effectively performs accident-aware video classification and visual grounding by leveraging off-the-shelf MLLMs. Source code will be available at \\url{https://github.com/ai4ce/SeeUnsafe}.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "21",
        "title": "Prompt-Enabled Large AI Models for CSI Feedback",
        "author": [
            "Jiajia Guo",
            "Yiming Cui",
            "Chao-Kai Wen",
            "Shi Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10629",
        "abstract": "Artificial intelligence (AI) has emerged as a promising tool for channel state information (CSI) feedback. While recent research primarily focuses on improving feedback accuracy through novel architectures, the underlying mechanisms of AI-based CSI feedback remain unclear. This study investigates these mechanisms by analyzing performance across diverse datasets and reveals that superior feedback performance stems from the strong fitting capabilities of AI models and their ability to leverage environmental knowledge. Building on these findings, we propose a prompt-enabled large AI model (LAM) for CSI feedback. The LAM employs powerful transformer blocks and is trained on extensive datasets from various scenarios. To further enhance reconstruction quality, the channel distribution -- represented as the mean of channel magnitude in the angular domain -- is incorporated as a prompt within the decoder. Simulation results confirm that the proposed prompt-enabled LAM significantly improves feedback accuracy and generalization performance while reducing data collection requirements in new scenarios.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "22",
        "title": "Exploring the Potential of Large Language Models for Massive MIMO CSI Feedback",
        "author": [
            "Yiming Cui",
            "Jiajia Guo",
            "Chao-Kai Wen",
            "Shi Jin",
            "En Tong"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10630",
        "abstract": "Large language models (LLMs) have achieved remarkable success across a wide range of tasks, particularly in natural language processing and computer vision. This success naturally raises an intriguing yet unexplored question: Can LLMs be harnessed to tackle channel state information (CSI) compression and feedback in massive multiple-input multiple-output (MIMO) systems? Efficient CSI feedback is a critical challenge in next-generation wireless communication. In this paper, we pioneer the use of LLMs for CSI compression, introducing a novel framework that leverages the powerful denoising capabilities of LLMs -- capable of error correction in language tasks -- to enhance CSI reconstruction performance. To effectively adapt LLMs to CSI data, we design customized pre-processing, embedding, and post-processing modules tailored to the unique characteristics of wireless signals. Extensive numerical results demonstrate the promising potential of LLMs in CSI feedback, opening up possibilities for this research direction.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "23",
        "title": "Latent-space adversarial training with post-aware calibration for defending large language models against jailbreak attacks",
        "author": [
            "Xin Yi",
            "Yue Li",
            "Linlin Wang",
            "Xiaoling Wang",
            "Liang He"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10639",
        "abstract": "Ensuring safety alignment has become a critical requirement for large language models (LLMs), particularly given their widespread deployment in real-world applications. However, LLMs remain susceptible to jailbreak attacks, which exploit system vulnerabilities to bypass safety measures and generate harmful outputs. Although numerous defense mechanisms based on adversarial training have been proposed, a persistent challenge lies in the exacerbation of over-refusal behaviors, which compromise the overall utility of the model. To address these challenges, we propose a Latent-space Adversarial Training with Post-aware Calibration (LATPC) framework. During the adversarial training phase, LATPC compares harmful and harmless instructions in the latent space and extracts safety-critical dimensions to construct refusal features attack, precisely simulating agnostic jailbreak attack types requiring adversarial mitigation. At the inference stage, an embedding-level calibration mechanism is employed to alleviate over-refusal behaviors with minimal computational overhead. Experimental results demonstrate that, compared to various defense methods across five types of jailbreak attacks, LATPC framework achieves a superior balance between safety and utility. Moreover, our analysis underscores the effectiveness of extracting safety-critical dimensions from the latent space for constructing robust refusal feature attacks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "24",
        "title": "ClusterViG: Efficient Globally Aware Vision GNNs via Image Partitioning",
        "author": [
            "Dhruv Parikh",
            "Jacob Fein-Ashley",
            "Tian Ye",
            "Rajgopal Kannan",
            "Viktor Prasanna"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10640",
        "abstract": "Convolutional Neural Networks (CNN) and Vision Transformers (ViT) have dominated the field of Computer Vision (CV). Graph Neural Networks (GNN) have performed remarkably well across diverse domains because they can represent complex relationships via unstructured graphs. However, the applicability of GNNs for visual tasks was unexplored till the introduction of Vision GNNs (ViG). Despite the success of ViGs, their performance is severely bottlenecked due to the expensive $k$-Nearest Neighbors ($k$-NN) based graph construction. Recent works addressing this bottleneck impose constraints on the flexibility of GNNs to build unstructured graphs, undermining their core advantage while introducing additional inefficiencies. To address these issues, in this paper, we propose a novel method called Dynamic Efficient Graph Convolution (DEGC) for designing efficient and globally aware ViGs. DEGC partitions the input image and constructs graphs in parallel for each partition, improving graph construction efficiency. Further, DEGC integrates local intra-graph and global inter-graph feature learning, enabling enhanced global context awareness. Using DEGC as a building block, we propose a novel CNN-GNN architecture, ClusterViG, for CV tasks. Extensive experiments indicate that ClusterViG reduces end-to-end inference latency for vision tasks by up to $5\\times$ when compared against a suite of models such as ViG, ViHGNN, PVG, and GreedyViG, with a similar model parameter count. Additionally, ClusterViG reaches state-of-the-art performance on image classification, object detection, and instance segmentation tasks, demonstrating the effectiveness of the proposed globally aware learning strategy. Finally, input partitioning performed by DEGC enables ClusterViG to be trained efficiently on higher-resolution images, underscoring the scalability of our approach.",
        "tags": [
            "Detection",
            "Segmentation",
            "ViT"
        ]
    },
    {
        "id": "25",
        "title": "DNA 1.0 Technical Report",
        "author": [
            "Jungyup Lee",
            "Jemin Kim",
            "Sang Park",
            "SeungJae Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10648",
        "abstract": "In this report, we present DNA 1.0 8B Instruct, a state-of-the-art bilingual language model optimized for Korean and English language tasks. By applying continual pre-training (CPT) with high-quality Korean datasets to Llama 3.1 8B and subsequent supervised fine-tuning (SFT), we create an instruction-following model with enhanced Korean language capabilities. This model is then merged with Llama 3.1 8B Instruct via spherical linear interpolation (SLERP) and undergoes further optimization through direct preference optimization (DPO) and knowledge distillation (KD). DNA 1.0 8B Instruct achieves state-of-the-art results on Korean-specific tasks, including KMMLU (53.26%), KoBEST (83.40%), and BELEBELE (57.99%), while maintaining strong English capabilities on MMLU (66.64%), MMLU-Pro (43.05%) and GSM8K (80.52%). As an open model, DNA 1.0 8B Instruct represents a significant advancement in bilingual language modeling. \nAs an open model, DNA 1.0 8B Instruct is freely available through https://huggingface.co/dnotitia/Llama-DNA-1.0-8B-Instruct . For commercial licensing inquiries or feedback, please contact us at https://www.dnotitia.com/contact/post-form",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "26",
        "title": "LUT-DLA: Lookup Table as Efficient Extreme Low-Bit Deep Learning Accelerator",
        "author": [
            "Guoyu Li",
            "Shengyu Ye",
            "Chunyun Chen",
            "Yang Wang",
            "Fan Yang",
            "Ting Cao",
            "Cheng Liu",
            "Mohamed M. Sabry",
            "Mao Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10658",
        "abstract": "The emergence of neural network capabilities invariably leads to a significant surge in computational demands due to expanding model sizes and increased computational complexity. To reduce model size and lower inference costs, recent research has focused on simplifying models and designing hardware accelerators using low-bit quantization. However, due to numerical representation limits, scalar quantization cannot reduce bit width lower than 1-bit, diminishing its benefits. To break through these limitations, we introduce LUT-DLA, a Look-Up Table (LUT) Deep Learning Accelerator Framework that utilizes vector quantization to convert neural network models into LUTs, achieving extreme low-bit quantization. The LUT-DLA framework facilitates efficient and cost-effective hardware accelerator designs and supports the LUTBoost algorithm, which helps to transform various DNN models into LUT-based models via multistage training, drastically cutting both computational and hardware overhead. Additionally, through co-design space exploration, LUT-DLA assesses the impact of various model and hardware parameters to fine-tune hardware configurations for different application scenarios, optimizing performance and efficiency. Our comprehensive experiments show that LUT-DLA achieves improvements in power efficiency and area efficiency with gains of $1.4$~$7.0\\times$ and $1.5$~$146.1\\times$, respectively, while maintaining only a modest accuracy drop. For CNNs, accuracy decreases by $0.1\\%$~$3.1\\%$ using the $L_2$ distance similarity, $0.1\\%$~$3.4\\%$ with the $L_1$ distance similarity, and $0.1\\%$~$3.8\\%$ when employing the Chebyshev distance similarity. For transformer-based models, the accuracy drop ranges from $1.4\\%$ to $3.0\\%$.",
        "tags": [
            "Transformer",
            "Vector Quantization"
        ]
    },
    {
        "id": "27",
        "title": "Can Multimodal LLMs do Visual Temporal Understanding and Reasoning? The answer is No!",
        "author": [
            "Mohamed Fazli Imam",
            "Chenyang Lyu",
            "Alham Fikri Aji"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10674",
        "abstract": "Multimodal Large Language Models (MLLMs) have achieved significant advancements in tasks like Visual Question Answering (VQA) by leveraging foundational Large Language Models (LLMs). However, their abilities in specific areas such as temporal understanding, which is crucial for comprehending real-world dynamics, remain underexplored. To address this, we propose a challenging evaluation benchmark named TemporalVQA, consisting of two parts: (1) Temporal Order Understanding and (2) Time-lapse Estimation. The first part requires MLLMs to determine the sequence of events by analyzing temporally consecutive video frames. The second part presents image pairs with varying time differences, framed as multiple-choice questions, asking MLLMs to estimate the time-lapse between images with options ranging from seconds to years. Our evaluations of advanced MLLMs, including models like GPT-4o and Gemini-1.5-Pro, reveal significant challenges: GPT-4o achieved only 43.8% average consistent accuracy in temporal order tasks and 70% in time-lapse estimation, with open-source models performing even less effectively. These findings underscore the limitations of current MLLMs in visual temporal understanding and reasoning, highlighting the need for further improvements in their temporal capabilities. Our dataset can be found at https://huggingface.co/datasets/fazliimam/temporal-vqa.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "28",
        "title": "Deep Operator Networks for Bayesian Parameter Estimation in PDEs",
        "author": [
            "Amogh Raj",
            "Carol Eunice Gudumotou",
            "Sakol Bun",
            "Keerthana Srinivasa",
            "Arash Sarshar"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10684",
        "abstract": "We present a novel framework combining Deep Operator Networks (DeepONets) with Physics-Informed Neural Networks (PINNs) to solve partial differential equations (PDEs) and estimate their unknown parameters. By integrating data-driven learning with physical constraints, our method achieves robust and accurate solutions across diverse scenarios. Bayesian training is implemented through variational inference, allowing for comprehensive uncertainty quantification for both aleatoric and epistemic uncertainties. This ensures reliable predictions and parameter estimates even in noisy conditions or when some of the physical equations governing the problem are missing. The framework demonstrates its efficacy in solving forward and inverse problems, including the 1D unsteady heat equation and 2D reaction-diffusion equations, as well as regression tasks with sparse, noisy observations. This approach provides a computationally efficient and generalizable method for addressing uncertainty quantification in PDE surrogate modeling.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "29",
        "title": "Harnessing the Potential of Large Language Models in Modern Marketing Management: Applications, Future Directions, and Strategic Recommendations",
        "author": [
            "Raha Aghaei",
            "Ali A. Kiaei",
            "Mahnaz Boush",
            "Javad Vahidi",
            "Mohammad Zavvar",
            "Zeynab Barzegar",
            "Mahan Rofoosheh"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10685",
        "abstract": "Large Language Models (LLMs) have revolutionized the process of customer engagement, campaign optimization, and content generation, in marketing management. In this paper, we explore the transformative potential of LLMs along with the current applications, future directions, and strategic recommendations for marketers. In particular, we focus on LLMs major business drivers such as personalization, real-time-interactive customer insights, and content automation, and how they enable customers and business outcomes. For instance, the ethical aspects of AI with respect to data privacy, transparency, and mitigation of bias are also covered, with the goal of promoting responsible use of the technology through best practices and the use of new technologies businesses can tap into the LLM potential, which help growth and stay one step ahead in the turmoil of digital marketing. This article is designed to give marketers the necessary guidance by using best industry practices to integrate these powerful LLMs into their marketing strategy and innovation without compromising on the ethos of their brand.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "30",
        "title": "EMO2: End-Effector Guided Audio-Driven Avatar Video Generation",
        "author": [
            "Linrui Tian",
            "Siqi Hu",
            "Qi Wang",
            "Bang Zhang",
            "Liefeng Bo"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10687",
        "abstract": "In this paper, we propose a novel audio-driven talking head method capable of simultaneously generating highly expressive facial expressions and hand gestures. Unlike existing methods that focus on generating full-body or half-body poses, we investigate the challenges of co-speech gesture generation and identify the weak correspondence between audio features and full-body gestures as a key limitation. To address this, we redefine the task as a two-stage process. In the first stage, we generate hand poses directly from audio input, leveraging the strong correlation between audio signals and hand movements. In the second stage, we employ a diffusion model to synthesize video frames, incorporating the hand poses generated in the first stage to produce realistic facial expressions and body movements. Our experimental results demonstrate that the proposed method outperforms state-of-the-art approaches, such as CyberHost and Vlogger, in terms of both visual quality and synchronization accuracy. This work provides a new perspective on audio-driven gesture generation and a robust framework for creating expressive and natural talking head animations.",
        "tags": [
            "Diffusion",
            "Talking Head",
            "Video Generation"
        ]
    },
    {
        "id": "31",
        "title": "Simulation of Hypergraph Algorithms with Looped Transformers",
        "author": [
            "Xiaoyu Li",
            "Yingyu Liang",
            "Jiangxuan Long",
            "Zhenmei Shi",
            "Zhao Song",
            "Zhen Zhuang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10688",
        "abstract": "Looped Transformers have shown exceptional capability in simulating traditional graph algorithms, but their application to more complex structures like hypergraphs remains underexplored. Hypergraphs generalize graphs by modeling higher-order relationships among multiple entities, enabling richer representations but introducing significant computational challenges. In this work, we extend the Loop Transformer architecture to simulate hypergraph algorithms efficiently, addressing the gap between neural networks and combinatorial optimization over hypergraphs. In this paper, we extend the Loop Transformer architecture to simulate hypergraph algorithms efficiently, addressing the gap between neural networks and combinatorial optimization over hypergraphs. Specifically, we propose a novel degradation mechanism for reducing hypergraphs to graph representations, enabling the simulation of graph-based algorithms, such as Dijkstra's shortest path. Furthermore, we introduce a hyperedge-aware encoding scheme to simulate hypergraph-specific algorithms, exemplified by Helly's algorithm. The paper establishes theoretical guarantees for these simulations, demonstrating the feasibility of processing high-dimensional and combinatorial data using Loop Transformers. This work highlights the potential of Transformers as general-purpose algorithmic solvers for structured data.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "32",
        "title": "How Should I Build A Benchmark?",
        "author": [
            "Jialun Cao",
            "Yuk-Kit Chan",
            "Zixuan Ling",
            "Wenxuan Wang",
            "Shuqing Li",
            "Mingwei Liu",
            "Chaozheng Wang",
            "Boxi Yu",
            "Pinjia He",
            "Shuai Wang",
            "Zibin Zheng",
            "Michael R. Lyu",
            "Shing-Chi Cheung"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10711",
        "abstract": "Various benchmarks have been proposed to assess the performance of large language models (LLMs) in different coding scenarios. We refer to them as code-related benchmarks. However, there are no systematic guidelines by which such a benchmark should be developed to ensure its quality, reliability, and reproducibility. We propose How2Bench, which is comprised of a 55- 55-criteria checklist as a set of guidelines to govern the development of code-related benchmarks comprehensively. Using HOW2BENCH, we profiled 274 benchmarks released within the past decade and found concerning issues. Nearly 70% of the benchmarks did not take measures for data quality assurance; over 10% did not even open source or only partially open source. Many highly cited benchmarks have loopholes, including duplicated samples, incorrect reference codes/tests/prompts, and unremoved sensitive/confidential information. Finally, we conducted a human study involving 49 participants, which revealed significant gaps in awareness of the importance of data quality, reproducibility, and transparency.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "33",
        "title": "FSMoE: A Flexible and Scalable Training System for Sparse Mixture-of-Experts Models",
        "author": [
            "Xinglin Pan",
            "Wenxiang Lin",
            "Lin Zhang",
            "Shaohuai Shi",
            "Zhenheng Tang",
            "Rui Wang",
            "Bo Li",
            "Xiaowen Chu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10714",
        "abstract": "Recent large language models (LLMs) have tended to leverage sparsity to reduce computations, employing the sparsely activated mixture-of-experts (MoE) technique. MoE introduces four modules, including token routing, token communication, expert computation, and expert parallelism, that impact model quality and training efficiency. To enable versatile usage of MoE models, we introduce FSMoE, a flexible training system optimizing task scheduling with three novel techniques: 1) Unified abstraction and online profiling of MoE modules for task scheduling across various MoE implementations. 2) Co-scheduling intra-node and inter-node communications with computations to minimize communication overheads. 3) To support near-optimal task scheduling, we design an adaptive gradient partitioning method for gradient aggregation and a schedule to adaptively pipeline communications and computations. We conduct extensive experiments with configured MoE layers and real-world MoE models on two GPU clusters. Experimental results show that 1) our FSMoE supports four popular types of MoE routing functions and is more efficient than existing implementations (with up to a 1.42$\\times$ speedup), and 2) FSMoE outperforms the state-of-the-art MoE training systems (DeepSpeed-MoE and Tutel) by 1.18$\\times$-1.22$\\times$ on 1458 MoE layers and 1.19$\\times$-3.01$\\times$ on real-world MoE models based on GPT-2 and Mixtral using a popular routing function.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "34",
        "title": "Development of Application-Specific Large Language Models to Facilitate Research Ethics Review",
        "author": [
            "Sebastian Porsdam Mann",
            "Joel Seah Jiehao",
            "Stephen R. Latham",
            "Julian Savulescu",
            "Mateo Aboy",
            "Brian D. Earp"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10741",
        "abstract": "Institutional review boards (IRBs) play a crucial role in ensuring the ethical conduct of human subjects research, but face challenges including inconsistency, delays, and inefficiencies. We propose the development and implementation of application-specific large language models (LLMs) to facilitate IRB review processes. These IRB-specific LLMs would be fine-tuned on IRB-specific literature and institutional datasets, and equipped with retrieval capabilities to access up-to-date, context-relevant information. We outline potential applications, including pre-review screening, preliminary analysis, consistency checking, and decision support. While addressing concerns about accuracy, context sensitivity, and human oversight, we acknowledge remaining challenges such as over-reliance on AI and the need for transparency. By enhancing the efficiency and quality of ethical review while maintaining human judgment in critical decisions, IRB-specific LLMs offer a promising tool to improve research oversight. We call for pilot studies to evaluate the feasibility and impact of this approach.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "35",
        "title": "MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science",
        "author": [
            "Erle Zhu",
            "Yadi Liu",
            "Zhe Zhang",
            "Xujun Li",
            "Jin Zhou",
            "Xinjie Yu",
            "Minlie Huang",
            "Hongning Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10768",
        "abstract": "Pre-trained on extensive text and image corpora, current Multi-Modal Large Language Models (MLLM) have shown strong capabilities in general visual reasoning tasks. However, their performance is still lacking in physical domains that require understanding diagrams with complex physical structures and quantitative analysis based on multi-modal information. To address this, we develop a new framework, named Multi-Modal Scientific Reasoning with Physics Perception and Simulation (MAPS) based on an MLLM. MAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator. The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions. At the inference stage, MAPS integrates the simulation language description of the input diagram provided by PPM and results obtained through a Chain-of-Simulation process with MLLM to derive the underlying rationale and the final answer. Validated using our collected college-level circuit analysis problems, MAPS significantly improves reasoning accuracy of MLLM and outperforms all existing models. The results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs. We will release our code, model and dataset used for our experiments upon publishing of this paper.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "36",
        "title": "ML-SceGen: A Multi-level Scenario Generation Framework",
        "author": [
            "Yicheng Xiao",
            "Yangyang Sun",
            "Yicheng Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10782",
        "abstract": "Current scientific research witnesses various attempts at applying Large Language Models for scenario generation but is inclined only to comprehensive or dangerous scenarios. In this paper, we seek to build a three-stage framework that not only lets users regain controllability over the generated scenarios but also generates comprehensive scenarios containing danger factors in uncontrolled intersection settings. In the first stage, LLM agents will contribute to translating the key components of the description of the expected scenarios into Functional Scenarios. For the second stage, we use Answer Set Programming (ASP) solver Clingo to help us generate comprehensive logical traffic within intersections. During the last stage, we use LLM to update relevant parameters to increase the critical level of the concrete scenario.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "37",
        "title": "LD-DETR: Loop Decoder DEtection TRansformer for Video Moment Retrieval and Highlight Detection",
        "author": [
            "Pengcheng Zhao",
            "Zhixian He",
            "Fuwei Zhang",
            "Shujin Lin",
            "Fan Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10787",
        "abstract": "Video Moment Retrieval and Highlight Detection aim to find corresponding content in the video based on a text query. Existing models usually first use contrastive learning methods to align video and text features, then fuse and extract multimodal information, and finally use a Transformer Decoder to decode multimodal information. However, existing methods face several issues: (1) Overlapping semantic information between different samples in the dataset hinders the model's multimodal aligning performance; (2) Existing models are not able to efficiently extract local features of the video; (3) The Transformer Decoder used by the existing model cannot adequately decode multimodal features. To address the above issues, we proposed the LD-DETR model for Video Moment Retrieval and Highlight Detection tasks. Specifically, we first distilled the similarity matrix into the identity matrix to mitigate the impact of overlapping semantic information. Then, we designed a method that enables convolutional layers to extract multimodal local features more efficiently. Finally, we fed the output of the Transformer Decoder back into itself to adequately decode multimodal information. We evaluated LD-DETR on four public benchmarks and conducted extensive experiments to demonstrate the superiority and effectiveness of our approach. Our model outperforms the State-Of-The-Art models on QVHighlight, Charades-STA and TACoS datasets. Our code is available at https://github.com/qingchen239/ld-detr.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "38",
        "title": "Decoupling Appearance Variations with 3D Consistent Features in Gaussian Splatting",
        "author": [
            "Jiaqi Lin",
            "Zhihao Li",
            "Binxiao Huang",
            "Xiao Tang",
            "Jianzhuang Liu",
            "Shiyong Liu",
            "Xiaofei Wu",
            "Fenglong Song",
            "Wenming Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10788",
        "abstract": "Gaussian Splatting has emerged as a prominent 3D representation in novel view synthesis, but it still suffers from appearance variations, which are caused by various factors, such as modern camera ISPs, different time of day, weather conditions, and local light changes. These variations can lead to floaters and color distortions in the rendered images/videos. Recent appearance modeling approaches in Gaussian Splatting are either tightly coupled with the rendering process, hindering real-time rendering, or they only account for mild global variations, performing poorly in scenes with local light changes. In this paper, we propose DAVIGS, a method that decouples appearance variations in a plug-and-play and efficient manner. By transforming the rendering results at the image level instead of the Gaussian level, our approach can model appearance variations with minimal optimization time and memory overhead. Furthermore, our method gathers appearance-related information in 3D space to transform the rendered images, thus building 3D consistency across views implicitly. We validate our method on several appearance-variant scenes, and demonstrate that it achieves state-of-the-art rendering quality with minimal training time and memory usage, without compromising rendering speeds. Additionally, it provides performance improvements for different Gaussian Splatting baselines in a plug-and-play manner.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "39",
        "title": "Dynamic Trend Fusion Module for Traffic Flow Prediction",
        "author": [
            "Jing Chen",
            "Haocheng Ye",
            "Zhian Ying",
            "Yuntao Sun",
            "Wenqiang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10796",
        "abstract": "Accurate traffic flow prediction is essential for applications like transport logistics but remains challenging due to complex spatio-temporal correlations and non-linear traffic patterns. Existing methods often model spatial and temporal dependencies separately, failing to effectively fuse them. To overcome this limitation, the Dynamic Spatial-Temporal Trend Transformer DST2former is proposed to capture spatio-temporal correlations through adaptive embedding and to fuse dynamic and static information for learning multi-view dynamic features of traffic networks. The approach employs the Dynamic Trend Representation Transformer (DTRformer) to generate dynamic trends using encoders for both temporal and spatial dimensions, fused via Cross Spatial-Temporal Attention. Predefined graphs are compressed into a representation graph to extract static attributes and reduce redundancy. Experiments on four real-world traffic datasets demonstrate that our framework achieves state-of-the-art performance.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "40",
        "title": "Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback",
        "author": [
            "Yen-Ting Lin",
            "Di Jin",
            "Tengyu Xu",
            "Tianhao Wu",
            "Sainbayar Sukhbaatar",
            "Chen Zhu",
            "Yun He",
            "Yun-Nung Chen",
            "Jason Weston",
            "Yuandong Tian",
            "Arash Rahnama",
            "Sinong Wang",
            "Hao Ma",
            "Han Fang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10799",
        "abstract": "Large language models (LLMs) have recently demonstrated remarkable success in mathematical reasoning. Despite progress in methods like chain-of-thought prompting and self-consistency sampling, these advances often focus on final correctness without ensuring that the underlying reasoning process is coherent and reliable. This paper introduces Step-KTO, a training framework that combines process-level and outcome-level binary feedback to guide LLMs toward more trustworthy reasoning trajectories. By providing binary evaluations for both the intermediate reasoning steps and the final answer, Step-KTO encourages the model to adhere to logical progressions rather than relying on superficial shortcuts. Our experiments on challenging mathematical benchmarks show that Step-KTO significantly improves both final answer accuracy and the quality of intermediate reasoning steps. For example, on the MATH-500 dataset, Step-KTO achieves a notable improvement in Pass@1 accuracy over strong baselines. These results highlight the promise of integrating stepwise process feedback into LLM training, paving the way toward more interpretable and dependable reasoning capabilities.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "41",
        "title": "Jailbreaking Large Language Models in Infinitely Many Ways",
        "author": [
            "Oliver Goldstein",
            "Emanuele La Malfa",
            "Felix Drinkall",
            "Samuele Marro",
            "Michael Wooldridge"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10800",
        "abstract": "We discuss the \"Infinitely Many Meanings\" attacks (IMM), a category of jailbreaks that leverages the increasing capabilities of a model to handle paraphrases and encoded communications to bypass their defensive mechanisms. IMMs' viability pairs and grows with a model's capabilities to handle and bind the semantics of simple mappings between tokens and work extremely well in practice, posing a concrete threat to the users of the most powerful LLMs in commerce. We show how one can bypass the safeguards of the most powerful open- and closed-source LLMs and generate content that explicitly violates their safety policies. One can protect against IMMs by improving the guardrails and making them scale with the LLMs' capabilities. For two categories of attacks that are straightforward to implement, i.e., bijection and encoding, we discuss two defensive strategies, one in token and the other in embedding space. We conclude with some research questions we believe should be prioritised to enhance the defensive mechanisms of LLMs and our understanding of their safety.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "42",
        "title": "Efficient Auto-Labeling of Large-Scale Poultry Datasets (ALPD) Using Semi-Supervised Models, Active Learning, and Prompt-then-Detect Approach",
        "author": [
            "Ramesh Bahadur Bist",
            "Lilong Chai",
            "Shawna Weimer",
            "Hannah Atungulua",
            "Chantel Pennicott",
            "Xiao Yang",
            "Sachin Subedi",
            "Chaitanya Pallerla",
            "Yang Tian",
            "Dongyi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10809",
        "abstract": "The rapid growth of AI in poultry farming has highlighted the challenge of efficiently labeling large, diverse datasets. Manual annotation is time-consuming, making it impractical for modern systems that continuously generate data. This study explores semi-supervised auto-labeling methods, integrating active learning, and prompt-then-detect paradigm to develop an efficient framework for auto-labeling of large poultry datasets aimed at advancing AI-driven behavior and health monitoring. Viideo data were collected from broilers and laying hens housed at the University of Arkansas and the University of Georgia. The collected videos were converted into images, pre-processed, augmented, and labeled. Various machine learning models, including zero-shot models like Grounding DINO, YOLO-World, and CLIP, and supervised models like YOLO and Faster-RCNN, were utilized for broilers, hens, and behavior detection. The results showed that YOLOv8s-World and YOLOv9s performed better when compared performance metrics for broiler and hen detection under supervised learning, while among the semi-supervised model, YOLOv8s-ALPD achieved the highest precision (96.1%) and recall (99.0%) with an RMSE of 1.9. The hybrid YOLO-World model, incorporating the optimal YOLOv8s backbone, demonstrated the highest overall performance. It achieved a precision of 99.2%, recall of 99.4%, and an F1 score of 98.7% for breed detection, alongside a precision of 88.4%, recall of 83.1%, and an F1 score of 84.5% for individual behavior detection. Additionally, semi-supervised models showed significant improvements in behavior detection, achieving up to 31% improvement in precision and 16% in F1-score. The semi-supervised models with minimal active learning reduced annotation time by over 80% compared to full manual labeling. Moreover, integrating zero-shot models enhanced detection and behavior identification.",
        "tags": [
            "CLIP",
            "Detection"
        ]
    },
    {
        "id": "43",
        "title": "GAUDA: Generative Adaptive Uncertainty-guided Diffusion-based Augmentation for Surgical Segmentation",
        "author": [
            "Yannik Frisch",
            "Christina Bornberg",
            "Moritz Fuchs",
            "Anirban Mukhopadhyay"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10819",
        "abstract": "Augmentation by generative modelling yields a promising alternative to the accumulation of surgical data, where ethical, organisational and regulatory aspects must be considered. Yet, the joint synthesis of (image, mask) pairs for segmentation, a major application in surgery, is rather unexplored. We propose to learn semantically comprehensive yet compact latent representations of the (image, mask) space, which we jointly model with a Latent Diffusion Model. We show that our approach can effectively synthesise unseen high-quality paired segmentation data of remarkable semantic coherence. Generative augmentation is typically applied pre-training by synthesising a fixed number of additional training samples to improve downstream task models. To enhance this approach, we further propose Generative Adaptive Uncertainty-guided Diffusion-based Augmentation (GAUDA), leveraging the epistemic uncertainty of a Bayesian downstream model for targeted online synthesis. We condition the generative model on classes with high estimated uncertainty during training to produce additional unseen samples for these classes. By adaptively utilising the generative model online, we can minimise the number of additional training samples and centre them around the currently most uncertain parts of the data distribution. GAUDA effectively improves downstream segmentation results over comparable methods by an average absolute IoU of 1.6% on CaDISv2 and 1.5% on CholecSeg8k, two prominent surgical datasets for semantic segmentation.",
        "tags": [
            "Diffusion",
            "Segmentation"
        ]
    },
    {
        "id": "44",
        "title": "Addressing Multilabel Imbalance with an Efficiency-Focused Approach Using Diffusion Model-Generated Synthetic Samples",
        "author": [
            "Francisco Charte",
            "Miguel Ãngel DÃ¡vila",
            "MarÃ­a Dolores PÃ©rez-Godoy",
            "MarÃ­a JosÃ© del Jesus"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10822",
        "abstract": "Predictive models trained on imbalanced data tend to produce biased results. This problem is exacerbated when there is not just one output label, but a set of them. This is the case for multilabel learning (MLL) algorithms used to classify patterns, rank labels, or learn the distribution of outputs. Many solutions have been proposed in the literature. The one that can be applied universally, independent of the algorithm used to build the model, is data resampling. The generation of new instances associated with minority labels, so that empty areas of the feature space are filled, helps to improve the obtained models. The quality of these new instances depends on the algorithm used to generate them. In this paper, a diffusion model tailored to produce new instances for MLL data, called MLDM (\\textit{MultiLabel Diffusion Model}), is proposed. Diffusion models have been mainly used to generate artificial images and videos. Our proposed MLDM is based on this type of models. The experiments conducted compare MLDM with several other MLL resampling algorithms. The results show that MLDM is competitive while it improves efficiency.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "45",
        "title": "Visual RAG: Expanding MLLM visual knowledge without fine-tuning",
        "author": [
            "Mirco Bonomo",
            "Simone Bianco"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10834",
        "abstract": "Multimodal Large Language Models (MLLMs) have achieved notable performance in computer vision tasks that require reasoning across visual and textual modalities, yet their capabilities are limited to their pre-trained data, requiring extensive fine-tuning for updates. Recent researches have explored the use of In-Context Learning (ICL) to overcome these challenges by providing a set of demonstrating examples as context to augment MLLMs performance in several tasks, showing that many-shot ICL leads to substantial improvements compared to few-shot ICL. However, the reliance on numerous demonstrating examples and the limited MLLMs context windows presents significant obstacles. This paper aims to address these challenges by introducing a novel approach, Visual RAG, that synergically combines the MLLMs capability to learn from the context, with a retrieval mechanism. The crux of this approach is to ensure to augment the MLLM knowledge by selecting only the most relevant demonstrating examples for the query, pushing it to learn by analogy. In this way, relying on the new information provided dynamically during inference time, the resulting system is not limited to the knowledge extracted from the training data, but can be updated rapidly and easily without fine-tuning. Furthermore, this greatly reduces the computational costs for improving the model image classification performance, and augments the model knowledge to new visual domains and tasks it was not trained for. Extensive experiments on eight different datasets in the state of the art spanning several domains and image classification tasks show that the proposed Visual RAG, compared to the most recent state of the art (i.e., many-shot ICL), is able to obtain an accuracy that is very close or even higher (approx. +2% improvement on average) while using a much smaller set of demonstrating examples (approx. only 23% on average).",
        "tags": [
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "46",
        "title": "BAP v2: An Enhanced Task Framework for Instruction Following in Minecraft Dialogues",
        "author": [
            "Prashant Jayannavar",
            "Liliang Ren",
            "Marisa Hudspeth",
            "Charlotte Lambert",
            "Ariel Cordes",
            "Elizabeth Kaplan",
            "Anjali Narayan-Chen",
            "Julia Hockenmaier"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10836",
        "abstract": "Interactive agents capable of understanding and executing instructions in the physical world have long been a central goal in AI research. The Minecraft Collaborative Building Task (MCBT) provides one such setting to work towards this goal (Narayan-Chen, Jayannavar, and Hockenmaier 2019). It is a two-player game in which an Architect (A) instructs a Builder (B) to construct a target structure in a simulated Blocks World Environment. We focus on the challenging Builder Action Prediction (BAP) subtask of predicting correct action sequences in a given multimodal game context with limited training data (Jayannavar, Narayan-Chen, and Hockenmaier 2020). We take a closer look at evaluation and data for the BAP task, discovering key challenges and making significant improvements on both fronts to propose BAP v2, an upgraded version of the task. This will allow future work to make more efficient and meaningful progress on it. It comprises of: (1) an enhanced evaluation benchmark that includes a cleaner test set and fairer, more insightful metrics, and (2) additional synthetic training data generated from novel Minecraft dialogue and target structure simulators emulating the MCBT. We show that the synthetic data can be used to train more performant and robust neural models even with relatively simple training methods. Looking ahead, such data could also be crucial for training more sophisticated, data-hungry deep transformer models and training/fine-tuning increasingly large LLMs. Although modeling is not the primary focus of this work, we also illustrate the impact of our data and training methodologies on a simple LLM- and transformer-based model, thus validating the robustness of our approach, and setting the stage for more advanced architectures and LLMs going forward.",
        "tags": [
            "LLMs",
            "Transformer"
        ]
    },
    {
        "id": "47",
        "title": "Systems Engineering for Autonomous Vehicles; Supervising AI using Large Language Models (SSuperLLM)",
        "author": [
            "Diomidis Katzourakis"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10839",
        "abstract": "Generative Artificial Intelligence (GAI) and the idea to use hierarchical models has been around for some years now. GAI has proved to be an extremely useful tool for Autonomous Vehicles (AVs). AVs need to perform robustly in their environment. Thus the AV behavior and short-term trajectory planning needs to be: a) designed and architected using safeguarding and supervisory systems and b) verified using proper Systems Engineering (SysEng) Principles. Can AV Systems Engineering also use Large Language Models (LLM) to help Autonomous vehicles (AV) development? This reader-friendly paper advocates the use of LLMs in 1) requirements (Reqs) development and 2) Reqs verification and 3) provides a proof-of-concept of AV supervisory control. The latter uses a simulation environment of a simple planar (bicycle) vehicle dynamics model and a Linear Quadratic Regulator (LQR) control with an LLM Application Interface (API). The Open-Source simulation SW is available from the author accessible to the readers so that they can engage into the AV stack, LLM API and rules, SysEng and Reqs and fundamental vehicle dynamics and control.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "48",
        "title": "Learning Nonverbal Cues in Multiparty Social Interactions for Robotic Facilitators",
        "author": [
            "Antonio Lech Martin-Ozimek",
            "Isuru Jayarathne",
            "Su Larb Mon",
            "Jouhyeong Chew"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10857",
        "abstract": "Conventional behavior cloning (BC) models often struggle to replicate the subtleties of human actions. Previous studies have attempted to address this issue through the development of a new BC technique: Implicit Behavior Cloning (IBC). This new technique consistently outperformed the conventional Mean Squared Error (MSE) BC models in a variety of tasks. Our goal is to replicate the performance of the IBC model by Florence [in Proceedings of the 5th Conference on Robot Learning, 164:158-168, 2022], for social interaction tasks using our custom dataset. While previous studies have explored the use of large language models (LLMs) for enhancing group conversations, they often overlook the significance of non-verbal cues, which constitute a substantial part of human communication. We propose using IBC to replicate nonverbal cues like gaze behaviors. The model is evaluated against various types of facilitator data and compared to an explicit, MSE BC model. Results show that the IBC model outperforms the MSE BC model across session types using the same metrics used in the previous IBC paper. Despite some metrics showing mixed results which are explainable for the custom dataset for social interaction, we successfully replicated the IBC model to generate nonverbal cues. Our contributions are (1) the replication and extension of the IBC model, and (2) a nonverbal cues generation model for social interaction. These advancements facilitate the integration of robots into the complex interactions between robots and humans, e.g., in the absence of a human facilitator.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Robot"
        ]
    },
    {
        "id": "49",
        "title": "Zero-shot and Few-shot Learning with Instruction-following LLMs for Claim Matching in Automated Fact-checking",
        "author": [
            "Dina Pisarevskaya",
            "Arkaitz Zubiaga"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10860",
        "abstract": "The claim matching (CM) task can benefit an automated fact-checking pipeline by putting together claims that can be resolved with the same fact-check. In this work, we are the first to explore zero-shot and few-shot learning approaches to the task. We consider CM as a binary classification task and experiment with a set of instruction-following large language models (GPT-3.5-turbo, Gemini-1.5-flash, Mistral-7B-Instruct, and Llama-3-8B-Instruct), investigating prompt templates. We introduce a new CM dataset, ClaimMatch, which will be released upon acceptance. We put LLMs to the test in the CM task and find that it can be tackled by leveraging more mature yet similar tasks such as natural language inference or paraphrase detection. We also propose a pipeline for CM, which we evaluate on texts of different lengths.",
        "tags": [
            "Detection",
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "50",
        "title": "Diffusion-Based Imitation Learning for Social Pose Generation",
        "author": [
            "Antonio Lech Martin-Ozimek",
            "Isuru Jayarathne",
            "Su Larb Mon",
            "Jouh Yeong Chew"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10869",
        "abstract": "Intelligent agents, such as robots and virtual agents, must understand the dynamics of complex social interactions to interact with humans. Effectively representing social dynamics is challenging because we require multi-modal, synchronized observations to understand a scene. We explore how using a single modality, the pose behavior, of multiple individuals in a social interaction can be used to generate nonverbal social cues for the facilitator of that interaction. The facilitator acts to make a social interaction proceed smoothly and is an essential role for intelligent agents to replicate in human-robot interactions. In this paper, we adapt an existing diffusion behavior cloning model to learn and replicate facilitator behaviors. Furthermore, we evaluate two representations of pose observations from a scene, one representation has pre-processing applied and one does not. The purpose of this paper is to introduce a new use for diffusion behavior cloning for pose generation in social interactions. The second is to understand the relationship between performance and computational load for generating social pose behavior using two different techniques for collecting scene observations. As such, we are essentially testing the effectiveness of two different types of conditioning for a diffusion model. We then evaluate the resulting generated behavior from each technique using quantitative measures such as mean per-joint position error (MPJPE), training time, and inference time. Additionally, we plot training and inference time against MPJPE to examine the trade-offs between efficiency and performance. Our results suggest that the further pre-processed data can successfully condition diffusion models to generate realistic social behavior, with reasonable trade-offs in accuracy and processing time.",
        "tags": [
            "Diffusion",
            "Robot"
        ]
    },
    {
        "id": "51",
        "title": "Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments",
        "author": [
            "Hongjin Su",
            "Ruoxi Sun",
            "Jinsung Yoon",
            "Pengcheng Yin",
            "Tao Yu",
            "Sercan Ã. ArÄ±k"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10893",
        "abstract": "Autonomous agents powered by large language models (LLMs) have the potential to enhance human capabilities, assisting with digital tasks from sending emails to performing data analysis. The abilities of existing LLMs at such tasks are often hindered by the lack of high-quality agent data from the corresponding environments they interact with. We propose Learn-by-interact, a data-centric framework to adapt LLM agents to any given environments without human annotations. Learn-by-interact synthesizes trajectories of agent-environment interactions based on documentations, and constructs instructions by summarizing or abstracting the interaction histories, a process called backward construction. We assess the quality of our synthetic data by using them in both training-based scenarios and training-free in-context learning (ICL), where we craft innovative retrieval approaches optimized for agents. Extensive experiments on SWE-bench, WebArena, OSWorld and Spider2-V spanning across realistic coding, web, and desktop environments show the effectiveness of Learn-by-interact in various downstream agentic tasks -- baseline results are improved by up to 12.2\\% for ICL with Claude-3.5 and 19.5\\% for training with Codestral-22B. We further demonstrate the critical role of backward construction, which provides up to 14.0\\% improvement for training. Our ablation studies demonstrate the efficiency provided by our synthesized data in ICL and the superiority of our retrieval pipeline over alternative approaches like conventional retrieval-augmented generation (RAG). We expect that Learn-by-interact will serve as a foundation for agent data synthesis as LLMs are increasingly deployed at real-world environments.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "52",
        "title": "A Generative Security Application Engineering Curriculum",
        "author": [
            "Wu-chang Feng",
            "David Baker-Robinson"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10900",
        "abstract": "Generative AI and large language models (LLMs) are transforming security by automating many tasks being performed manually. With such automation changing the practice of security as we know it, it is imperative that we prepare future students for the technology landscape they will ultimately face. Towards this end, we describe an initial curriculum and course that attempts to show students how to apply generative AI in order to solve problems in security. By refocusing security education and training on aspects uniquely suited for humans and showing students how to leverage automation for the rest, we believe we can better align security education practices with generative AI as it evolves.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "53",
        "title": "ARD-VAE: A Statistical Formulation to Find the Relevant Latent Dimensions of Variational Autoencoders",
        "author": [
            "Surojit Saha",
            "Sarang Joshi",
            "Ross Whitaker"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10901",
        "abstract": "The variational autoencoder (VAE) is a popular, deep, latent-variable model (DLVM) due to its simple yet effective formulation for modeling the data distribution. Moreover, optimizing the VAE objective function is more manageable than other DLVMs. The bottleneck dimension of the VAE is a crucial design choice, and it has strong ramifications for the model's performance, such as finding the hidden explanatory factors of a dataset using the representations learned by the VAE. However, the size of the latent dimension of the VAE is often treated as a hyperparameter estimated empirically through trial and error. To this end, we propose a statistical formulation to discover the relevant latent factors required for modeling a dataset. In this work, we use a hierarchical prior in the latent space that estimates the variance of the latent axes using the encoded data, which identifies the relevant latent dimensions. For this, we replace the fixed prior in the VAE objective function with a hierarchical prior, keeping the remainder of the formulation unchanged. We call the proposed method the automatic relevancy detection in the variational autoencoder (ARD-VAE). We demonstrate the efficacy of the ARD-VAE on multiple benchmark datasets in finding the relevant latent dimensions and their effect on different evaluation metrics, such as FID score and disentanglement analysis.",
        "tags": [
            "Detection",
            "VAE"
        ]
    },
    {
        "id": "54",
        "title": "Fine-Grained Appropriate Reliance: Human-AI Collaboration with a Multi-Step Transparent Decision Workflow for Complex Task Decomposition",
        "author": [
            "Gaole He",
            "Patrick Hemmer",
            "Michael VÃ¶ssing",
            "Max Schemmer",
            "Ujwal Gadiraju"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10909",
        "abstract": "In recent years, the rapid development of AI systems has brought about the benefits of intelligent services but also concerns about security and reliability. By fostering appropriate user reliance on an AI system, both complementary team performance and reduced human workload can be achieved. Previous empirical studies have extensively analyzed the impact of factors ranging from task, system, and human behavior on user trust and appropriate reliance in the context of one-step decision making. However, user reliance on AI systems in tasks with complex semantics that require multi-step workflows remains under-explored. Inspired by recent work on task decomposition with large language models, we propose to investigate the impact of a novel Multi-Step Transparent (MST) decision workflow on user reliance behaviors. We conducted an empirical study (N = 233) of AI-assisted decision making in composite fact-checking tasks (i.e., fact-checking tasks that entail multiple sub-fact verification steps). Our findings demonstrate that human-AI collaboration with an MST decision workflow can outperform one-step collaboration in specific contexts (e.g., when advice from an AI system is misleading). Further analysis of the appropriate reliance at fine-grained levels indicates that an MST decision workflow can be effective when users demonstrate a relatively high consideration of the intermediate steps. Our work highlights that there is no one-size-fits-all decision workflow that can help obtain optimal human-AI collaboration. Our insights help deepen the understanding of the role of decision workflows in facilitating appropriate reliance. We synthesize important implications for designing effective means to facilitate appropriate reliance on AI systems in composite tasks, positioning opportunities for the human-centered AI and broader HCI communities.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "55",
        "title": "Know \"No\" Better: A Data-Driven Approach for Enhancing Negation Awareness in CLIP",
        "author": [
            "Junsung Park",
            "Jungbeom Lee",
            "Jongyoon Song",
            "Sangwon Yu",
            "Dahuin Jung",
            "Sungroh Yoon"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10913",
        "abstract": "While CLIP has significantly advanced multimodal understanding by bridging vision and language, the inability to grasp negation - such as failing to differentiate concepts like \"parking\" from \"no parking\" - poses substantial challenges. By analyzing the data used in the public CLIP model's pre-training, we posit this limitation stems from a lack of negation-inclusive data. To address this, we introduce data generation pipelines that employ a large language model (LLM) and a multimodal LLM to produce negation-inclusive captions. Fine-tuning CLIP with data generated from our pipelines, we develop NegationCLIP, which enhances negation awareness while preserving the generality. Moreover, to enable a comprehensive evaluation of negation understanding, we propose NegRefCOCOg-a benchmark tailored to test VLMs' ability to interpret negation across diverse expressions and positions within a sentence. Experiments on various CLIP architectures validate the effectiveness of our data generation pipelines in enhancing CLIP's ability to perceive negation accurately. Additionally, NegationCLIP's enhanced negation awareness has practical applications across various multimodal tasks, demonstrated by performance gains in text-to-image generation and referring image segmentation.",
        "tags": [
            "CLIP",
            "Segmentation",
            "Text-to-Image"
        ]
    },
    {
        "id": "56",
        "title": "LegalGuardian: A Privacy-Preserving Framework for Secure Integration of Large Language Models in Legal Practice",
        "author": [
            "M. Mikail Demir",
            "Hakan T. Otal",
            "M. Abdullah Canbaz"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10915",
        "abstract": "Large Language Models (LLMs) hold promise for advancing legal practice by automating complex tasks and improving access to justice. However, their adoption is limited by concerns over client confidentiality, especially when lawyers include sensitive Personally Identifiable Information (PII) in prompts, risking unauthorized data exposure. To mitigate this, we introduce LegalGuardian, a lightweight, privacy-preserving framework tailored for lawyers using LLM-based tools. LegalGuardian employs Named Entity Recognition (NER) techniques and local LLMs to mask and unmask confidential PII within prompts, safeguarding sensitive data before any external interaction. We detail its development and assess its effectiveness using a synthetic prompt library in immigration law scenarios. Comparing traditional NER models with one-shot prompted local LLM, we find that LegalGuardian achieves a F1-score of 93% with GLiNER and 97% with Qwen2.5-14B in PII detection. Semantic similarity analysis confirms that the framework maintains high fidelity in outputs, ensuring robust utility of LLM-based tools. Our findings indicate that legal professionals can harness advanced AI technologies without compromising client confidentiality or the quality of legal documents.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "57",
        "title": "A Semantic Approach to Successive Interference Cancellation for Multiple Access Networks",
        "author": [
            "Mingxiao Li",
            "Kaiming Shen",
            "Shuguang Cui"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10926",
        "abstract": "Differing from the conventional communication system paradigm that models information source as a sequence of (i.i.d. or stationary) random variables, the semantic approach aims at extracting and sending the high-level features of the content deeply contained in the source, thereby breaking the performance limits from the statistical information theory. As a pioneering work in this area, the deep learning-enabled semantic communication (DeepSC) constitutes a novel algorithmic framework based on the transformer--which is a deep learning tool widely used to process text numerically. The main goal of this work is to extend the DeepSC approach from the point-to-point link to the multi-user multiple access channel (MAC). The inter-user interference has long been identified as the bottleneck of the MAC. In the classic information theory, the successive interference cancellation (SIC) scheme is a common way to mitigate interference and achieve the channel capacity. Our main contribution is to incorporate the SIC scheme into the DeepSC. As opposed to the traditional SIC that removes interference in the digital symbol domain, the proposed semantic SIC works in the domain of the semantic word embedding vectors. Furthermore, to enhance the training efficiency, we propose a pretraining scheme and a partial retraining scheme that quickly adjust the neural network parameters when new users are added to the MAC. We also modify the existing loss function to facilitate training. Finally, we present numerical experiments to demonstrate the advantage of the proposed semantic approach as compared to the existing benchmark methods.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "58",
        "title": "Leveraging Chain of Thought towards Empathetic Spoken Dialogue without Corresponding Question-Answering Data",
        "author": [
            "Jingran Xie",
            "Shun Lei",
            "Yue Yu",
            "Yang Xiang",
            "Hui Wang",
            "Xixin Wu",
            "Zhiyong Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10937",
        "abstract": "Empathetic dialogue is crucial for natural human-computer interaction, allowing the dialogue system to respond in a more personalized and emotionally aware manner, improving user satisfaction and engagement. The emergence of large language models (LLMs) has revolutionized dialogue generation by harnessing their powerful capabilities and shown its potential in multimodal domains. Many studies have integrated speech with text-based LLMs to take speech question as input and output text response. However, the lack of spoken question-answering datasets that include speech style information to supervised fine-tuning (SFT) limits the performance of these systems. As a result, while these systems excel at understanding speech content, they often struggle to generate empathetic responses. In response, we propose a novel approach that circumvents the need for question-answering data, called Listen, Perceive, and Express (LPE). Our method employs a two-stage training process, initially guiding the LLM to listen the content and perceive the emotional aspects of speech. Subsequently, we utilize Chain-of-Thought (CoT) prompting to unlock the model's potential for expressing empathetic responses based on listened spoken content and perceived emotional cues. We employ experiments to prove the effectiveness of proposed method. To our knowledge, this is the first attempt to leverage CoT for speech-based dialogue.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "59",
        "title": "InsQABench: Benchmarking Chinese Insurance Domain Question Answering with Large Language Models",
        "author": [
            "Jing Ding",
            "Kai Feng",
            "Binbin Lin",
            "Jiarui Cai",
            "Qiushi Wang",
            "Yu Xie",
            "Xiaojin Zhang",
            "Zhongyu Wei",
            "Wei Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10943",
        "abstract": "The application of large language models (LLMs) has achieved remarkable success in various fields, but their effectiveness in specialized domains like the Chinese insurance industry remains underexplored. The complexity of insurance knowledge, encompassing specialized terminology and diverse data types, poses significant challenges for both models and users. To address this, we introduce InsQABench, a benchmark dataset for the Chinese insurance sector, structured into three categories: Insurance Commonsense Knowledge, Insurance Structured Database, and Insurance Unstructured Documents, reflecting real-world insurance question-answering http://tasks.We also propose two methods, SQL-ReAct and RAG-ReAct, to tackle challenges in structured and unstructured data tasks. Evaluations show that while LLMs struggle with domain-specific terminology and nuanced clause texts, fine-tuning on InsQABench significantly improves performance. Our benchmark establishes a solid foundation for advancing LLM applications in the insurance domain, with data and code available at https://github.com/HaileyFamo/InsQABench.git.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "60",
        "title": "Factor Graph-Based Active SLAM for Spacecraft Proximity Operations",
        "author": [
            "Lorenzo Ticozzi",
            "Panagiotis Tsiotras"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10950",
        "abstract": "We investigate a scenario where a chaser spacecraft or satellite equipped with a monocular camera navigates in close proximity to a target spacecraft. The satellite's primary objective is to construct a representation of the operational environment and localize itself within it, utilizing the available image data. We frame the joint task of state trajectory and map estimation as an instance of smoothing-based simultaneous localization and mapping (SLAM), where the underlying structure of the problem is represented as a factor graph. Rather than considering estimation and planning as separate tasks, we propose to control the camera observations to actively reduce the uncertainty of the estimation variables, the spacecraft state, and the map landmarks. This is accomplished by adopting an information-theoretic metric to reason about the impact of candidate actions on the evolution of the belief state. Numerical simulations indicate that the proposed method successfully captures the interplay between planning and estimation, hence yielding reduced uncertainty and higher accuracy when compared to commonly adopted passive sensing strategies.",
        "tags": [
            "SLAM"
        ]
    },
    {
        "id": "61",
        "title": "Open FinLLM Leaderboard: Towards Financial AI Readiness",
        "author": [
            "Shengyuan Colin Lin",
            "Felix Tian",
            "Keyi Wang",
            "Xingjian Zhao",
            "Jimin Huang",
            "Qianqian Xie",
            "Luca Borella",
            "Matt White",
            "Christina Dan Wang",
            "Kairong Xiao",
            "Xiao-Yang Liu Yanglet",
            "Li Deng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10963",
        "abstract": "Financial large language models (FinLLMs) with multimodal capabilities are envisioned to revolutionize applications across business, finance, accounting, and auditing. However, real-world adoption requires robust benchmarks of FinLLMs' and agents' performance. Maintaining an open leaderboard of models is crucial for encouraging innovative adoption and improving model effectiveness. In collaboration with Linux Foundation and Hugging Face, we create an open FinLLM leaderboard, which serves as an open platform for assessing and comparing LLMs' performance on a wide spectrum of financial tasks. By demoncratizing access to advanced AI tools and financial knowledge, a chatbot or agent may enhance the analytical capabilities of the general public to a professional-level within a few months of usage. This open leaderboard welcomes contributions from academia, open-source community, industry, and stakeholders. In particular, we encourage contributions of new datasets, tasks, and models for continual update. Through fostering a collaborative and open ecosystem, we seek to ensure the long-term sustainability and relevance of LLMs and agents as they evolve with the financial sector's needs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "62",
        "title": "The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs",
        "author": [
            "Nitay Calderon",
            "Roi Reichart",
            "Rotem Dror"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10970",
        "abstract": "The \"LLM-as-a-judge\" paradigm employs Large Language Models (LLMs) as annotators and evaluators in tasks traditionally performed by humans. LLM annotations are widely used, not only in NLP research but also in fields like medicine, psychology, and social science. Despite their role in shaping study results and insights, there is no standard or rigorous procedure to determine whether LLMs can replace human annotators. In this paper, we propose a novel statistical procedure -- the Alternative Annotator Test (alt-test) -- that requires only a modest subset of annotated examples to justify using LLM annotations. Additionally, we introduce a versatile and interpretable measure for comparing LLM judges. To demonstrate our procedure, we curated a diverse collection of ten datasets, consisting of language and vision-language tasks, and conducted experiments with six LLMs and four prompting techniques. Our results show that LLMs can sometimes replace humans with closed-source LLMs (such as GPT-4o), outperforming open-source LLMs, and that prompting techniques yield judges of varying quality. We hope this study encourages more rigorous and reliable practices.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "63",
        "title": "Control LLM: Controlled Evolution for Intelligence Retention in LLM",
        "author": [
            "Haichao Wei",
            "Yunxiang Ren",
            "Zhoutong Fu",
            "Aman Lunia",
            "Yi-Lin Chen",
            "Alice Leung",
            "Ya Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10979",
        "abstract": "Large Language Models (LLMs) demand significant computational resources, making it essential to enhance their capabilities without retraining from scratch. A key challenge in this domain is \\textit{catastrophic forgetting} (CF), which hampers performance during Continuous Pre-training (CPT) and Continuous Supervised Fine-Tuning (CSFT). We propose \\textbf{Control LLM}, a novel approach that leverages parallel pre-trained and expanded transformer blocks, aligning their hidden-states through interpolation strategies This method effectively preserves performance on existing tasks while seamlessly integrating new knowledge.\nExtensive experiments demonstrate the effectiveness of Control LLM in both CPT and CSFT. On Llama3.1-8B-Instruct, it achieves significant improvements in mathematical reasoning ($+14.4\\%$ on Math-Hard) and coding performance ($+10\\%$ on MBPP-PLUS). On Llama3.1-8B, it enhances multilingual capabilities ($+10.6\\%$ on C-Eval, $+6.8\\%$ on CMMLU, and $+30.2\\%$ on CMMLU-0shot-CoT). It surpasses existing methods and achieves SOTA among open-source models tuned from the same base model, using substantially less data and compute. Crucially, these gains are realized while preserving strong original capabilities, with minimal degradation ($<4.3\\% \\text{on MMLU}$) compared to $>35\\%$ in open-source Math and Coding models. This approach has been successfully deployed in LinkedIn's GenAI-powered job seeker and Ads unit products.\nTo support further research, we release the training and evaluation code (\\url{https://github.com/linkedin/ControlLLM}) along with models trained on public datasets (\\url{ https://huggingface.co/ControlLLM}) to the community.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "64",
        "title": "GREEN-CODE: Optimizing Energy Efficiency in Large Language Models for Code Generation",
        "author": [
            "Shashikant Ilager",
            "Lukas Florian Briem",
            "Ivona Brandic"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11006",
        "abstract": "Large Language Models (LLMs) are becoming integral to daily life, showcasing their vast potential across various Natural Language Processing (NLP) tasks. Beyond NLP, LLMs are increasingly used in software development tasks, such as code completion, modification, bug fixing, and code translation. Software engineers widely use tools like GitHub Copilot and Amazon Q, streamlining workflows and automating tasks with high accuracy. While the resource and energy intensity of LLM training is often highlighted, inference can be even more resource-intensive over time, as it's a continuous process with a high number of invocations. Therefore, developing resource-efficient alternatives for LLM inference is crucial for sustainability. This work proposes GREEN-CODE, a framework for energy-aware code generation in LLMs. GREEN-CODE performs dynamic early exit during LLM inference. We train a Reinforcement Learning (RL) agent that learns to balance the trade-offs between accuracy, latency, and energy consumption. Our approach is evaluated on two open-source LLMs, Llama 3.2 3B and OPT 2.7B, using the JavaCorpus and PY150 datasets. Results show that our method reduces the energy consumption between 23-50 % on average for code generation tasks without significantly affecting accuracy.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "65",
        "title": "Laplacian Eigenvector Centrality",
        "author": [
            "Koya Shimono",
            "Wataru Tamura"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11024",
        "abstract": "Networks significantly influence social, economic, and organizational outcomes, with centrality measures serving as crucial tools to capture the importance of individual nodes. This paper introduces Laplacian Eigenvector Centrality (LEC), a novel framework for network analysis based on spectral graph theory and the eigendecomposition of the Laplacian matrix. A distinctive feature of LEC is its adjustable parameter, the LEC order, which enables researchers to control and assess the scope of centrality measurement using the Laplacian spectrum. Using random graph models, LEC demonstrates robustness and scalability across diverse network structures. We connect LEC to equilibrium responses to external shocks in an economic model, showing how LEC quantifies agents' roles in attenuating shocks and facilitating coordinated responses through quadratic optimization. Finally, we apply LEC to the study of microfinance diffusion, illustrating how it complements classical centrality measures, such as eigenvector and Katz-Bonacich centralities, by capturing distinctive aspects of node positions within the network.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "66",
        "title": "AdaptiveLog: An Adaptive Log Analysis Framework with the Collaboration of Large and Small Language Model",
        "author": [
            "Lipeng Ma",
            "Weidong Yang",
            "Yixuan Li",
            "Ben Fei",
            "Mingjie Zhou",
            "Shuhao Li",
            "Sihang Jiang",
            "Bo Xu",
            "Yanghua Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11031",
        "abstract": "Automated log analysis is crucial to ensure high availability and reliability of complex systems. The advent of LLMs in NLP has ushered in a new era of language model-driven automated log analysis, garnering significant interest. Within this field, two primary paradigms based on language models for log analysis have become prominent. Small Language Models (SLMs) follow the pre-train and fine-tune paradigm, focusing on the specific log analysis task through fine-tuning on supervised datasets. On the other hand, LLMs following the in-context learning paradigm, analyze logs by providing a few examples in prompt contexts without updating parameters. Despite their respective strengths, we notice that SLMs are more cost-effective but less powerful, whereas LLMs with large parameters are highly powerful but expensive and inefficient. To trade-off between the performance and inference costs of both models in automated log analysis, this paper introduces an adaptive log analysis framework known as AdaptiveLog, which effectively reduces the costs associated with LLM while ensuring superior results. This framework collaborates an LLM and a small language model, strategically allocating the LLM to tackle complex logs while delegating simpler logs to the SLM. Specifically, to efficiently query the LLM, we propose an adaptive selection strategy based on the uncertainty estimation of the SLM, where the LLM is invoked only when the SLM is uncertain. In addition, to enhance the reasoning ability of the LLM in log analysis tasks, we propose a novel prompt strategy by retrieving similar error-prone cases as the reference, enabling the model to leverage past error experiences and learn solutions from these cases. Extensive experiments demonstrate that AdaptiveLog achieves state-of-the-art results across different tasks, elevating the overall accuracy of log analysis while maintaining cost efficiency.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "67",
        "title": "From Arabic Text to Puzzles: LLM-Driven Development of Arabic Educational Crosswords",
        "author": [
            "Kamyar Zeinalipour",
            "Mohamed Zaky Saad",
            "Marco Maggini",
            "Marco Gori"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11035",
        "abstract": "We present an Arabic crossword puzzle generator from a given text that utilizes advanced language models such as GPT-4-Turbo, GPT-3.5-Turbo and Llama3-8B-Instruct, specifically developed for educational purposes, this innovative generator leverages a meticulously compiled dataset named Arabic-Clue-Instruct with over 50,000 entries encompassing text, answers, clues, and categories. This dataset is intricately designed to aid in the generation of pertinent clues linked to specific texts and keywords within defined categories. This project addresses the scarcity of advanced educational tools tailored for the Arabic language, promoting enhanced language learning and cognitive development. By providing a culturally and linguistically relevant tool, our objective is to make learning more engaging and effective through gamification and interactivity. Integrating state-of-the-art artificial intelligence with contemporary learning methodologies, this tool can generate crossword puzzles from any given educational text, thereby facilitating an interactive and enjoyable learning experience. This tool not only advances educational paradigms but also sets a new standard in interactive and cognitive learning technologies. The model and dataset are publicly available.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "68",
        "title": "LF-Steering: Latent Feature Activation Steering for Enhancing Semantic Consistency in Large Language Models",
        "author": [
            "Jingyuan Yang",
            "Rongjun Li",
            "Weixuan Wang",
            "Ziyu Zhou",
            "Zhiyong Feng",
            "Wei Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11036",
        "abstract": "Large Language Models (LLMs) often generate inconsistent responses when prompted with semantically equivalent paraphrased inputs. Recently, activation steering, a technique that modulates LLM behavior by adjusting their latent representations during inference time, has been explored to improve the semantic consistency of LLMs. However, these methods typically operate at the model component level, such as layer hidden states or attention heads. They face a challenge due to the ``polysemanticity issue'', where the model components of LLMs typically encode multiple entangled features, making precise steering difficult. To address this challenge, we drill down to feature-level representations and propose LF-Steering, a novel activation steering approach to precisely identify latent feature representations responsible for semantic inconsistency. More specifically, our method maps the hidden states of relevant transformer layer into a sparsely activated, high-dimensional feature space based on a sparse autoencoder (SAE), ensuring model steering based on decoupled feature representations with minimal interference. Comprehensive experiments on both NLU and NLG datasets demonstrate the effectiveness of our method in enhancing semantic consistency, resulting in significant performance gains for various NLU and NLG tasks.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "69",
        "title": "Enhancing Semantic Consistency of Large Language Models through Model Editing: An Interpretability-Oriented Approach",
        "author": [
            "Jingyuan Yang",
            "Dapeng Chen",
            "Yajing Sun",
            "Rongjun Li",
            "Zhiyong Feng",
            "Wei Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11041",
        "abstract": "A Large Language Model (LLM) tends to generate inconsistent and sometimes contradictory outputs when presented with a prompt that has equivalent semantics but is expressed differently from the original prompt. To achieve semantic consistency of an LLM, one of the key approaches is to finetune the model with prompt-output pairs with semantically equivalent meanings. Despite its effectiveness, a data-driven finetuning method incurs substantial computation costs in data preparation and model optimization. In this regime, an LLM is treated as a ``black box'', restricting our ability to gain deeper insights into its internal mechanism. In this paper, we are motivated to enhance the semantic consistency of LLMs through a more interpretable method (i.e., model editing) to this end. We first identify the model components (i.e., attention heads) that have a key impact on the semantic consistency of an LLM. We subsequently inject biases into the output of these model components along the semantic-consistency activation direction. It is noteworthy that these modifications are cost-effective, without reliance on mass manipulations of the original model parameters. Through comprehensive experiments on the constructed NLU and open-source NLG datasets, our method demonstrates significant improvements in the semantic consistency and task performance of LLMs. Additionally, our method exhibits promising generalization capabilities by performing well on tasks beyond the primary tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "70",
        "title": "IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems",
        "author": [
            "Elad Levi",
            "Ilan Kadar"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11067",
        "abstract": "Large Language Models (LLMs) are transforming artificial intelligence, evolving into task-oriented systems capable of autonomous planning and execution. One of the primary applications of LLMs is conversational AI systems, which must navigate multi-turn dialogues, integrate domain-specific APIs, and adhere to strict policy constraints. However, evaluating these agents remains a significant challenge, as traditional methods fail to capture the complexity and variability of real-world interactions. We introduce IntellAgent, a scalable, open-source multi-agent framework designed to evaluate conversational AI systems comprehensively. IntellAgent automates the creation of diverse, synthetic benchmarks by combining policy-driven graph modeling, realistic event generation, and interactive user-agent simulations. This innovative approach provides fine-grained diagnostics, addressing the limitations of static and manually curated benchmarks with coarse-grained metrics. IntellAgent represents a paradigm shift in evaluating conversational AI. By simulating realistic, multi-policy scenarios across varying levels of complexity, IntellAgent captures the nuanced interplay of agent capabilities and policy constraints. Unlike traditional methods, it employs a graph-based policy model to represent relationships, likelihoods, and complexities of policy interactions, enabling highly detailed diagnostics. IntellAgent also identifies critical performance gaps, offering actionable insights for targeted optimization. Its modular, open-source design supports seamless integration of new domains, policies, and APIs, fostering reproducibility and community collaboration. Our findings demonstrate that IntellAgent serves as an effective framework for advancing conversational AI by addressing challenges in bridging research and deployment. The framework is available at https://github.com/plurai-ai/intellagent",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "71",
        "title": "Generative AI-driven Cross-layer Covert Communication: Fundamentals, Framework and Case Study",
        "author": [
            "Tianhao Liu",
            "Jiqiang Liu",
            "Tao Zhang",
            "Jian Wang",
            "Jiacheng Wang",
            "Jiawen Kang",
            "Dusit Niyato",
            "Shiwen Mao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11068",
        "abstract": "Ensuring end-to-end cross-layer communication security in military networks by selecting covert schemes between nodes is a key solution for military communication security.\nWith the development of communication technology, covert communication has expanded from the physical layer to the network and application layers, utilizing methods such as artificial noise, private networks, and semantic coding to transmit secret messages.\nHowever, as adversaries continuously eavesdrop on specific communication channels, the accumulation of sufficient data may reveal underlying patterns that influence concealment, and establishing a cross-layer covert communication mechanism emerges as an effective strategy to mitigate these regulatory challenges.\nIn this article, we first survey the communication security solution based on covert communication, specifically targeting three typical scenarios: device-to-device, private network communication, and public network communication, and analyze their application scopes.\nFurthermore, we propose an end-to-end cross-layer covert communication scheme driven by Generative Artificial Intelligence (GenAI), highlighting challenges and their solutions. Additionally, a case study is conducted using diffusion reinforcement learning to sovle cloud edge internet of things cross-layer secure communication.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "72",
        "title": "Can LLM Generate Regression Tests for Software Commits?",
        "author": [
            "Jing Liu",
            "Seongmin Lee",
            "Eleonora Losiouk",
            "Marcel BÃ¶hme"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11086",
        "abstract": "Large Language Models (LLMs) have shown tremendous promise in automated software engineering. In this paper, we investigate the opportunities of LLMs for automatic regression test generation for programs that take highly structured, human-readable inputs, such as XML parsers or JavaScript interpreters. Concretely, we explore the following regression test generation scenarios for such programs that have so far been difficult to test automatically in the absence of corresponding input grammars:\n$\\bullet$ Bug finding. Given a code change (e.g., a commit or pull request), our LLM-based approach generates a test case with the objective of revealing any bugs that might be introduced if that change is applied.\n$\\bullet$ Patch testing. Given a patch, our LLM-based approach generates a test case that fails before but passes after the patch. This test can be added to the regression test suite to catch similar bugs in the future.\nWe implement Cleverest, a feedback-directed, zero-shot LLM-based regression test generation technique, and evaluate its effectiveness on 22 commits to three subject programs: Mujs, Libxml2, and Poppler. For programs using more human-readable file formats, like XML or JavaScript, we found Cleverest performed very well. It generated easy-to-understand bug-revealing or bug-reproduction test cases for the majority of commits in just under three minutes -- even when only the code diff or commit message (unless it was too vague) was given. For programs with more compact file formats, like PDF, as expected, it struggled to generate effective test cases. However, the LLM-supplied test cases are not very far from becoming effective (e.g., when used as a seed by a greybox fuzzer or as a starting point by the developer).",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "73",
        "title": "RDG-GS: Relative Depth Guidance with Gaussian Splatting for Real-time Sparse-View 3D Rendering",
        "author": [
            "Chenlu Zhan",
            "Yufei Zhang",
            "Yu Lin",
            "Gaoang Wang",
            "Hongwei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11102",
        "abstract": "Efficiently synthesizing novel views from sparse inputs while maintaining accuracy remains a critical challenge in 3D reconstruction. While advanced techniques like radiance fields and 3D Gaussian Splatting achieve rendering quality and impressive efficiency with dense view inputs, they suffer from significant geometric reconstruction errors when applied to sparse input views. Moreover, although recent methods leverage monocular depth estimation to enhance geometric learning, their dependence on single-view estimated depth often leads to view inconsistency issues across different viewpoints. Consequently, this reliance on absolute depth can introduce inaccuracies in geometric information, ultimately compromising the quality of scene reconstruction with Gaussian splats. In this paper, we present RDG-GS, a novel sparse-view 3D rendering framework with Relative Depth Guidance based on 3D Gaussian Splatting. The core innovation lies in utilizing relative depth guidance to refine the Gaussian field, steering it towards view-consistent spatial geometric representations, thereby enabling the reconstruction of accurate geometric structures and capturing intricate textures. First, we devise refined depth priors to rectify the coarse estimated depth and insert global and fine-grained scene information to regular Gaussians. Building on this, to address spatial geometric inaccuracies from absolute depth, we propose relative depth guidance by optimizing the similarity between spatially correlated patches of depth and images. Additionally, we also directly deal with the sparse areas challenging to converge by the adaptive sampling for quick densification. Across extensive experiments on Mip-NeRF360, LLFF, DTU, and Blender, RDG-GS demonstrates state-of-the-art rendering quality and efficiency, making a significant advancement for real-world application.",
        "tags": [
            "3D",
            "Depth Estimation",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "74",
        "title": "ChaosEater: Fully Automating Chaos Engineering with Large Language Models",
        "author": [
            "Daisuke Kikuta",
            "Hiroki Ikeuchi",
            "Kengo Tajiri",
            "Yuusuke Nakano"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11107",
        "abstract": "Chaos Engineering (CE) is an engineering technique aimed at improving the resiliency of distributed systems. It involves artificially injecting specific failures into a distributed system and observing its behavior in response. Based on the observation, the system can be proactively improved to handle those failures. Recent CE tools realize the automated execution of predefined CE experiments. However, defining these experiments and reconfiguring the system after the experiments still remain manual. To reduce the costs of the manual operations, we propose \\textsc{ChaosEater}, a \\textit{system} for automating the entire CE operations with Large Language Models (LLMs). It pre-defines the general flow according to the systematic CE cycle and assigns subdivided operations within the flow to LLMs. We assume systems based on Infrastructure as Code (IaC), wherein the system configurations and artificial failures are managed through code. Hence, the LLMs' operations in our \\textit{system} correspond to software engineering tasks, including requirement definition, code generation and debugging, and testing. We validate our \\textit{system} through case studies on both small and large systems. The results demonstrate that our \\textit{system} significantly reduces both time and monetary costs while completing reasonable single CE cycles.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "75",
        "title": "Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective",
        "author": [
            "Yiyao Yu",
            "Yuxiang Zhang",
            "Dongdong Zhang",
            "Xiao Liang",
            "Hengyuan Zhang",
            "Xingxing Zhang",
            "Ziyi Yang",
            "Mahmoud Khademi",
            "Hany Awadalla",
            "Junjie Wang",
            "Yujiu Yang",
            "Furu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11110",
        "abstract": "Large Language Models (LLMs) have made notable progress in mathematical reasoning, yet they often rely on single-paradigm reasoning that limits their effectiveness across diverse tasks. In this paper, we introduce Chain-of-Reasoning (CoR), a novel unified framework that integrates multiple reasoning paradigms--Natural Language Reasoning (NLR), Algorithmic Reasoning (AR), and Symbolic Reasoning (SR)--to enable synergistic collaboration. CoR generates multiple potential answers using different reasoning paradigms and synthesizes them into a coherent final solution. We propose a Progressive Paradigm Training (PPT) strategy that allows models to progressively master these paradigms, culminating in the development of CoR-Math-7B. Experimental results demonstrate that CoR-Math-7B significantly outperforms current SOTA models, achieving up to a 41.0% absolute improvement over GPT-4 in theorem proving tasks and a 7.9% improvement over RL-based methods in arithmetic tasks. These results showcase the enhanced mathematical comprehensive ability of our model, achieving significant performance gains on specific tasks and enabling zero-shot generalization across tasks.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "76",
        "title": "OpenLiDARMap: Zero-Drift Point Cloud Mapping using Map Priors",
        "author": [
            "Dominik Kulmer",
            "Maximilian Leitenstern",
            "Marcel Weinmann",
            "Markus Lienkamp"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11111",
        "abstract": "Accurate localization is a critical component of mobile autonomous systems, especially in Global Navigation Satellite Systems (GNSS)-denied environments where traditional methods fail. In such scenarios, environmental sensing is essential for reliable operation. However, approaches such as LiDAR odometry and Simultaneous Localization and Mapping (SLAM) suffer from drift over long distances, especially in the absence of loop closures. Map-based localization offers a robust alternative, but the challenge lies in creating and georeferencing maps without GNSS support. To address this issue, we propose a method for creating georeferenced maps without GNSS by using publicly available data, such as building footprints and surface models derived from sparse aerial scans. Our approach integrates these data with onboard LiDAR scans to produce dense, accurate, georeferenced 3D point cloud maps. By combining an Iterative Closest Point (ICP) scan-to-scan and scan-to-map matching strategy, we achieve high local consistency without suffering from long-term drift. Thus, we eliminate the reliance on GNSS for the creation of georeferenced maps. The results demonstrate that LiDAR-only mapping can produce accurate georeferenced point cloud maps when augmented with existing map priors.",
        "tags": [
            "3D",
            "SLAM"
        ]
    },
    {
        "id": "77",
        "title": "Advanced technology in railway track monitoring using the GPR Technique: A Review",
        "author": [
            "Farhad Kooban",
            "Aleksandra RadliÅska",
            "Reza Mousapour",
            "Maryam Saraei"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11132",
        "abstract": "Subsurface evaluation of railway tracks is crucial for safe operation, as it allows for the early detection and remediation of potential structural weaknesses or defects that could lead to accidents or derailments. Ground Penetrating Radar (GPR) is an electromagnetic survey technique as advanced non-destructive technology (NDT) that can be used to monitor railway tracks. This technology is well-suited for railway applications due to the sub-layered composition of the track, which includes ties, ballast, sub-ballast, and subgrade regions. It can detect defects such as ballast pockets, fouled ballast, poor drainage, and subgrade settlement. The paper reviews recent works on advanced technology and interpretations of GPR data collected for different layers. Further, this paper demonstrates the current techniques for using synthetic modeling to calibrate real-world GPR data, enhancing accuracy in identifying subsurface features like ballast conditions and structural anomalies and applying various algorithms to refine GPR data analysis. These include Support Vector Machine (SVM) for classifying railway ballast types, Fuzzy C-means, and Generalized Regression Neural Networks for high-accuracy defect classification. Deep learning techniques, particularly Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) are also highlighted for their effectiveness in recognizing patterns associated with defects in GPR images. The article specifically focuses on the development of a Convolutional Recurrent Neural Network (CRNN) model, which combines CNN and RNN architectures for efficient processing of GPR data. This model demonstrates enhanced detection capabilities and faster processing compared to traditional object detection models like Faster R-CNN.",
        "tags": [
            "Detection",
            "RNN"
        ]
    },
    {
        "id": "78",
        "title": "Counteracting temporal attacks in Video Copy Detection",
        "author": [
            "Katarzyna Fojcik",
            "Piotr Syga"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11171",
        "abstract": "Video Copy Detection (VCD) plays a crucial role in copyright protection and content verification by identifying duplicates and near-duplicates in large-scale video databases. The META AI Challenge on video copy detection provided a benchmark for evaluating state-of-the-art methods, with the Dual-level detection approach emerging as a winning solution. This method integrates Video Editing Detection and Frame Scene Detection to handle adversarial transformations and large datasets efficiently. However, our analysis reveals significant limitations in the VED component, particularly in its ability to handle exact copies. Moreover, Dual-level detection shows vulnerability to temporal attacks. To address it, we propose an improved frame selection strategy based on local maxima of interframe differences, which enhances robustness against adversarial temporal modifications while significantly reducing computational overhead. Our method achieves an increase of 1.4 to 5.8 times in efficiency over the standard 1 FPS approach. Compared to Dual-level detection method, our approach maintains comparable micro-average precision ($\\mu$AP) while also demonstrating improved robustness against temporal attacks. Given 56\\% reduced representation size and the inference time of more than 2 times faster, our approach is more suitable to real-world resource restriction.",
        "tags": [
            "Detection",
            "Video Editing"
        ]
    },
    {
        "id": "79",
        "title": "ProKeR: A Kernel Perspective on Few-Shot Adaptation of Large Vision-Language Models",
        "author": [
            "Yassir Bendou",
            "Amine Ouasfi",
            "Vincent Gripon",
            "Adnane Boukhayma"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11175",
        "abstract": "The growing popularity of Contrastive Language-Image Pretraining (CLIP) has led to its widespread application in various visual downstream tasks. To enhance CLIP's effectiveness and versatility, efficient few-shot adaptation techniques have been widely adopted. Among these approaches, training-free methods, particularly caching methods exemplified by Tip-Adapter, have gained attention for their lightweight adaptation without the need for additional fine-tuning. In this paper, we revisit Tip-Adapter from a kernel perspective, showing that caching methods function as local adapters and are connected to a well-established kernel literature. Drawing on this insight, we offer a theoretical understanding of how these methods operate and suggest multiple avenues for enhancing the Tip-Adapter baseline. Notably, our analysis shows the importance of incorporating global information in local adapters. Therefore, we subsequently propose a global method that learns a proximal regularizer in a reproducing kernel Hilbert space (RKHS) using CLIP as a base learner. Our method, which we call ProKeR (Proximal Kernel ridge Regression), has a closed form solution and achieves state-of-the-art performances across 11 datasets in the standard few-shot adaptation benchmark.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "80",
        "title": "Can Safety Fine-Tuning Be More Principled? Lessons Learned from Cybersecurity",
        "author": [
            "David Williams-King",
            "Linh Le",
            "Adam Oberman",
            "Yoshua Bengio"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11183",
        "abstract": "As LLMs develop increasingly advanced capabilities, there is an increased need to minimize the harm that could be caused to society by certain model outputs; hence, most LLMs have safety guardrails added, for example via fine-tuning. In this paper, we argue the position that current safety fine-tuning is very similar to a traditional cat-and-mouse game (or arms race) between attackers and defenders in cybersecurity. Model jailbreaks and attacks are patched with bandaids to target the specific attack mechanism, but many similar attack vectors might remain. When defenders are not proactively coming up with principled mechanisms, it becomes very easy for attackers to sidestep any new defenses. We show how current defenses are insufficient to prevent new adversarial jailbreak attacks, reward hacking, and loss of control problems. In order to learn from past mistakes in cybersecurity, we draw analogies with historical examples and develop lessons learned that can be applied to LLM safety. These arguments support the need for new and more principled approaches to designing safe models, which are architected for security from the beginning. We describe several such approaches from the AI literature.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "81",
        "title": "Embedding-Driven Diversity Sampling to Improve Few-Shot Synthetic Data Generation",
        "author": [
            "Ivan Lopez",
            "Fateme Nateghi Haredasht",
            "Kaitlin Caoili",
            "Jonathan H Chen",
            "Akshay Chaudhari"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11199",
        "abstract": "Accurate classification of clinical text often requires fine-tuning pre-trained language models, a process that is costly and time-consuming due to the need for high-quality data and expert annotators. Synthetic data generation offers an alternative, though pre-trained models may not capture the syntactic diversity of clinical notes. We propose an embedding-driven approach that uses diversity sampling from a small set of real clinical notes to guide large language models in few-shot prompting, generating synthetic text that better reflects clinical syntax. We evaluated this method using the CheXpert dataset on a classification task, comparing it to random few-shot and zero-shot approaches. Using cosine similarity and a Turing test, our approach produced synthetic notes that more closely align with real clinical text. Our pipeline reduced the data needed to reach the 0.85 AUC cutoff by 40% for AUROC and 30% for AUPRC, while augmenting models with synthetic data improved AUROC by 57% and AUPRC by 68%. Additionally, our synthetic data was 0.9 times as effective as real data, a 60% improvement in value.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "82",
        "title": "Ditto: Accelerating Diffusion Model via Temporal Value Similarity",
        "author": [
            "Sungbin Kim",
            "Hyunwuk Lee",
            "Wonho Cho",
            "Mincheol Park",
            "Won Woo Ro"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11211",
        "abstract": "Diffusion models achieve superior performance in image generation tasks. However, it incurs significant computation overheads due to its iterative structure. To address these overheads, we analyze this iterative structure and observe that adjacent time steps in diffusion models exhibit high value similarity, leading to narrower differences between consecutive time steps. We adapt these characteristics to a quantized diffusion model and reveal that the majority of these differences can be represented with reduced bit-width, and even zero. Based on our observations, we propose the Ditto algorithm, a difference processing algorithm that leverages temporal similarity with quantization to enhance the efficiency of diffusion models. By exploiting the narrower differences and the distributive property of layer operations, it performs full bit-width operations for the initial time step and processes subsequent steps with temporal differences. In addition, Ditto execution flow optimization is designed to mitigate the memory overhead of temporal difference processing, further boosting the efficiency of the Ditto algorithm. We also design the Ditto hardware, a specialized hardware accelerator, fully exploiting the dynamic characteristics of the proposed algorithm. As a result, the Ditto hardware achieves up to 1.5x speedup and 17.74% energy saving compared to other accelerators.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "83",
        "title": "Reasoning Language Models: A Blueprint",
        "author": [
            "Maciej Besta",
            "Julia Barth",
            "Eric Schreiber",
            "Ales Kubicek",
            "Afonso Catarino",
            "Robert Gerstenberger",
            "Piotr Nyczyk",
            "Patrick Iff",
            "Yueling Li",
            "Sam Houliston",
            "Tomasz Sternal",
            "Marcin Copik",
            "Grzegorz KwaÅniewski",
            "JÃ¼rgen MÃ¼ller",
            "Åukasz Flis",
            "Hannes Eberhard",
            "Hubert Niewiadomski",
            "Torsten Hoefler"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11223",
        "abstract": "Reasoning language models (RLMs), also known as Large Reasoning Models (LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, have redefined AI's problem-solving capabilities by extending large language models (LLMs) with advanced reasoning mechanisms. Yet, their high costs, proprietary nature, and complex architectures - uniquely combining Reinforcement Learning (RL), search heuristics, and LLMs - present accessibility and scalability challenges. To address these, we propose a comprehensive blueprint that organizes RLM components into a modular framework, based on a survey and analysis of all RLM works. This blueprint incorporates diverse reasoning structures (chains, trees, graphs, and nested forms), reasoning strategies (e.g., Monte Carlo Tree Search, Beam Search), RL concepts (policy, value models and others), and supervision schemes (Output-Based and Process-Based Supervision). We also provide detailed mathematical formulations and algorithmic specifications to simplify RLM implementation. By showing how schemes like LLaMA-Berry, QwQ, Journey Learning, and Graph of Thoughts fit as special cases, we demonstrate the blueprint's versatility and unifying potential. To illustrate its utility, we introduce x1, a modular implementation for rapid RLM prototyping and experimentation. Using x1 and a literature review, we provide key insights, such as multi-phase training for policy and value models, and the importance of familiar training distributions. Finally, we outline how RLMs can integrate with a broader LLM ecosystem, including tools and databases. Our work demystifies RLM construction, democratizes advanced reasoning capabilities, and fosters innovation, aiming to mitigate the gap between \"rich AI\" and \"poor AI\" by lowering barriers to RLM development and experimentation.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "84",
        "title": "Successive Interference Cancellation-aided Diffusion Models for Joint Channel Estimation and Data Detection in Low Rank Channel Scenarios",
        "author": [
            "Sagnik Bhattacharya",
            "Muhammad Ahmed Mohsin",
            "Kamyar Rajabalifardi",
            "John M. Cioffi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11229",
        "abstract": "This paper proposes a novel joint channel-estimation and source-detection algorithm using successive interference cancellation (SIC)-aided generative score-based diffusion models. Prior work in this area focuses on massive MIMO scenarios, which are typically characterized by full-rank channels, and fail in low-rank channel scenarios. The proposed algorithm outperforms existing methods in joint source-channel estimation, especially in low-rank scenarios where the number of users exceeds the number of antennas at the access point (AP). The proposed score-based iterative diffusion process estimates the gradient of the prior distribution on partial channels, and recursively updates the estimated channel parts as well as the source. Extensive simulation results show that the proposed method outperforms the baseline methods in terms of normalized mean squared error (NMSE) and symbol error rate (SER) in both full-rank and low-rank channel scenarios, while having a more dominant effect in the latter, at various signal-to-noise ratios (SNR).",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "85",
        "title": "PlotEdit: Natural Language-Driven Accessible Chart Editing in PDFs via Multimodal LLM Agents",
        "author": [
            "Kanika Goswami",
            "Puneet Mathur",
            "Ryan Rossi",
            "Franck Dernoncourt"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11233",
        "abstract": "Chart visualizations, while essential for data interpretation and communication, are predominantly accessible only as images in PDFs, lacking source data tables and stylistic information. To enable effective editing of charts in PDFs or digital scans, we present PlotEdit, a novel multi-agent framework for natural language-driven end-to-end chart image editing via self-reflective LLM agents. PlotEdit orchestrates five LLM agents: (1) Chart2Table for data table extraction, (2) Chart2Vision for style attribute identification, (3) Chart2Code for retrieving rendering code, (4) Instruction Decomposition Agent for parsing user requests into executable steps, and (5) Multimodal Editing Agent for implementing nuanced chart component modifications - all coordinated through multimodal feedback to maintain visual fidelity. PlotEdit outperforms existing baselines on the ChartCraft dataset across style, layout, format, and data-centric edits, enhancing accessibility for visually challenged users and improving novice productivity.",
        "tags": [
            "Image Editing"
        ]
    },
    {
        "id": "86",
        "title": "A New Formulation of Lipschitz Constrained With Functional Gradient Learning for GANs",
        "author": [
            "Chang Wan",
            "Ke Fan",
            "Xinwei Sun",
            "Yanwei Fu",
            "Minglu Li",
            "Yunliang Jiang",
            "Zhonglong Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11236",
        "abstract": "This paper introduces a promising alternative method for training Generative Adversarial Networks (GANs) on large-scale datasets with clear theoretical guarantees. GANs are typically learned through a minimax game between a generator and a discriminator, which is known to be empirically unstable. Previous learning paradigms have encountered mode collapse issues without a theoretical solution. To address these challenges, we propose a novel Lipschitz-constrained Functional Gradient GANs learning (Li-CFG) method to stabilize the training of GAN and provide a theoretical foundation for effectively increasing the diversity of synthetic samples by reducing the neighborhood size of the latent vector. Specifically, we demonstrate that the neighborhood size of the latent vector can be reduced by increasing the norm of the discriminator gradient, resulting in enhanced diversity of synthetic samples. To efficiently enlarge the norm of the discriminator gradient, we introduce a novel {\\epsilon}-centered gradient penalty that amplifies the norm of the discriminator gradient using the hyper-parameter {\\epsilon}. In comparison to other constraints, our method enlarging the discriminator norm, thus obtaining the smallest neighborhood size of the latent vector. Extensive experiments on benchmark datasets for image generation demonstrate the efficacy of the Li-CFG method and the {\\epsilon}-centered gradient penalty. The results showcase improved stability and increased diversity of synthetic samples.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "87",
        "title": "WSSM: Geographic-enhanced hierarchical state-space model for global station weather forecast",
        "author": [
            "Songru Yang",
            "Zili Liu",
            "Zhenwei Shi",
            "Zhengxia Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11238",
        "abstract": "Global Station Weather Forecasting (GSWF), a prominent meteorological research area, is pivotal in providing timely localized weather predictions. Despite the progress existing models have made in the overall accuracy of the GSWF, executing high-precision extreme event prediction still presents a substantial challenge. The recent emergence of state-space models, with their ability to efficiently capture continuous-time dynamics and latent states, offer potential solutions. However, early investigations indicated that Mamba underperforms in the context of GSWF, suggesting further adaptation and optimization. To tackle this problem, in this paper, we introduce Weather State-space Model (WSSM), a novel Mamba-based approach tailored for GSWF. Geographical knowledge is integrated in addition to the widely-used positional encoding to represent the absolute special-temporal position. The multi-scale time-frequency features are synthesized from coarse to fine to model the seasonal to extreme weather dynamic. Our method effectively improves the overall prediction accuracy and addresses the challenge of forecasting extreme weather events. The state-of-the-art results obtained on the Weather-5K subset underscore the efficacy of the WSSM",
        "tags": [
            "Mamba",
            "State Space Models"
        ]
    },
    {
        "id": "88",
        "title": "Irony in Emojis: A Comparative Study of Human and LLM Interpretation",
        "author": [
            "Yawen Zheng",
            "Hanjia Lyu",
            "Jiebo Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11241",
        "abstract": "Emojis have become a universal language in online communication, often carrying nuanced and context-dependent meanings. Among these, irony poses a significant challenge for Large Language Models (LLMs) due to its inherent incongruity between appearance and intent. This study examines the ability of GPT-4o to interpret irony in emojis. By prompting GPT-4o to evaluate the likelihood of specific emojis being used to express irony on social media and comparing its interpretations with human perceptions, we aim to bridge the gap between machine and human understanding. Our findings reveal nuanced insights into GPT-4o's interpretive capabilities, highlighting areas of alignment with and divergence from human behavior. Additionally, this research underscores the importance of demographic factors, such as age and gender, in shaping emoji interpretation and evaluates how these factors influence GPT-4o's performance.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "89",
        "title": "Multivariate Wireless Link Quality Prediction Based on Pre-trained Large Language Models",
        "author": [
            "Zhuangzhuang Yan",
            "Xinyu Gu",
            "Shilong Fan",
            "Zhenyu Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11247",
        "abstract": "Accurate and reliable link quality prediction (LQP) is crucial for optimizing network performance, ensuring communication stability, and enhancing user experience in wireless communications. However, LQP faces significant challenges due to the dynamic and lossy nature of wireless links, which are influenced by interference, multipath effects, fading, and blockage. In this paper, we propose GAT-LLM, a novel multivariate wireless link quality prediction model that combines Large Language Models (LLMs) with Graph Attention Networks (GAT) to enable accurate and reliable multivariate LQP of wireless communications. By framing LQP as a time series prediction task and appropriately preprocessing the input data, we leverage LLMs to improve the accuracy of link quality prediction. To address the limitations of LLMs in multivariate prediction due to typically handling one-dimensional data, we integrate GAT to model interdependencies among multiple variables across different protocol layers, enhancing the model's ability to handle complex dependencies. Experimental results demonstrate that GAT-LLM significantly improves the accuracy and robustness of link quality prediction, particularly in multi-step prediction scenarios.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "90",
        "title": "Code Readability in the Age of Large Language Models: An Industrial Case Study from Atlassian",
        "author": [
            "Wannita Takerngsaksiri",
            "Micheal Fu",
            "Chakkrit Tantithamthavorn",
            "Jirat Pasuksmit",
            "Kun Chen",
            "Ming Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11264",
        "abstract": "Programmers spend a significant amount of time reading code during the software development process. This trend is amplified by the emergence of large language models (LLMs) that automatically generate code. However, little is known about the readability of the LLM-generated code and whether it is still important from practitioners' perspectives in this new era. In this paper, we conduct a survey to explore the practitioners' perspectives on code readability in the age of LLMs and investigate the readability of our LLM-based software development agents framework, HULA, by comparing its generated code with human-written code in real-world scenarios. Overall, the findings underscore that (1) readability remains a critical aspect of software development; (2) the readability of our LLM-generated code is comparable to human-written code, fostering the establishment of appropriate trust and driving the broad adoption of our LLM-powered software development platform.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "91",
        "title": "Can xLLMs Understand the Structure of Dialog? Exploring Multilingual Response Generation in Complex Scenarios",
        "author": [
            "Zhongtian Hu",
            "Yiwen Cui",
            "Ronghan Li",
            "Meng Zhao",
            "Lifang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11269",
        "abstract": "Multilingual research has garnered increasing attention, especially in the domain of dialogue systems. The rapid advancements in large language models (LLMs) have fueled the demand for high-performing multilingual models. However, two major challenges persist: the scarcity of high-quality multilingual datasets and the limited complexity of existing datasets in capturing realistic dialogue scenarios. To address these gaps, we introduce XMP, a high-quality parallel Multilingual dataset sourced from Multi-party Podcast dialogues. Each sample in the dataset features at least three participants discussing a wide range of topics, including society, culture, politics, and http://entertainment.Through extensive experiments, we uncover significant limitations in previously recognized multilingual capabilities of LLMs when applied to such complex dialogue scenarios. For instance, the widely accepted multilingual complementary ability of LLMs is notably impacted. By conducting further experiments, we explore the mechanisms of LLMs in multilingual environments from multiple perspectives, shedding new light on their performance in real-world, diverse conversational contexts.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "92",
        "title": "Multi-round, Chain-of-thought Post-editing for Unfaithful Summaries",
        "author": [
            "Yi-Hui Lee",
            "Xiangci Li",
            "Jessica Ouyang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11273",
        "abstract": "Recent large language models (LLMs) have demonstrated a remarkable ability to perform natural language understanding and generation tasks. In this work, we investigate the use of LLMs for evaluating faithfulness in news summarization, finding that it achieves a strong correlation with human judgments. We further investigate LLMs' capabilities as a faithfulness post-editor, experimenting with different chain-of-thought prompts for locating and correcting factual inconsistencies between a generated summary and the source news document and are able to achieve a higher editing success rate than was reported in prior work. We perform both automated and human evaluations of the post-edited summaries, finding that prompting LLMs using chain-of-thought reasoning about factual error types is an effective faithfulness post-editing strategy, performing comparably to fine-tuned post-editing models. We also demonstrate that multiple rounds of post-editing, which has not previously been explored, can be used to gradually improve the faithfulness of summaries whose errors cannot be fully corrected in a single round.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "93",
        "title": "RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?",
        "author": [
            "Haotian Xu",
            "Xing Wu",
            "Weinong Wang",
            "Zhongzhi Li",
            "Da Zheng",
            "Boyuan Chen",
            "Yi Hu",
            "Shijia Kang",
            "Jiaming Ji",
            "Yingying Zhang",
            "Zhijiang Guo",
            "Yaodong Yang",
            "Muhan Zhang",
            "Debing Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11284",
        "abstract": "Can scaling transform reasoning? In this work, we explore the untapped potential of scaling Long Chain-of-Thought (Long-CoT) data to 1000k samples, pioneering the development of a slow-thinking model, RedStar. Through extensive experiments with various LLMs and different sizes, we uncover the ingredients for specialization and scale for Long-CoT training. Surprisingly, even smaller models show significant performance gains with limited data, revealing the sample efficiency of Long-CoT and the critical role of sample difficulty in the learning process. Our findings demonstrate that Long-CoT reasoning can be effectively triggered with just a few thousand examples, while larger models achieve unparalleled improvements. We also introduce reinforcement learning (RL)-scale training as a promising direction for advancing slow-thinking systems. RedStar shines across domains: on the MATH-Hard benchmark, RedStar-code-math boosts performance from 66.2\\% to 81.6\\%, and on the USA Math Olympiad (AIME), it solves 46.7\\% of problems using only 21k mixed-code-math datasets. In multimodal tasks like GeoQA and MathVista-GEO, RedStar-Geo achieves competitive results with minimal Long-CoT data, outperforming other slow-thinking systems like QvQ-Preview. Compared to QwQ, RedStar strikes the perfect balance between reasoning and generalizability. Our work highlights that, with careful tuning, scaling Long-CoT can unlock extraordinary reasoning capabilities-even with limited dataset and set a new standard for slow-thinking models across diverse challenges. Our data and models are released at https://huggingface.co/RedStar-Reasoning.",
        "tags": [
            "LLMs",
            "RL"
        ]
    },
    {
        "id": "94",
        "title": "Hybrid Photonic-digital Accelerator for Attention Mechanism",
        "author": [
            "Huize Li",
            "Dan Chen",
            "Tulika Mitra"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11286",
        "abstract": "The wide adoption and substantial computational resource requirements of attention-based Transformers have spurred the demand for efficient hardware accelerators. Unlike digital-based accelerators, there is growing interest in exploring photonics due to its high energy efficiency and ultra-fast processing speeds. However, the significant signal conversion overhead limits the performance of photonic-based accelerators. In this work, we propose HyAtten, a photonic-based attention accelerator with minimize signal conversion overhead. HyAtten incorporates a signal comparator to classify signals into two categories based on whether they can be processed by low-resolution converters. HyAtten integrates low-resolution converters to process all low-resolution signals, thereby boosting the parallelism of photonic computing. For signals requiring high-resolution conversion, HyAtten uses digital circuits instead of signal converters to reduce area and latency overhead. Compared to state-of-the-art photonic-based Transformer accelerator, HyAtten achieves 9.8X performance/area and 2.2X energy-efficiency/area improvement.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "95",
        "title": "Nested Annealed Training Scheme for Generative Adversarial Networks",
        "author": [
            "Chang Wan",
            "Ming-Hsuan Yang",
            "Minglu Li",
            "Yunliang Jiang",
            "Zhonglong Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11318",
        "abstract": "Recently, researchers have proposed many deep generative models, including generative adversarial networks(GANs) and denoising diffusion models. Although significant breakthroughs have been made and empirical success has been achieved with the GAN, its mathematical underpinnings remain relatively unknown. This paper focuses on a rigorous mathematical theoretical framework: the composite-functional-gradient GAN (CFG)[1]. Specifically, we reveal the theoretical connection between the CFG model and score-based models. We find that the training objective of the CFG discriminator is equivalent to finding an optimal D(x). The optimal gradient of D(x) differentiates the integral of the differences between the score functions of real and synthesized samples. Conversely, training the CFG generator involves finding an optimal G(x) that minimizes this difference. In this paper, we aim to derive an annealed weight preceding the weight of the CFG discriminator. This new explicit theoretical explanation model is called the annealed CFG method. To overcome the limitation of the annealed CFG method, as the method is not readily applicable to the SOTA GAN model, we propose a nested annealed training scheme (NATS). This scheme keeps the annealed weight from the CFG method and can be seamlessly adapted to various GAN models, no matter their structural, loss, or regularization differences. We conduct thorough experimental evaluations on various benchmark datasets for image generation. The results show that our annealed CFG and NATS methods significantly improve the quality and diversity of the synthesized samples. This improvement is clear when comparing the CFG method and the SOTA GAN models.",
        "tags": [
            "Diffusion",
            "GAN"
        ]
    },
    {
        "id": "96",
        "title": "StyleSSP: Sampling StartPoint Enhancement for Training-free Diffusion-based Method for Style Transfer",
        "author": [
            "Ruojun Xu",
            "Weijie Xi",
            "Xiaodi Wang",
            "Yongbo Mao",
            "Zach Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11319",
        "abstract": "Training-free diffusion-based methods have achieved remarkable success in style transfer, eliminating the need for extensive training or fine-tuning. However, due to the lack of targeted training for style information extraction and constraints on the content image layout, training-free methods often suffer from layout changes of original content and content leakage from style images. Through a series of experiments, we discovered that an effective startpoint in the sampling stage significantly enhances the style transfer process. Based on this discovery, we propose StyleSSP, which focuses on obtaining a better startpoint to address layout changes of original content and content leakage from style image. StyleSSP comprises two key components: (1) Frequency Manipulation: To improve content preservation, we reduce the low-frequency components of the DDIM latent, allowing the sampling stage to pay more attention to the layout of content images; and (2) Negative Guidance via Inversion: To mitigate the content leakage from style image, we employ negative guidance in the inversion stage to ensure that the startpoint of the sampling stage is distanced from the content of style image. Experiments show that StyleSSP surpasses previous training-free style transfer baselines, particularly in preserving original content and minimizing the content leakage from style image.",
        "tags": [
            "DDIM",
            "Diffusion",
            "Style Transfer"
        ]
    },
    {
        "id": "97",
        "title": "CatV2TON: Taming Diffusion Transformers for Vision-Based Virtual Try-On with Temporal Concatenation",
        "author": [
            "Zheng Chong",
            "Wenqing Zhang",
            "Shiyue Zhang",
            "Jun Zheng",
            "Xiao Dong",
            "Haoxiang Li",
            "Yiling Wu",
            "Dongmei Jiang",
            "Xiaodan Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11325",
        "abstract": "Virtual try-on (VTON) technology has gained attention due to its potential to transform online retail by enabling realistic clothing visualization of images and videos. However, most existing methods struggle to achieve high-quality results across image and video try-on tasks, especially in long video scenarios. In this work, we introduce CatV2TON, a simple and effective vision-based virtual try-on (V2TON) method that supports both image and video try-on tasks with a single diffusion transformer model. By temporally concatenating garment and person inputs and training on a mix of image and video datasets, CatV2TON achieves robust try-on performance across static and dynamic settings. For efficient long-video generation, we propose an overlapping clip-based inference strategy that uses sequential frame guidance and Adaptive Clip Normalization (AdaCN) to maintain temporal consistency with reduced resource demands. We also present ViViD-S, a refined video try-on dataset, achieved by filtering back-facing frames and applying 3D mask smoothing for enhanced temporal consistency. Comprehensive experiments demonstrate that CatV2TON outperforms existing methods in both image and video try-on tasks, offering a versatile and reliable solution for realistic virtual try-ons across diverse scenarios.",
        "tags": [
            "3D",
            "CLIP",
            "Diffusion",
            "Diffusion Transformer",
            "Transformer",
            "Video Generation",
            "Virtual Try-On"
        ]
    },
    {
        "id": "98",
        "title": "Few-shot Policy (de)composition in Conversational Question Answering",
        "author": [
            "Kyle Erwin",
            "Guy Axelrod",
            "Maria Chang",
            "Achille Fokoue",
            "Maxwell Crouse",
            "Soham Dan",
            "Tian Gao",
            "Rosario Uceda-Sosa",
            "Ndivhuwo Makondo",
            "Naweed Khan",
            "Alexander Gray"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11335",
        "abstract": "The task of policy compliance detection (PCD) is to determine if a scenario is in compliance with respect to a set of written policies. In a conversational setting, the results of PCD can indicate if clarifying questions must be asked to determine compliance status. Existing approaches usually claim to have reasoning capabilities that are latent or require a large amount of annotated data. In this work, we propose logical decomposition for policy compliance (LDPC): a neuro-symbolic framework to detect policy compliance using large language models (LLMs) in a few-shot setting. By selecting only a few exemplars alongside recently developed prompting techniques, we demonstrate that our approach soundly reasons about policy compliance conversations by extracting sub-questions to be answered, assigning truth values from contextual information, and explicitly producing a set of logic statements from the given policies. The formulation of explicit logic graphs can in turn help answer PCDrelated questions with increased transparency and explainability. We apply this approach to the popular PCD and conversational machine reading benchmark, ShARC, and show competitive performance with no task-specific finetuning. We also leverage the inherently interpretable architecture of LDPC to understand where errors occur, revealing ambiguities in the ShARC dataset and highlighting the challenges involved with reasoning for conversational question answering.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "99",
        "title": "GenVidBench: A Challenging Benchmark for Detecting AI-Generated Video",
        "author": [
            "Zhenliang Ni",
            "Qiangyu Yan",
            "Mouxiao Huang",
            "Tianning Yuan",
            "Yehui Tang",
            "Hailin Hu",
            "Xinghao Chen",
            "Yunhe Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11340",
        "abstract": "The rapid advancement of video generation models has made it increasingly challenging to distinguish AI-generated videos from real ones. This issue underscores the urgent need for effective AI-generated video detectors to prevent the dissemination of false information through such videos. However, the development of high-performance generative video detectors is currently impeded by the lack of large-scale, high-quality datasets specifically designed for generative video detection. To this end, we introduce GenVidBench, a challenging AI-generated video detection dataset with several key advantages: 1) Cross Source and Cross Generator: The cross-generation source mitigates the interference of video content on the detection. The cross-generator ensures diversity in video attributes between the training and test sets, preventing them from being overly similar. 2) State-of-the-Art Video Generators: The dataset includes videos from 8 state-of-the-art AI video generators, ensuring that it covers the latest advancements in the field of video generation. 3) Rich Semantics: The videos in GenVidBench are analyzed from multiple dimensions and classified into various semantic categories based on their content. This classification ensures that the dataset is not only large but also diverse, aiding in the development of more generalized and effective detection models. We conduct a comprehensive evaluation of different advanced video generators and present a challenging setting. Additionally, we present rich experimental results including advanced video classification models as baselines. With the GenVidBench, researchers can efficiently develop and evaluate AI-generated video detection models. Datasets and code are available at https://genvidbench.github.io.",
        "tags": [
            "Detection",
            "Video Generation"
        ]
    },
    {
        "id": "100",
        "title": "EndoChat: Grounded Multimodal Large Language Model for Endoscopic Surgery",
        "author": [
            "Guankun Wang",
            "Long Bai",
            "Junyi Wang",
            "Kun Yuan",
            "Zhen Li",
            "Tianxu Jiang",
            "Xiting He",
            "Jinlin Wu",
            "Zhen Chen",
            "Zhen Lei",
            "Hongbin Liu",
            "Jiazheng Wang",
            "Fan Zhang",
            "Nicolas Padoy",
            "Nassir Navab",
            "Hongliang Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11347",
        "abstract": "Recently, Multimodal Large Language Models (MLLMs) have demonstrated their immense potential in computer-aided diagnosis and decision-making. In the context of robotic-assisted surgery, MLLMs can serve as effective tools for surgical training and guidance. However, there is still a lack of MLLMs specialized for surgical scene understanding in clinical applications. In this work, we introduce EndoChat to address various dialogue paradigms and subtasks in surgical scene understanding that surgeons encounter. To train our EndoChat, we construct the Surg-396K dataset through a novel pipeline that systematically extracts surgical information and generates structured annotations based on collected large-scale endoscopic surgery datasets. Furthermore, we introduce a multi-scale visual token interaction mechanism and a visual contrast-based reasoning mechanism to enhance the model's representation learning and reasoning capabilities. Our model achieves state-of-the-art performance across five dialogue paradigms and eight surgical scene understanding tasks. Additionally, we conduct evaluations with professional surgeons, most of whom provide positive feedback on collaborating with EndoChat. Overall, these results demonstrate that our EndoChat has great potential to significantly advance training and automation in robotic-assisted surgery.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "101",
        "title": "Adaptive parameters identification for nonlinear dynamics using deep permutation invariant networks",
        "author": [
            "Mouad Elaarabi",
            "Domenico Borzacchiello",
            "Yves Le Guennec",
            "Philippe Le Bot",
            "Sebastien Comas-Cardona"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11350",
        "abstract": "The promising outcomes of dynamical system identification techniques, such as SINDy [Brunton et al. 2016], highlight their advantages in providing qualitative interpretability and extrapolation compared to non-interpretable deep neural networks [Rudin 2019]. These techniques suffer from parameter updating in real-time use cases, especially when the system parameters are likely to change during or between processes. Recently, the OASIS [Bhadriraju et al. 2020] framework introduced a data-driven technique to address the limitations of real-time dynamical system parameters updating, yielding interesting results. Nevertheless, we show in this work that superior performance can be achieved using more advanced model architectures. We present an innovative encoding approach, based mainly on the use of Set Encoding methods of sequence data, which give accurate adaptive model identification for complex dynamic systems, with variable input time series length. Two Set Encoding methods are used, the first is Deep Set [Zaheer et al. 2017], and the second is Set Transformer [Lee et al. 2019]. Comparing Set Transformer to OASIS framework on Lotka Volterra for real-time local dynamical system identification and time series forecasting, we find that the Set Transformer architecture is well adapted to learning relationships within data sets. We then compare the two Set Encoding methods based on the Lorenz system for online global dynamical system identification. Finally, we trained a Deep Set model to perform identification and characterization of abnormalities for 1D heat-transfer problem.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "102",
        "title": "Towards Advancing Code Generation with Large Language Models: A Research Roadmap",
        "author": [
            "Haolin Jin",
            "Huaming Chen",
            "Qinghua Lu",
            "Liming Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11354",
        "abstract": "Recently, we have witnessed the rapid development of large language models, which have demonstrated excellent capabilities in the downstream task of code generation. However, despite their potential, LLM-based code generation still faces numerous technical and evaluation challenges, particularly when embedded in real-world development. In this paper, we present our vision for current research directions, and provide an in-depth analysis of existing studies on this task. We propose a six-layer vision framework that categorizes code generation process into distinct phases, namely Input Phase, Orchestration Phase, Development Phase, and Validation Phase. Additionally, we outline our vision workflow, which reflects on the currently prevalent frameworks. We systematically analyse the challenges faced by large language models, including those LLM-based agent frameworks, in code generation tasks. With these, we offer various perspectives and actionable recommendations in this area. Our aim is to provide guidelines for improving the reliability, robustness and usability of LLM-based code generation systems. Ultimately, this work seeks to address persistent challenges and to provide practical suggestions for a more pragmatic LLM-based solution for future code generation endeavors.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "103",
        "title": "Block Flow: Learning Straight Flow on Data Blocks",
        "author": [
            "Zibin Wang",
            "Zhiyuan Ouyang",
            "Xiangyun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11361",
        "abstract": "Flow-matching models provide a powerful framework for various applications, offering efficient sampling and flexible probability path modeling. These models are characterized by flows with low curvature in learned generative trajectories, which results in reduced truncation error at each sampling step. To further reduce curvature, we propose block matching. This novel approach leverages label information to partition the data distribution into blocks and match them with a prior distribution parameterized using the same label information, thereby learning straighter flows. We demonstrate that the variance of the prior distribution can control the curvature upper bound of forward trajectories in flow-matching models. By designing flexible regularization strategies to adjust this variance, we achieve optimal generation performance, effectively balancing the trade-off between maintaining diversity in generated samples and minimizing numerical solver errors. Our results demonstrate competitive performance with models of the same parameter http://scale.Code is available at \\url{https://github.com/wpp13749/block_flow}.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "104",
        "title": "Beyond the Hype: Benchmarking LLM-Evolved Heuristics for Bin Packing",
        "author": [
            "Kevin Sim",
            "Quentin Renau",
            "Emma Hart"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11411",
        "abstract": "Coupling Large Language Models (LLMs) with Evolutionary Algorithms has recently shown significant promise as a technique to design new heuristics that outperform existing methods, particularly in the field of combinatorial optimisation. An escalating arms race is both rapidly producing new heuristics and improving the efficiency of the processes evolving them. However, driven by the desire to quickly demonstrate the superiority of new approaches, evaluation of the new heuristics produced for a specific domain is often cursory: testing on very few datasets in which instances all belong to a specific class from the domain, and on few instances per class. Taking bin-packing as an example, to the best of our knowledge we conduct the first rigorous benchmarking study of new LLM-generated heuristics, comparing them to well-known existing heuristics across a large suite of benchmark instances using three performance metrics. For each heuristic, we then evolve new instances won by the heuristic and perform an instance space analysis to understand where in the feature space each heuristic performs well. We show that most of the LLM heuristics do not generalise well when evaluated across a broad range of benchmarks in contrast to existing simple heuristics, and suggest that any gains from generating very specialist heuristics that only work in small areas of the instance space need to be weighed carefully against the considerable cost of generating these heuristics.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "105",
        "title": "Neural Contextual Reinforcement Framework for Logical Structure Language Generation",
        "author": [
            "Marcus Irvin",
            "William Cooper",
            "Edward Hughes",
            "Jessica Morgan",
            "Christopher Hamilton"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11417",
        "abstract": "The Neural Contextual Reinforcement Framework introduces an innovative approach to enhancing the logical coherence and structural consistency of text generated by large language models. Leveraging reinforcement learning principles, the framework integrates custom reward functions and dynamic context alignment mechanisms to address challenges inherent in maintaining long-range dependencies across extended sequences. The architecture incorporates multi-head attention layers and hierarchical encoding modules, enabling the model to produce outputs that align closely with human expectations of logical structure and semantic flow. Quantitative evaluations across diverse datasets demonstrate substantial improvements in coherence metrics, perplexity reduction, and semantic alignment, showcasing the framework's ability to outperform baseline models in both general and domain-specific tasks. Qualitative analyses further highlight the framework's capacity to generate text with improved narrative clarity and reduced redundancy, reflecting its effectiveness in balancing fluency with structural precision. In addition to its performance gains, the framework exhibits robustness in handling noisy input data and scalability across varying model sizes, reinforcing its versatility in practical applications. Experimental results reveal that optimal context window sizes significantly influence coherence outcomes, showing the importance of architectural flexibility in adapting to diverse linguistic structures. Cross-lingual performance evaluations affirm the framework's adaptability to multiple languages, extending its utility beyond monolingual contexts. Resource efficiency analyses indicate a reduction in computational overhead compared to traditional approaches, emphasizing the practicality of the framework for large-scale deployment.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "106",
        "title": "Agent-R: Training Language Model Agents to Reflect via Iterative Self-Training",
        "author": [
            "Siyu Yuan",
            "Zehui Chen",
            "Zhiheng Xi",
            "Junjie Ye",
            "Zhengyin Du",
            "Jiecao Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11425",
        "abstract": "Large Language Models (LLMs) agents are increasingly pivotal for addressing complex tasks in interactive environments. Existing work mainly focuses on enhancing performance through behavior cloning from stronger experts, yet such approaches often falter in real-world applications, mainly due to the inability to recover from errors. However, step-level critique data is difficult and expensive to collect. Automating and dynamically constructing self-critique datasets is thus crucial to empowering models with intelligent agent capabilities. In this work, we propose an iterative self-training framework, Agent-R, that enables language Agent to Reflect on the fly. Unlike traditional methods that reward or penalize actions based on correctness, Agent-R leverages MCTS to construct training data that recover correct trajectories from erroneous ones. A key challenge of agent reflection lies in the necessity for timely revision rather than waiting until the end of a rollout. To address this, we introduce a model-guided critique construction mechanism: the actor model identifies the first error step (within its current capability) in a failed trajectory. Starting from it, we splice it with the adjacent correct path, which shares the same parent node in the tree. This strategy enables the model to learn reflection based on its current policy, therefore yielding better learning efficiency. To further explore the scalability of this self-improvement paradigm, we investigate iterative refinement of both error correction capabilities and dataset construction. Our findings demonstrate that Agent-R continuously improves the model's ability to recover from errors and enables timely error correction. Experiments on three interactive environments show that Agent-R effectively equips agents to correct erroneous actions while avoiding loops, achieving superior performance compared to baseline methods (+5.59%).",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "107",
        "title": "One Does Not Simply Meme Alone: Evaluating Co-Creativity Between LLMs and Humans in the Generation of Humor",
        "author": [
            "Zhikun Wu",
            "Thomas Weber",
            "Florian MÃ¼ller"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11433",
        "abstract": "Collaboration has been shown to enhance creativity leading to more innovative and effective outcomes While previous research has explored the abilities of Large Language Models LLMs to serve as cocreative partners in tasks like writing poetry or creating narratives the collaborative potential of LLMs in humorrich and culturally nuanced domains remains an open question To address this gap we conducted a user study to explore the potential of LLMs in cocreating memesa humordriven and culturally specific form of creative expression We conducted a user study with three groups of 50 participants each a humanonly group creating memes without AI assistance a humanAI collaboration group interacting with a stateoftheart LLM model and an AIonly group where the LLM autonomously generated memes We assessed the quality of the generated memes through crowdsourcing with each meme rated on creativity humor and shareability Our results showed that LLM assistance increased the number of ideas generated and reduced the effort participants felt However it did not improve the quality of the memes when humans were collaborated with LLM Interestingly memes created entirely by AI performed better than both humanonly and humanAI collaborative memes in all areas on average However when looking at the topperforming memes humancreated ones were better in humor while humanAI collaborations stood out in creativity and shareability These findings highlight the complexities of humanAI collaboration in creative tasks While AI can boost productivity and create content that appeals to a broad audience human creativity remains crucial for content that connects on a deeper level.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "108",
        "title": "RACCOON: A Retrieval-Augmented Generation Approach for Location Coordinate Capture from News Articles",
        "author": [
            "Jonathan Lin",
            "Aditya Joshi",
            "Hye-young Paik",
            "Tri Dung Doung",
            "Deepti Gurdasani"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11440",
        "abstract": "Geocoding involves automatic extraction of location coordinates of incidents reported in news articles, and can be used for epidemic intelligence or disaster management. This paper introduces Retrieval-Augmented Coordinate Capture Of Online News articles (RACCOON), an open-source geocoding approach that extracts geolocations from news articles. RACCOON uses a retrieval-augmented generation (RAG) approach where candidate locations and associated information are retrieved in the form of context from a location database, and a prompt containing the retrieved context, location mentions and news articles is fed to an LLM to generate the location coordinates. Our evaluation on three datasets, two underlying LLMs, three baselines and several ablation tests based on the components of RACCOON demonstrate the utility of RACCOON. To the best of our knowledge, RACCOON is the first RAG-based approach for geocoding using pre-trained LLMs.",
        "tags": [
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "109",
        "title": "Ontology Matching with Large Language Models and Prioritized Depth-First Search",
        "author": [
            "Maria Taboada",
            "Diego Martinez",
            "Mohammed Arideh",
            "Rosa Mosquera"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11441",
        "abstract": "Ontology matching (OM) plays a key role in enabling data interoperability and knowledge sharing, but it remains challenging due to the need for large training datasets and limited vocabulary processing in machine learning approaches. Recently, methods based on Large Language Model (LLMs) have shown great promise in OM, particularly through the use of a retrieve-then-prompt pipeline. In this approach, relevant target entities are first retrieved and then used to prompt the LLM to predict the final matches. Despite their potential, these systems still present limited performance and high computational overhead. To address these issues, we introduce MILA, a novel approach that embeds a retrieve-identify-prompt pipeline within a prioritized depth-first search (PDFS) strategy. This approach efficiently identifies a large number of semantic correspondences with high accuracy, limiting LLM requests to only the most borderline cases. We evaluated MILA using the biomedical challenge proposed in the 2023 and 2024 editions of the Ontology Alignment Evaluation Initiative. Our method achieved the highest F-Measure in four of the five unsupervised tasks, outperforming state-of-the-art OM systems by up to 17%. It also performed better than or comparable to the leading supervised OM systems. MILA further exhibited task-agnostic performance, remaining stable across all tasks and settings, while significantly reducing LLM requests. These findings highlight that high-performance LLM-based OM can be achieved through a combination of programmed (PDFS), learned (embedding vectors), and prompting-based heuristics, without the need of domain-specific heuristics or fine-tuning.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "110",
        "title": "Curiosity-Driven Reinforcement Learning from Human Feedback",
        "author": [
            "Haoran Sun",
            "Yekun Chai",
            "Shuohuan Wang",
            "Yu Sun",
            "Hua Wu",
            "Haifeng Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11463",
        "abstract": "Reinforcement learning from human feedback (RLHF) has proven effective in aligning large language models (LLMs) with human preferences, but often at the cost of reduced output diversity. This trade-off between diversity and alignment quality remains a significant challenge. Drawing inspiration from curiosity-driven exploration in reinforcement learning, we introduce curiosity-driven RLHF (CD-RLHF), a framework that incorporates intrinsic rewards for novel states, alongside traditional sparse extrinsic rewards, to optimize both output diversity and alignment quality. We demonstrate the effectiveness of CD-RLHF through extensive experiments on a range of tasks, including text summarization and instruction following. Our approach achieves significant gains in diversity on multiple diversity-oriented metrics while maintaining alignment with human preferences comparable to standard RLHF. We make our code publicly available at https://github.com/ernie-research/CD-RLHF.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "111",
        "title": "Graph-defined Language Learning with LLMs",
        "author": [
            "Huachi Zhou",
            "Jiahe Du",
            "Chuang Zhou",
            "Chang Yang",
            "Yilin Xiao",
            "Yuxuan Xie",
            "Xiao Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11478",
        "abstract": "Recent efforts leverage Large Language Models (LLMs) for modeling text-attributed graph structures in node classification tasks. These approaches describe graph structures for LLMs to understand or aggregate LLM-generated textual attribute embeddings through graph structure. However, these approaches face two main limitations in modeling graph structures with LLMs. (i) Graph descriptions become verbose in describing high-order graph structure. (ii) Textual attributes alone do not contain adequate graph structure information. It is challenging to model graph structure concisely and adequately with LLMs. LLMs lack built-in mechanisms to model graph structures directly. They also struggle with complex long-range dependencies between high-order nodes and target nodes.\nInspired by the observation that LLMs pre-trained on one language can achieve exceptional performance on another with minimal additional training, we propose \\textbf{G}raph-\\textbf{D}efined \\textbf{L}anguage for \\textbf{L}arge \\textbf{L}anguage \\textbf{M}odel (GDL4LLM). This novel framework enables LLMs to transfer their powerful language understanding capabilities to graph-structured data. GDL4LLM translates graphs into a graph language corpus instead of graph descriptions and pre-trains LLMs on this corpus to adequately understand graph structures. During fine-tuning, this corpus describes the structural information of target nodes concisely with only a few tokens. By treating graphs as a new language, GDL4LLM enables LLMs to model graph structures adequately and concisely for node classification tasks. Extensive experiments on three real-world datasets demonstrate that GDL4LLM outperforms description-based and textual attribute embeddings-based baselines by efficiently modeling different orders of graph structure with LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "112",
        "title": "Generative AI and Large Language Models in Language Preservation: Opportunities and Challenges",
        "author": [
            "Vincent Koc"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11496",
        "abstract": "Generative AI and large-scale language models (LLM) have emerged as powerful tools in language preservation, particularly for near-native and endangered languages. With the increasing reliance on technology for communication, education, and cultural documentation, new opportunities have emerged to mitigate the dramatic decline of linguistic diversity worldwide. This paper examines the role of generative AIs and LLMs in preserving endangered languages, highlighting the risks and challenges associated with their use. We analyze the underlying technologies driving these models, including natural language processing (NLP) and deep learning, and explore several cases where these technologies have been applied to low-resource languages. Additionally, we discuss ethical considerations, data scarcity issues, and technical challenges while proposing solutions to enhance AI-driven language preservation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "113",
        "title": "KEIR @ ECIR 2025: The Second Workshop on Knowledge-Enhanced Information Retrieval",
        "author": [
            "Zihan Wang",
            "Jinyuan Fang",
            "Giacomo Frisoni",
            "Zhuyun Dai",
            "Zaiqiao Meng",
            "Gianluca Moro",
            "Emine Yilmaz"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11499",
        "abstract": "Pretrained language models (PLMs) like BERT and GPT-4 have become the foundation for modern information retrieval (IR) systems. However, existing PLM-based IR models primarily rely on the knowledge learned during training for prediction, limiting their ability to access and incorporate external, up-to-date, or domain-specific information. Therefore, current information retrieval systems struggle with semantic nuances, context relevance, and domain-specific issues. To address these challenges, we propose the second Knowledge-Enhanced Information Retrieval workshop (KEIR @ ECIR 2025) as a platform to discuss innovative approaches that integrate external knowledge, aiming to enhance the effectiveness of information retrieval in a rapidly evolving technological landscape. The goal of this workshop is to bring together researchers from academia and industry to discuss various aspects of knowledge-enhanced information retrieval.",
        "tags": [
            "BERT",
            "GPT"
        ]
    },
    {
        "id": "114",
        "title": "See In Detail: Enhancing Sparse-view 3D Gaussian Splatting with Local Depth and Semantic Regularization",
        "author": [
            "Zongqi He",
            "Zhe Xiao",
            "Kin-Chung Chan",
            "Yushen Zuo",
            "Jun Xiao",
            "Kin-Man Lam"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11508",
        "abstract": "3D Gaussian Splatting (3DGS) has shown remarkable performance in novel view synthesis. However, its rendering quality deteriorates with sparse inphut views, leading to distorted content and reduced details. This limitation hinders its practical application. To address this issue, we propose a sparse-view 3DGS method. Given the inherently ill-posed nature of sparse-view rendering, incorporating prior information is crucial. We propose a semantic regularization technique, using features extracted from the pretrained DINO-ViT model, to ensure multi-view semantic consistency. Additionally, we propose local depth regularization, which constrains depth values to improve generalization on unseen views. Our method outperforms state-of-the-art novel view synthesis approaches, achieving up to 0.4dB improvement in terms of PSNR on the LLFF dataset, with reduced distortion and enhanced visual quality.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "ViT"
        ]
    },
    {
        "id": "115",
        "title": "UltraFusion: Ultra High Dynamic Imaging using Exposure Fusion",
        "author": [
            "Zixuan Chen",
            "Yujin Wang",
            "Xin Cai",
            "Zhiyuan You",
            "Zheming Lu",
            "Fan Zhang",
            "Shi Guo",
            "Tianfan Xue"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11515",
        "abstract": "Capturing high dynamic range (HDR) scenes is one of the most important issues in camera design. Majority of cameras use exposure fusion technique, which fuses images captured by different exposure levels, to increase dynamic range. However, this approach can only handle images with limited exposure difference, normally 3-4 stops. When applying to very high dynamic scenes where a large exposure difference is required, this approach often fails due to incorrect alignment or inconsistent lighting between inputs, or tone mapping artifacts. In this work, we propose UltraFusion, the first exposure fusion technique that can merge input with 9 stops differences. The key idea is that we model the exposure fusion as a guided inpainting problem, where the under-exposed image is used as a guidance to fill the missing information of over-exposed highlight in the over-exposed region. Using under-exposed image as a soft guidance, instead of a hard constrain, our model is robust to potential alignment issue or lighting variations. Moreover, utilizing the image prior of the generative model, our model also generates natural tone mapping, even for very high-dynamic range scene. Our approach outperforms HDR-Transformer on latest HDR benchmarks. Moreover, to test its performance in ultra high dynamic range scene, we capture a new real-world exposure fusion benchmark, UltraFusion Dataset, with exposure difference up to 9 stops, and experiments show that \\model~can generate beautiful and high-quality fusion results under various scenarios. An online demo is provided at https://openimaginglab.github.io/UltraFusion/.",
        "tags": [
            "Inpainting",
            "Transformer"
        ]
    },
    {
        "id": "116",
        "title": "DLinear-based Prediction of Remaining Useful Life of Lithium-Ion Batteries: Feature Engineering through Explainable Artificial Intelligence",
        "author": [
            "Minsu Kim",
            "Jaehyun Oh",
            "Sang-Young Lee",
            "Junghwan Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11542",
        "abstract": "Accurate prediction of the Remaining Useful Life (RUL) of lithium-ion batteries is essential for ensuring safety, reducing maintenance costs, and optimizing usage. However, predicting RUL is challenging due to the nonlinear characteristics of the degradation caused by complex chemical reactions. Machine learning allows precise predictions by learning the latent functions of degradation relationships based on cycling behavior. This study introduces an accurate RUL prediction approach based on feature engineering and DLinear, applied to the dataset from NASA's Prognostics Center of Excellence. Among the 20 features generated from current, voltage, temperature, and time provided in this dataset, key features contributing to degradation are selected using Pearson correlation coefficient and Shapley values. Shapley value-based feature selection effectively reflects cell-to-cell variability, showing similar importance rankings across all cells. The DLinear-based RUL prediction using key features efficiently captures the time-series trend, demonstrating significantly better performance compared to Long Short-Term Memory and Transformer models.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "117",
        "title": "Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas",
        "author": [
            "Nishant Balepur",
            "Vishakh Padmakumar",
            "Fumeng Yang",
            "Shi Feng",
            "Rachel Rudinger",
            "Jordan Lee Boyd-Graber"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11549",
        "abstract": "LLMs are tuned to follow instructions (aligned) by learning which of two outputs users prefer for a prompt. However, this preference data format does not convey why users prefer responses that are chosen or rejected, so LLMs trained on these datasets cannot tailor responses to varied user needs. To surface these parameters of personalization, we apply abductive reasoning to preference data, inferring needs and interests of users, i.e. personas, that may prefer each output. We test this idea in two steps: Persona Inference (PI)-abductively inferring personas of users who prefer chosen or rejected outputs-and Persona Tailoring (PT)-training models to tailor responses to personas from PI. We find: 1) LLMs infer personas accurately explaining why different users may prefer both chosen or rejected outputs; 2) Training on preference data augmented with PI personas via PT boosts personalization, enabling models to support user-written personas; and 3) Rejected response personas form harder personalization evaluations, showing PT better aids users with uncommon preferences versus typical alignment methods. We argue for an abductive view of preferences for personalization, asking not only which response is better but when, why, and for whom.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "118",
        "title": "PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation",
        "author": [
            "Jinyu Wang",
            "Jingjing Fu",
            "Lei Song",
            "Jiang Bian"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11551",
        "abstract": "Despite notable advancements in Retrieval-Augmented Generation (RAG) systems that expand large language model (LLM) capabilities through external retrieval, these systems often struggle to meet the complex and diverse needs of real-world industrial applications. The reliance on retrieval alone proves insufficient for extracting deep, domain-specific knowledge performing in logical reasoning from specialized corpora. To address this, we introduce sPecIalized KnowledgE and Rationale Augmentation Generation (PIKE-RAG), focusing on extracting, understanding, and applying specialized knowledge, while constructing coherent rationale to incrementally steer LLMs toward accurate responses. Recognizing the diverse challenges of industrial tasks, we introduce a new paradigm that classifies tasks based on their complexity in knowledge extraction and application, allowing for a systematic evaluation of RAG systems' problem-solving capabilities. This strategic approach offers a roadmap for the phased development and enhancement of RAG systems, tailored to meet the evolving demands of industrial applications. Furthermore, we propose knowledge atomizing and knowledge-aware task decomposition to effectively extract multifaceted knowledge from the data chunks and iteratively construct the rationale based on original query and the accumulated knowledge, respectively, showcasing exceptional performance across various benchmarks.",
        "tags": [
            "LLMs",
            "RAG"
        ]
    },
    {
        "id": "119",
        "title": "Teaching Large Language Models to Regress Accurate Image Quality Scores using Score Distribution",
        "author": [
            "Zhiyuan You",
            "Xin Cai",
            "Jinjin Gu",
            "Tianfan Xue",
            "Chao Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11561",
        "abstract": "With the rapid advancement of Multi-modal Large Language Models (MLLMs), MLLM-based Image Quality Assessment (IQA) methods have shown promising performance in linguistic quality description. However, current methods still fall short in accurately scoring image quality. In this work, we aim to leverage MLLMs to regress accurate quality scores. A key challenge is that the quality score is inherently continuous, typically modeled as a Gaussian distribution, whereas MLLMs generate discrete token outputs. This mismatch necessitates score discretization. Previous approaches discretize the mean score into a one-hot label, resulting in information loss and failing to capture inter-image relationships. We propose a distribution-based approach that discretizes the score distribution into a soft label. This method preserves the characteristics of the score distribution, achieving high accuracy and maintaining inter-image relationships. Moreover, to address dataset variation, where different IQA datasets exhibit various distributions, we introduce a fidelity loss based on Thurstone's model. This loss captures intra-dataset relationships, facilitating co-training across multiple IQA datasets. With these designs, we develop the distribution-based Depicted image Quality Assessment model for Score regression (DeQA-Score). Experiments across multiple benchmarks show that DeQA-Score stably outperforms baselines in score regression. Also, DeQA-Score can predict the score distribution that closely aligns with human annotations. Codes and model weights have been released in https://depictqa.github.io/deqa-score/.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "120",
        "title": "Recurrent Diffusion for Large-Scale Parameter Generation",
        "author": [
            "Kai Wang",
            "Dongwen Tang",
            "Wangbo Zhao",
            "Yang You"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11587",
        "abstract": "Parameter generation has struggled to scale up for a long time, significantly limiting its range of applications. In this study, we introduce \\textbf{R}ecurrent diffusion for large-scale \\textbf{P}arameter \\textbf{G}eneration, called \\textbf{RPG}. We first divide the trained parameters into non-overlapping parts, after which a recurrent model is proposed to learn their relationships. The recurrent model's outputs, as conditions, are then fed into a diffusion model to generate the neural network parameters. Using only a single GPU, recurrent diffusion enables us to generate popular vision and language models such as ConvNeXt-L and LoRA parameters of LLaMA-7B. Meanwhile, across various architectures and tasks, the generated parameters consistently perform comparable results over trained networks. Notably, our approach also shows the potential to generate models for handling unseen tasks, which largely increases the practicality of parameter generation. Our code is available \\href{https://github.com/NUS-HPC-AI-Lab/Recurrent-Parameter-Generation}{here}.",
        "tags": [
            "Diffusion",
            "LLaMA",
            "LoRA"
        ]
    },
    {
        "id": "121",
        "title": "SR-FoT: A Syllogistic-Reasoning Framework of Thought for Large Language Models Tackling Knowledge-based Reasoning Tasks",
        "author": [
            "Wentao Wan",
            "Zhuojie Yang",
            "Yongcan Chen",
            "Chenglin Luo",
            "Ruilin Wang",
            "Kehao Cai",
            "Nan Kang",
            "Liang Lin",
            "Keze Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11599",
        "abstract": "Deductive reasoning is a crucial logical capability that assists us in solving complex problems based on existing knowledge. Although augmented by Chain-of-Thought prompts, Large Language Models (LLMs) might not follow the correct reasoning paths. Enhancing the deductive reasoning abilities of LLMs, and leveraging their extensive built-in knowledge for various reasoning tasks, remains an open question. Attempting to mimic the human deductive reasoning paradigm, we propose a multi-stage Syllogistic-Reasoning Framework of Thought (SR-FoT) that enables LLMs to perform syllogistic deductive reasoning to handle complex knowledge-based reasoning tasks. Our SR-FoT begins by interpreting the question and then uses the interpretation and the original question to propose a suitable major premise. It proceeds by generating and answering minor premise questions in two stages to match the minor premises. Finally, it guides LLMs to use the previously generated major and minor premises to perform syllogistic deductive reasoning to derive the answer to the original question. Extensive and thorough experiments on knowledge-based reasoning tasks have demonstrated the effectiveness and advantages of our SR-FoT.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "122",
        "title": "Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems",
        "author": [
            "Giorgio Robino"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11613",
        "abstract": "This study introduces Conversation Routines (CR), a structured prompt engineering framework for developing task-oriented dialog systems using Large Language Models (LLMs). While LLMs demonstrate remarkable natural language understanding capabilities, engineering them to reliably execute complex business workflows remains challenging. The proposed CR framework enables the development of Conversation Agentic Systems (CAS) through natural language specifications, embedding task-oriented logic within LLM prompts. This approach provides a systematic methodology for designing and implementing complex conversational workflows while maintaining behavioral consistency. We demonstrate the framework's effectiveness through two proof of concept implementations: a Train Ticket Booking System and an Interactive Troubleshooting Copilot. These case studies validate CR's capability to encode sophisticated behavioral patterns and decision logic while preserving natural conversational flexibility. Results show that CR enables domain experts to design conversational workflows in natural language while leveraging custom enterprise functionalities (tools) developed by software engineers, creating an efficient division of responsibilities where developers focus on core API implementation and domain experts handle conversation design. While the framework shows promise in accessibility and adaptability, we identify key challenges including computational overhead, non-deterministic behavior, and domain-specific logic optimization. Future research directions include enhancing system robustness, improving scalability for complex multi-agent interactions, and addressing the identified limitations across diverse business applications.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "123",
        "title": "Trojan Detection Through Pattern Recognition for Large Language Models",
        "author": [
            "Vedant Bhasin",
            "Matthew Yudin",
            "Razvan Stefanescu",
            "Rauf Izmailov"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11621",
        "abstract": "Trojan backdoors can be injected into large language models at various stages, including pretraining, fine-tuning, and in-context learning, posing a significant threat to the model's alignment. Due to the nature of causal language modeling, detecting these triggers is challenging given the vast search space. In this study, we propose a multistage framework for detecting Trojan triggers in large language models consisting of token filtration, trigger identification, and trigger verification. We discuss existing trigger identification methods and propose two variants of a black-box trigger inversion method that rely on output logits, utilizing beam search and greedy decoding respectively. We show that the verification stage is critical in the process and propose semantic-preserving prompts and special perturbations to differentiate between actual Trojan triggers and other adversarial strings that display similar characteristics. The evaluation of our approach on the TrojAI and RLHF poisoned model datasets demonstrates promising results.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "124",
        "title": "StAyaL | Multilingual Style Transfer",
        "author": [
            "Karishma Thakrar",
            "Katrina Lawrence",
            "Kyle Howard"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11639",
        "abstract": "Stylistic text generation plays a vital role in enhancing communication by reflecting the nuances of individual expression. This paper presents a novel approach for generating text in a specific speaker's style across different languages. We show that by leveraging only 100 lines of text, an individuals unique style can be captured as a high-dimensional embedding, which can be used for both text generation and stylistic translation. This methodology breaks down the language barrier by transferring the style of a speaker between languages. The paper is structured into three main phases: augmenting the speaker's data with stylistically consistent external sources, separating style from content using machine learning and deep learning techniques, and generating an abstract style profile by mean pooling the learned embeddings. The proposed approach is shown to be topic-agnostic, with test accuracy and F1 scores of 74.9\\% and 0.75, respectively. The results demonstrate the potential of the style profile for multilingual communication, paving the way for further applications in personalized content generation and cross-linguistic stylistic transfer.",
        "tags": [
            "Style Transfer"
        ]
    },
    {
        "id": "125",
        "title": "Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling",
        "author": [
            "Zhenyu Hou",
            "Xin Lv",
            "Rui Lu",
            "Jiajie Zhang",
            "Yujiang Li",
            "Zijun Yao",
            "Juanzi Li",
            "Jie Tang",
            "Yuxiao Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11651",
        "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks. However, existing approaches mainly rely on imitation learning and struggle to achieve effective test-time scaling. While reinforcement learning (RL) holds promise for enabling self-exploration and learning from feedback, recent attempts yield only modest improvements in complex reasoning. In this paper, we present T1 to scale RL by encouraging exploration and understand inference scaling. We first initialize the LLM using synthesized chain-of-thought data that integrates trial-and-error and self-verification. To scale RL training, we promote increased sampling diversity through oversampling. We further employ an entropy bonus as an auxiliary loss, alongside a dynamic anchor for regularization to facilitate reward optimization. We demonstrate that T1 with open LLMs as its base exhibits inference scaling behavior and achieves superior performance on challenging math reasoning benchmarks. For example, T1 with Qwen2.5-32B as the base model outperforms the recent Qwen QwQ-32B-Preview model on MATH500, AIME2024, and Omni-math-500. More importantly, we present a simple strategy to examine inference scaling, where increased inference budgets directly lead to T1's better performance without any additional verification. We will open-source the T1 models and the data used to train them at \\url{https://github.com/THUDM/T1}.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "126",
        "title": "Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)",
        "author": [
            "Brian E. Perron",
            "Lauri Goldkind",
            "Zia Qi",
            "Bryan G. Victor"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11705",
        "abstract": "This paper examines the responsible integration of artificial intelligence (AI) in human services organizations (HSOs), proposing a nuanced framework for evaluating AI applications across multiple dimensions of risk. The authors argue that ethical concerns about AI deployment -- including professional judgment displacement, environmental impact, model bias, and data laborer exploitation -- vary significantly based on implementation context and specific use cases. They challenge the binary view of AI adoption, demonstrating how different applications present varying levels of risk that can often be effectively managed through careful implementation strategies. The paper highlights promising solutions, such as local large language models, that can facilitate responsible AI integration while addressing common ethical concerns. The authors propose a dimensional risk assessment approach that considers factors like data sensitivity, professional oversight requirements, and potential impact on client wellbeing. They conclude by outlining a path forward that emphasizes empirical evaluation, starting with lower-risk applications and building evidence-based understanding through careful experimentation. This approach enables organizations to maintain high ethical standards while thoughtfully exploring how AI might enhance their capacity to serve clients and communities effectively.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "127",
        "title": "Trustformer: A Trusted Federated Transformer",
        "author": [
            "Ali Abbasi Tadi",
            "Dima Alhadidi",
            "Luis Rueda"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11706",
        "abstract": "Transformers, a cornerstone of deep-learning architectures for sequential data, have achieved state-of-the-art results in tasks like Natural Language Processing (NLP). Models such as BERT and GPT-3 exemplify their success and have driven the rise of large language models (LLMs). However, a critical challenge persists: safeguarding the privacy of data used in LLM training. Privacy-preserving techniques like Federated Learning (FL) offer potential solutions, but practical limitations hinder their effectiveness for Transformer training. Two primary issues are (I) the risk of sensitive information leakage due to aggregation methods like FedAvg or FedSGD, and (II) the high communication overhead caused by the large size of Transformer models.\nThis paper introduces a novel FL method that reduces communication overhead while maintaining competitive utility. Our approach avoids sharing full model weights by simulating a global model locally. We apply k-means clustering to each Transformer layer, compute centroids locally, and transmit only these centroids to the server instead of full weights or gradients. To enhance security, we leverage Intel SGX for secure transmission of centroids. Evaluated on a translation task, our method achieves utility comparable to state-of-the-art baselines while significantly reducing communication costs. This provides a more efficient and privacy-preserving FL solution for Transformer models.",
        "tags": [
            "BERT",
            "GPT",
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "128",
        "title": "Towards Detecting Prompt Knowledge Gaps for Improved LLM-guided Issue Resolution",
        "author": [
            "Ramtin Ehsani",
            "Sakshi Pathak",
            "Preetha Chatterjee"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11709",
        "abstract": "Large language models (LLMs) have become essential in software development, especially for issue resolution. However, despite their widespread use, significant challenges persist in the quality of LLM responses to issue resolution queries. LLM interactions often yield incorrect, incomplete, or ambiguous information, largely due to knowledge gaps in prompt design, which can lead to unproductive exchanges and reduced developer productivity. In this paper, we analyze 433 developer-ChatGPT conversations within GitHub issue threads to examine the impact of prompt knowledge gaps and conversation styles on issue resolution. We identify four main knowledge gaps in developer prompts: Missing Context, Missing Specifications, Multiple Context, and Unclear Instructions. Assuming that conversations within closed issues contributed to successful resolutions while those in open issues did not, we find that ineffective conversations contain knowledge gaps in 54.7% of prompts, compared to only 13.2% in effective ones. Additionally, we observe seven distinct conversational styles, with Directive Prompting, Chain of Thought, and Responsive Feedback being the most prevalent. We find that knowledge gaps are present in all styles of conversations, with Missing Context being the most repeated challenge developers face in issue-resolution conversations. Based on our analysis, we identify key textual and code related heuristics-Specificity, Contextual Richness, and Clarity-that are associated with successful issue closure and help assess prompt quality. These heuristics lay the foundation for an automated tool that can dynamically flag unclear prompts and suggest structured improvements. To test feasibility, we developed a lightweight browser extension prototype for detecting prompt gaps, that can be easily adapted to other tools within developer workflows.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "129",
        "title": "YouLeQD: Decoding the Cognitive Complexity of Questions and Engagement in Online Educational Videos from Learners' Perspectives",
        "author": [
            "Nong Ming",
            "Sachin Sharma",
            "Jiho Noh"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11712",
        "abstract": "Questioning is a fundamental aspect of education, as it helps assess students' understanding, promotes critical thinking, and encourages active engagement. With the rise of artificial intelligence in education, there is a growing interest in developing intelligent systems that can automatically generate and answer questions and facilitate interactions in both virtual and in-person education settings. However, to develop effective AI models for education, it is essential to have a fundamental understanding of questioning. In this study, we created the YouTube Learners' Questions on Bloom's Taxonomy Dataset (YouLeQD), which contains learner-posed questions from YouTube lecture video comments. Along with the dataset, we developed two RoBERTa-based classification models leveraging Large Language Models to detect questions and analyze their cognitive complexity using Bloom's Taxonomy. This dataset and our findings provide valuable insights into the cognitive complexity of learner-posed questions in educational videos and their relationship with interaction metrics. This can aid in the development of more effective AI models for education and improve the overall learning experience for students.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "130",
        "title": "Explain-Query-Test: Self-Evaluating LLMs Via Explanation and Comprehension Discrepancy",
        "author": [
            "Saeid Asgari Taghanaki",
            "Joao Monteiro"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11721",
        "abstract": "Large language models (LLMs) have demonstrated remarkable proficiency in generating detailed and coherent explanations of complex concepts. However, the extent to which these models truly comprehend the concepts they articulate remains unclear. To assess the level of comprehension of a model relative to the content it generates, we implemented a self-evaluation pipeline where models: (i) given a topic generate an excerpt with information about the topic, (ii) given an excerpt generate question-answer pairs, and finally (iii) given a question generate an answer. We refer to this self-evaluation approach as Explain-Query-Test (EQT). Interestingly, the accuracy on generated questions resulting from running the EQT pipeline correlates strongly with the model performance as verified by typical benchmarks such as MMLU-Pro. In other words, EQT's performance is predictive of MMLU-Pro's, and EQT can be used to rank models without the need for any external source of evaluation data other than lists of topics of interest. Moreover, our results reveal a disparity between the models' ability to produce detailed explanations and their performance on questions related to those explanations. This gap highlights fundamental limitations in the internal knowledge representation and reasoning abilities of current LLMs. We release the code at https://github.com/asgsaeid/EQT.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "131",
        "title": "SeRpEnt: Selective Resampling for Expressive State Space Models",
        "author": [
            "Stefano Rando",
            "Luca Romani",
            "Matteo Migliarini",
            "Luca Franco",
            "Denis Gudovskiy",
            "Fabio Galasso"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11729",
        "abstract": "State Space Models (SSMs) have recently enjoyed a rise to prominence in the field of deep learning for sequence modeling, especially as an alternative to Transformers. Their success stems from avoiding two well-known drawbacks of attention-based models: quadratic complexity with respect to the sequence length and inability to model long-range dependencies. The SSM variant Mamba has demonstrated performance comparable to Transformers without any form of attention, thanks to the use of a selective mechanism for the state parameters. Selectivity, however, is only evaluated empirically and the reasons of its effectiveness remain unclear. In this work, we show how selectivity is related to the sequence processing. Our analysis shows that selective time intervals in Mamba act as linear approximators of information. Then, we propose our SeRpEnt architecture, a SSM that further exploits selectivity to compress sequences in an information-aware fashion. It employs a resampling mechanism that aggregates elements based on their information content. Our empirical results in the Long Range Arena benchmark and other language modeling tasks show benefits of the SeRpEnt's resampling mechanism.",
        "tags": [
            "Mamba",
            "SSMs",
            "State Space Models"
        ]
    },
    {
        "id": "132",
        "title": "Transformer Vibration Forecasting for Advancing Rail Safety and Maintenance 4.0",
        "author": [
            "DarÃ­o C. Larese",
            "Almudena Bravo Cerrada",
            "Gabriel Dambrosio Tomei",
            "Alejandro Guerrero-LÃ³pez",
            "Pablo M. Olmos",
            "MarÃ­a JesÃºs GÃ³mez GarcÃ­a"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11730",
        "abstract": "Maintaining railway axles is critical to preventing severe accidents and financial losses. The railway industry is increasingly interested in advanced condition monitoring techniques to enhance safety and efficiency, moving beyond traditional periodic inspections toward Maintenance 4.0.\nThis study introduces a robust Deep Autoregressive solution that integrates seamlessly with existing systems to avert mechanical failures. Our approach simulates and predicts vibration signals under various conditions and fault scenarios, improving dataset robustness for more effective detection systems. These systems can alert maintenance needs, preventing accidents preemptively. We use experimental vibration signals from accelerometers on train axles.\nOur primary contributions include a transformer model, ShaftFormer, designed for processing time series data, and an alternative model incorporating spectral methods and enhanced observation models. Simulating vibration signals under diverse conditions mitigates the high cost of obtaining experimental signals for all scenarios. Given the non-stationary nature of railway vibration signals, influenced by speed and load changes, our models address these complexities, offering a powerful tool for predictive maintenance in the rail industry.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "133",
        "title": "SILO: Solving Inverse Problems with Latent Operators",
        "author": [
            "Ron Raphaeli",
            "Sean Man",
            "Michael Elad"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11746",
        "abstract": "Consistent improvement of image priors over the years has led to the development of better inverse problem solvers. Diffusion models are the newcomers to this arena, posing the strongest known prior to date. Recently, such models operating in a latent space have become increasingly predominant due to their efficiency. In recent works, these models have been applied to solve inverse problems. Working in the latent space typically requires multiple applications of an Autoencoder during the restoration process, which leads to both computational and restoration quality challenges. In this work, we propose a new approach for handling inverse problems with latent diffusion models, where a learned degradation function operates within the latent space, emulating a known image space degradation. Usage of the learned operator reduces the dependency on the Autoencoder to only the initial and final steps of the restoration process, facilitating faster sampling and superior restoration quality. We demonstrate the effectiveness of our method on a variety of image restoration tasks and datasets, achieving significant improvements over prior art.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "134",
        "title": "Optimizing Pretraining Data Mixtures with LLM-Estimated Utility",
        "author": [
            "William Held",
            "Bhargavi Paranjape",
            "Punit Singh Koura",
            "Mike Lewis",
            "Frank Zhang",
            "Todor Mihaylov"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11747",
        "abstract": "Large Language Models improve with increasing amounts of high-quality training data. However, leveraging larger datasets requires balancing quality, quantity, and diversity across sources. After evaluating nine baseline methods under both compute- and data-constrained scenarios, we find token-count heuristics outperform manual and learned mixes, indicating that simple approaches accounting for dataset size and diversity are surprisingly effective. Building on this insight, we propose two complementary approaches: UtiliMax, which extends token-based heuristics by incorporating utility estimates from reduced-scale ablations, achieving up to a 10.6x speedup over manual baselines; and Model Estimated Data Utility (MEDU), which leverages LLMs to estimate data utility from small samples, matching ablation-based performance while reducing computational requirements by $\\sim$200x. Together, these approaches establish a new framework for automated, compute-efficient data mixing that is robust across training regimes.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "135",
        "title": "Are generative models fair? A study of racial bias in dermatological image generation",
        "author": [
            "Miguel LÃ³pez-PÃ©rez",
            "SÃ¸ren Hauberg",
            "Aasa Feragen"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11752",
        "abstract": "Racial bias in medicine, particularly in dermatology, presents significant ethical and clinical challenges. It often results from the underrepresentation of darker skin tones in training datasets for machine learning models. While efforts to address bias in dermatology have focused on improving dataset diversity and mitigating disparities in discriminative models, the impact of racial bias on generative models remains underexplored. Generative models, such as Variational Autoencoders (VAEs), are increasingly used in healthcare applications, yet their fairness across diverse skin tones is currently not well understood. In this study, we evaluate the fairness of generative models in clinical dermatology with respect to racial bias. For this purpose, we first train a VAE with a perceptual loss to generate and reconstruct high-quality skin images across different skin tones. We utilize the Fitzpatrick17k dataset to examine how racial bias influences the representation and performance of these models. Our findings indicate that the VAE is influenced by the diversity of skin tones in the training dataset, with better performance observed for lighter skin tones. Additionally, the uncertainty estimates produced by the VAE are ineffective in assessing the model's fairness. These results highlight the need for improved uncertainty quantification mechanisms to detect and address racial bias in generative models for trustworthy healthcare technologies.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "136",
        "title": "Is logical analysis performed by transformers taking place in self-attention or in the fully connected part?",
        "author": [
            "Evgeniy Shin",
            "Heinrich Matzinger"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11765",
        "abstract": "Transformers architecture apply self-attention to tokens represented as vectors, before a fully connected (neuronal network) layer. These two parts can be layered many times. Traditionally, self-attention is seen as a mechanism for aggregating information before logical operations are performed by the fully connected layer. In this paper, we show, that quite counter-intuitively, the logical analysis can also be performed within the self-attention. For this we implement a handcrafted single-level encoder layer which performs the logical analysis within self-attention. We then study the scenario in which a one-level transformer model undergoes self-learning using gradient descent. We investigate whether the model utilizes fully connected layers or self-attention mechanisms for logical analysis when it has the choice. Given that gradient descent can become stuck at undesired zeros, we explicitly calculate these unwanted zeros and find ways to avoid them. We do all this in the context of predicting grammatical category pairs of adjacent tokens in a text. We believe that our findings have broader implications for understanding the potential logical operations performed by self-attention.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "137",
        "title": "The Value of Nothing: Multimodal Extraction of Human Values Expressed by TikTok Influencers",
        "author": [
            "Alina Starovolsky-Shitrit",
            "Alon Neduva",
            "Naama Appel Doron",
            "Ella Daniel",
            "Oren Tsur"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11770",
        "abstract": "Societal and personal values are transmitted to younger generations through interaction and exposure. Traditionally, children and adolescents learned values from parents, educators, or peers. Nowadays, social platforms serve as a significant channel through which youth (and adults) consume information, as the main medium of entertainment, and possibly the medium through which they learn different values. In this paper we extract implicit values from TikTok movies uploaded by online influencers targeting children and adolescents. We curated a dataset of hundreds of TikTok movies and annotated them according to the Schwartz Theory of Personal Values. We then experimented with an array of Masked and Large language model, exploring how values can be detected. Specifically, we considered two pipelines -- direct extraction of values from video and a 2-step approach in which videos are first converted to elaborated scripts and then values are extracted.\nAchieving state-of-the-art results, we find that the 2-step approach performs significantly better than the direct approach and that using a trainable Masked Language Model as a second step significantly outperforms a few-shot application of a number of Large Language Models. We further discuss the impact of fine-tuning and compare the performance of the different models on identification of values present or contradicted in the TikTok. Finally, we share the first values-annotated dataset of TikTok videos. Our results pave the way to further research on influence and value transmission in video-based social platforms.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "138",
        "title": "EfficientVITON: An Efficient Virtual Try-On Model using Optimized Diffusion Process",
        "author": [
            "Mostafa Atef",
            "Mariam Ayman",
            "Ahmed Rashed",
            "Ashrakat Saeed",
            "Abdelrahman Saeed",
            "Ahmed Fares"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11776",
        "abstract": "Would not it be much more convenient for everybody to try on clothes by only looking into a mirror ? The answer to that problem is virtual try-on, enabling users to digitally experiment with outfits. The core challenge lies in realistic image-to-image translation, where clothing must fit diverse human forms, poses, and figures. Early methods, which used 2D transformations, offered speed, but image quality was often disappointing and lacked the nuance of deep learning. Though GAN-based techniques enhanced realism, their dependence on paired data proved limiting. More adaptable methods offered great visuals but demanded significant computing power and time. Recent advances in diffusion models have shown promise for high-fidelity translation, yet the current crop of virtual try-on tools still struggle with detail loss and warping issues. To tackle these challenges, this paper proposes EfficientVITON, a new virtual try-on system leveraging the impressive pre-trained Stable Diffusion model for better images and deployment feasibility. The system includes a spatial encoder to maintain clothings finer details and zero cross-attention blocks to capture the subtleties of how clothes fit a human body. Input images are carefully prepared, and the diffusion process has been tweaked to significantly cut generation time without image quality loss. The training process involves two distinct stages of fine-tuning, carefully incorporating a balance of loss functions to ensure both accurate try-on results and high-quality visuals. Rigorous testing on the VITON-HD dataset, supplemented with real-world examples, has demonstrated that EfficientVITON achieves state-of-the-art results.",
        "tags": [
            "Diffusion",
            "GAN",
            "Virtual Try-On"
        ]
    },
    {
        "id": "139",
        "title": "Glinthawk: A Two-Tiered Architecture for High-Throughput LLM Inference",
        "author": [
            "Pouya Hamadanian",
            "Sadjad Fouladi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11779",
        "abstract": "Large Language Models (LLM) have revolutionized natural language processing, but their inference demands substantial resources, while under-utilizing high-end accelerators like GPUs. A major bottleneck arises from the attention mechanism, which requires storing large key-value caches, limiting the maximum achievable throughput way below the available computing resources. Current approaches attempt to mitigate this issue through memory-efficient attention and paging mechanisms, but remained constrained by the assumption that all operations must be performed on high-end accelerators.\nIn this work, we propose Glinthawk, a two-tiered architecture that decouples the attention mechanism from the rest of the Transformer model. This approach allows the memory requirements for attention to scale independently, enabling larger batch sizes and more efficient use of the high-end accelerators. We prototype Glinthawk with NVIDIA T4 GPUs as one tier and standard CPU VMs as the other. Compared to a traditional single-tier setup, it improves throughput by $5.9\\times$ and reduces cost of generation by $2.8\\times$. For longer sequence lengths, it achieves $16.3\\times$ throughput improvement at $2.4\\times$ less cost. Our evaluation shows that this architecture can tolerate moderate network latency with minimal performance degradation, making it highly effective for latency-tolerant, throughput-oriented applications such as batch processing. We shared our prototype publicly at \\url{https://github.com/microsoft/glinthawk}.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "140",
        "title": "Synthetic Data Can Mislead Evaluations: Membership Inference as Machine Text Detection",
        "author": [
            "Ali Naseh",
            "Niloofar Mireshghallah"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11786",
        "abstract": "Recent work shows membership inference attacks (MIAs) on large language models (LLMs) produce inconclusive results, partly due to difficulties in creating non-member datasets without temporal shifts. While researchers have turned to synthetic data as an alternative, we show this approach can be fundamentally misleading. Our experiments indicate that MIAs function as machine-generated text detectors, incorrectly identifying synthetic data as training samples regardless of the data source. This behavior persists across different model architectures and sizes, from open-source models to commercial ones such as GPT-3.5. Even synthetic text generated by different, potentially larger models is classified as training data by the target model. Our findings highlight a serious concern: using synthetic data in membership evaluations may lead to false conclusions about model memorization and data leakage. We caution that this issue could affect other evaluations using model signals such as loss where synthetic or machine-generated translated data substitutes for real-world samples.",
        "tags": [
            "Detection",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "141",
        "title": "Benchmarking Large Language Models via Random Variables",
        "author": [
            "Zijin Hong",
            "Hao Wu",
            "Su Dong",
            "Junnan Dong",
            "Yilin Xiao",
            "Yujing Zhang",
            "Zhu Wang",
            "Feiran Huang",
            "Linyi Li",
            "Hongxia Yang",
            "Xiao Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11790",
        "abstract": "With the continuous advancement of large language models (LLMs) in mathematical reasoning, evaluating their performance in this domain has become a prominent research focus. Recent studies have raised concerns about the reliability of current mathematical benchmarks, highlighting issues such as simplistic design and potential data leakage. Therefore, creating a reliable benchmark that effectively evaluates the genuine capabilities of LLMs in mathematical reasoning remains a significant challenge. To address this, we propose RV-Bench, a framework for Benchmarking LLMs via Random Variables in mathematical reasoning. Specifically, the background content of a random variable question (RV question) mirrors the original problem in existing standard benchmarks, but the variable combinations are randomized into different values. LLMs must fully understand the problem-solving process for the original problem to correctly answer RV questions with various combinations of variable values. As a result, the LLM's genuine capability in mathematical reasoning is reflected by its accuracy on RV-Bench. Extensive experiments are conducted with 29 representative LLMs across 900+ RV questions. A leaderboard for RV-Bench ranks the genuine capability of these LLMs. Further analysis of accuracy dropping indicates that current LLMs still struggle with complex mathematical reasoning problems.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "142",
        "title": "CogMorph: Cognitive Morphing Attacks for Text-to-Image Models",
        "author": [
            "Zonglei Jing",
            "Zonghao Ying",
            "Le Wang",
            "Siyuan Liang",
            "Aishan Liu",
            "Xianglong Liu",
            "Dacheng Tao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11815",
        "abstract": "The development of text-to-image (T2I) generative models, that enable the creation of high-quality synthetic images from textual prompts, has opened new frontiers in creative design and content generation. However, this paper reveals a significant and previously unrecognized ethical risk inherent in this technology and introduces a novel method, termed the Cognitive Morphing Attack (CogMorph), which manipulates T2I models to generate images that retain the original core subjects but embeds toxic or harmful contextual elements. This nuanced manipulation exploits the cognitive principle that human perception of concepts is shaped by the entire visual scene and its context, producing images that amplify emotional harm far beyond attacks that merely preserve the original semantics. To address this, we first construct an imagery toxicity taxonomy spanning 10 major and 48 sub-categories, aligned with human cognitive-perceptual dimensions, and further build a toxicity risk matrix resulting in 1,176 high-quality T2I toxic prompts. Based on this, our CogMorph first introduces Cognitive Toxicity Augmentation, which develops a cognitive toxicity knowledge base with rich external toxic representations for humans (e.g., fine-grained visual features) that can be utilized to further guide the optimization of adversarial prompts. In addition, we present Contextual Hierarchical Morphing, which hierarchically extracts critical parts of the original prompt (e.g., scenes, subjects, and body parts), and then iteratively retrieves and fuses toxic features to inject harmful contexts. Extensive experiments on multiple open-sourced T2I models and black-box commercial APIs (e.g., DALLE-3) demonstrate the efficacy of CogMorph which significantly outperforms other baselines by large margins (+20.62\\% on average).",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "143",
        "title": "Is your LLM trapped in a Mental Set? Investigative study on how mental sets affect the reasoning capabilities of LLMs",
        "author": [
            "Saiful Haq",
            "Niyati Chhaya",
            "Piyush Pandey",
            "Pushpak Bhattacharya"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11833",
        "abstract": "In this paper, we present an investigative study on how Mental Sets influence the reasoning capabilities of LLMs. LLMs have excelled in diverse natural language processing (NLP) tasks, driven by advancements in parameter-efficient fine-tuning (PEFT) and emergent capabilities like in-context learning (ICL). For complex reasoning tasks, selecting the right model for PEFT or ICL is critical, often relying on scores on benchmarks such as MMLU, MATH, and GSM8K. However, current evaluation methods, based on metrics like F1 Score or reasoning chain assessments by larger models, overlook a key dimension: adaptability to unfamiliar situations and overcoming entrenched thinking patterns. In cognitive psychology, Mental Set refers to the tendency to persist with previously successful strategies, even when they become inefficient - a challenge for problem solving and reasoning. We compare the performance of LLM models like Llama-3.1-8B-Instruct, Llama-3.1-70B-Instruct and GPT-4o in the presence of mental sets. To the best of our knowledge, this is the first study to integrate cognitive psychology concepts into the evaluation of LLMs for complex reasoning tasks, providing deeper insights into their adaptability and problem-solving efficacy.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA"
        ]
    },
    {
        "id": "144",
        "title": "Large Language Models with Human-In-The-Loop Validation for Systematic Review Data Extraction",
        "author": [
            "Noah L. Schroeder",
            "Chris Davis Jaldi",
            "Shan Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11840",
        "abstract": "Systematic reviews are time-consuming endeavors. Historically speaking, knowledgeable humans have had to screen and extract data from studies before it can be analyzed. However, large language models (LLMs) hold promise to greatly accelerate this process. After a pilot study which showed great promise, we investigated the use of freely available LLMs for extracting data for systematic reviews. Using three different LLMs, we extracted 24 types of data, 9 explicitly stated variables and 15 derived categorical variables, from 112 studies that were included in a published scoping review. Overall we found that Gemini 1.5 Flash, Gemini 1.5 Pro, and Mistral Large 2 performed reasonably well, with 71.17%, 72.14%, and 62.43% of data extracted being consistent with human coding, respectively. While promising, these results highlight the dire need for a human-in-the-loop (HIL) process for AI-assisted data extraction. As a result, we present a free, open-source program we developed (AIDE) to facilitate user-friendly, HIL data extraction with LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "145",
        "title": "Survey on Monocular Metric Depth Estimation",
        "author": [
            "Jiuling Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11841",
        "abstract": "Monocular Depth Estimation (MDE) is a fundamental computer vision task underpinning applications such as spatial understanding, 3D reconstruction, and autonomous driving. While deep learning-based MDE methods can predict relative depth from a single image, their lack of metric scale information often results in scale inconsistencies, limiting their utility in downstream tasks like visual SLAM, 3D reconstruction, and novel view synthesis. Monocular Metric Depth Estimation (MMDE) addresses these challenges by enabling precise, scene-scale depth inference. MMDE improves depth consistency, enhances sequential task stability, simplifies integration into downstream applications, and broadens practical use cases. This paper provides a comprehensive review of depth estimation technologies, highlighting the evolution from geometry-based methods to state-of-the-art deep learning approaches. It emphasizes advancements in scale-agnostic methods, which are crucial for enabling zero-shot generalization as the foundational capability for MMDE. Recent progress in zero-shot MMDE research is explored, focusing on challenges such as model generalization and the loss of detail at scene boundaries. Innovative strategies to address these issues include unlabelled data augmentation, image patching, architectural optimization, and generative techniques. These advancements, analyzed in detail, demonstrate significant contributions to overcoming existing limitations. Finally, this paper synthesizes recent developments in zero-shot MMDE, identifies unresolved challenges, and outlines future research directions. By offering a clear roadmap and cutting-edge insights, this work aims to deepen understanding of MMDE, inspire novel applications, and drive technological innovation.",
        "tags": [
            "3D",
            "Depth Estimation",
            "SLAM"
        ]
    },
    {
        "id": "146",
        "title": "A Survey on Memory-Efficient Large-Scale Model Training in AI for Science",
        "author": [
            "Kaiyuan Tian",
            "Linbo Qiao",
            "Baihui Liu",
            "Gongqingjian Jiang",
            "Dongsheng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11847",
        "abstract": "Scientific research faces high costs and inefficiencies with traditional methods, but the rise of deep learning and large language models (LLMs) offers innovative solutions. This survey reviews LLM applications across scientific fields such as biology, medicine, chemistry, and meteorology, underscoring their role in advancing research. However, the continuous expansion of model size has led to significant memory demands, hindering further development and application of LLMs for science. To address this, we review memory-efficient training techniques for LLMs based on the transformer architecture, including distributed training, mixed precision training, and gradient checkpointing. Using AlphaFold 2 as an example, we demonstrate how tailored memory optimization methods can reduce storage needs while preserving prediction accuracy. We also discuss the challenges of memory optimization in practice and potential future directions, hoping to provide valuable insights for researchers and engineers.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "147",
        "title": "Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance",
        "author": [
            "Nikos Kanakaris",
            "Heng Ping",
            "Xiongye Xiao",
            "Nesreen K. Ahmed",
            "Luca Luceri",
            "Emilio Ferrara",
            "Paul Bogdan"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11849",
        "abstract": "Detecting organized political campaigns is of paramount importance in fighting against disinformation on social media. Existing approaches for the identification of such organized actions employ techniques mostly from network science, graph machine learning and natural language processing. Their ultimate goal is to analyze the relationships and interactions (e.g. re-posting) among users and the textual similarities of their posts. Despite their effectiveness in recognizing astroturf campaigns, these methods face significant challenges, notably the class imbalance in available training datasets. To mitigate this issue, recent methods usually resort to data augmentation or increasing the number of positive samples, which may not always be feasible or sufficient in real-world settings. Following a different path, in this paper, we propose a novel framework for identifying astroturf campaigns based solely on large language models (LLMs), introducing a Balanced Retrieval-Augmented Generation (Balanced RAG) component. Our approach first gives both textual information concerning the posts (in our case tweets) and the user interactions of the social network as input to a language model. Then, through prompt engineering and the proposed Balanced RAG method, it effectively detects coordinated disinformation campaigns on X (Twitter). The proposed framework does not require any training or fine-tuning of the language model. Instead, by strategically harnessing the strengths of prompt engineering and Balanced RAG, it facilitates LLMs to overcome the effects of class imbalance and effectively identify coordinated political campaigns. The experimental results demonstrate that by incorporating the proposed prompt engineering and Balanced RAG methods, our framework outperforms the traditional graph-based baselines, achieving 2x-3x improvements in terms of precision, recall and F1 scores.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "148",
        "title": "EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents",
        "author": [
            "Zhili Cheng",
            "Yuge Tu",
            "Ran Li",
            "Shiqi Dai",
            "Jinyi Hu",
            "Shengding Hu",
            "Jiahao Li",
            "Yang Shi",
            "Tianyu Yu",
            "Weize Chen",
            "Lei Shi",
            "Maosong Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11858",
        "abstract": "Multimodal Large Language Models (MLLMs) have shown significant advancements, providing a promising future for embodied agents. Existing benchmarks for evaluating MLLMs primarily utilize static images or videos, limiting assessments to non-interactive scenarios. Meanwhile, existing embodied AI benchmarks are task-specific and not diverse enough, which do not adequately evaluate the embodied capabilities of MLLMs. To address this, we propose EmbodiedEval, a comprehensive and interactive evaluation benchmark for MLLMs with embodied tasks. EmbodiedEval features 328 distinct tasks within 125 varied 3D scenes, each of which is rigorously selected and annotated. It covers a broad spectrum of existing embodied AI tasks with significantly enhanced diversity, all within a unified simulation and evaluation framework tailored for MLLMs. The tasks are organized into five categories: navigation, object interaction, social interaction, attribute question answering, and spatial question answering to assess different capabilities of the agents. We evaluated the state-of-the-art MLLMs on EmbodiedEval and found that they have a significant shortfall compared to human level on embodied tasks. Our analysis demonstrates the limitations of existing MLLMs in embodied capabilities, providing insights for their future development. We open-source all evaluation data and simulation framework at https://github.com/thunlp/EmbodiedEval.",
        "tags": [
            "3D",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "149",
        "title": "Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models",
        "author": [
            "Zihan Qiu",
            "Zeyu Huang",
            "Bo Zheng",
            "Kaiyue Wen",
            "Zekun Wang",
            "Rui Men",
            "Ivan Titov",
            "Dayiheng Liu",
            "Jingren Zhou",
            "Junyang Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11873",
        "abstract": "This paper revisits the implementation of $\\textbf{L}$oad-$\\textbf{b}$alancing $\\textbf{L}$oss (LBL) when training Mixture-of-Experts (MoEs) models. Specifically, LBL for MoEs is defined as $N_E \\sum_{i=1}^{N_E} f_i p_i$, where $N_E$ is the total number of experts, $f_i$ represents the frequency of expert $i$ being selected, and $p_i$ denotes the average gating score of the expert $i$. Existing MoE training frameworks usually employ the parallel training strategy so that $f_i$ and the LBL are calculated within a $\\textbf{micro-batch}$ and then averaged across parallel groups. In essence, a micro-batch for training billion-scale LLMs normally contains very few sequences. So, the micro-batch LBL is almost at the sequence level, and the router is pushed to distribute the token evenly within each sequence. Under this strict constraint, even tokens from a domain-specific sequence ($\\textit{e.g.}$, code) are uniformly routed to all experts, thereby inhibiting expert specialization. In this work, we propose calculating LBL using a $\\textbf{global-batch}$ to loose this constraint. Because a global-batch contains much more diverse sequences than a micro-batch, which will encourage load balance at the corpus level. Specifically, we introduce an extra communication step to synchronize $f_i$ across micro-batches and then use it to calculate the LBL. Through experiments on training MoEs-based LLMs (up to $\\textbf{42.8B}$ total parameters and $\\textbf{400B}$ tokens), we surprisingly find that the global-batch LBL strategy yields excellent performance gains in both pre-training perplexity and downstream tasks. Our analysis reveals that the global-batch LBL also greatly improves the domain specialization of MoE experts.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "150",
        "title": "From Drafts to Answers: Unlocking LLM Potential via Aggregation Fine-Tuning",
        "author": [
            "Yafu Li",
            "Zhilin Wang",
            "Tingchen Fu",
            "Ganqu Cui",
            "Sen Yang",
            "Yu Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11877",
        "abstract": "Scaling data and model size has been proven effective for boosting the performance of large language models. In addition to training-time scaling, recent studies have revealed that increasing test-time computational resources can further improve performance. In this work, we introduce Aggregation Fine-Tuning (AFT), a supervised finetuning paradigm where the model learns to synthesize multiple draft responses, referred to as proposals, into a single, refined answer, termed aggregation. At inference time, a propose-and-aggregate strategy further boosts performance by iteratively generating proposals and aggregating them. Empirical evaluations on benchmark datasets show that AFT-trained models substantially outperform standard SFT. Notably, an AFT model, fine-tuned from Llama3.1-8B-Base with only 64k data, achieves a 41.3% LC win rate on AlpacaEval 2, surpassing significantly larger LLMs such as Llama3.1-405B-Instruct and GPT4. By combining sequential refinement and parallel sampling, the propose-and-aggregate framework scales inference-time computation in a flexible manner. Overall, These findings position AFT as a promising approach to unlocking additional capabilities of LLMs without resorting to increasing data volume or model size.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "151",
        "title": "DynoSAM: Open-Source Smoothing and Mapping Framework for Dynamic SLAM",
        "author": [
            "Jesse Morris",
            "Yiduo Wang",
            "Mikolaj Kliniewski",
            "Viorela Ila"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11893",
        "abstract": "Traditional Visual Simultaneous Localization and Mapping (vSLAM) systems focus solely on static scene structures, overlooking dynamic elements in the environment. Although effective for accurate visual odometry in complex scenarios, these methods discard crucial information about moving objects. By incorporating this information into a Dynamic SLAM framework, the motion of dynamic entities can be estimated, enhancing navigation whilst ensuring accurate localization. However, the fundamental formulation of Dynamic SLAM remains an open challenge, with no consensus on the optimal approach for accurate motion estimation within a SLAM pipeline. Therefore, we developed DynoSAM, an open-source framework for Dynamic SLAM that enables the efficient implementation, testing, and comparison of various Dynamic SLAM optimization formulations. DynoSAM integrates static and dynamic measurements into a unified optimization problem solved using factor graphs, simultaneously estimating camera poses, static scene, object motion or poses, and object structures. We evaluate DynoSAM across diverse simulated and real-world datasets, achieving state-of-the-art motion estimation in indoor and outdoor environments, with substantial improvements over existing systems. Additionally, we demonstrate DynoSAM utility in downstream applications, including 3D reconstruction of dynamic scenes and trajectory prediction, thereby showcasing potential for advancing dynamic object-aware SLAM systems. DynoSAM is open-sourced at https://github.com/ACFR-RPG/DynOSAM.",
        "tags": [
            "3D",
            "SLAM"
        ]
    },
    {
        "id": "152",
        "title": "Enhancing Adversarial Transferability via Component-Wise Augmentation Method",
        "author": [
            "Hangyu Liu",
            "Bo Peng",
            "Pengxiang Ding",
            "Donglin Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11901",
        "abstract": "Deep Neural Networks (DNNs) are highly vulnerable to adversarial examples, which pose significant challenges in security-sensitive applications. Among various adversarial attack strategies, input transformation-based attacks have demonstrated remarkable effectiveness in enhancing adversarial transferability. However, existing methods fail to diversify attention regions across models adequately and introduce excessive information loss during transformations. In this paper, we introduce a novel input transformation-based method, termed Component-Wise Augmentation (CWA), designed to enhance transferability by locally applying block-wise transformations. CWA strategically integrates interpolation and selective rotation on individual image blocks to diversify model attention regions while preserving semantic integrity. Extensive experiments on the standard ImageNet dataset show that CWA consistently outperforms state-of-the-art methods in both attack success rates and stability across CNN- and Transformer-based models, while also demonstrating superior performance against multiple defense methods.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "153",
        "title": "Integrate Temporal Graph Learning into LLM-based Temporal Knowledge Graph Model",
        "author": [
            "He Chang",
            "Jie Wu",
            "Zhulin Tao",
            "Yunshan Ma",
            "Xianglin Huang",
            "Tat-Seng Chua"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11911",
        "abstract": "Temporal Knowledge Graph Forecasting (TKGF) aims to predict future events based on the observed events in history. Recently, Large Language Models (LLMs) have exhibited remarkable capabilities, generating significant research interest in their application for reasoning over temporal knowledge graphs (TKGs). Existing LLM-based methods have integrated retrieved historical facts or static graph representations into LLMs. Despite the notable performance of LLM-based methods, they are limited by the insufficient modeling of temporal patterns and ineffective cross-modal alignment between graph and language, hindering the ability of LLMs to fully grasp the temporal and structural information in TKGs. To tackle these issues, we propose a novel framework TGL-LLM to integrate temporal graph learning into LLM-based temporal knowledge graph model. Specifically, we introduce temporal graph learning to capture the temporal and relational patterns and obtain the historical graph embedding. Furthermore, we design a hybrid graph tokenization to sufficiently model the temporal patterns within LLMs. To achieve better alignment between graph and language, we employ a two-stage training paradigm to finetune LLMs on high-quality and diverse data, thereby resulting in better performance. Extensive experiments on three real-world datasets show that our approach outperforms a range of state-of-the-art (SOTA) methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "154",
        "title": "LuxVeri at GenAI Detection Task 1: Inverse Perplexity Weighted Ensemble for Robust Detection of AI-Generated Text across English and Multilingual Contexts",
        "author": [
            "Md Kamrujjaman Mobin",
            "Md Saiful Islam"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11914",
        "abstract": "This paper presents a system developed for Task 1 of the COLING 2025 Workshop on Detecting AI-Generated Content, focusing on the binary classification of machine-generated versus human-written text. Our approach utilizes an ensemble of models, with weights assigned according to each model's inverse perplexity, to enhance classification accuracy. For the English text detection task, we combined RoBERTa-base, RoBERTa-base with the OpenAI detector, and BERT-base-cased, achieving a Macro F1-score of 0.7458, which ranked us 12th out of 35 teams. We ensembled RemBERT, XLM-RoBERTa-base, and BERT-base-multilingual-case for the multilingual text detection task, employing the same inverse perplexity weighting technique. This resulted in a Macro F1-score of 0.7513, positioning us 4th out of 25 teams. Our results demonstrate the effectiveness of inverse perplexity weighting in improving the robustness of machine-generated text detection across both monolingual and multilingual settings, highlighting the potential of ensemble methods for this challenging task.",
        "tags": [
            "BERT",
            "Detection"
        ]
    },
    {
        "id": "155",
        "title": "LuxVeri at GenAI Detection Task 3: Cross-Domain Detection of AI-Generated Text Using Inverse Perplexity-Weighted Ensemble of Fine-Tuned Transformer Models",
        "author": [
            "Md Kamrujjaman Mobin",
            "Md Saiful Islam"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11918",
        "abstract": "This paper presents our approach for Task 3 of the GenAI content detection workshop at COLING-2025, focusing on Cross-Domain Machine-Generated Text (MGT) Detection. We propose an ensemble of fine-tuned transformer models, enhanced by inverse perplexity weighting, to improve classification accuracy across diverse text domains. For Subtask A (Non-Adversarial MGT Detection), we combined a fine-tuned RoBERTa-base model with an OpenAI detector-integrated RoBERTa-base model, achieving an aggregate TPR score of 0.826, ranking 10th out of 23 detectors. In Subtask B (Adversarial MGT Detection), our fine-tuned RoBERTa-base model achieved a TPR score of 0.801, securing 8th out of 22 detectors. Our results demonstrate the effectiveness of inverse perplexity-based weighting for enhancing generalization and performance in both non-adversarial and adversarial MGT detection, highlighting the potential for transformer models in cross-domain AI-generated content detection.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "156",
        "title": "ALoFTRAG: Automatic Local Fine Tuning for Retrieval Augmented Generation",
        "author": [
            "Peter Devine"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11929",
        "abstract": "Retrieval Augmented Generation (RAG) systems have been shown to improve the accuracy of Large Language Model (LLM) outputs. However, these models can often achieve low accuracy when applied to new data domains.\nWe introduce the Automatic Local Fine Tuning of Retrieval Augmented Generation models (ALoFTRAG) framework, designed to improve the accuracy of RAG systems on a given domain by training LLMs without manually labeled data or using larger teacher models.\nBy generating and filtering synthetic training data and performing LoRA fine-tuning, ALoFTRAG improves citation and answer accuracy across 20 datasets in 26 languages by, on average, 8.3% and 3.0% respectively.\nOur results demonstrate that ALoFTRAG offers a practical, cost-effective, and data-secure solution for improving RAG accuracy, making it particularly applicable to sensitive domains such as healthcare and finance.",
        "tags": [
            "LLMs",
            "LoRA",
            "RAG"
        ]
    },
    {
        "id": "157",
        "title": "Webvs. LLMs: An Empirical Study of Learning Behaviors of CS2 Students",
        "author": [
            "Aayush Kumar",
            "Daniel Prol",
            "Amin Alipour",
            "Sruti Srinivasa Ragavan"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11935",
        "abstract": "LLMs such as ChatGPT have been widely adopted by students in higher education as tools for learning programming and related concepts. However, it remains unclear how effective students are and what strategies students use while learning with LLMs. Since the majority of students' experiences in online self-learning have come through using search engines such as Google, evaluating AI tools in this context can help us address these gaps. In this mixed methods research, we conducted an exploratory within-subjects study to understand how CS2 students learn programming concepts using both LLMs as well as traditional online methods such as educational websites and videos to examine how students approach learning within and across both scenarios. We discovered that students found it easier to learn a more difficult concept using traditional methods than using ChatGPT. We also found that students ask fewer follow-ups and use more keyword-based queries for search engines while their prompts to LLMs tend to explicitly ask for information.",
        "tags": [
            "ChatGPT",
            "LLMs"
        ]
    },
    {
        "id": "158",
        "title": "GLAM: Global-Local Variation Awareness in Mamba-based World Model",
        "author": [
            "Qian He",
            "Wenqi Liang",
            "Chunhui Hao",
            "Gan Sun",
            "Jiandong Tian"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11949",
        "abstract": "Mimicking the real interaction trajectory in the inference of the world model has been shown to improve the sample efficiency of model-based reinforcement learning (MBRL) algorithms. Many methods directly use known state sequences for reasoning. However, this approach fails to enhance the quality of reasoning by capturing the subtle variation between states. Much like how humans infer trends in event development from this variation, in this work, we introduce Global-Local variation Awareness Mamba-based world model (GLAM) that improves reasoning quality by perceiving and predicting variation between states. GLAM comprises two Mambabased parallel reasoning modules, GMamba and LMamba, which focus on perceiving variation from global and local perspectives, respectively, during the reasoning process. GMamba focuses on identifying patterns of variation between states in the input sequence and leverages these patterns to enhance the prediction of future state variation. LMamba emphasizes reasoning about unknown information, such as rewards, termination signals, and visual representations, by perceiving variation in adjacent states. By integrating the strengths of the two modules, GLAM accounts for highervalue variation in environmental changes, providing the agent with more efficient imagination-based training. We demonstrate that our method outperforms existing methods in normalized human scores on the Atari 100k benchmark.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "159",
        "title": "Proverbs Run in Pairs: Evaluating Proverb Translation Capability of Large Language Model",
        "author": [
            "Minghan Wang",
            "Viet-Thanh Pham",
            "Farhad Moghimifar",
            "Thuy-Trang Vu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11953",
        "abstract": "Despite achieving remarkable performance, machine translation (MT) research remains underexplored in terms of translating cultural elements in languages, such as idioms, proverbs, and colloquial expressions. This paper investigates the capability of state-of-the-art neural machine translation (NMT) and large language models (LLMs) in translating proverbs, which are deeply rooted in cultural contexts. We construct a translation dataset of standalone proverbs and proverbs in conversation for four language pairs. Our experiments show that the studied models can achieve good translation between languages with similar cultural backgrounds, and LLMs generally outperform NMT models in proverb translation. Furthermore, we find that current automatic evaluation metrics such as BLEU, CHRF++ and COMET are inadequate for reliably assessing the quality of proverb translation, highlighting the need for more culturally aware evaluation metrics.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "160",
        "title": "A Hybrid Attention Framework for Fake News Detection with Large Language Models",
        "author": [
            "Xiaochuan Xu",
            "Peiyang Yu",
            "Zeqiu Xu",
            "Jiani Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11967",
        "abstract": "With the rapid growth of online information, the spread of fake news has become a serious social challenge. In this study, we propose a novel detection framework based on Large Language Models (LLMs) to identify and classify fake news by integrating textual statistical features and deep semantic features. Our approach utilizes the contextual understanding capability of the large language model for text analysis and introduces a hybrid attention mechanism to focus on feature combinations that are particularly important for fake news identification. Extensive experiments on the WELFake news dataset show that our model significantly outperforms existing methods, with a 1.5\\% improvement in F1 score. In addition, we assess the interpretability of the model through attention heat maps and SHAP values, providing actionable insights for content review strategies. Our framework provides a scalable and efficient solution to deal with the spread of fake news and helps build a more reliable online information ecosystem.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "161",
        "title": "Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization",
        "author": [
            "Jie Zhao",
            "Kang Hao Cheong",
            "Witold Pedrycz"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11968",
        "abstract": "Graph-structured combinatorial challenges are inherently difficult due to their nonlinear and intricate nature, often rendering traditional computational methods ineffective or expensive. However, these challenges can be more naturally tackled by humans through visual representations that harness our innate ability for spatial reasoning. In this study, we propose transforming graphs into images to preserve their higher-order structural features accurately, revolutionizing the representation used in solving graph-structured combinatorial tasks. This approach allows machines to emulate human-like processing in addressing complex combinatorial challenges. By combining the innovative paradigm powered by multimodal large language models (MLLMs) with simple search techniques, we aim to develop a novel and effective framework for tackling such problems. Our investigation into MLLMs spanned a variety of graph-based tasks, from combinatorial problems like influence maximization to sequential decision-making in network dismantling, as well as addressing six fundamental graph-related issues. Our findings demonstrate that MLLMs exhibit exceptional spatial intelligence and a distinctive capability for handling these problems, significantly advancing the potential for machines to comprehend and analyze graph-structured data with a depth and intuition akin to human cognition. These results also imply that integrating MLLMs with simple optimization strategies could form a novel and efficient approach for navigating graph-structured combinatorial challenges without complex derivations, computationally demanding training and fine-tuning.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "162",
        "title": "SMamba: Sparse Mamba for Event-based Object Detection",
        "author": [
            "Nan Yang",
            "Yang Wang",
            "Zhanwen Liu",
            "Meng Li",
            "Yisheng An",
            "Xiangmo Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11971",
        "abstract": "Transformer-based methods have achieved remarkable performance in event-based object detection, owing to the global modeling ability. However, they neglect the influence of non-event and noisy regions and process them uniformly, leading to high computational overhead. To mitigate computation cost, some researchers propose window attention based sparsification strategies to discard unimportant regions, which sacrifices the global modeling ability and results in suboptimal performance. To achieve better trade-off between accuracy and efficiency, we propose Sparse Mamba (SMamba), which performs adaptive sparsification to reduce computational effort while maintaining global modeling capability. Specifically, a Spatio-Temporal Continuity Assessment module is proposed to measure the information content of tokens and discard uninformative ones by leveraging the spatiotemporal distribution differences between activity and noise events. Based on the assessment results, an Information-Prioritized Local Scan strategy is designed to shorten the scan distance between high-information tokens, facilitating interactions among them in the spatial dimension. Furthermore, to extend the global interaction from 2D space to 3D representations, a Global Channel Interaction module is proposed to aggregate channel information from a global spatial perspective. Results on three datasets (Gen1, 1Mpx, and eTram) demonstrate that our model outperforms other methods in both performance and efficiency.",
        "tags": [
            "3D",
            "Detection",
            "Mamba",
            "Transformer"
        ]
    },
    {
        "id": "163",
        "title": "Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues",
        "author": [
            "Maya Medjad",
            "Hugo Imbert",
            "Bruno Yun",
            "RaphaÃ«l Szymocha",
            "FrÃ©dÃ©ric Armetta"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11977",
        "abstract": "Training task-oriented dialogue systems is both costly and time-consuming, due to the need for high-quality datasets encompassing diverse intents. Traditional methods depend on extensive human annotation, while recent advancements leverage large language models (LLMs) to generate synthetic data. However, these approaches often require custom prompts or code, limiting accessibility for non-technical users. We introduce GraphTOD, an end-to-end framework that simplifies the generation of task-oriented dialogues. Users can create dialogues by specifying transition graphs in JSON format. Our evaluation demonstrates that GraphTOD generates high-quality dialogues across various domains, significantly lowering the cost and complexity of dataset creation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "164",
        "title": "Linear Feedback Control Systems for Iterative Prompt Optimization in Large Language Models",
        "author": [
            "Rupesh Raj Karn"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11979",
        "abstract": "Large Language Models (LLMs) have revolutionized various applications by generating outputs based on given prompts. However, achieving the desired output requires iterative prompt refinement. This paper presents a novel approach that draws parallels between the iterative prompt optimization process in LLMs and feedback control systems. We iteratively refine the prompt by treating the deviation between the LLM output and the desired result as an error term until the output criteria are met. This process is akin to a feedback control system, where the LLM, despite being non-linear and non-deterministic, is managed using principles from linear feedback control systems. We explore the application of different types of controllers within this framework, providing a mathematical foundation for integrating linear feedback control mechanisms with LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "165",
        "title": "Comparative Analysis of Pre-trained Deep Learning Models and DINOv2 for Cushing's Syndrome Diagnosis in Facial Analysis",
        "author": [
            "Hongjun Liu",
            "Changwei Song",
            "Jiaqi Qiang",
            "Jianqiang Li",
            "Hui Pan",
            "Lin Lu",
            "Xiao Long",
            "Qing Zhao",
            "Jiuzuo Huang",
            "Shi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12023",
        "abstract": "Cushing's syndrome is a condition caused by excessive glucocorticoid secretion from the adrenal cortex, often manifesting with moon facies and plethora, making facial data crucial for diagnosis. Previous studies have used pre-trained convolutional neural networks (CNNs) for diagnosing Cushing's syndrome using frontal facial images. However, CNNs are better at capturing local features, while Cushing's syndrome often presents with global facial features. Transformer-based models like ViT and SWIN, which utilize self-attention mechanisms, can better capture long-range dependencies and global features. Recently, DINOv2, a foundation model based on visual Transformers, has gained interest. This study compares the performance of various pre-trained models, including CNNs, Transformer-based models, and DINOv2, in diagnosing Cushing's syndrome. We also analyze gender bias and the impact of freezing mechanisms on DINOv2. Our results show that Transformer-based models and DINOv2 outperformed CNNs, with ViT achieving the highest F1 score of 85.74%. Both the pre-trained model and DINOv2 had higher accuracy for female samples. DINOv2 also showed improved performance when freezing parameters. In conclusion, Transformer-based models and DINOv2 are effective for Cushing's syndrome classification.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "166",
        "title": "Harnessing Generative Pre-Trained Transformer for Datacenter Packet Trace Generation",
        "author": [
            "Chen Griner"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12033",
        "abstract": "Today, the rapid growth of applications reliant on datacenters calls for new advancements to meet the increasing traffic and computational demands. Traffic traces from datacenters are essential for further development and optimization of future datacenters. However, traces are rarely released to the public. Researchers often use simplified mathematical models that lack the depth needed to recreate intricate traffic patterns and, thus, miss optimization opportunities found in realistic traffic. In this preliminary work, we introduce DTG-GPT, a packet-level Datacenter Traffic Generator (DTG), based on the generative pre-trained transformer (GPT) architecture used by many state-of-the-art large language models. We train our model on a small set of available traffic traces from different domains and offer a simple methodology to evaluate the fidelity of the generated traces to their original counterparts. We show that DTG-GPT can synthesize novel traces that mimic the spatiotemporal patterns found in real traffic traces. We further demonstrate that DTG-GPT can generate traces for networks of different scales while maintaining fidelity. Our findings indicate the potential that, in the future, similar models to DTG-GPT will allow datacenter operators to release traffic information to the research community via trained GPT models.",
        "tags": [
            "GPT",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "167",
        "title": "PINNsAgent: Automated PDE Surrogation with Large Language Models",
        "author": [
            "Qingpo Wuwu",
            "Chonghan Gao",
            "Tianyu Chen",
            "Yihang Huang",
            "Yuekai Zhang",
            "Jianing Wang",
            "Jianxin Li",
            "Haoyi Zhou",
            "Shanghang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12053",
        "abstract": "Solving partial differential equations (PDEs) using neural methods has been a long-standing scientific and engineering research pursuit. Physics-Informed Neural Networks (PINNs) have emerged as a promising alternative to traditional numerical methods for solving PDEs. However, the gap between domain-specific knowledge and deep learning expertise often limits the practical application of PINNs. Previous works typically involve manually conducting extensive PINNs experiments and summarizing heuristic rules for hyperparameter tuning. In this work, we introduce PINNsAgent, a novel surrogation framework that leverages large language models (LLMs) and utilizes PINNs as a foundation to bridge the gap between domain-specific knowledge and deep learning. Specifically, PINNsAgent integrates (1) Physics-Guided Knowledge Replay (PGKR), which encodes the essential characteristics of PDEs and their associated best-performing PINNs configurations into a structured format, enabling efficient knowledge transfer from solved PDEs to similar problems and (2) Memory Tree Reasoning, a strategy that effectively explores the search space for optimal PINNs architectures. By leveraging LLMs and exploration strategies, PINNsAgent enhances the automation and efficiency of PINNs-based solutions. We evaluate PINNsAgent on 14 benchmark PDEs, demonstrating its effectiveness in automating the surrogation process and significantly improving the accuracy of PINNs-based solutions.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "168",
        "title": "GaussianVideo: Efficient Video Representation Through 2D Gaussian Splatting",
        "author": [
            "Longan Wang",
            "Yuang Shi",
            "Wei Tsang Ooi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12060",
        "abstract": "3D Gaussian splats have emerged as a revolutionary, effective, learned representation for static 3D scenes. In this work, we explore using 2D Gaussian splats as a new primitive for representing videos. We propose GaussianVideo, an approach to learning a set of 2D Gaussian splats that can effectively represent video frames. GaussianVideo incorporates the following techniques: (i) To exploit temporal redundancy among adjacent frames, which can speed up training and improve the compression efficiency, we predict the Gaussian splats of a frame based on its previous frame; (ii) To control the trade-offs between file size and quality, we remove Gaussian splats with low contribution to the video quality; (iii) To capture dynamics in videos, we randomly add Gaussian splats to fit content with large motion or newly-appeared objects; (iv) To handle significant changes in the scene, we detect key frames based on loss differences during the learning process. Experiment results show that GaussianVideo achieves good rate-distortion trade-offs, comparable to state-of-the-art video codecs such as AV1 and VVC, and a rendering speed of 1500 fps for a 1920x1080 video.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "169",
        "title": "EDoRA: Efficient Weight-Decomposed Low-Rank Adaptation via Singular Value Decomposition",
        "author": [
            "Hamid Nasiri",
            "Peter Garraghan"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12067",
        "abstract": "Parameter-efficient fine-tuning methods, such as LoRA, reduces the number of trainable parameters. However, they often suffer from scalability issues and differences between their learning pattern and full fine-tuning. To overcome these limitations, we propose Efficient Weight-Decomposed Low-Rank Adaptation (EDoRA): a novel PEFT method that decomposes pre-trained weights into magnitude and directional components. By freezing low-rank matrices, initializing them by singular value decomposition, and introducing a small trainable matrix between them, EDoRA achieves substantial reduction in trainable parameters while maintaining learning capacity. Experimental results on the GLUE benchmark demonstrate that EDoRA achieves competitive or superior performance compared to state-of-the-art methods, such as LoRA and DoRA, with up to 30x fewer trainable parameters. This makes EDoRA a highly efficient solution for adapting LLMs to diverse tasks under memory-constrained settings. Code is available at https://github.com/Hamid-Nasiri/EDoRA .",
        "tags": [
            "LLMs",
            "LoRA"
        ]
    },
    {
        "id": "170",
        "title": "Directional Diffusion-Style Code Editing Pre-training",
        "author": [
            "Qingyuan Liang",
            "Zeyu Sun",
            "Qihao Zhu",
            "Junhao Hu",
            "Yifan Zhao",
            "Yizhou Chen",
            "Mingxuan Zhu",
            "Guoqing Wang",
            "Lu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12079",
        "abstract": "Code pre-trained models have shown promising effectiveness in various software engineering tasks. Among these tasks, many tasks are related to software evolution and/or code editing. However, existing code pre-trained models often overlook the real-world code editing data and the evolutionary nature of the editing process. In this paper, to simulate the step-by-step code editing process of human developers, we propose DivoT5, a pre-trained model based on directional diffusion at the data level. In DivoT5, we adopt two categories of pre-training tasks. The first category is mask and denoising tasks augmented with a diffusion direction representing code evolution. That is, we first apply a noising process to the code snippets before evolution, and then ask the pre-training process to restore the snippets with noise into the code snippets after evolution. The second category is tasks aiming to reinforce the evolutionary direction. That is, we first generate various intermediate versions for each pair of snippets before and after evolution, and then ask the pre-training process to transform the intermediate versions into the snippet after evolution for each pair. We evaluate DivoT5 for two code-editing scenarios and one non-editing scenario using five downstream tasks. Given each downstream task, we fine-tune the pre-trained DivoT5 to evaluate its effectiveness. Our experimental results show that DivoT5 achieves state-of-the-art (SOTA) performance on most tasks in comparison to models of the same scale (220M), large scale (770M) models in fine-tuning, and billion-scale (6.7B, 8B, ChatGPT) models in few-shot settings. For one code-editing task (i.e., automated code review), DivoT5 pre-trained on top of CodeT5-small (60M) can even outperform CodeT5-base (220M) and other pre-trained models with 220M parameters except for DivoT5 pre-trained on top of CodeT5-base (220M).",
        "tags": [
            "ChatGPT",
            "Diffusion"
        ]
    },
    {
        "id": "171",
        "title": "Dissecting the NVIDIA Hopper Architecture through Microbenchmarking and Multiple Level Analysis",
        "author": [
            "Weile Luo",
            "Ruibo Fan",
            "Zeyu Li",
            "Dayou Du",
            "Hongyuan Liu",
            "Qiang Wang",
            "Xiaowen Chu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12084",
        "abstract": "Modern GPUs, with their specialized hardware like tensor cores, are essential for demanding AI and deep learning applications. This study presents a comprehensive, multi-level microbenchmarking analysis of the NVIDIA Hopper GPU architecture, delving into its performance characteristics and novel features. We benchmark Hopper's memory subsystem latency and throughput, comparing its L2 partitioned cache behavior and global memory access patterns against recent GPU generations, Ampere and Ada Lovelace. Our analysis reveals significant performance differences and architectural improvements in Hopper. A core contribution of this work is a detailed evaluation of Hopper's fourth-generation tensor cores, including their FP8 precision support and the novel asynchronous wgmma instructions, assessing their impact on matrix multiply-accumulate operations. We further investigate the performance implications of other key Hopper innovations: DPX instructions for accelerating dynamic programming algorithms, distributed shared memory (DSM) for inter-SM communication, and the Tensor Memory Accelerator (TMA) for asynchronous data movement. This multi-level approach encompasses instruction-level microbenchmarks, library-level analysis of the Transformer Engine, and application-level benchmarks of tensor core performance within large language models. Our findings provide valuable, in-depth insights for software developers seeking to optimize performance and develop accurate performance models for the Hopper architecture, ultimately contributing to a deeper understanding of its potential for accelerating AI and other computationally intensive workloads.",
        "tags": [
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "172",
        "title": "UAV-Assisted Real-Time Disaster Detection Using Optimized Transformer Model",
        "author": [
            "Branislava Jankovic",
            "Sabina Jangirova",
            "Waseem Ullah",
            "Latif U. Khan",
            "Mohsen Guizani"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12087",
        "abstract": "Disaster recovery and management present significant challenges, particularly in unstable environments and hard-to-reach terrains. These difficulties can be overcome by employing unmanned aerial vehicles (UAVs) equipped with onboard embedded platforms and camera sensors. In this work, we address the critical need for accurate and timely disaster detection by enabling onboard aerial imagery processing and avoiding connectivity, privacy, and latency issues despite the challenges posed by limited onboard hardware resources. We propose a UAV-assisted edge framework for real-time disaster management, leveraging our proposed model optimized for real-time aerial image classification. The optimization of the model employs post-training quantization techniques. For real-world disaster scenarios, we introduce a novel dataset, DisasterEye, featuring UAV-captured disaster scenes as well as ground-level images taken by individuals on-site. Experimental results demonstrate the effectiveness of our model, achieving high accuracy with reduced inference latency and memory usage on resource-constrained devices. The framework's scalability and adaptability make it a robust solution for real-time disaster detection on resource-limited UAV platforms.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "173",
        "title": "Proxies for Distortion and Consistency with Applications for Real-World Image Restoration",
        "author": [
            "Sean Man",
            "Guy Ohayon",
            "Ron Raphaeli",
            "Michael Elad"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12102",
        "abstract": "Real-world image restoration deals with the recovery of images suffering from an unknown degradation. This task is typically addressed while being given only degraded images, without their corresponding ground-truth versions. In this hard setting, designing and evaluating restoration algorithms becomes highly challenging. This paper offers a suite of tools that can serve both the design and assessment of real-world image restoration algorithms. Our work starts by proposing a trained model that predicts the chain of degradations a given real-world measured input has gone through. We show how this estimator can be used to approximate the consistency -- the match between the measurements and any proposed recovered image. We also use this estimator as a guiding force for the design of a simple and highly-effective plug-and-play real-world image restoration algorithm, leveraging a pre-trained diffusion-based image prior. Furthermore, this work proposes no-reference proxy measures of MSE and LPIPS, which, without access to the ground-truth images, allow ranking of real-world image restoration algorithms according to their (approximate) MSE and LPIPS. The proposed suite provides a versatile, first of its kind framework for evaluating and comparing blind image restoration algorithms in real-world scenarios.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "174",
        "title": "Evaluating Efficiency and Engagement in Scripted and LLM-Enhanced Human-Robot Interactions",
        "author": [
            "Tim Schreiter",
            "Jens V. RÃ¼ppel",
            "Rishi Hazra",
            "Andrey Rudenko",
            "Martin Magnusson",
            "Achim J. Lilienthal"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12128",
        "abstract": "To achieve natural and intuitive interaction with people, HRI frameworks combine a wide array of methods for human perception, intention communication, human-aware navigation and collaborative action. In practice, when encountering unpredictable behavior of people or unexpected states of the environment, these frameworks may lack the ability to dynamically recognize such states, adapt and recover to resume the interaction. Large Language Models (LLMs), owing to their advanced reasoning capabilities and context retention, present a promising solution for enhancing robot adaptability. This potential, however, may not directly translate to improved interaction metrics. This paper considers a representative interaction with an industrial robot involving approach, instruction, and object manipulation, implemented in two conditions: (1) fully scripted and (2) including LLM-enhanced responses. We use gaze tracking and questionnaires to measure the participants' task efficiency, engagement, and robot perception. The results indicate higher subjective ratings for the LLM condition, but objective metrics show that the scripted condition performs comparably, particularly in efficiency and focus during simple tasks. We also note that the scripted condition may have an edge over LLM-enhanced responses in terms of response latency and energy consumption, especially for trivial and repetitive interactions.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Robot"
        ]
    },
    {
        "id": "175",
        "title": "Do LLMs Provide Links to Code Similar to what they Generate? A Study with Gemini and Bing CoPilot",
        "author": [
            "Daniele Bifolco",
            "Pietro Cassieri",
            "Giuseppe Scanniello",
            "Massimiliano Di Penta",
            "Fiorella Zampetti"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12134",
        "abstract": "Large Language Models (LLMs) are currently used for various software development tasks, including generating code snippets to solve specific problems. Unlike reuse from the Web, LLMs are limited in providing provenance information about the generated code, which may have important trustworthiness and legal consequences. While LLM-based assistants may provide external links that are \"related\" to the generated code, we do not know how relevant such links are. This paper presents the findings of an empirical study assessing the extent to which 243 and 194 code snippets, across six programming languages, generated by Bing CoPilot and Google Gemini, likely originate from the links provided by these two LLM-based assistants. The study leverages automated code similarity assessments with thorough manual analysis. The study's findings indicate that the LLM-based assistants provide a mix of relevant and irrelevant links having a different nature. Specifically, although 66% of the links from Bing CoPilot and 28% from Google Gemini are relevant, LLMs-based assistants still suffer from serious \"provenance debt\".",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "176",
        "title": "Improving Influence-based Instruction Tuning Data Selection for Balanced Learning of Diverse Capabilities",
        "author": [
            "Qirun Dai",
            "Dylan Zhang",
            "Jiaqi W. Ma",
            "Hao Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12147",
        "abstract": "Selecting appropriate training data is crucial for effective instruction fine-tuning of large language models (LLMs), which aims to (1) elicit strong capabilities, and (2) achieve balanced performance across a diverse range of tasks. Influence-based methods show promise in achieving (1) by estimating the contribution of each training example to the model's predictions, but often struggle with (2). Our systematic investigation reveals that this underperformance can be attributed to an inherent bias where certain tasks intrinsically have greater influence than others. As a result, data selection is often biased towards these tasks, not only hurting the model's performance on others but also, counterintuitively, harms performance on these high-influence tasks themselves.\nAs a remedy, we propose BIDS, a Balanced and Influential Data Selection algorithm. BIDS first normalizes influence scores of the training data, and then iteratively balances data selection by choosing the training example with the highest influence on the most underrepresented task. Experiments with both Llama-3 and Mistral-v0.3 on seven benchmarks spanning five diverse capabilities show that BIDS consistently outperforms both state-of-the-art influence-based algorithms and other non-influence-based selection frameworks. Surprisingly, training on a 15% subset selected by BIDS can even outperform full-dataset training with a much more balanced performance. Our analysis further highlights the importance of both instance-level normalization and iterative optimization of selected data for balanced learning of diverse capabilities.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "177",
        "title": "DNRSelect: Active Best View Selection for Deferred Neural Rendering",
        "author": [
            "Dongli Wu",
            "Haochen Li",
            "Xiaobao Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12150",
        "abstract": "Deferred neural rendering (DNR) is an emerging computer graphics pipeline designed for high-fidelity rendering and robotic perception. However, DNR heavily relies on datasets composed of numerous ray-traced images and demands substantial computational resources. It remains under-explored how to reduce the reliance on high-quality ray-traced images while maintaining the rendering fidelity. In this paper, we propose DNRSelect, which integrates a reinforcement learning-based view selector and a 3D texture aggregator for deferred neural rendering. We first propose a novel view selector for deferred neural rendering based on reinforcement learning, which is trained on easily obtained rasterized images to identify the optimal views. By acquiring only a few ray-traced images for these selected views, the selector enables DNR to achieve high-quality rendering. To further enhance spatial awareness and geometric consistency in DNR, we introduce a 3D texture aggregator that fuses pyramid features from depth maps and normal maps with UV maps. Given that acquiring ray-traced images is more time-consuming than generating rasterized images, DNRSelect minimizes the need for ray-traced data by using only a few selected views while still achieving high-fidelity rendering results. We conduct detailed experiments and ablation studies on the NeRF-Synthetic dataset to demonstrate the effectiveness of DNRSelect. The code will be released.",
        "tags": [
            "3D",
            "NeRF"
        ]
    },
    {
        "id": "178",
        "title": "ComposeAnyone: Controllable Layout-to-Human Generation with Decoupled Multimodal Conditions",
        "author": [
            "Shiyue Zhang",
            "Zheng Chong",
            "Xi Lu",
            "Wenqing Zhang",
            "Haoxiang Li",
            "Xujie Zhang",
            "Jiehui Huang",
            "Xiao Dong",
            "Xiaodan Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12173",
        "abstract": "Building on the success of diffusion models, significant advancements have been made in multimodal image generation tasks. Among these, human image generation has emerged as a promising technique, offering the potential to revolutionize the fashion design process. However, existing methods often focus solely on text-to-image or image reference-based human generation, which fails to satisfy the increasingly sophisticated demands. To address the limitations of flexibility and precision in human generation, we introduce ComposeAnyone, a controllable layout-to-human generation method with decoupled multimodal conditions. Specifically, our method allows decoupled control of any part in hand-drawn human layouts using text or reference images, seamlessly integrating them during the generation process. The hand-drawn layout, which utilizes color-blocked geometric shapes such as ellipses and rectangles, can be easily drawn, offering a more flexible and accessible way to define spatial layouts. Additionally, we introduce the ComposeHuman dataset, which provides decoupled text and reference image annotations for different components of each human image, enabling broader applications in human image generation tasks. Extensive experiments on multiple datasets demonstrate that ComposeAnyone generates human images with better alignment to given layouts, text descriptions, and reference images, showcasing its multi-task capability and controllability.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "179",
        "title": "Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation",
        "author": [
            "Zibo Zhao",
            "Zeqiang Lai",
            "Qingxiang Lin",
            "Yunfei Zhao",
            "Haolin Liu",
            "Shuhui Yang",
            "Yifei Feng",
            "Mingxin Yang",
            "Sheng Zhang",
            "Xianghui Yang",
            "Huiwen Shi",
            "Sicong Liu",
            "Junta Wu",
            "Yihang Lian",
            "Fan Yang",
            "Ruining Tang",
            "Zebin He",
            "Xinzhou Wang",
            "Jian Liu",
            "Xuhui Zuo",
            "Zhuo Chen",
            "Biwen Lei",
            "Haohan Weng",
            "Jing Xu",
            "Yiling Zhu",
            "Xinhai Liu",
            "Lixin Xu",
            "Changrong Hu",
            "Tianyu Huang",
            "Lifu Wang",
            "Jihong Zhang",
            "Meng Chen",
            "Liang Dong",
            "Yiwen Jia",
            "Yulin Cai",
            "Jiaao Yu",
            "Yixuan Tang",
            "Hao Zhang",
            "Zheng Ye",
            "Peng He",
            "Runzhou Wu",
            "Chao Zhang",
            "Yonghao Tan",
            "Jie Xiao",
            "Yangyu Tao",
            "Jianchen Zhu",
            "Jinbao Xue",
            "Kai Liu",
            "Chongqing Zhao",
            "Xinming Wu",
            "Zhichao Hu",
            "Lei Qin",
            "Jianbing Peng",
            "Zhan Li",
            "Minghui Chen",
            "Xipeng Zhang",
            "Lin Niu",
            "Paige Wang",
            "Yingkai Wang",
            "Haozhao Kuang",
            "Zhongyi Fan",
            "Xu Zheng",
            "Weihao Zhuang",
            "YingPing He",
            "Tian Liu",
            "Yong Yang",
            "Di Wang",
            "Yuhong Liu",
            "Jie Jiang",
            "Jingwei Huang",
            "Chunchao Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12202",
        "abstract": "We present Hunyuan3D 2.0, an advanced large-scale 3D synthesis system for generating high-resolution textured 3D assets. This system includes two foundation components: a large-scale shape generation model -- Hunyuan3D-DiT, and a large-scale texture synthesis model -- Hunyuan3D-Paint. The shape generative model, built on a scalable flow-based diffusion transformer, aims to create geometry that properly aligns with a given condition image, laying a solid foundation for downstream applications. The texture synthesis model, benefiting from strong geometric and diffusion priors, produces high-resolution and vibrant texture maps for either generated or hand-crafted meshes. Furthermore, we build Hunyuan3D-Studio -- a versatile, user-friendly production platform that simplifies the re-creation process of 3D assets. It allows both professional and amateur users to manipulate or even animate their meshes efficiently. We systematically evaluate our models, showing that Hunyuan3D 2.0 outperforms previous state-of-the-art models, including the open-source models and closed-source models in geometry details, condition alignment, texture quality, and etc. Hunyuan3D 2.0 is publicly released in order to fill the gaps in the open-source 3D community for large-scale foundation generative models. The code and pre-trained weights of our models are available at: https://github.com/Tencent/Hunyuan3D-2",
        "tags": [
            "3D",
            "DiT",
            "Diffusion",
            "Diffusion Transformer",
            "Transformer"
        ]
    },
    {
        "id": "180",
        "title": "Fixing Imbalanced Attention to Mitigate In-Context Hallucination of Large Vision-Language Model",
        "author": [
            "Kazi Hasan Ibn Arif",
            "Sajib Acharjee Dip",
            "Khizar Hussain",
            "Lang Zhang",
            "Chris Thomas"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12206",
        "abstract": "Large Vision Language Models (LVLMs) have demonstrated remarkable capabilities in understanding and describing visual content, achieving state-of-the-art performance across various vision-language tasks. However, these models frequently exhibit hallucination behavior, where they generate descriptions containing objects or details absent in the input image. Our work investigates this phenomenon by analyzing attention patterns across transformer layers and heads, revealing that hallucinations often stem from progressive degradation of visual grounding in deeper layers. We propose a novel attention modification approach that combines selective token emphasis and head-specific modulation to maintain visual grounding throughout the generation process. Our method introduces two key components: (1) a dual-stream token selection mechanism that identifies and prioritizes both locally informative and spatially significant visual tokens, and (2) an attention head-specific modulation strategy that differentially amplifies visual information processing based on measured visual sensitivity of individual attention heads. Through extensive experimentation on the MSCOCO dataset, we demonstrate that our approach reduces hallucination rates by up to 62.3\\% compared to baseline models while maintaining comparable task performance. Our analysis reveals that selectively modulating tokens across attention heads with varying levels of visual sensitivity can significantly improve visual grounding without requiring model retraining.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "181",
        "title": "You Can't Eat Your Cake and Have It Too: The Performance Degradation of LLMs with Jailbreak Defense",
        "author": [
            "Wuyuao Mai",
            "Geng Hong",
            "Pei Chen",
            "Xudong Pan",
            "Baojun Liu",
            "Yuan Zhang",
            "Haixin Duan",
            "Min Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12210",
        "abstract": "With the rise of generative large language models (LLMs) like LLaMA and ChatGPT, these models have significantly transformed daily life and work by providing advanced insights. However, as jailbreak attacks continue to circumvent built-in safety mechanisms, exploiting carefully crafted scenarios or tokens, the safety risks of LLMs have come into focus. While numerous defense strategies--such as prompt detection, modification, and model fine-tuning--have been proposed to counter these attacks, a critical question arises: do these defenses compromise the utility and usability of LLMs for legitimate users? Existing research predominantly focuses on the effectiveness of defense strategies without thoroughly examining their impact on performance, leaving a gap in understanding the trade-offs between LLM safety and performance. Our research addresses this gap by conducting a comprehensive study on the utility degradation, safety elevation, and exaggerated-safety escalation of LLMs with jailbreak defense strategies. We propose USEBench, a novel benchmark designed to evaluate these aspects, along with USEIndex, a comprehensive metric for assessing overall model performance. Through experiments on seven state-of-the-art LLMs, we found that mainstream jailbreak defenses fail to ensure both safety and performance simultaneously. Although model-finetuning performs the best overall, their effectiveness varies across LLMs. Furthermore, vertical comparisons reveal that developers commonly prioritize performance over safety when iterating or fine-tuning their LLMs.",
        "tags": [
            "ChatGPT",
            "Detection",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "182",
        "title": "Automatic selection of the best neural architecture for time series forecasting via multi-objective optimization and Pareto optimality conditions",
        "author": [
            "Qianying Cao",
            "Shanqing Liu",
            "Alan John Varghese",
            "Jerome Darbon",
            "Michael Triantafyllou",
            "George Em Karniadakis"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12215",
        "abstract": "Time series forecasting plays a pivotal role in a wide range of applications, including weather prediction, healthcare, structural health monitoring, predictive maintenance, energy systems, and financial markets. While models such as LSTM, GRU, Transformers, and State-Space Models (SSMs) have become standard tools in this domain, selecting the optimal architecture remains a challenge. Performance comparisons often depend on evaluation metrics and the datasets under analysis, making the choice of a universally optimal model controversial. In this work, we introduce a flexible automated framework for time series forecasting that systematically designs and evaluates diverse network architectures by integrating LSTM, GRU, multi-head Attention, and SSM blocks. Using a multi-objective optimization approach, our framework determines the number, sequence, and combination of blocks to align with specific requirements and evaluation objectives. From the resulting Pareto-optimal architectures, the best model for a given context is selected via a user-defined preference function. We validate our framework across four distinct real-world applications. Results show that a single-layer GRU or LSTM is usually optimal when minimizing training time alone. However, when maximizing accuracy or balancing multiple objectives, the best architectures are often composite designs incorporating multiple block types in specific configurations. By employing a weighted preference function, users can resolve trade-offs between objectives, revealing novel, context-specific optimal architectures. Our findings underscore that no single neural architecture is universally optimal for time series forecasting. Instead, the best-performing model emerges as a data-driven composite architecture tailored to user-defined criteria and evaluation objectives.",
        "tags": [
            "SSMs",
            "State Space Models"
        ]
    },
    {
        "id": "183",
        "title": "Exploring Temporally-Aware Features for Point Tracking",
        "author": [
            "InÃ¨s Hyeonsu Kim",
            "Seokju Cho",
            "Jiahui Huang",
            "Jung Yi",
            "Joon-Young Lee",
            "Seungryong Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12218",
        "abstract": "Point tracking in videos is a fundamental task with applications in robotics, video editing, and more. While many vision tasks benefit from pre-trained feature backbones to improve generalizability, point tracking has primarily relied on simpler backbones trained from scratch on synthetic data, which may limit robustness in real-world scenarios. Additionally, point tracking requires temporal awareness to ensure coherence across frames, but using temporally-aware features is still underexplored. Most current methods often employ a two-stage process: an initial coarse prediction followed by a refinement stage to inject temporal information and correct errors from the coarse stage. These approach, however, is computationally expensive and potentially redundant if the feature backbone itself captures sufficient temporal information.\nIn this work, we introduce Chrono, a feature backbone specifically designed for point tracking with built-in temporal awareness. Leveraging pre-trained representations from self-supervised learner DINOv2 and enhanced with a temporal adapter, Chrono effectively captures long-term temporal context, enabling precise prediction even without the refinement stage. Experimental results demonstrate that Chrono achieves state-of-the-art performance in a refiner-free setting on the TAP-Vid-DAVIS and TAP-Vid-Kinetics datasets, among common feature backbones used in point tracking as well as DINOv2, with exceptional efficiency. Project page: https://cvlab-kaist.github.io/Chrono/",
        "tags": [
            "Robotics",
            "Video Editing"
        ]
    },
    {
        "id": "184",
        "title": "Leveraging Large Language Models for Realizing Truly Intelligent User Interfaces",
        "author": [
            "Allard Oelen",
            "SÃ¶ren Auer"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12221",
        "abstract": "The number of published scholarly articles is growing at a significant rate, making scholarly knowledge organization increasingly important. Various approaches have been proposed to organize scholarly information, including describing scholarly knowledge semantically leveraging knowledge graphs. Transforming unstructured knowledge, presented within articles, to structured and semantically represented knowledge generally requires human intelligence and labor since natural language processing methods alone typically do not render sufficient precision and recall for many applications. With the recent developments of Large Language Models (LLMs), it becomes increasingly possible to provide truly intelligent user interfaces guiding humans in the transformation process. We present an approach to integrate non-intrusive LLMs guidance into existing user interfaces. More specifically, we integrate LLM-supported user interface components into an existing scholarly knowledge infrastructure. Additionally, we provide our experiences with LLM integration, detailing best practices and obstacles. Finally, we evaluate the approach using a small-scale user evaluation with domain experts.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "185",
        "title": "TokenVerse: Versatile Multi-concept Personalization in Token Modulation Space",
        "author": [
            "Daniel Garibi",
            "Shahar Yadin",
            "Roni Paiss",
            "Omer Tov",
            "Shiran Zada",
            "Ariel Ephrat",
            "Tomer Michaeli",
            "Inbar Mosseri",
            "Tali Dekel"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12224",
        "abstract": "We present TokenVerse -- a method for multi-concept personalization, leveraging a pre-trained text-to-image diffusion model. Our framework can disentangle complex visual elements and attributes from as little as a single image, while enabling seamless plug-and-play generation of combinations of concepts extracted from multiple images. As opposed to existing works, TokenVerse can handle multiple images with multiple concepts each, and supports a wide-range of concepts, including objects, accessories, materials, pose, and lighting. Our work exploits a DiT-based text-to-image model, in which the input text affects the generation through both attention and modulation (shift and scale). We observe that the modulation space is semantic and enables localized control over complex concepts. Building on this insight, we devise an optimization-based framework that takes as input an image and a text description, and finds for each word a distinct direction in the modulation space. These directions can then be used to generate new images that combine the learned concepts in a desired configuration. We demonstrate the effectiveness of TokenVerse in challenging personalization settings, and showcase its advantages over existing methods. project's webpage in https://token-verse.github.io/",
        "tags": [
            "DiT",
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "186",
        "title": "CDW-CoT: Clustered Distance-Weighted Chain-of-Thoughts Reasoning",
        "author": [
            "Yuanheng Fang",
            "Guoqing Chao",
            "Wenqiang Lei",
            "Shaobo Li",
            "Dianhui Chu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12226",
        "abstract": "Large Language Models (LLMs) have recently achieved impressive results in complex reasoning tasks through Chain of Thought (CoT) prompting. However, most existing CoT methods rely on using the same prompts, whether manually designed or automatically generated, to handle the entire dataset. This one-size-fits-all approach may fail to meet the specific needs arising from the diversities within a single dataset. To solve this problem, we propose the Clustered Distance-Weighted Chain of Thought (CDW-CoT) method, which dynamically constructs prompts tailored to the characteristics of each data instance by integrating clustering and prompt optimization techniques. Our method employs clustering algorithms to categorize the dataset into distinct groups, from which a candidate pool of prompts is selected to reflect the inherent diversity within the dataset. For each cluster, CDW-CoT trains the optimal prompt probability distribution tailored to their specific characteristics. Finally, it dynamically constructs a unique prompt probability distribution for each test instance, based on its proximity to cluster centers, from which prompts are selected for reasoning. CDW-CoT consistently outperforms traditional CoT methods across six datasets, including commonsense, symbolic, and mathematical reasoning tasks. Specifically, when compared to manual CoT, CDW-CoT achieves an average accuracy improvement of 25.34% on LLaMA2 (13B) and 15.72% on LLaMA3 (8B).",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "187",
        "title": "InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models",
        "author": [
            "Pha Nguyen",
            "Sailik Sengupta",
            "Girik Malik",
            "Arshit Gupta",
            "Bonan Min"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12231",
        "abstract": "The improved competence of generative models can help building multi-modal virtual assistants that leverage modalities beyond language. By observing humans performing multi-step tasks, one can build assistants that have situational awareness of actions and tasks being performed, enabling them to cater assistance based on this understanding. In this paper, we develop a Context-aware Instructional Task Assistant with Multi-modal Large Language Models (InsTALL) that leverages an online visual stream (e.g. a user's screen share or video recording) and responds in real-time to user queries related to the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal model on task videos and paired textual data, and 2) automatically extracts task graph from video data and leverages it at training and inference time. We show InsTALL achieves state-of-the-art performance across proposed sub-tasks considered for multimodal activity understanding -- task recognition (TR), action recognition (AR), next action prediction (AP), and plan prediction (PP) -- and outperforms existing baselines on two novel sub-tasks related to automatic error identification.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "188",
        "title": "DLEN: Dual Branch of Transformer for Low-Light Image Enhancement in Dual Domains",
        "author": [
            "Junyu Xia",
            "Jiesong Bai",
            "Yihang Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12235",
        "abstract": "Low-light image enhancement (LLE) aims to improve the visual quality of images captured in poorly lit conditions, which often suffer from low brightness, low contrast, noise, and color distortions. These issues hinder the performance of computer vision tasks such as object detection, facial recognition, and autonomous http://driving.Traditional enhancement techniques, such as multi-scale fusion and histogram equalization, fail to preserve fine details and often struggle with maintaining the natural appearance of enhanced images under complex lighting conditions. Although the Retinex theory provides a foundation for image decomposition, it often amplifies noise, leading to suboptimal image quality. In this paper, we propose the Dual Light Enhance Network (DLEN), a novel architecture that incorporates two distinct attention mechanisms, considering both spatial and frequency domains. Our model introduces a learnable wavelet transform module in the illumination estimation phase, preserving high- and low-frequency components to enhance edge and texture details. Additionally, we design a dual-branch structure that leverages the power of the Transformer architecture to enhance both the illumination and structural components of the http://image.Through extensive experiments, our model outperforms state-of-the-art methods on standard http://benchmarks.Code is available here: https://github.com/LaLaLoXX/DLEN",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "189",
        "title": "FOCUS: First Order Concentrated Updating Scheme",
        "author": [
            "Yizhou Liu",
            "Ziming Liu",
            "Jeff Gore"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12243",
        "abstract": "Large language models (LLMs) demonstrate remarkable performance, and improving their pre-training process appears to be key to enhancing their capabilities further. Based on the documented success of Adam, learning rate decay, and weight decay, we hypothesize that the pre-training loss landscape features a narrowing valley structure. Through experiments with synthetic loss functions, we discover that when gradient query noise is high relative to the valley's sharpness, Adam's performance falls behind that of Signum because Adam reduces the effective step size too drastically. This observation led us to develop FOCUS, an optimizer that enhances Signum by incorporating attraction toward moving averaged parameters, allowing it to handle noise better while maintaining larger step sizes. In training GPT-2, FOCUS proves to be more stable than Signum and faster than Adam. These results suggest that gradient noise may be an underappreciated limiting factor in LLM training, and FOCUS offers promising solutions.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "190",
        "title": "HAC++: Towards 100X Compression of 3D Gaussian Splatting",
        "author": [
            "Yihang Chen",
            "Qianyi Wu",
            "Weiyao Lin",
            "Mehrtash Harandi",
            "Jianfei Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12255",
        "abstract": "3D Gaussian Splatting (3DGS) has emerged as a promising framework for novel view synthesis, boasting rapid rendering speed with high fidelity. However, the substantial Gaussians and their associated attributes necessitate effective compression techniques. Nevertheless, the sparse and unorganized nature of the point cloud of Gaussians (or anchors in our paper) presents challenges for compression. To achieve a compact size, we propose HAC++, which leverages the relationships between unorganized anchors and a structured hash grid, utilizing their mutual information for context modeling. Additionally, HAC++ captures intra-anchor contextual relationships to further enhance compression performance. To facilitate entropy coding, we utilize Gaussian distributions to precisely estimate the probability of each quantized attribute, where an adaptive quantization module is proposed to enable high-precision quantization of these attributes for improved fidelity restoration. Moreover, we incorporate an adaptive masking strategy to eliminate invalid Gaussians and anchors. Overall, HAC++ achieves a remarkable size reduction of over 100X compared to vanilla 3DGS when averaged on all datasets, while simultaneously improving fidelity. It also delivers more than 20X size reduction compared to Scaffold-GS. Our code is available at https://github.com/YihangChen-ee/HAC-plus.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "191",
        "title": "VipDiff: Towards Coherent and Diverse Video Inpainting via Training-free Denoising Diffusion Models",
        "author": [
            "Chaohao Xie",
            "Kai Han",
            "Kwan-Yee K. Wong"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12267",
        "abstract": "Recent video inpainting methods have achieved encouraging improvements by leveraging optical flow to guide pixel propagation from reference frames either in the image space or feature space. However, they would produce severe artifacts in the mask center when the masked area is too large and no pixel correspondences can be found for the center. Recently, diffusion models have demonstrated impressive performance in generating diverse and high-quality images, and have been exploited in a number of works for image inpainting. These methods, however, cannot be applied directly to videos to produce temporal-coherent inpainting results. In this paper, we propose a training-free framework, named VipDiff, for conditioning diffusion model on the reverse diffusion process to produce temporal-coherent inpainting results without requiring any training data or fine-tuning the pre-trained diffusion models. VipDiff takes optical flow as guidance to extract valid pixels from reference frames to serve as constraints in optimizing the randomly sampled Gaussian noise, and uses the generated results for further pixel propagation and conditional generation. VipDiff also allows for generating diverse video inpainting results over different sampled noise. Experiments demonstrate that VipDiff can largely outperform state-of-the-art video inpainting methods in terms of both spatial-temporal coherence and fidelity.",
        "tags": [
            "Diffusion",
            "Inpainting"
        ]
    },
    {
        "id": "192",
        "title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement",
        "author": [
            "Maosong Cao",
            "Taolin Zhang",
            "Mo Li",
            "Chuyu Zhang",
            "Yunxin Liu",
            "Haodong Duan",
            "Songyang Zhang",
            "Kai Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12273",
        "abstract": "The quality of Supervised Fine-Tuning (SFT) data plays a critical role in enhancing the conversational capabilities of Large Language Models (LLMs). However, as LLMs become more advanced, the availability of high-quality human-annotated SFT data has become a significant bottleneck, necessitating a greater reliance on synthetic training data. In this work, we introduce Condor, a novel two-stage synthetic data generation framework that incorporates World Knowledge Tree and Self-Reflection Refinement to produce high-quality SFT data at scale. Our experimental results demonstrate that a base model fine-tuned on only 20K Condor-generated samples achieves superior performance compared to counterparts. The additional refinement stage in Condor further enables iterative self-improvement for LLMs at various scales (up to 72B), validating the effectiveness of our approach. Furthermore, our investigation into the scaling for synthetic data in post-training reveals substantial unexplored potential for performance improvements, opening promising avenues for future research.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "193",
        "title": "MoGERNN: An Inductive Traffic Predictor for Unobserved Locations in Dynamic Sensing Networks",
        "author": [
            "Qishen Zhou",
            "Yifan Zhang",
            "Michail A. Makridis",
            "Anastasios Kouvelas",
            "Yibing Wang",
            "Simon Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12281",
        "abstract": "Given a partially observed road network, how can we predict the traffic state of unobserved locations? While deep learning approaches show exceptional performance in traffic prediction, most assume sensors at all locations of interest, which is impractical due to financial constraints. Furthermore, these methods typically require costly retraining when sensor configurations change. We propose MoGERNN, an inductive spatio-temporal graph representation model, to address these challenges. Inspired by the Mixture of Experts approach in Large Language Models, we introduce a Mixture of Graph Expert (MoGE) block to model complex spatial dependencies through multiple graph message aggregators and a sparse gating network. This block estimates initial states for unobserved locations, which are then processed by a GRU-based Encoder-Decoder that integrates a graph message aggregator to capture spatio-temporal dependencies and predict future states. Experiments on two real-world datasets show MoGERNN consistently outperforms baseline methods for both observed and unobserved locations. MoGERNN can accurately predict congestion evolution even in areas without sensors, offering valuable information for traffic management. Moreover, MoGERNN is adaptable to dynamic sensing networks, maintaining competitive performance even compared to its retrained counterpart. Tests with different numbers of available sensors confirm its consistent superiority, and ablation studies validate the effectiveness of its key modules.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "194",
        "title": "Regressor-Guided Image Editing Regulates Emotional Response to Reduce Online Engagement",
        "author": [
            "Christoph Gebhardt",
            "Robin Willardt",
            "Seyedmorteza Sadat",
            "Chih-Wei Ning",
            "Andreas Brombach",
            "Jie Song",
            "Otmar Hilliges",
            "Christian Holz"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12289",
        "abstract": "Emotions are known to mediate the relationship between users' content consumption and their online engagement, with heightened emotional intensity leading to increased engagement. Building on this insight, we propose three regressor-guided image editing approaches aimed at diminishing the emotional impact of images. These include (i) a parameter optimization approach based on global image transformations known to influence emotions, (ii) an optimization approach targeting the style latent space of a generative adversarial network, and (iii) a diffusion-based approach employing classifier guidance and classifier-free guidance. Our findings demonstrate that approaches can effectively alter the emotional properties of images while maintaining high visual quality. Optimization-based methods primarily adjust low-level properties like color hues and brightness, whereas the diffusion-based approach introduces semantic changes, such as altering appearance or facial expressions. Notably, results from a behavioral study reveal that only the diffusion-based approach successfully elicits changes in viewers' emotional responses while preserving high perceived image quality. In future work, we will investigate the impact of these image adaptations on internet user behavior.",
        "tags": [
            "Diffusion",
            "Image Editing"
        ]
    },
    {
        "id": "195",
        "title": "LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations",
        "author": [
            "Hasan Abu-Rasheed",
            "Constance Jumbo",
            "Rashed Al Amin",
            "Christian Weber",
            "Veit Wiese",
            "Roman Obermaisser",
            "Madjid Fathi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12300",
        "abstract": "While learning personalization offers great potential for learners, modern practices in higher education require a deeper consideration of domain models and learning contexts, to develop effective personalization algorithms. This paper introduces an innovative approach to higher education curriculum modelling that utilizes large language models (LLMs) for knowledge graph (KG) completion, with the goal of creating personalized learning-path recommendations. Our research focuses on modelling university subjects and linking their topics to corresponding domain models, enabling the integration of learning modules from different faculties and institutions in the student's learning path. Central to our approach is a collaborative process, where LLMs assist human experts in extracting high-quality, fine-grained topics from lecture materials. We develop a domain, curriculum, and user models for university modules and stakeholders. We implement this model to create the KG from two study modules: Embedded Systems and Development of Embedded Systems Using FPGA. The resulting KG structures the curriculum and links it to the domain models. We evaluate our approach through qualitative expert feedback and quantitative graph quality metrics. Domain experts validated the relevance and accuracy of the model, while the graph quality metrics measured the structural properties of our KG. Our results show that the LLM-assisted graph completion approach enhances the ability to connect related courses across disciplines to personalize the learning experience. Expert feedback also showed high acceptance of the proposed collaborative approach for concept extraction and classification.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "196",
        "title": "UI-TARS: Pioneering Automated GUI Interaction with Native Agents",
        "author": [
            "Yujia Qin",
            "Yining Ye",
            "Junjie Fang",
            "Haoming Wang",
            "Shihao Liang",
            "Shizuo Tian",
            "Junda Zhang",
            "Jiahao Li",
            "Yunxin Li",
            "Shijue Huang",
            "Wanjun Zhong",
            "Kuanye Li",
            "Jiale Yang",
            "Yu Miao",
            "Woyu Lin",
            "Longxiang Liu",
            "Xu Jiang",
            "Qianli Ma",
            "Jingyu Li",
            "Xiaojun Xiao",
            "Kai Cai",
            "Chuang Li",
            "Yaowei Zheng",
            "Chaolin Jin",
            "Chen Li",
            "Xiao Zhou",
            "Minchao Wang",
            "Haoli Chen",
            "Zhaojian Li",
            "Haihua Yang",
            "Haifeng Liu",
            "Feng Lin",
            "Tao Peng",
            "Xin Liu",
            "Guang Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12326",
        "abstract": "This paper introduces UI-TARS, a native GUI agent model that solely perceives the screenshots as input and performs human-like interactions (e.g., keyboard and mouse operations). Unlike prevailing agent frameworks that depend on heavily wrapped commercial models (e.g., GPT-4o) with expert-crafted prompts and workflows, UI-TARS is an end-to-end model that outperforms these sophisticated frameworks. Experiments demonstrate its superior performance: UI-TARS achieves SOTA performance in 10+ GUI agent benchmarks evaluating perception, grounding, and GUI task execution. Notably, in the OSWorld benchmark, UI-TARS achieves scores of 24.6 with 50 steps and 22.7 with 15 steps, outperforming Claude (22.0 and 14.9 respectively). In AndroidWorld, UI-TARS achieves 46.6, surpassing GPT-4o (34.5). UI-TARS incorporates several key innovations: (1) Enhanced Perception: leveraging a large-scale dataset of GUI screenshots for context-aware understanding of UI elements and precise captioning; (2) Unified Action Modeling, which standardizes actions into a unified space across platforms and achieves precise grounding and interaction through large-scale action traces; (3) System-2 Reasoning, which incorporates deliberate reasoning into multi-step decision making, involving multiple reasoning patterns such as task decomposition, reflection thinking, milestone recognition, etc. (4) Iterative Training with Reflective Online Traces, which addresses the data bottleneck by automatically collecting, filtering, and reflectively refining new interaction traces on hundreds of virtual machines. Through iterative training and reflection tuning, UI-TARS continuously learns from its mistakes and adapts to unforeseen situations with minimal human intervention. We also analyze the evolution path of GUI agents to guide the further development of this domain.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "197",
        "title": "VARGPT: Unified Understanding and Generation in a Visual Autoregressive Multimodal Large Language Model",
        "author": [
            "Xianwei Zhuang",
            "Yuxin Xie",
            "Yufan Deng",
            "Liming Liang",
            "Jinghan Ru",
            "Yuguo Yin",
            "Yuexian Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12327",
        "abstract": "We present VARGPT, a novel multimodal large language model (MLLM) that unifies visual understanding and generation within a single autoregressive framework. VARGPT employs a next-token prediction paradigm for visual understanding and a next-scale prediction paradigm for visual autoregressive generation. VARGPT innovatively extends the LLaVA architecture, achieving efficient scale-wise autoregressive visual generation within MLLMs while seamlessly accommodating mixed-modal input and output within a single model framework. Our VARGPT undergoes a three-stage unified training process on specially curated datasets, comprising a pre-training phase and two mixed visual instruction-tuning phases. The unified training strategy are designed to achieve alignment between visual and textual features, enhance instruction following for both understanding and generation, and improve visual generation quality, respectively. Despite its LLAVA-based architecture for multimodel understanding, VARGPT significantly outperforms LLaVA-1.5 across various vision-centric benchmarks, such as visual question-answering and reasoning tasks. Notably, VARGPT naturally supports capabilities in autoregressive visual generation and instruction-to-image synthesis, showcasing its versatility in both visual understanding and generation tasks. Project page is at: \\url{https://vargpt-1.github.io/}",
        "tags": [
            "LLaVA"
        ]
    },
    {
        "id": "198",
        "title": "Automatic Labelling with Open-source LLMs using Dynamic Label Schema Integration",
        "author": [
            "Thomas Walshe",
            "Sae Young Moon",
            "Chunyang Xiao",
            "Yawwani Gunawardana",
            "Fran Silavong"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12332",
        "abstract": "Acquiring labelled training data remains a costly task in real world machine learning projects to meet quantity and quality requirements. Recently Large Language Models (LLMs), notably GPT-4, have shown great promises in labelling data with high accuracy. However, privacy and cost concerns prevent the ubiquitous use of GPT-4. In this work, we explore effectively leveraging open-source models for automatic labelling. We identify integrating label schema as a promising technology but found that naively using the label description for classification leads to poor performance on high cardinality tasks. To address this, we propose Retrieval Augmented Classification (RAC) for which LLM performs inferences for one label at a time using corresponding label schema; we start with the most related label and iterates until a label is chosen by the LLM. We show that our method, which dynamically integrates label description, leads to performance improvements in labelling tasks. We further show that by focusing only on the most promising labels, RAC can trade off between label quality and coverage - a property we leverage to automatically label our internal datasets.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "199",
        "title": "Treefix: Enabling Execution with a Tree of Prefixes",
        "author": [
            "Beatriz Souza",
            "Michael Pradel"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12339",
        "abstract": "The ability to execute code is a prerequisite for various dynamic program analyses. Learning-guided execution has been proposed as an approach to enable the execution of arbitrary code snippets by letting a neural model predict likely values for any missing variables. Although state-of-the-art learning-guided execution approaches, such as LExecutor, can enable the execution of a relative high amount of code, they are limited to predicting a restricted set of possible values and do not use any feedback from previous executions to execute even more code. This paper presents Treefix, a novel learning-guided execution approach that leverages LLMs to iteratively create code prefixes that enable the execution of a given code snippet. The approach addresses the problem in a multi-step fashion, where each step uses feedback about the code snippet and its execution to instruct an LLM to improve a previously generated prefix. This process iteratively creates a tree of prefixes, a subset of which is returned to the user as prefixes that maximize the number of executed lines in the code snippet. In our experiments with two datasets of Python code snippets, Treefix achieves 25% and 7% more coverage relative to the current state of the art in learning-guided execution, covering a total of 84% and 82% of all lines in the code snippets.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "200",
        "title": "Test-time regression: a unifying framework for designing sequence models with associative memory",
        "author": [
            "Ke Alexander Wang",
            "Jiaxin Shi",
            "Emily B. Fox"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12352",
        "abstract": "Sequences provide a remarkably general way to represent and process information. This powerful abstraction has placed sequence modeling at the center of modern deep learning applications, inspiring numerous architectures from transformers to recurrent networks. While this fragmented development has yielded powerful models, it has left us without a unified framework to understand their fundamental similarities and explain their effectiveness. We present a unifying framework motivated by an empirical observation: effective sequence models must be able to perform associative recall. Our key insight is that memorizing input tokens through an associative memory is equivalent to performing regression at test-time. This regression-memory correspondence provides a framework for deriving sequence models that can perform associative recall, offering a systematic lens to understand seemingly ad-hoc architectural choices. We show numerous recent architectures -- including linear attention models, their gated variants, state-space models, online learners, and softmax attention -- emerge naturally as specific approaches to test-time regression. Each architecture corresponds to three design choices: the relative importance of each association, the regressor function class, and the optimization algorithm. This connection leads to new understanding: we provide theoretical justification for QKNorm in softmax attention, and we motivate higher-order generalizations of softmax attention. Beyond unification, our work unlocks decades of rich statistical tools that can guide future development of more powerful yet principled sequence models.",
        "tags": [
            "State Space Models"
        ]
    },
    {
        "id": "201",
        "title": "Diffusion-aware Censored Gaussian Processes for Demand Modelling",
        "author": [
            "Filipe Rodrigues"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12354",
        "abstract": "Inferring the true demand for a product or a service from aggregate data is often challenging due to the limited available supply, thus resulting in observations that are censored and correspond to the realized demand, thereby not accounting for the unsatisfied demand. Censored regression models are able to account for the effect of censoring due to the limited supply, but they don't consider the effect of substitutions, which may cause the demand for similar alternative products or services to increase. This paper proposes Diffusion-aware Censored Demand Models, which combine a Tobit likelihood with a graph diffusion process in order to model the latent process of transfer of unsatisfied demand between similar products or services. We instantiate this new class of models under the framework of GPs and, based on both simulated and real-world data for modeling sales, bike-sharing demand, and EV charging demand, demonstrate its ability to better recover the true demand and produce more accurate out-of-sample predictions.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "202",
        "title": "DARB-Splatting: Generalizing Splatting with Decaying Anisotropic Radial Basis Functions",
        "author": [
            "Vishagar Arunan",
            "Saeedha Nazar",
            "Hashiru Pramuditha",
            "Vinasirajan Viruthshaan",
            "Sameera Ramasinghe",
            "Simon Lucey",
            "Ranga Rodrigo"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12369",
        "abstract": "Splatting-based 3D reconstruction methods have gained popularity with the advent of 3D Gaussian Splatting, efficiently synthesizing high-quality novel views. These methods commonly resort to using exponential family functions, such as the Gaussian function, as reconstruction kernels due to their anisotropic nature, ease of projection, and differentiability in rasterization. However, the field remains restricted to variations within the exponential family, leaving generalized reconstruction kernels largely underexplored, partly due to the lack of easy integrability in 3D to 2D projections. In this light, we show that a class of decaying anisotropic radial basis functions (DARBFs), which are non-negative functions of the Mahalanobis distance, supports splatting by approximating the Gaussian function's closed-form integration advantage. With this fresh perspective, we demonstrate up to 34% faster convergence during training and a 15% reduction in memory consumption across various DARB reconstruction kernels, while maintaining comparable PSNR, SSIM, and LPIPS results. We will make the code available.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "203",
        "title": "Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL",
        "author": [
            "Yeounoh Chung",
            "Gaurav T. Kakkar",
            "Yu Gan",
            "Brenton Milne",
            "Fatma Ozcan"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12372",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across a range of natural language processing tasks. In particular, improvements in reasoning abilities and the expansion of context windows have opened new avenues for leveraging these powerful models. NL2SQL is challenging in that the natural language question is inherently ambiguous, while the SQL generation requires a precise understanding of complex data schema and semantics. One approach to this semantic ambiguous problem is to provide more and sufficient contextual information.\nIn this work, we explore the performance and the latency trade-offs of the extended context window (a.k.a., long context) offered by Google's state-of-the-art LLM (\\textit{gemini-1.5-pro}). We study the impact of various contextual information, including column example values, question and SQL query pairs, user-provided hints, SQL documentation, and schema. To the best of our knowledge, this is the first work to study how the extended context window and extra contextual information can help NL2SQL generation with respect to both accuracy and latency cost. We show that long context LLMs are robust and do not get lost in the extended contextual information. Additionally, our long-context NL2SQL pipeline based on Google's \\textit{gemini-pro-1.5} achieve a strong performance with 67.41\\% on BIRD benchmark (dev) without finetuning and expensive self-consistency based techniques.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "204",
        "title": "Expertise elevates AI usage: experimental evidence comparing laypeople and professional artists",
        "author": [
            "Thomas F. Eisenmann",
            "Andres Karjus",
            "Mar Canet Sola",
            "Levin Brinkmann",
            "Bramantyo Ibrahim Supriyatno",
            "Iyad Rahwan"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12374",
        "abstract": "Novel capacities of generative AI to analyze and generate cultural artifacts raise inevitable questions about the nature and value of artistic education and human expertise. Has AI already leveled the playing field between professional artists and laypeople, or do trained artistic expressive capacity, curation skills and experience instead enhance the ability to use these new tools? In this pre-registered study, we conduct experimental comparisons between 50 active artists and a demographically matched sample of laypeople. We designed two tasks to approximate artistic practice for testing their capabilities in both faithful and creative image creation: replicating a reference image, and moving as far away as possible from it. We developed a bespoke platform where participants used a modern text-to-image model to complete both tasks. We also collected and compared participants' sentiments towards AI. On average, artists produced more faithful and creative outputs than their lay counterparts, although only by a small margin. While AI may ease content creation, professional expertise is still valuable - even within the confined space of generative AI itself. Finally, we also explored how well an exemplary vision-capable large language model (GPT-4o) would complete the same tasks, if given the role of an image generation agent, and found it performed on par in copying but outperformed even artists in the creative task. The very best results were still produced by humans in both tasks. These outcomes highlight the importance of integrating artistic skills with AI training to prepare artists and other visual professionals for a technologically evolving landscape. We see a potential in collaborative synergy with generative AI, which could reshape creative industries and education in the arts.",
        "tags": [
            "GPT",
            "Text-to-Image"
        ]
    },
    {
        "id": "205",
        "title": "Video Depth Anything: Consistent Depth Estimation for Super-Long Videos",
        "author": [
            "Sili Chen",
            "Hengkai Guo",
            "Shengnan Zhu",
            "Feihu Zhang",
            "Zilong Huang",
            "Jiashi Feng",
            "Bingyi Kang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12375",
        "abstract": "Depth Anything has achieved remarkable success in monocular depth estimation with strong generalization ability. However, it suffers from temporal inconsistency in videos, hindering its practical applications. Various methods have been proposed to alleviate this issue by leveraging video generation models or introducing priors from optical flow and camera poses. Nonetheless, these methods are only applicable to short videos (< 10 seconds) and require a trade-off between quality and computational efficiency. We propose Video Depth Anything for high-quality, consistent depth estimation in super-long videos (over several minutes) without sacrificing efficiency. We base our model on Depth Anything V2 and replace its head with an efficient spatial-temporal head. We design a straightforward yet effective temporal consistency loss by constraining the temporal depth gradient, eliminating the need for additional geometric priors. The model is trained on a joint dataset of video depth and unlabeled images, similar to Depth Anything V2. Moreover, a novel key-frame-based strategy is developed for long video inference. Experiments show that our model can be applied to arbitrarily long videos without compromising quality, consistency, or generalization ability. Comprehensive evaluations on multiple video benchmarks demonstrate that our approach sets a new state-of-the-art in zero-shot video depth estimation. We offer models of different scales to support a range of scenarios, with our smallest model capable of real-time performance at 30 FPS.",
        "tags": [
            "Depth Estimation",
            "Video Generation"
        ]
    },
    {
        "id": "206",
        "title": "Parallel Sequence Modeling via Generalized Spatial Propagation Network",
        "author": [
            "Hongjun Wang",
            "Wonmin Byeon",
            "Jiarui Xu",
            "Jinwei Gu",
            "Ka Chun Cheung",
            "Xiaolong Wang",
            "Kai Han",
            "Jan Kautz",
            "Sifei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12381",
        "abstract": "We present the Generalized Spatial Propagation Network (GSPN), a new attention mechanism optimized for vision tasks that inherently captures 2D spatial structures. Existing attention models, including transformers, linear attention, and state-space models like Mamba, process multi-dimensional data as 1D sequences, compromising spatial coherence and efficiency. GSPN overcomes these limitations by directly operating on spatially coherent image data and forming dense pairwise connections through a line-scan approach. Central to GSPN is the Stability-Context Condition, which ensures stable, context-aware propagation across 2D sequences and reduces the effective sequence length to $\\sqrt{N}$ for a square map with N elements, significantly enhancing computational efficiency. With learnable, input-dependent weights and no reliance on positional embeddings, GSPN achieves superior spatial fidelity and state-of-the-art performance in vision tasks, including ImageNet classification, class-guided image generation, and text-to-image generation. Notably, GSPN accelerates SD-XL with softmax-attention by over $84\\times$ when generating 16K images.",
        "tags": [
            "Mamba",
            "State Space Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "207",
        "title": "DiffDoctor: Diagnosing Image Diffusion Models Before Treating",
        "author": [
            "Yiyang Wang",
            "Xi Chen",
            "Xiaogang Xu",
            "Sihui Ji",
            "Yu Liu",
            "Yujun Shen",
            "Hengshuang Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12382",
        "abstract": "In spite of the recent progress, image diffusion models still produce artifacts. A common solution is to refine an established model with a quality assessment system, which generally rates an image in its entirety. In this work, we believe problem-solving starts with identification, yielding the request that the model should be aware of not just the presence of defects in an image, but their specific locations. Motivated by this, we propose DiffDoctor, a two-stage pipeline to assist image diffusion models in generating fewer artifacts. Concretely, the first stage targets developing a robust artifact detector, for which we collect a dataset of over 1M flawed synthesized images and set up an efficient human-in-the-loop annotation process, incorporating a carefully designed class-balance strategy. The learned artifact detector is then involved in the second stage to tune the diffusion model through assigning a per-pixel confidence map for each synthesis. Extensive experiments on text-to-image diffusion models demonstrate the effectiveness of our artifact detector as well as the soundness of our diagnose-then-treat design.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "208",
        "title": "Audio Texture Manipulation by Exemplar-Based Analogy",
        "author": [
            "Kan Jen Cheng",
            "Tingle Li",
            "Gopala Anumanchipalli"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12385",
        "abstract": "Audio texture manipulation involves modifying the perceptual characteristics of a sound to achieve specific transformations, such as adding, removing, or replacing auditory elements. In this paper, we propose an exemplar-based analogy model for audio texture manipulation. Instead of conditioning on text-based instructions, our method uses paired speech examples, where one clip represents the original sound and another illustrates the desired transformation. The model learns to apply the same transformation to new input, allowing for the manipulation of sound textures. We construct a quadruplet dataset representing various editing tasks, and train a latent diffusion model in a self-supervised manner. We show through quantitative evaluations and perceptual studies that our model outperforms text-conditioned baselines and generalizes to real-world, out-of-distribution, and non-speech scenarios. Project page: https://berkeley-speech-group.github.io/audio-texture-analogy/",
        "tags": [
            "CLIP",
            "Diffusion"
        ]
    },
    {
        "id": "209",
        "title": "InternVideo2.5: Empowering Video MLLMs with Long and Rich Context Modeling",
        "author": [
            "Yi Wang",
            "Xinhao Li",
            "Ziang Yan",
            "Yinan He",
            "Jiashuo Yu",
            "Xiangyu Zeng",
            "Chenting Wang",
            "Changlian Ma",
            "Haian Huang",
            "Jianfei Gao",
            "Min Dou",
            "Kai Chen",
            "Wenhai Wang",
            "Yu Qiao",
            "Yali Wang",
            "Limin Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12386",
        "abstract": "This paper aims to improve the performance of video multimodal large language models (MLLM) via long and rich context (LRC) modeling. As a result, we develop a new version of InternVideo2.5 with a focus on enhancing the original MLLMs' ability to perceive fine-grained details and capture long-form temporal structure in videos. Specifically, our approach incorporates dense vision task annotations into MLLMs using direct preference optimization and develops compact spatiotemporal representations through adaptive hierarchical token compression. Experimental results demonstrate this unique design of LRC greatly improves the results of video MLLM in mainstream video understanding benchmarks (short & long), enabling the MLLM to memorize significantly longer video inputs (at least 6x longer than the original), and master specialized vision capabilities like object tracking and segmentation. Our work highlights the importance of multimodal context richness (length and fineness) in empowering MLLM's innate abilites (focus and memory), providing new insights for future research on video MLLM. Code and models are available at https://github.com/OpenGVLab/InternVideo/tree/main/InternVideo2.5",
        "tags": [
            "Large Language Models",
            "Segmentation"
        ]
    },
    {
        "id": "210",
        "title": "Continuous 3D Perception Model with Persistent State",
        "author": [
            "Qianqian Wang",
            "Yifei Zhang",
            "Aleksander Holynski",
            "Alexei A. Efros",
            "Angjoo Kanazawa"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12387",
        "abstract": "We present a unified framework capable of solving a broad range of 3D tasks. Our approach features a stateful recurrent model that continuously updates its state representation with each new observation. Given a stream of images, this evolving state can be used to generate metric-scale pointmaps (per-pixel 3D points) for each new input in an online fashion. These pointmaps reside within a common coordinate system, and can be accumulated into a coherent, dense scene reconstruction that updates as new images arrive. Our model, called CUT3R (Continuous Updating Transformer for 3D Reconstruction), captures rich priors of real-world scenes: not only can it predict accurate pointmaps from image observations, but it can also infer unseen regions of the scene by probing at virtual, unobserved views. Our method is simple yet highly flexible, naturally accepting varying lengths of images that may be either video streams or unordered photo collections, containing both static and dynamic content. We evaluate our method on various 3D/4D tasks and demonstrate competitive or state-of-the-art performance in each. Project Page: https://cut3r.github.io/",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "211",
        "title": "Taming Teacher Forcing for Masked Autoregressive Video Generation",
        "author": [
            "Deyu Zhou",
            "Quan Sun",
            "Yuang Peng",
            "Kun Yan",
            "Runpei Dong",
            "Duomin Wang",
            "Zheng Ge",
            "Nan Duan",
            "Xiangyu Zhang",
            "Lionel M. Ni",
            "Heung-Yeung Shum"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12389",
        "abstract": "We introduce MAGI, a hybrid video generation framework that combines masked modeling for intra-frame generation with causal modeling for next-frame generation. Our key innovation, Complete Teacher Forcing (CTF), conditions masked frames on complete observation frames rather than masked ones (namely Masked Teacher Forcing, MTF), enabling a smooth transition from token-level (patch-level) to frame-level autoregressive generation. CTF significantly outperforms MTF, achieving a +23% improvement in FVD scores on first-frame conditioned video prediction. To address issues like exposure bias, we employ targeted training strategies, setting a new benchmark in autoregressive video generation. Experiments show that MAGI can generate long, coherent video sequences exceeding 100 frames, even when trained on as few as 16 frames, highlighting its potential for scalable, high-quality video generation.",
        "tags": [
            "Video Generation"
        ]
    },
    {
        "id": "212",
        "title": "GPS as a Control Signal for Image Generation",
        "author": [
            "Chao Feng",
            "Ziyang Chen",
            "Aleksander Holynski",
            "Alexei A. Efros",
            "Andrew Owens"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12390",
        "abstract": "We show that the GPS tags contained in photo metadata provide a useful control signal for image generation. We train GPS-to-image models and use them for tasks that require a fine-grained understanding of how images vary within a city. In particular, we train a diffusion model to generate images conditioned on both GPS and text. The learned model generates images that capture the distinctive appearance of different neighborhoods, parks, and landmarks. We also extract 3D models from 2D GPS-to-image models through score distillation sampling, using GPS conditioning to constrain the appearance of the reconstruction from each viewpoint. Our evaluations suggest that our GPS-conditioned models successfully learn to generate images that vary based on location, and that GPS conditioning improves estimated 3D structure.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "213",
        "title": "Towards Affordance-Aware Articulation Synthesis for Rigged Objects",
        "author": [
            "Yu-Chu Yu",
            "Chieh Hubert Lin",
            "Hsin-Ying Lee",
            "Chaoyang Wang",
            "Yu-Chiang Frank Wang",
            "Ming-Hsuan Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.12393",
        "abstract": "Rigged objects are commonly used in artist pipelines, as they can flexibly adapt to different scenes and postures. However, articulating the rigs into realistic affordance-aware postures (e.g., following the context, respecting the physics and the personalities of the object) remains time-consuming and heavily relies on human labor from experienced artists. In this paper, we tackle the novel problem and design A3Syn. With a given context, such as the environment mesh and a text prompt of the desired posture, A3Syn synthesizes articulation parameters for arbitrary and open-domain rigged objects obtained from the Internet. The task is incredibly challenging due to the lack of training data, and we do not make any topological assumptions about the open-domain rigs. We propose using 2D inpainting diffusion model and several control techniques to synthesize in-context affordance information. Then, we develop an efficient bone correspondence alignment using a combination of differentiable rendering and semantic correspondence. A3Syn has stable convergence, completes in minutes, and synthesizes plausible affordance on different combinations of in-the-wild object rigs and scenes.",
        "tags": [
            "Diffusion",
            "Inpainting"
        ]
    },
    {
        "id": "214",
        "title": "Handwriting Anomalies and Learning Disabilities through Recurrent Neural Networks and Geometric Pattern Analysis",
        "author": [
            "Vasileios Alevizos",
            "Sabrina Edralin",
            "Akebu Simasiku",
            "Dimitra Malliarou",
            "Antonis Messinis",
            "George Papakostas",
            "Clark Xu",
            "Zongliang Yue"
        ],
        "pdf": "https://arxiv.org/pdf/2405.07238",
        "abstract": "Dyslexia and dysgraphia are learning disabilities that profoundly impact reading, writing, and language processing capabilities. Dyslexia primarily affects reading, manifesting as difficulties in word recognition and phonological processing, where individuals struggle to connect sounds with their corresponding letters. Dysgraphia, on the other hand, affects writing skills, resulting in difficulties with letter formation, spacing, and alignment. The coexistence of dyslexia and dysgraphia complicates diagnosis, requiring a nuanced approach capable of adapting to these complexities while accurately identifying and differentiating between the disorders. This study utilizes advanced geometrical patterns and recurrent neural networks (RNN) to identify handwriting anomalies indicative of dyslexia and dysgraphia. Handwriting is first standardized, followed by feature extraction that focuses on baseline deviations, letter connectivity, stroke thickness, and other anomalies. These features are then fed into an RNN-based autoencoder to identify irregularities. Initial results demonstrate the ability of this RNN model to achieve state-of-art performance on combined dyslexia and dysgraphia detection, while showing the challenges associated with complex pattern adaptation of deep-learning to a diverse corpus of about 33,000 writing samples.",
        "tags": [
            "Detection",
            "RNN"
        ]
    },
    {
        "id": "215",
        "title": "SSM2Mel: State Space Model to Reconstruct Mel Spectrogram from the EEG",
        "author": [
            "Cunhang Fan",
            "Sheng Zhang",
            "Jingjing Zhang",
            "Zexu Pan",
            "Zhao Lv"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10402",
        "abstract": "Decoding speech from brain signals is a challenging research problem that holds significant importance for studying speech processing in the brain. Although breakthroughs have been made in reconstructing the mel spectrograms of audio stimuli perceived by subjects at the word or letter level using noninvasive electroencephalography (EEG), there is still a critical gap in precisely reconstructing continuous speech features, especially at the minute level. To address this issue, this paper proposes a State Space Model (SSM) to reconstruct the mel spectrogram of continuous speech from EEG, named SSM2Mel. This model introduces a novel Mamba module to effectively model the long sequence of EEG signals for imagined speech. In the SSM2Mel model, the S4-UNet structure is used to enhance the extraction of local features of EEG signals, and the Embedding Strength Modulator (ESM) module is used to incorporate subject-specific information. Experimental results show that our model achieves a Pearson correlation of 0.069 on the SparrKULee dataset, which is a 38% improvement over the previous baseline.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "216",
        "title": "Automated Detection of Epileptic Spikes and Seizures Incorporating a Novel Spatial Clustering Prior",
        "author": [
            "Hanyang Dong",
            "Shurong Sheng",
            "Xiongfei Wang",
            "Jiahong Gao",
            "Yi Sun",
            "Wanli Yang",
            "Kuntao Xiao",
            "Pengfei Teng",
            "Guoming Luan",
            "Zhao Lv"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10404",
        "abstract": "A Magnetoencephalography (MEG) time-series recording consists of multi-channel signals collected by superconducting sensors, with each signal's intensity reflecting magnetic field changes over time at the sensor location. Automating epileptic MEG spike detection significantly reduces manual assessment time and effort, yielding substantial clinical benefits. Existing research addresses MEG spike detection by encoding neural network inputs with signals from all channel within a time segment, followed by classification. However, these methods overlook simultaneous spiking occurred from nearby sensors. We introduce a simple yet effective paradigm that first clusters MEG channels based on their sensor's spatial position. Next, a novel convolutional input module is designed to integrate the spatial clustering and temporal changes of the signals. This module is fed into a custom MEEG-ResNet3D developed by the authors, which learns to extract relevant features and classify the input as a spike clip or not. Our method achieves an F1 score of 94.73% on a large real-world MEG dataset Sanbo-CMR collected from two centers, outperforming state-of-the-art approaches by 1.85%. Moreover, it demonstrates efficacy and stability in the Electroencephalographic (EEG) seizure detection task, yielding an improved weighted F1 score of 1.4% compared to current state-of-the-art techniques evaluated on TUSZ, whch is the largest EEG seizure dataset.",
        "tags": [
            "CLIP",
            "Detection"
        ]
    },
    {
        "id": "217",
        "title": "Leveraging Cross-Attention Transformer and Multi-Feature Fusion for Cross-Linguistic Speech Emotion Recognition",
        "author": [
            "Ruoyu Zhao",
            "Xiantao Jiang",
            "F. Richard Yu",
            "Victor C.M. Leung",
            "Tao Wang",
            "Shaohu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10408",
        "abstract": "Speech Emotion Recognition (SER) plays a crucial role in enhancing human-computer interaction. Cross-Linguistic SER (CLSER) has been a challenging research problem due to significant variability in linguistic and acoustic features of different languages. In this study, we propose a novel approach HuMP-CAT, which combines HuBERT, MFCC, and prosodic characteristics. These features are fused using a cross-attention transformer (CAT) mechanism during feature extraction. Transfer learning is applied to gain from a source emotional speech dataset to the target corpus for emotion recognition. We use IEMOCAP as the source dataset to train the source model and evaluate the proposed method on seven datasets in five languages (e.g., English, German, Spanish, Italian, and Chinese). We show that, by fine-tuning the source model with a small portion of speech from the target datasets, HuMP-CAT achieves an average accuracy of 78.75% across the seven datasets, with notable performance of 88.69% on EMODB (German language) and 79.48% on EMOVO (Italian language). Our extensive evaluation demonstrates that HuMP-CAT outperforms existing methods across multiple target languages.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "218",
        "title": "Enhancing the Reliability in Machine Learning for Gravitational Wave Parameter Estimation with Attention-Based Models",
        "author": [
            "Hibiki Iwanaga",
            "Mahoro Matsuyama",
            "Yousuke Itoh"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10486",
        "abstract": "We introduce a technique to enhance the reliability of gravitational wave parameter estimation results produced by machine learning. We develop two independent machine learning models based on the Vision Transformer to estimate effective spin and chirp mass from spectrograms of gravitational wave signals from binary black hole mergers. To enhance the reliability of these models, we utilize attention maps to visualize the areas our models focus on when making predictions. This approach enables demonstrating that both models perform parameter estimation based on physically meaningful information. Furthermore, by leveraging these attention maps, we demonstrate a method to quantify the impact of glitches on parameter estimation. We show that as the models focus more on glitches, the parameter estimation results become more strongly biased. This suggests that attention maps could potentially be used to distinguish between cases where the results produced by the machine learning model are reliable and cases where they are not.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "219",
        "title": "FlashSR: One-step Versatile Audio Super-resolution via Diffusion Distillation",
        "author": [
            "Jaekwon Im",
            "Juhan Nam"
        ],
        "pdf": "https://arxiv.org/pdf/2501.10807",
        "abstract": "Versatile audio super-resolution (SR) is the challenging task of restoring high-frequency components from low-resolution audio with sampling rates between 4kHz and 32kHz in various domains such as music, speech, and sound effects. Previous diffusion-based SR methods suffer from slow inference due to the need for a large number of sampling steps. In this paper, we introduce FlashSR, a single-step diffusion model for versatile audio super-resolution aimed at producing 48kHz audio. FlashSR achieves fast inference by utilizing diffusion distillation with three objectives: distillation loss, adversarial loss, and distribution-matching distillation loss. We further enhance performance by proposing the SR Vocoder, which is specifically designed for SR models operating on mel-spectrograms. FlashSR demonstrates competitive performance with the current state-of-the-art model in both objective and subjective evaluations while being approximately 22 times faster.",
        "tags": [
            "Diffusion",
            "Super Resolution"
        ]
    },
    {
        "id": "220",
        "title": "On the Dimension of Pullback Attractors in Recurrent Neural Networks",
        "author": [
            "Muhammed Fadera"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11357",
        "abstract": "Recurrent Neural Networks (RNNs) are high-dimensional state space models capable of learning functions on sequence data. Recently, it has been conjectured that reservoir computers, a particular class of RNNs, trained on observations of a dynamical systems can be interpreted as embeddings. This result has been established for the case of linear reservoir systems. In this work, we use a nonautonomous dynamical systems approach to establish an upper bound for the fractal dimension of the subset of reservoir state space approximated during training and prediction phase. We prove that when the input sequences comes from an Nin-dimensional invertible dynamical system, the fractal dimension of this set is bounded above by Nin. The result obtained here are useful in dimensionality reduction of computation in RNNs as well as estimating fractal dimensions of dynamical systems from limited observations of their time series. It is also a step towards understanding embedding properties of reservoir computers.",
        "tags": [
            "State Space Models"
        ]
    },
    {
        "id": "221",
        "title": "Disentangling stellar atmospheric parameters in astronomical spectra using Generative Adversarial Neural Networks",
        "author": [
            "Minia Manteiga",
            "RaÃºl SantoveÃ±a",
            "Marco A. Ãlvarez",
            "Carlos Dafonte",
            "Manuel G. Penedo",
            "Silvana Navarro",
            "Luis Corral"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11762",
        "abstract": "A method based on Generative Adversaria! Networks (GANs) is developed for disentangling the physical (effective temperature and gravity) and chemical (metallicity, overabundance of a-elements with respect to iron) atmospheric properties in astronomical spectra. Using a projection of the stellar spectra, commonly called latent space, in which the contribution dueto one or several main stellar physicochemical properties is minimised while others are enhanced, it was possible to maximise the information related to certain properties, which can then be extracted using artificial neural networks (ANN) as regressors with higher accuracy than a reference method based on the use of ANN trained with the original spectra. Methods. Our model utilises autoencoders, comprising two artificial neural networks: an encoder anda decoder which transform input data into a low-dimensional representation known as latent space. It also uses discriminators, which are additional neural networks aimed at transforming the traditional autoencoder training into an adversaria! approach, to disentangle or reinforce the astrophysical parameters from the latent space. The GANDALF tool is described. It was developed to define, train, and test our GAN model with a web framework to show how the disentangling algorithm works visually. It is open to the community in Github. Results. The performance of our approach for retrieving atmospheric stellar properties from spectra is demonstrated using Gaia Radial Velocity Spectrograph (RVS) data from DR3. We use a data-driven perspective and obtain very competitive values, ali within the literature errors, and with the advantage of an important dimensionality reduction of the data to be processed.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "222",
        "title": "Rate-Aware Learned Speech Compression",
        "author": [
            "Jun Xu",
            "Zhengxue Cheng",
            "Guangchuan Chi",
            "Yuhan Liu",
            "Yuelin Hu",
            "Li Song"
        ],
        "pdf": "https://arxiv.org/pdf/2501.11999",
        "abstract": "The rapid rise of real-time communication and large language models has significantly increased the importance of speech compression. Deep learning-based neural speech codecs have outperformed traditional signal-level speech codecs in terms of rate-distortion (RD) performance. Typically, these neural codecs employ an encoder-quantizer-decoder architecture, where audio is first converted into latent code feature representations and then into discrete tokens. However, this architecture exhibits insufficient RD performance due to two main drawbacks: (1) the inadequate performance of the quantizer, challenging training processes, and issues such as codebook collapse; (2) the limited representational capacity of the encoder and decoder, making it difficult to meet feature representation requirements across various bitrates. In this paper, we propose a rate-aware learned speech compression scheme that replaces the quantizer with an advanced channel-wise entropy model to improve RD performance, simplify training, and avoid codebook collapse. We employ multi-scale convolution and linear attention mixture blocks to enhance the representational capacity and flexibility of the encoder and decoder. Experimental results demonstrate that the proposed method achieves state-of-the-art RD performance, obtaining 53.51% BD-Rate bitrate saving in average, and achieves 0.26 BD-VisQol and 0.44 BD-PESQ gains.",
        "tags": [
            "Large Language Models"
        ]
    }
]