[
    {
        "id": "1",
        "title": "Inductive Linguistic Reasoning with Large Language Models",
        "author": [
            "Raghav Ramji",
            "Keshav Ramji"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17819",
        "abstract": "Evaluating large language models (LLMs) on their linguistic reasoning capabilities is an important task to understand the gaps in their skills that may surface during large-scale adoption. In this work, we investigate the abilities of such models to perform abstract multilingual reasoning through the lens of linguistic puzzles on extremely low-resource languages. As these translation tasks involve inductive and deductive reasoning from reference instances, we examine whether diverse auxiliary demonstrations can be automatically induced from seed exemplars, through analogical prompting. We employ a two-stage procedure, first generating analogical exemplars with a language model, and then applying them in-context along with provided target language exemplars. Our results on the modeLing dataset show that analogical prompting is effective in eliciting models' knowledge of language grammar similarities, boosting the performance of GPT-4o by as much as 8.1% and Llama-3.1-405B-Instruct by 5.9% over chain-of-thought approaches. These gains are attributable to the analogical demonstrations, both when self-generated as well as when produced by weaker multilingual models. Furthermore, we demonstrate that our method generalizes to other tasks present in Linguistics Olympiad competitions, achieving sizable improvements across all problem types and difficulty levels included in the LINGOLY dataset with GPT-4o. We also report several findings about interesting phenomena which drive linguistic reasoning performance, suggesting that such puzzles are a valuable benchmark for new reasoning methods.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "2",
        "title": "The Rosetta Paradox: Domain-Specific Performance Inversions in Large Language Models",
        "author": [
            "Basab Jha",
            "Ujjwal Puri"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17821",
        "abstract": "While large language models, such as GPT and BERT, have already demonstrated unprecedented skills in everything from natural language processing to domain-specific applications, there came an unexplored phenomenon we term the Rosetta Paradox. The Rosetta Paradox characterizes the counterintuitive performance inversions across domains of knowledge. This paradox captures how such LLMs can excel in highly specialized fields but do poorly on tasks which require general, everyday knowledge. This paper formalizes the definition of the Rosetta Paradox and introduces a panoramic analysis framework that includes both a Domain Specificity Index (DSI) and a Performance Inversion Metric (PIM) for consistent quantification of domain-specific behavior in LLMs.\nWe adopt this paradox and conduct a series of investigations through extensive experiments across diverse models and knowledge domains, ranging from rich technical areas to common-sense reasoning. Our findings indicate that the Rosetta Paradox is likely not a mere artifact of data distribution but an intrinsic architectural and emergent property of deep neural networks. We present comparative analyses across different model architectures, sizes, and training methodologies that shed light into the peculiar ways this paradox manifests itself and challenge the standard evaluation metrics.",
        "tags": [
            "BERT",
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "3",
        "title": "Look Ahead Text Understanding and LLM Stitching",
        "author": [
            "Junlin Julian Jiang",
            "Xin Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17836",
        "abstract": "This paper proposes a look ahead text understanding problem with look ahead section identification (LASI) as an example. This problem may appear in generative AI as well as human interactions, where we want to understand the direction of a developing text or conversation. We tackle the problem using transformer-based LLMs. We show that LASI is more challenging than classic section identification (SI). We argue that both bidirectional contextual information (e.g., BERT) and unidirectional predictive ability (e.g., GPT) will benefit the task. We propose two approaches to stitch together BERT and GPT. Experiments show that our approach outperforms the established models, especially when there is noise in the text (which is often the case for developing text in generative AI). Our paper sheds light on other look ahead text understanding tasks that are important to social media, such as look ahead sentiment classification, and points out the opportunities to leverage pre-trained LLMs through stitching.",
        "tags": [
            "BERT",
            "GPT",
            "LLMs",
            "Transformer"
        ]
    },
    {
        "id": "4",
        "title": "Evaluating the Capabilities of Large Language Models for Multi-label Emotion Understanding",
        "author": [
            "Tadesse Destaw Belay",
            "Israel Abebe Azime",
            "Abinew Ali Ayele",
            "Grigori Sidorov",
            "Dietrich Klakow",
            "Philipp Slusallek",
            "Olga Kolesnikova",
            "Seid Muhie Yimam"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17837",
        "abstract": "Large Language Models (LLMs) show promising learning and reasoning abilities. Compared to other NLP tasks, multilingual and multi-label emotion evaluation tasks are under-explored in LLMs. In this paper, we present EthioEmo, a multi-label emotion classification dataset for four Ethiopian languages, namely, Amharic (amh), Afan Oromo (orm), Somali (som), and Tigrinya (tir). We perform extensive experiments with an additional English multi-label emotion dataset from SemEval 2018 Task 1. Our evaluation includes encoder-only, encoder-decoder, and decoder-only language models. We compare zero and few-shot approaches of LLMs to fine-tuning smaller language models. The results show that accurate multi-label emotion classification is still insufficient even for high-resource languages such as English, and there is a large gap between the performance of high-resource and low-resource languages. The results also show varying performance levels depending on the language and model type. EthioEmo is available publicly to further improve the understanding of emotions in language models and how people convey emotions through various languages.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "5",
        "title": "LaMI-GO: Latent Mixture Integration for Goal-Oriented Communications Achieving High Spectrum Efficiency",
        "author": [
            "Achintha Wijesinghe",
            "Suchinthaka Wanninayaka",
            "Weiwei Wang",
            "Yu-Chieh Chao",
            "Songyang Zhang",
            "Zhi Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17839",
        "abstract": "The recent rise of semantic-style communications includes the development of goal-oriented communications (GOCOMs) remarkably efficient multimedia information transmissions. The concept of GO-COMS leverages advanced artificial intelligence (AI) tools to address the rising demand for bandwidth efficiency in applications, such as edge computing and Internet-of-Things (IoT). Unlike traditional communication systems focusing on source data accuracy, GO-COMs provide intelligent message delivery catering to the special needs critical to accomplishing downstream tasks at the receiver. In this work, we present a novel GO-COM framework, namely LaMI-GO that utilizes emerging generative AI for better quality-of-service (QoS) with ultra-high communication efficiency. Specifically, we design our LaMI-GO system backbone based on a latent diffusion model followed by a vector-quantized generative adversarial network (VQGAN) for efficient latent embedding and information representation. The system trains a common feature codebook the receiver side. Our experimental results demonstrate substantial improvement in perceptual quality, accuracy of downstream tasks, and bandwidth consumption over the state-of-the-art GOCOM systems and establish the power of our proposed LaMI-GO communication framework.",
        "tags": [
            "Diffusion",
            "VQGAN"
        ]
    },
    {
        "id": "6",
        "title": "Enhancing Knowledge Distillation for LLMs with Response-Priming Prompting",
        "author": [
            "Vijay Goyal",
            "Mustafa Khan",
            "Aprameya Tirupati",
            "Harveer Saini",
            "Michael Lam",
            "Kevin Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17846",
        "abstract": "Large language models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing (NLP) tasks. However, these models are often difficult to deploy due to significant computational requirements and resource constraints. Knowledge distillation (KD) is an effective technique for transferring the performance of larger LLMs to smaller models. Traditional KD methods primarily focus on the direct output of the teacher model, with little emphasis on the role of prompting during knowledge transfer. In this paper, we propose a set of novel response-priming prompting strategies applied in the knowledge distillation pipeline to enhance the performance of student models. Our approach fine-tunes a smaller Llama 3.1 8B Instruct model by distilling knowledge from a quantized Llama 3.1 405B Instruct teacher model. We apply LoRA optimization and evaluate on the GSM8K benchmark. Experimental results demonstrate that integrating reasoning-eliciting prompting into the proposed KD pipeline significantly improves student model performance, offering an efficient way to deploy powerful models in resource-constrained environments. We find that Ground Truth prompting results in a 55\\% performance increase on GSM8K for a distilled Llama 3.1 8B Instruct compared to the same model distilled without prompting. A thorough investigation into the self-attention layers of the student models indicates that the more successful prompted models tend to exhibit certain positive behaviors inside their attention heads which can be tied to their increased accuracy. Our implementation can be found at https://github.com/alonso130r/knowledge-distillation.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "LoRA"
        ]
    },
    {
        "id": "7",
        "title": "Zero Shot Time Series Forecasting Using Kolmogorov Arnold Networks",
        "author": [
            "Abhiroop Bhattacharya",
            "Nandinee Haq"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17853",
        "abstract": "Accurate energy price forecasting is crucial for participants in day-ahead energy markets, as it significantly influences their decision-making processes. While machine learning-based approaches have shown promise in enhancing these forecasts, they often remain confined to the specific markets on which they are trained, thereby limiting their adaptability to new or unseen markets. In this paper, we introduce a cross-domain adaptation model designed to forecast energy prices by learning market-invariant representations across different markets during the training phase. We propose a doubly residual N-BEATS network with Kolmogorov Arnold networks at its core for time series forecasting. These networks, grounded in the Kolmogorov-Arnold representation theorem, offer a powerful way to approximate multivariate continuous functions. The cross domain adaptation model was generated with an adversarial framework. The model's effectiveness was tested in predicting day-ahead electricity prices in a zero shot fashion. In comparison with baseline models, our proposed framework shows promising results. By leveraging the Kolmogorov-Arnold networks, our model can potentially enhance its ability to capture complex patterns in energy price data, thus improving forecast accuracy across diverse market conditions. This addition not only enriches the model's representational capacity but also contributes to a more robust and flexible forecasting tool adaptable to various energy markets.",
        "tags": [
            "Kolmogorov-Arnold Networks"
        ]
    },
    {
        "id": "8",
        "title": "Graph Structure Refinement with Energy-based Contrastive Learning",
        "author": [
            "Xianlin Zeng",
            "Yufeng Wang",
            "Yuqi Sun",
            "Guodong Guo",
            "Wenrui Ding",
            "Baochang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17856",
        "abstract": "Graph Neural Networks (GNNs) have recently gained widespread attention as a successful tool for analyzing graph-structured data. However, imperfect graph structure with noisy links lacks enough robustness and may damage graph representations, therefore limiting the GNNs' performance in practical tasks. Moreover, existing generative architectures fail to fit discriminative graph-related tasks. To tackle these issues, we introduce an unsupervised method based on a joint of generative training and discriminative training to learn graph structure and representation, aiming to improve the discriminative performance of generative models. We propose an Energy-based Contrastive Learning (ECL) guided Graph Structure Refinement (GSR) framework, denoted as ECL-GSR. To our knowledge, this is the first work to combine energy-based models with contrastive learning for GSR. Specifically, we leverage ECL to approximate the joint distribution of sample pairs, which increases the similarity between representations of positive pairs while reducing the similarity between negative ones. Refined structure is produced by augmenting and removing edges according to the similarity metrics among node representations. Extensive experiments demonstrate that ECL-GSR outperforms \\textit{the state-of-the-art on eight benchmark datasets} in node classification. ECL-GSR achieves \\textit{faster training with fewer samples and memories} against the leading baseline, highlighting its simplicity and efficiency in downstream tasks.",
        "tags": [
            "Energy-Based Models"
        ]
    },
    {
        "id": "9",
        "title": "Joint Knowledge Editing for Information Enrichment and Probability Promotion",
        "author": [
            "Wenhang Shi",
            "Yiren Chen",
            "Shuqing Bian",
            "Xinyi Zhang",
            "Zhe Zhao",
            "Pengfei Hu",
            "Wei Lu",
            "Xiaoyong Du"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17872",
        "abstract": "Knowledge stored in large language models requires timely updates to reflect the dynamic nature of real-world information. To update the knowledge, most knowledge editing methods focus on the low layers, since recent probes into the knowledge recall process reveal that the answer information is enriched in low layers. However, these probes only and could only reveal critical recall stages for the original answers, while the goal of editing is to rectify model's prediction for the target answers. This inconsistency indicates that both the probe approaches and the associated editing methods are deficient. To mitigate the inconsistency and identify critical editing regions, we propose a contrast-based probe approach, and locate two crucial stages where the model behavior diverges between the original and target answers: Information Enrichment in low layers and Probability Promotion in high layers. Building upon the insights, we develop the Joint knowledge Editing for information Enrichment and probability Promotion (JEEP) method, which jointly edits both the low and high layers to modify the two critical recall stages. Considering the mutual interference and growing forgetting due to dual modifications, JEEP is designed to ensure that updates to distinct regions share the same objectives and are complementary. We rigorously evaluate JEEP by editing up to thousands of facts on various models, i.e., GPT-J (6B) and LLaMA (7B), and addressing diverse editing objectives, i.e., adding factual and counterfactual knowledge. In all tested scenarios, JEEP achieves best performances, validating the effectiveness of the revealings of our probe approach and the designs of our editing method. Our code and data are available at https://github.com/Eric8932/JEEP.",
        "tags": [
            "GPT",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "10",
        "title": "Evaluating LLM Reasoning in the Operations Research Domain with ORQA",
        "author": [
            "Mahdi Mostajabdaveh",
            "Timothy T. Yu",
            "Samarendra Chandan Bindu Dash",
            "Rindranirina Ramamonjison",
            "Jabo Serge Byusa",
            "Giuseppe Carenini",
            "Zirui Zhou",
            "Yong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17874",
        "abstract": "In this paper, we introduce and apply Operations Research Question Answering (ORQA), a new benchmark designed to assess the generalization capabilities of Large Language Models (LLMs) in the specialized technical domain of Operations Research (OR). This benchmark evaluates whether LLMs can emulate the knowledge and reasoning skills of OR experts when confronted with diverse and complex optimization problems. The dataset, developed by OR experts, features real-world optimization problems that demand multistep reasoning to construct their mathematical models. Our evaluations of various open source LLMs, such as LLaMA 3.1, DeepSeek, and Mixtral, reveal their modest performance, highlighting a gap in their ability to generalize to specialized technical domains. This work contributes to the ongoing discourse on LLMs generalization capabilities, offering valuable insights for future research in this area. The dataset and evaluation code are publicly available.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "11",
        "title": "The Power of Adaptation: Boosting In-Context Learning through Adaptive Prompting",
        "author": [
            "Shuzhang Cai",
            "Twumasi Mensah-Boateng",
            "Xander Kuksov",
            "Jing Yuan",
            "Shaojie Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17891",
        "abstract": "Large Language Models (LLMs) have demonstrated exceptional abilities across a broad range of language-related tasks, including generating solutions to complex reasoning problems. An effective technique to enhance LLM performance is in-context learning, which encourages a step-by-step reasoning process by including explanatory examples to guide the model's responses. However, selecting appropriate exemplars for the model poses a challenge, as each dataset demands a distinct set of exemplars to enable the LLM to learn effectively and perform well on the test set. Current studies often rely on uncertainty- or diversity-based selection strategies to select exemplars for annotation and to improve model learning. However, these studies typically employ a non-adaptive approach, selecting a set of exemplars all at once. We argue that this non-adaptive strategy may result in a set of exemplars with high redundancy in terms of the knowledge covered, ultimately reducing their overall informativeness. To address this limitation, we propose \\textsc{Adaptive-Prompt}, a novel method that adaptively selects exemplars by leveraging model feedback from previously chosen exemplars. Experimental results show that \\textsc{Adaptive-Prompt} significantly enhances LLM performance across a variety of reasoning tasks.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "12",
        "title": "Causal Composition Diffusion Model for Closed-loop Traffic Generation",
        "author": [
            "Haohong Lin",
            "Xin Huang",
            "Tung Phan-Minh",
            "David S. Hayden",
            "Huan Zhang",
            "Ding Zhao",
            "Siddhartha Srinivasa",
            "Eric M. Wolff",
            "Hongge Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17920",
        "abstract": "Simulation is critical for safety evaluation in autonomous driving, particularly in capturing complex interactive behaviors. However, generating realistic and controllable traffic scenarios in long-tail situations remains a significant challenge. Existing generative models suffer from the conflicting objective between user-defined controllability and realism constraints, which is amplified in safety-critical contexts. In this work, we introduce the Causal Compositional Diffusion Model (CCDiff), a structure-guided diffusion framework to address these challenges. We first formulate the learning of controllable and realistic closed-loop simulation as a constrained optimization problem. Then, CCDiff maximizes controllability while adhering to realism by automatically identifying and injecting causal structures directly into the diffusion process, providing structured guidance to enhance both realism and controllability. Through rigorous evaluations on benchmark datasets and in a closed-loop simulator, CCDiff demonstrates substantial gains over state-of-the-art approaches in generating realistic and user-preferred trajectories. Our results show CCDiff's effectiveness in extracting and leveraging causal structures, showing improved closed-loop performance based on key metrics such as collision rate, off-road rate, FDE, and comfort.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "13",
        "title": "VITRO: Vocabulary Inversion for Time-series Representation Optimization",
        "author": [
            "Filippos Bellos",
            "Nam H. Nguyen",
            "Jason J. Corso"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17921",
        "abstract": "Although LLMs have demonstrated remarkable capabilities in processing and generating textual data, their pre-trained vocabularies are ill-suited for capturing the nuanced temporal dynamics and patterns inherent in time series. The discrete, symbolic nature of natural language tokens, which these vocabularies are designed to represent, does not align well with the continuous, numerical nature of time series data. To address this fundamental limitation, we propose VITRO. Our method adapts textual inversion optimization from the vision-language domain in order to learn a new time series per-dataset vocabulary that bridges the gap between the discrete, semantic nature of natural language and the continuous, numerical nature of time series data. We show that learnable time series-specific pseudo-word embeddings represent time series data better than existing general language model vocabularies, with VITRO-enhanced methods achieving state-of-the-art performance in long-term forecasting across most datasets.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "14",
        "title": "BenCzechMark : A Czech-centric Multitask and Multimetric Benchmark for Large Language Models with Duel Scoring Mechanism",
        "author": [
            "Martin Fajcik",
            "Martin Docekal",
            "Jan Dolezal",
            "Karel Ondrej",
            "Karel Beneš",
            "Jan Kapsa",
            "Pavel Smrz",
            "Alexander Polok",
            "Michal Hradis",
            "Zuzana Neverilova",
            "Ales Horak",
            "Radoslav Sabol",
            "Michal Stefanik",
            "Adam Jirkovsky",
            "David Adamczyk",
            "Petr Hyner",
            "Jan Hula",
            "Hynek Kydlicek"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17933",
        "abstract": "We present BenCzechMark (BCM), the first comprehensive Czech language benchmark designed for large language models, offering diverse tasks, multiple task formats, and multiple evaluation metrics. Its scoring system is grounded in statistical significance theory and uses aggregation across tasks inspired by social preference theory. Our benchmark encompasses 50 challenging tasks, with corresponding test datasets, primarily in native Czech, with 11 newly collected ones. These tasks span 8 categories and cover diverse domains, including historical Czech news, essays from pupils or language learners, and spoken word.\nFurthermore, we collect and clean BUT-Large Czech Collection, the largest publicly available clean Czech language corpus, and use it for (i) contamination analysis, (ii) continuous pretraining of the first Czech-centric 7B language model, with Czech-specific tokenization. We use our model as a baseline for comparison with publicly available multilingual models. Lastly, we release and maintain a leaderboard, with existing 44 model submissions, where new model submissions can be made at https://huggingface.co/spaces/CZLC/BenCzechMark.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "15",
        "title": "IITR-CIOL@NLU of Devanagari Script Languages 2025: Multilingual Hate Speech Detection and Target Identification in Devanagari-Scripted Languages",
        "author": [
            "Siddhant Gupta",
            "Siddh Singhal",
            "Azmine Toushik Wasi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17947",
        "abstract": "This work focuses on two subtasks related to hate speech detection and target identification in Devanagari-scripted languages, specifically Hindi, Marathi, Nepali, Bhojpuri, and Sanskrit. Subtask B involves detecting hate speech in online text, while Subtask C requires identifying the specific targets of hate speech, such as individuals, organizations, or communities. We propose the MultilingualRobertaClass model, a deep neural network built on the pretrained multilingual transformer model ia-multilingual-transliterated-roberta, optimized for classification tasks in multilingual and transliterated contexts. The model leverages contextualized embeddings to handle linguistic diversity, with a classifier head for binary classification. We received 88.40% accuracy in Subtask B and 66.11% accuracy in Subtask C, in the test set.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "16",
        "title": "ArchComplete: Autoregressive 3D Architectural Design Generation with Hierarchical Diffusion-Based Upsampling",
        "author": [
            "S. Rasoulzadeh",
            "M. Bank",
            "M. Wimmer",
            "I. Kovacic",
            "K. Schinegger",
            "S. Rutzinger"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17957",
        "abstract": "$\\textit{ArchComplete}$ is a two-stage dense voxel-based 3D generative pipeline developed to tackle the high complexity in architectural geometries and topologies, assisting with ideation and geometric detailisation in the early design process. In stage 1, a $\\textit{3D Voxel VQGAN}$ model is devised, whose composition is then modelled with an autoregressive transformer for generating coarse models. Subsequently, in stage 2, $\\textit{Hierarchical Voxel Upsampling Networks}$ consisting of a set of 3D conditional denoising diffusion probabilistic models are defined to augment the coarse shapes with fine geometric details. The first stage is trained on a dataset of house models with fully modelled exteriors and interiors with a novel 2.5D perceptual loss to capture input complexities across multiple abstraction levels, while the second stage trains on randomly cropped local volumetric patches, requiring significantly less compute and memory. For inference, the pipeline first autoregressively generates house models at a resolution of $64^3$ and then progressively refines them to resolution of $256^3$ with voxel sizes as small as $18\\text{cm}$. ArchComplete supports a range of interaction modes solving a variety of tasks, including interpolation, variation generation, unconditional synthesis, and two conditional synthesis tasks: shape completion and plan-drawing completion, as well as geometric detailisation. The results demonstrate notable improvements against state-of-the-art on established metrics.",
        "tags": [
            "3D",
            "Diffusion",
            "Transformer",
            "VQGAN"
        ]
    },
    {
        "id": "17",
        "title": "Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models",
        "author": [
            "Ge Zhang",
            "Mohammad Ali Alomrani",
            "Hongjian Gu",
            "Jiaming Zhou",
            "Yaochen Hu",
            "Bin Wang",
            "Qun Liu",
            "Mark Coates",
            "Yingxue Zhang",
            "Jianye Hao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17963",
        "abstract": "Large language models (LLMs) possess vast semantic knowledge but often struggle with complex reasoning tasks, particularly in relational reasoning problems such as kinship or spatial reasoning. In this paper, we present Path-of-Thoughts (PoT), a novel framework designed to tackle relation reasoning by decomposing the task into three key stages: graph extraction, path identification, and reasoning. Unlike previous approaches, PoT efficiently extracts a task-agnostic graph that identifies crucial entities, relations, and attributes within the problem context. Subsequently, PoT identifies relevant reasoning chains within the graph corresponding to the posed question, facilitating inference of potential answers. Experimental evaluations on four benchmark datasets, demanding long reasoning chains, demonstrate that PoT surpasses state-of-the-art baselines by a significant margin (maximum 21.3%) without necessitating fine-tuning or extensive LLM calls. Furthermore, as opposed to prior neuro-symbolic methods, PoT exhibits improved resilience against LLM errors by leveraging the compositional nature of graphs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "18",
        "title": "Dynamic Multi-Agent Orchestration and Retrieval for Multi-Source Question-Answer Systems using Large Language Models",
        "author": [
            "Antony Seabra",
            "Claudio Cavalcante",
            "Joao Nepomuceno",
            "Lucas Lago",
            "Nicolaas Ruberg",
            "Sergio Lifschitz"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17964",
        "abstract": "We propose a methodology that combines several advanced techniques in Large Language Model (LLM) retrieval to support the development of robust, multi-source question-answer systems. This methodology is designed to integrate information from diverse data sources, including unstructured documents (PDFs) and structured databases, through a coordinated multi-agent orchestration and dynamic retrieval approach. Our methodology leverages specialized agents-such as SQL agents, Retrieval-Augmented Generation (RAG) agents, and router agents - that dynamically select the most appropriate retrieval strategy based on the nature of each query. To further improve accuracy and contextual relevance, we employ dynamic prompt engineering, which adapts in real time to query-specific contexts. The methodology's effectiveness is demonstrated within the domain of Contract Management, where complex queries often require seamless interaction between unstructured and structured data. Our results indicate that this approach enhances response accuracy and relevance, offering a versatile and scalable framework for developing question-answer systems that can operate across various domains and data sources.",
        "tags": [
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "19",
        "title": "LMV-RPA: Large Model Voting-based Robotic Process Automation",
        "author": [
            "Osama Abdellatif",
            "Ahmed Ayman",
            "Ali Hamdi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17965",
        "abstract": "Automating high-volume unstructured data processing is essential for operational efficiency. Optical Character Recognition (OCR) is critical but often struggles with accuracy and efficiency in complex layouts and ambiguous text. These challenges are especially pronounced in large-scale tasks requiring both speed and precision. This paper introduces LMV-RPA, a Large Model Voting-based Robotic Process Automation system to enhance OCR workflows. LMV-RPA integrates outputs from OCR engines such as Paddle OCR, Tesseract OCR, Easy OCR, and DocTR with Large Language Models (LLMs) like LLaMA 3 and Gemini-1.5-pro. Using a majority voting mechanism, it processes OCR outputs into structured JSON formats, improving accuracy, particularly in complex layouts. The multi-phase pipeline processes text extracted by OCR engines through LLMs, combining results to ensure the most accurate outputs. LMV-RPA achieves 99 percent accuracy in OCR tasks, surpassing baseline models with 94 percent, while reducing processing time by 80 percent. Benchmark evaluations confirm its scalability and demonstrate that LMV-RPA offers a faster, more reliable, and efficient solution for automating large-scale document processing tasks.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "20",
        "title": "Data-driven Modeling of Parameterized Nonlinear Fluid Dynamical Systems with a Dynamics-embedded Conditional Generative Adversarial Network",
        "author": [
            "Abdolvahhab Rostamijavanani",
            "Shanwu Li",
            "Yongchao Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17978",
        "abstract": "This work presents a data-driven solution to accurately predict parameterized nonlinear fluid dynamical systems using a dynamics-generator conditional GAN (Dyn-cGAN) as a surrogate model. The Dyn-cGAN includes a dynamics block within a modified conditional GAN, enabling the simultaneous identification of temporal dynamics and their dependence on system parameters. The learned Dyn-cGAN model takes into account the system parameters to predict the flow fields of the system accurately. We evaluate the effectiveness and limitations of the developed Dyn-cGAN through numerical studies of various parameterized nonlinear fluid dynamical systems, including flow over a cylinder and a 2-D cavity problem, with different Reynolds numbers. Furthermore, we examine how Reynolds number affects the accuracy of the predictions for both case studies. Additionally, we investigate the impact of the number of time steps involved in the process of dynamics block training on the accuracy of predictions, and we find that an optimal value exists based on errors and mutual information relative to the ground truth.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "21",
        "title": "Multi-Agent Path Finding in Continuous Spaces with Projected Diffusion Models",
        "author": [
            "Jinhao Liang",
            "Jacob K. Christopher",
            "Sven Koenig",
            "Ferdinando Fioretto"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17993",
        "abstract": "Multi-Agent Path Finding (MAPF) is a fundamental problem in robotics, requiring the computation of collision-free paths for multiple agents moving from their respective start to goal positions. Coordinating multiple agents in a shared environment poses significant challenges, especially in continuous spaces where traditional optimization algorithms struggle with scalability. Moreover, these algorithms often depend on discretized representations of the environment, which can be impractical in image-based or high-dimensional settings. Recently, diffusion models have shown promise in single-agent path planning, capturing complex trajectory distributions and generating smooth paths that navigate continuous, high-dimensional spaces. However, directly extending diffusion models to MAPF introduces new challenges since these models struggle to ensure constraint feasibility, such as inter-agent collision avoidance. To overcome this limitation, this work proposes a novel approach that integrates constrained optimization with diffusion models for MAPF in continuous spaces. This unique combination directly produces feasible multi-agent trajectories that respect collision avoidance and kinematic constraints. The effectiveness of our approach is demonstrated across various challenging simulated scenarios of varying dimensionality.",
        "tags": [
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "22",
        "title": "StructTest: Benchmarking LLMs' Reasoning through Compositional Structured Outputs",
        "author": [
            "Hailin Chen",
            "Fangkai Jiao",
            "Mathieu Ravaut",
            "Nawshad Farruque",
            "Xuan Phi Nguyen",
            "Chengwei Qin",
            "Manan Dey",
            "Bosheng Ding",
            "Caiming Xiong",
            "Shafiq Joty",
            "Yingbo Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18011",
        "abstract": "The rapid development of large language models (LLMs) necessitates robust, unbiased, and scalable methods for evaluating their capabilities. However, human annotations are expensive to scale, model-based evaluations are prone to biases in answer style, while target-answer-based benchmarks are vulnerable to data contamination and cheating. To address these limitations, we propose StructTest, a novel benchmark that evaluates LLMs on their ability to produce compositionally specified structured outputs as an unbiased, cheap-to-run and difficult-to-cheat measure. The evaluation is done deterministically by a rule-based evaluator, which can be easily extended to new tasks. By testing structured outputs across diverse task domains -- including Summarization, Code, HTML and Math -- we demonstrate that StructTest serves as a good proxy for general reasoning abilities, as producing structured outputs often requires internal logical reasoning. We believe that StructTest offers a critical, complementary approach to objective and robust model evaluation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "23",
        "title": "Trustworthy and Efficient LLMs Meet Databases",
        "author": [
            "Kyoungmin Kim",
            "Anastasia Ailamaki"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18022",
        "abstract": "In the rapidly evolving AI era with large language models (LLMs) at the core, making LLMs more trustworthy and efficient, especially in output generation (inference), has gained significant attention. This is to reduce plausible but faulty LLM outputs (a.k.a hallucinations) and meet the highly increased inference demands. This tutorial explores such efforts and makes them transparent to the database community. Understanding these efforts is essential in harnessing LLMs in database tasks and adapting database techniques to LLMs. Furthermore, we delve into the synergy between LLMs and databases, highlighting new opportunities and challenges in their intersection. This tutorial aims to share with database researchers and practitioners essential concepts and strategies around LLMs, reduce the unfamiliarity of LLMs, and inspire joining in the intersection between LLMs and databases.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "24",
        "title": "More than Chit-Chat: Developing Robots for Small-Talk Interactions",
        "author": [
            "Rebecca Ramnauth",
            "Dražen Brščić",
            "Brian Scassellati"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18023",
        "abstract": "Beyond mere formality, small talk plays a pivotal role in social dynamics, serving as a verbal handshake for building rapport and understanding. For conversational AI and social robots, the ability to engage in small talk enhances their perceived sociability, leading to more comfortable and natural user interactions. In this study, we evaluate the capacity of current Large Language Models (LLMs) to drive the small talk of a social robot and identify key areas for improvement. We introduce a novel method that autonomously generates feedback and ensures LLM-generated responses align with small talk conventions. Through several evaluations -- involving chatbot interactions and human-robot interactions -- we demonstrate the system's effectiveness in guiding LLM-generated responses toward realistic, human-like, and natural small-talk exchanges.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Robot"
        ]
    },
    {
        "id": "25",
        "title": "LayerDropBack: A Universally Applicable Approach for Accelerating Training of Deep Networks",
        "author": [
            "Evgeny Hershkovitch Neiterman",
            "Gil Ben-Artzi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18027",
        "abstract": "Training very deep convolutional networks is challenging, requiring significant computational resources and time. Existing acceleration methods often depend on specific architectures or require network modifications. We introduce LayerDropBack (LDB), a simple yet effective method to accelerate training across a wide range of deep networks. LDB introduces randomness only in the backward pass, maintaining the integrity of the forward pass, guaranteeing that the same network is used during both training and inference. LDB can be seamlessly integrated into the training process of any model without altering its architecture, making it suitable for various network topologies. Our extensive experiments across multiple architectures (ViT, Swin Transformer, EfficientNet, DLA) and datasets (CIFAR-100, ImageNet) show significant training time reductions of 16.93\\% to 23.97\\%, while preserving or even enhancing model accuracy. Code is available at \\url{https://github.com/neiterman21/LDB}.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "26",
        "title": "Generating refactored code accurately using reinforcement learning",
        "author": [
            "Indranil Palit",
            "Tushar Sharma"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18035",
        "abstract": "Automated source code refactoring, particularly extract method refactoring, is a crucial and frequently employed technique during software development. Despite its importance and frequent use by practitioners, current automated techniques face significant limitations. These approaches often rely on developers to identify the precise bounds of refactoring opportunities in terms of source code statements. Also, they often do not capture the semantic context, resulting in offering no automated means to suggest meaningful method name, for instance. To address these challenges, we propose a novel reinforcement learning-based approach for fine-tuning and aligning code language models to perform automated, intelligent extract method refactoring on Java source code. Our approach fine-tunes sequence-to-sequence generative models and aligns them using the Proximal Policy Optimization (PPO) algorithm. We utilize code compilation and presence of the refactoring in the generated code as reward signals, providing a code-centric optimization process. Our experiments demonstrate that our approach significantly enhances the performance of large language models in code refactoring, as evidenced by both quantitative evaluation metrics such as BLEU, ROUGE, and CodeBLEU, and qualitative measures including syntactical and functional correctness. The supervised fine-tuned model, further aligned with PPO, surpasses traditional supervised fine-tuning by 11.96% and 16.45% in terms of BLEU and CodeBLEU scores, respectively. When subjected to a suite of 122 unit tests, the number of successful tests increased from 41 to 66 for the reinforcement learning aligned fine-tuned Code-T5 model, highlighting the effectiveness of our approach in producing functionally correct refactorings.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "27",
        "title": "AA-SGAN: Adversarially Augmented Social GAN with Synthetic Data",
        "author": [
            "Mirko Zaffaroni",
            "Federico Signoretta",
            "Marco Grangetto",
            "Attilio Fiandrotti"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18038",
        "abstract": "Accurately predicting pedestrian trajectories is crucial in applications such as autonomous driving or service robotics, to name a few. Deep generative models achieve top performance in this task, assuming enough labelled trajectories are available for training. To this end, large amounts of synthetically generated, labelled trajectories exist (e.g., generated by video games). However, such trajectories are not meant to represent pedestrian motion realistically and are ineffective at training a predictive model. We propose a method and an architecture to augment synthetic trajectories at training time and with an adversarial approach. We show that trajectory augmentation at training time unleashes significant gains when a state-of-the-art generative model is evaluated over real-world trajectories.",
        "tags": [
            "GAN",
            "Robotics"
        ]
    },
    {
        "id": "28",
        "title": "Theoretical Constraints on the Expressive Power of $\\mathsf{RoPE}$-based Tensor Attention Transformers",
        "author": [
            "Xiaoyu Li",
            "Yingyu Liang",
            "Zhenmei Shi",
            "Zhao Song",
            "Mingda Wan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18040",
        "abstract": "Tensor Attention extends traditional attention mechanisms by capturing high-order correlations across multiple modalities, addressing the limitations of classical matrix-based attention. Meanwhile, Rotary Position Embedding ($\\mathsf{RoPE}$) has shown superior performance in encoding positional information in long-context scenarios, significantly enhancing transformer models' expressiveness. Despite these empirical successes, the theoretical limitations of these technologies remain underexplored. In this study, we analyze the circuit complexity of Tensor Attention and $\\mathsf{RoPE}$-based Tensor Attention, showing that with polynomial precision, constant-depth layers, and linear or sublinear hidden dimension, they cannot solve fixed membership problems or $(A_{F,r})^*$ closure problems, under the assumption that $\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$. These findings highlight a gap between the empirical performance and theoretical constraints of Tensor Attention and $\\mathsf{RoPE}$-based Tensor Attention Transformers, offering insights that could guide the development of more theoretically grounded approaches to Transformer model design and scaling.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "29",
        "title": "Factuality or Fiction? Benchmarking Modern LLMs on Ambiguous QA with Citations",
        "author": [
            "Maya Patel",
            "Aditi Anand"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18051",
        "abstract": "Benchmarking modern large language models (LLMs) on complex and realistic tasks is critical to advancing their development. In this work, we evaluate the factual accuracy and citation performance of state-of-the-art LLMs on the task of Question Answering (QA) in ambiguous settings with source citations. Using three recently published datasets-DisentQA-DupliCite, DisentQA-ParaCite, and AmbigQA-Cite-featuring a range of real-world ambiguities, we analyze the performance of two leading LLMs, GPT-4o-mini and Claude-3.5. Our results show that larger, recent models consistently predict at least one correct answer in ambiguous contexts but fail to handle cases with multiple valid answers. Additionally, all models perform equally poorly in citation generation, with citation accuracy consistently at 0. However, introducing conflict-aware prompting leads to large improvements, enabling models to better address multiple valid answers and improve citation accuracy, while maintaining their ability to predict correct answers. These findings highlight the challenges and opportunities in developing LLMs that can handle ambiguity and provide reliable source citations. Our benchmarking study provides critical insights and sets a foundation for future improvements in trustworthy and interpretable QA systems.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "30",
        "title": "An Ensemble Approach to Short-form Video Quality Assessment Using Multimodal LLM",
        "author": [
            "Wen Wen",
            "Yilin Wang",
            "Neil Birkbeck",
            "Balu Adsumilli"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18060",
        "abstract": "The rise of short-form videos, characterized by diverse content, editing styles, and artifacts, poses substantial challenges for learning-based blind video quality assessment (BVQA) models. Multimodal large language models (MLLMs), renowned for their superior generalization capabilities, present a promising solution. This paper focuses on effectively leveraging a pretrained MLLM for short-form video quality assessment, regarding the impacts of pre-processing and response variability, and insights on combining the MLLM with BVQA models. We first investigated how frame pre-processing and sampling techniques influence the MLLM's performance. Then, we introduced a lightweight learning-based ensemble method that adaptively integrates predictions from the MLLM and state-of-the-art BVQA models. Our results demonstrated superior generalization performance with the proposed ensemble approach. Furthermore, the analysis of content-aware ensemble weights highlighted that some video characteristics are not fully represented by existing BVQA models, revealing potential directions to improve BVQA models further.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "31",
        "title": "Lla-VAP: LSTM Ensemble of Llama and VAP for Turn-Taking Prediction",
        "author": [
            "Hyunbae Jeon",
            "Frederic Guintu",
            "Rayvant Sahni"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18061",
        "abstract": "Turn-taking prediction is the task of anticipating when the speaker in a conversation will yield their turn to another speaker to begin speaking. This project expands on existing strategies for turn-taking prediction by employing a multi-modal ensemble approach that integrates large language models (LLMs) and voice activity projection (VAP) models. By combining the linguistic capabilities of LLMs with the temporal precision of VAP models, we aim to improve the accuracy and efficiency of identifying TRPs in both scripted and unscripted conversational scenarios. Our methods are evaluated on the In-Conversation Corpus (ICC) and Coached Conversational Preference Elicitation (CCPE) datasets, highlighting the strengths and limitations of current models while proposing a potentially more robust framework for enhanced prediction.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "32",
        "title": "LMRPA: Large Language Model-Driven Efficient Robotic Process Automation for OCR",
        "author": [
            "Osama Hosam Abdellaif",
            "Abdelrahman Nader",
            "Ali Hamdi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18063",
        "abstract": "This paper introduces LMRPA, a novel Large Model-Driven Robotic Process Automation (RPA) model designed to greatly improve the efficiency and speed of Optical Character Recognition (OCR) tasks. Traditional RPA platforms often suffer from performance bottlenecks when handling high-volume repetitive processes like OCR, leading to a less efficient and more time-consuming process. LMRPA allows the integration of Large Language Models (LLMs) to improve the accuracy and readability of extracted text, overcoming the challenges posed by ambiguous characters and complex text http://structures.Extensive benchmarks were conducted comparing LMRPA to leading RPA platforms, including UiPath and Automation Anywhere, using OCR engines like Tesseract and DocTR. The results are that LMRPA achieves superior performance, cutting the processing times by up to 52\\%. For instance, in Batch 2 of the Tesseract OCR task, LMRPA completed the process in 9.8 seconds, where UiPath finished in 18.1 seconds and Automation Anywhere finished in 18.7 seconds. Similar improvements were observed with DocTR, where LMRPA outperformed other automation tools conducting the same process by completing tasks in 12.7 seconds, while competitors took over 20 seconds to do the same. These findings highlight the potential of LMRPA to revolutionize OCR-driven automation processes, offering a more efficient and effective alternative solution to the existing state-of-the-art RPA models.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "33",
        "title": "Improving Factuality with Explicit Working Memory",
        "author": [
            "Mingda Chen",
            "Yang Li",
            "Karthik Padthe",
            "Rulin Shao",
            "Alicia Sun",
            "Luke Zettlemoyer",
            "Gargi Gosh",
            "Wen-tau Yih"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18069",
        "abstract": "Large language models can generate factually inaccurate content, a problem known as hallucination. Recent works have built upon retrieved-augmented generation to improve factuality through iterative prompting but these methods are limited by the traditional RAG design. To address these challenges, we introduce EWE (Explicit Working Memory), a novel approach that enhances factuality in long-form text generation by integrating a working memory that receives real-time feedback from external resources. The memory is refreshed based on online fact-checking and retrieval feedback, allowing EWE to rectify false claims during the generation process and ensure more accurate and reliable outputs. Our experiments demonstrate that Ewe outperforms strong baselines on four fact-seeking long-form generation datasets, increasing the factuality metric, VeriScore, by 2 to 10 points absolute without sacrificing the helpfulness of the responses. Further analysis reveals that the design of rules for memory updates, configurations of memory units, and the quality of the retrieval datastore are crucial factors for influencing model performance.",
        "tags": [
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "34",
        "title": "MMFactory: A Universal Solution Search Engine for Vision-Language Tasks",
        "author": [
            "Wan-Cyuan Fan",
            "Tanzila Rahman",
            "Leonid Sigal"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18072",
        "abstract": "With advances in foundational and vision-language models, and effective fine-tuning techniques, a large number of both general and special-purpose models have been developed for a variety of visual tasks. Despite the flexibility and accessibility of these models, no single model is able to handle all tasks and/or applications that may be envisioned by potential users. Recent approaches, such as visual programming and multimodal LLMs with integrated tools aim to tackle complex visual tasks, by way of program synthesis. However, such approaches overlook user constraints (e.g., performance / computational needs), produce test-time sample-specific solutions that are difficult to deploy, and, sometimes, require low-level instructions that maybe beyond the abilities of a naive user. To address these limitations, we introduce MMFactory, a universal framework that includes model and metrics routing components, acting like a solution search engine across various available models. Based on a task description and few sample input-output pairs and (optionally) resource and/or performance constraints, MMFactory can suggest a diverse pool of programmatic solutions by instantiating and combining visio-lingual tools from its model repository. In addition to synthesizing these solutions, MMFactory also proposes metrics and benchmarks performance / resource characteristics, allowing users to pick a solution that meets their unique design constraints. From the technical perspective, we also introduced a committee-based solution proposer that leverages multi-agent LLM conversation to generate executable, diverse, universal, and robust solutions for the user. Experimental results show that MMFactory outperforms existing methods by delivering state-of-the-art solutions tailored to user problem specifications. Project page is available at https://davidhalladay.github.io/mmfactory_demo.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "35",
        "title": "AutoSculpt: A Pattern-based Model Auto-pruning Framework Using Reinforcement Learning and Graph Learning",
        "author": [
            "Lixian Jing",
            "Jianpeng Qi",
            "Junyu Dong",
            "Yanwei Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18091",
        "abstract": "As deep neural networks (DNNs) are increasingly deployed on edge devices, optimizing models for constrained computational resources is critical. Existing auto-pruning methods face challenges due to the diversity of DNN models, various operators (e.g., filters), and the difficulty in balancing pruning granularity with model accuracy. To address these limitations, we introduce AutoSculpt, a pattern-based automated pruning framework designed to enhance efficiency and accuracy by leveraging graph learning and deep reinforcement learning (DRL). AutoSculpt automatically identifies and prunes regular patterns within DNN architectures that can be recognized by existing inference engines, enabling runtime acceleration. Three key steps in AutoSculpt include: (1) Constructing DNNs as graphs to encode their topology and parameter dependencies, (2) embedding computationally efficient pruning patterns, and (3) utilizing DRL to iteratively refine auto-pruning strategies until the optimal balance between compression and accuracy is achieved. Experimental results demonstrate the effectiveness of AutoSculpt across various architectures, including ResNet, MobileNet, VGG, and Vision Transformer, achieving pruning rates of up to 90% and nearly 18% improvement in FLOPs reduction, outperforming all baselines. The codes can be available at https://anonymous.4open.science/r/AutoSculpt-DDA0",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "36",
        "title": "Molly: Making Large Language Model Agents Solve Python Problem More Logically",
        "author": [
            "Rui Xiao",
            "Jiong Wang",
            "Lu Han",
            "Na Zong",
            "Han Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18093",
        "abstract": "Applying large language models (LLMs) as teaching assists has attracted much attention as an integral part of intelligent education, particularly in computing courses. To reduce the gap between the LLMs and the computer programming education expert, fine-tuning and retrieval augmented generation (RAG) are the two mainstream methods in existing researches. However, fine-tuning for specific tasks is resource-intensive and may diminish the model`s generalization capabilities. RAG can perform well on reducing the illusion of LLMs, but the generation of irrelevant factual content during reasoning can cause significant confusion for learners. To address these problems, we introduce the Molly agent, focusing on solving the proposed problem encountered by learners when learning Python programming language. Our agent automatically parse the learners' questioning intent through a scenario-based interaction, enabling precise retrieval of relevant documents from the constructed knowledge base. At generation stage, the agent reflect on the generated responses to ensure that they not only align with factual content but also effectively answer the user's queries. Extensive experimentation on a constructed Chinese Python QA dataset shows the effectiveness of the Molly agent, indicating an enhancement in its performance for providing useful responses to Python questions.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "37",
        "title": "Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine",
        "author": [
            "Yu He Ke",
            "Liyuan Jin",
            "Kabilan Elangovan",
            "Bryan Wen Xi Ong",
            "Chin Yang Oh",
            "Jacqueline Sim",
            "Kenny Wei-Tsen Loh",
            "Chai Rick Soh",
            "Jonathan Ming Hua Cheng",
            "Aaron Kwang Yang Lee",
            "Daniel Shu Wei Ting",
            "Nan Liu",
            "Hairil Rizal Abdullah"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18096",
        "abstract": "Large Language Models (LLMs) are emerging as powerful tools in healthcare, particularly for complex, domain-specific tasks. This study describes the development and evaluation of the PErioperative AI CHatbot (PEACH), a secure LLM-based system integrated with local perioperative guidelines to support preoperative clinical decision-making. PEACH was embedded with 35 institutional perioperative protocols in the secure Claude 3.5 Sonet LLM framework within Pair Chat (developed by Singapore Government) and tested in a silent deployment with real-world data. Accuracy, safety, and usability were assessed. Deviations and hallucinations were categorized based on potential harm, and user feedback was evaluated using the Technology Acceptance Model (TAM). Updates were made after the initial silent deployment to amend one protocol.\nIn 240 real-world clinical iterations, PEACH achieved a first-generation accuracy of 97.5% (78/80) and an overall accuracy of 96.7% (232/240) across three iterations. The updated PEACH demonstrated improved accuracy of 97.9% (235/240), with a statistically significant difference from the null hypothesis of 95% accuracy (p = 0.018, 95% CI: 0.952-0.991). Minimal hallucinations and deviations were observed (both 1/240 and 2/240, respectively). Clinicians reported that PEACH expedited decisions in 95% of cases, and inter-rater reliability ranged from kappa 0.772-0.893 within PEACH and 0.610-0.784 among attendings.\nPEACH is an accurate, adaptable tool that enhances consistency and efficiency in perioperative decision-making. Future research should explore its scalability across specialties and its impact on clinical outcomes.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "38",
        "title": "EvoPat: A Multi-LLM-based Patents Summarization and Analysis Agent",
        "author": [
            "Suyuan Wang",
            "Xueqian Yin",
            "Menghao Wang",
            "Ruofeng Guo",
            "Kai Nan"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18100",
        "abstract": "The rapid growth of scientific techniques and knowledge is reflected in the exponential increase in new patents filed annually. While these patents drive innovation, they also present significant burden for researchers and engineers, especially newcomers. To avoid the tedious work of navigating a vast and complex landscape to identify trends and breakthroughs, researchers urgently need efficient tools to summarize, evaluate, and contextualize patents, revealing their innovative contributions and underlying scientific http://principles.To address this need, we present EvoPat, a multi-LLM-based patent agent designed to assist users in analyzing patents through Retrieval-Augmented Generation (RAG) and advanced search strategies. EvoPat leverages multiple Large Language Models (LLMs), each performing specialized roles such as planning, identifying innovations, and conducting comparative evaluations. The system integrates data from local databases, including patents, literature, product catalogous, and company repositories, and online searches to provide up-to-date insights. The ability to collect information not included in original database automatically is also implemented. Through extensive testing in the natural language processing (NLP) domain, we demonstrate that EvoPat outperforms GPT-4 in tasks such as patent summarization, comparative analysis, and technical evaluation. EvoPat represents a significant step toward creating AI-powered tools that empower researchers and engineers to efficiently navigate the complexities of the patent landscape.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "39",
        "title": "Beyond the Known: Enhancing Open Set Domain Adaptation with Unknown Exploration",
        "author": [
            "Lucas Fernando Alvarenga e Silva",
            "Samuel Felipe dos Santos",
            "Nicu Sebe",
            "Jurandy Almeida"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18105",
        "abstract": "Convolutional neural networks (CNNs) can learn directly from raw data, resulting in exceptional performance across various research areas. However, factors present in non-controllable environments such as unlabeled datasets with varying levels of domain and category shift can reduce model accuracy. The Open Set Domain Adaptation (OSDA) is a challenging problem that arises when both of these issues occur together. Existing OSDA approaches in literature only align known classes or use supervised training to learn unknown classes as a single new category. In this work, we introduce a new approach to improve OSDA techniques by extracting a set of high-confidence unknown instances and using it as a hard constraint to tighten the classification boundaries. Specifically, we use a new loss constraint that is evaluated in three different ways: (1) using pristine negative instances directly; (2) using data augmentation techniques to create randomly transformed negatives; and (3) with generated synthetic negatives containing adversarial features. We analyze different strategies to improve the discriminator and the training of the Generative Adversarial Network (GAN) used to generate synthetic negatives. We conducted extensive experiments and analysis on OVANet using three widely-used public benchmarks, the Office-31, Office-Home, and VisDA datasets. We were able to achieve similar H-score to other state-of-the-art methods, while increasing the accuracy on unknown categories.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "40",
        "title": "Unveiling Visual Perception in Language Models: An Attention Head Analysis Approach",
        "author": [
            "Jing Bi",
            "Junjia Guo",
            "Yunlong Tang",
            "Lianggong Bruce Wen",
            "Zhang Liu",
            "Chenliang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18108",
        "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated remarkable progress in visual understanding. This impressive leap raises a compelling question: how can language models, initially trained solely on linguistic data, effectively interpret and process visual content? This paper aims to address this question with systematic investigation across 4 model families and 4 model scales, uncovering a unique class of attention heads that focus specifically on visual content. Our analysis reveals a strong correlation between the behavior of these attention heads, the distribution of attention weights, and their concentration on visual tokens within the input. These findings enhance our understanding of how LLMs adapt to multimodal tasks, demonstrating their potential to bridge the gap between textual and visual understanding. This work paves the way for the development of AI systems capable of engaging with diverse modalities.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "41",
        "title": "SlimGPT: Layer-wise Structured Pruning for Large Language Models",
        "author": [
            "Gui Ling",
            "Ziyang Wang",
            "Yuliang Yan",
            "Qingwen Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18110",
        "abstract": "Large language models (LLMs) have garnered significant attention for their remarkable capabilities across various domains, whose vast parameter scales present challenges for practical deployment. Structured pruning is an effective method to balance model performance with efficiency, but performance restoration under computational resource constraints is a principal challenge in pruning LLMs. Therefore, we present a low-cost and fast structured pruning method for LLMs named SlimGPT based on the Optimal Brain Surgeon framework. We propose Batched Greedy Pruning for rapid and near-optimal pruning, which enhances the accuracy of head-wise pruning error estimation through grouped Cholesky decomposition and improves the pruning efficiency of FFN via Dynamic Group Size, thereby achieving approximate local optimal pruning results within one hour. Besides, we explore the limitations of layer-wise pruning from the perspective of error accumulation and propose Incremental Pruning Ratio, a non-uniform pruning strategy to reduce performance degradation. Experimental results on the LLaMA benchmark show that SlimGPT outperforms other methods and achieves state-of-the-art results.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "42",
        "title": "AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation",
        "author": [
            "Hao Wen",
            "Shizuo Tian",
            "Borislav Pavlov",
            "Wenjie Du",
            "Yixuan Li",
            "Ge Chang",
            "Shanhui Zhao",
            "Jiacheng Liu",
            "Yunxin Liu",
            "Ya-Qin Zhang",
            "Yuanchun Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18116",
        "abstract": "Large language models (LLMs) have brought exciting new advances to mobile UI agents, a long-standing research field that aims to complete arbitrary natural language tasks through mobile UI interactions. However, existing UI agents usually demand high reasoning capabilities of powerful large models that are difficult to be deployed locally on end-users' devices, which raises huge concerns about user privacy and centralized serving cost. One way to reduce the required model size is to customize a smaller domain-specific model with high-quality training data, e.g. large-scale human demonstrations of diverse types of apps and tasks, while such datasets are extremely difficult to obtain. Inspired by the remarkable coding abilities of recent small language models (SLMs), we propose to convert the UI task automation problem to a code generation problem, which can be effectively solved by an on-device SLM and efficiently executed with an on-device code interpreter. Unlike normal coding tasks that can be extensively pretrained with public datasets, generating UI automation code is challenging due to the diversity, complexity, and variability of target apps. Therefore, we adopt a document-centered approach that automatically builds fine-grained API documentation for each app and generates diverse task samples based on this documentation. By guiding the agent with the synthetic documents and task samples, it learns to generate precise and efficient scripts to complete unseen tasks. Based on detailed comparisons with state-of-the-art mobile UI agents, our approach effectively improves the mobile task automation with significantly higher success rates and lower latency/token consumption. Code will be open-sourced.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "43",
        "title": "Do Language Models Understand the Cognitive Tasks Given to Them? Investigations with the N-Back Paradigm",
        "author": [
            "Xiaoyang Hu",
            "Richard L. Lewis"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18120",
        "abstract": "Cognitive tasks originally developed for humans are now increasingly used to study language models. While applying these tasks is often straightforward, interpreting their results can be challenging. In particular, when a model underperforms, it's often unclear whether this results from a limitation in the cognitive ability being tested or a failure to understand the task itself. A recent study argued that GPT 3.5's declining performance on 2-back and 3-back tasks reflects a working memory capacity limit similar to humans. By analyzing a range of open-source language models of varying performance levels on these tasks, we show that the poor performance instead reflects a limitation in task comprehension and task set maintenance. In addition, we push the best performing model to higher n values and experiment with alternative prompting strategies, before analyzing model attentions. Our larger aim is to contribute to the ongoing conversation around refining methodologies for the cognitive evaluation of language models.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "44",
        "title": "AEIOU: A Unified Defense Framework against NSFW Prompts in Text-to-Image Models",
        "author": [
            "Yiming Wang",
            "Jiahao Chen",
            "Qingming Li",
            "Xing Yang",
            "Shouling Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18123",
        "abstract": "As text-to-image (T2I) models continue to advance and gain widespread adoption, their associated safety issues are becoming increasingly prominent. Malicious users often exploit these models to generate Not-Safe-for-Work (NSFW) images using harmful or adversarial prompts, highlighting the critical need for robust safeguards to ensure the integrity and compliance of model outputs. Current internal safeguards frequently degrade image quality, while external detection methods often suffer from low accuracy and inefficiency.\nIn this paper, we introduce AEIOU, a defense framework that is Adaptable, Efficient, Interpretable, Optimizable, and Unified against NSFW prompts in T2I models. AEIOU extracts NSFW features from the hidden states of the model's text encoder, utilizing the separable nature of these features to detect NSFW prompts. The detection process is efficient, requiring minimal inference time. AEIOU also offers real-time interpretation of results and supports optimization through data augmentation techniques. The framework is versatile, accommodating various T2I architectures. Our extensive experiments show that AEIOU significantly outperforms both commercial and open-source moderation tools, achieving over 95% accuracy across all datasets and improving efficiency by at least tenfold. It effectively counters adaptive attacks and excels in few-shot and multi-label scenarios.",
        "tags": [
            "Detection",
            "Text-to-Image"
        ]
    },
    {
        "id": "45",
        "title": "LSAQ: Layer-Specific Adaptive Quantization for Large Language Model Deployment",
        "author": [
            "Binrui Zeng",
            "Bin Ji",
            "Xiaodong Liu",
            "Jie Yu",
            "Shasha Li",
            "Jun Ma",
            "Xiaopeng Li",
            "Shangwen Wang",
            "Xinran Hong"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18135",
        "abstract": "As large language models (LLMs) demonstrate exceptional performance across various domains, the deployment of these models on edge devices has emerged as a new trend. Quantization techniques, which reduce the size and memory footprint of LLMs, are effective for enabling deployment on resource-constrained edge devices. However, existing one-size-fits-all quantization methods often fail to dynamically adjust the memory consumption of LLMs based on specific hardware characteristics and usage scenarios. To address this limitation, we propose LSAQ (Layer-Specific Adaptive Quantization), a system for adaptive quantization and dynamic deployment of LLMs based on layer importance. LSAQ evaluates layer importance by constructing top-k token sets from the inputs and outputs of each layer and calculating their Jaccard coefficient. Using this evaluation, the system adaptively adjusts quantization strategies in real time according to the resource availability of edge devices, assigning different precision levels to layers of varying importance. This approach significantly reduces the storage requirements of LLMs while maintaining model performance, enabling efficient deployment across diverse hardware platforms and usage scenarios.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "46",
        "title": "Ensuring Consistency for In-Image Translation",
        "author": [
            "Chengpeng Fu",
            "Xiaocheng Feng",
            "Yichong Huang",
            "Wenshuai Huo",
            "Baohang Li",
            "Zhirui Zhang",
            "Yunfei Lu",
            "Dandan Tu",
            "Duyu Tang",
            "Hui Wang",
            "Bing Qin",
            "Ting Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18139",
        "abstract": "The in-image machine translation task involves translating text embedded within images, with the translated results presented in image format. While this task has numerous applications in various scenarios such as film poster translation and everyday scene image translation, existing methods frequently neglect the aspect of consistency throughout this process. We propose the need to uphold two types of consistency in this task: translation consistency and image generation consistency. The former entails incorporating image information during translation, while the latter involves maintaining consistency between the style of the text-image and the original image, ensuring background integrity. To address these consistency requirements, we introduce a novel two-stage framework named HCIIT (High-Consistency In-Image Translation) which involves text-image translation using a multimodal multilingual large language model in the first stage and image backfilling with a diffusion model in the second stage. Chain of thought learning is utilized in the first stage to enhance the model's ability to leverage image information during translation. Subsequently, a diffusion model trained for style-consistent text-image generation ensures uniformity in text style within images and preserves background details. A dataset comprising 400,000 style-consistent pseudo text-image pairs is curated for model training. Results obtained on both curated test sets and authentic image test sets validate the effectiveness of our framework in ensuring consistency and producing high-quality translated images.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "47",
        "title": "Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media",
        "author": [
            "Zhen Sun",
            "Zongmin Zhang",
            "Xinyue Shen",
            "Ziyi Zhang",
            "Yule Liu",
            "Michael Backes",
            "Yang Zhang",
            "Xinlei He"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18148",
        "abstract": "Social media platforms are experiencing a growing presence of AI-Generated Texts (AIGTs). However, the misuse of AIGTs could have profound implications for public opinion, such as spreading misinformation and manipulating narratives. Despite its importance, a systematic study to assess the prevalence of AIGTs on social media is still lacking. To address this gap, this paper aims to quantify, monitor, and analyze the AIGTs on online social media platforms. We first collect a dataset (SM-D) with around 2.4M posts from 3 major social media platforms: Medium, Quora, and Reddit. Then, we construct a diverse dataset (AIGTBench) to train and evaluate AIGT detectors. AIGTBench combines popular open-source datasets and our AIGT datasets generated from social media texts by 12 LLMs, serving as a benchmark for evaluating mainstream detectors. With this setup, we identify the best-performing detector (OSM-Det). We then apply OSM-Det to SM-D to track AIGTs over time and observe different trends of AI Attribution Rate (AAR) across social media platforms from January 2022 to October 2024. Specifically, Medium and Quora exhibit marked increases in AAR, rising from 1.77% to 37.03% and 2.06% to 38.95%, respectively. In contrast, Reddit shows slower growth, with AAR increasing from 1.31% to 2.45% over the same period. Our further analysis indicates that AIGTs differ from human-written texts across several dimensions, including linguistic patterns, topic distributions, engagement levels, and the follower distribution of authors. We envision our analysis and findings on AIGTs in social media can shed light on future research in this domain.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "48",
        "title": "Dense-Face: Personalized Face Generation Model via Dense Annotation Prediction",
        "author": [
            "Xiao Guo",
            "Manh Tran",
            "Jiaxin Cheng",
            "Xiaoming Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18149",
        "abstract": "The text-to-image (T2I) personalization diffusion model can generate images of the novel concept based on the user input text caption. However, existing T2I personalized methods either require test-time fine-tuning or fail to generate images that align well with the given text caption. In this work, we propose a new T2I personalization diffusion model, Dense-Face, which can generate face images with a consistent identity as the given reference subject and align well with the text caption. Specifically, we introduce a pose-controllable adapter for the high-fidelity image generation while maintaining the text-based editing ability of the pre-trained stable diffusion (SD). Additionally, we use internal features of the SD UNet to predict dense face annotations, enabling the proposed method to gain domain knowledge in face generation. Empirically, our method achieves state-of-the-art or competitive generation performance in image-text alignment, identity preservation, and pose control.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "49",
        "title": "EvalMuse-40K: A Reliable and Fine-Grained Benchmark with Comprehensive Human Annotations for Text-to-Image Generation Model Evaluation",
        "author": [
            "Shuhao Han",
            "Haotian Fan",
            "Jiachen Fu",
            "Liang Li",
            "Tao Li",
            "Junhui Cui",
            "Yunqiu Wang",
            "Yang Tai",
            "Jingwei Sun",
            "Chunle Guo",
            "Chongyi Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18150",
        "abstract": "Recently, Text-to-Image (T2I) generation models have achieved significant advancements. Correspondingly, many automated metrics have emerged to evaluate the image-text alignment capabilities of generative models. However, the performance comparison among these automated metrics is limited by existing small datasets. Additionally, these datasets lack the capacity to assess the performance of automated metrics at a fine-grained level. In this study, we contribute an EvalMuse-40K benchmark, gathering 40K image-text pairs with fine-grained human annotations for image-text alignment-related tasks. In the construction process, we employ various strategies such as balanced prompt sampling and data re-annotation to ensure the diversity and reliability of our benchmark. This allows us to comprehensively evaluate the effectiveness of image-text alignment metrics for T2I models. Meanwhile, we introduce two new methods to evaluate the image-text alignment capabilities of T2I models: FGA-BLIP2 which involves end-to-end fine-tuning of a vision-language model to produce fine-grained image-text alignment scores and PN-VQA which adopts a novel positive-negative VQA manner in VQA models for zero-shot fine-grained evaluation. Both methods achieve impressive performance in image-text alignment evaluations. We also use our methods to rank current AIGC models, in which the results can serve as a reference source for future study and promote the development of T2I generation. The data and code will be made publicly available.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "50",
        "title": "DepthLab: From Partial to Complete",
        "author": [
            "Zhiheng Liu",
            "Ka Leong Cheng",
            "Qiuyu Wang",
            "Shuzhe Wang",
            "Hao Ouyang",
            "Bin Tan",
            "Kai Zhu",
            "Yujun Shen",
            "Qifeng Chen",
            "Ping Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18153",
        "abstract": "Missing values remain a common challenge for depth data across its wide range of applications, stemming from various causes like incomplete data acquisition and perspective alteration. This work bridges this gap with DepthLab, a foundation depth inpainting model powered by image diffusion priors. Our model features two notable strengths: (1) it demonstrates resilience to depth-deficient regions, providing reliable completion for both continuous areas and isolated points, and (2) it faithfully preserves scale consistency with the conditioned known depth when filling in missing values. Drawing on these advantages, our approach proves its worth in various downstream tasks, including 3D scene inpainting, text-to-3D scene generation, sparse-view reconstruction with DUST3R, and LiDAR depth completion, exceeding current solutions in both numerical performance and visual quality. Our project page with source code is available at https://johanan528.github.io/depthlab_web/.",
        "tags": [
            "3D",
            "Diffusion",
            "Inpainting",
            "Text-to-3D"
        ]
    },
    {
        "id": "51",
        "title": "Stochastic Control for Fine-tuning Diffusion Models: Optimality, Regularity, and Convergence",
        "author": [
            "Yinbin Han",
            "Meisam Razaviyayn",
            "Renyuan Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18164",
        "abstract": "Diffusion models have emerged as powerful tools for generative modeling, demonstrating exceptional capability in capturing target data distributions from large datasets. However, fine-tuning these massive models for specific downstream tasks, constraints, and human preferences remains a critical challenge. While recent advances have leveraged reinforcement learning algorithms to tackle this problem, much of the progress has been empirical, with limited theoretical understanding. To bridge this gap, we propose a stochastic control framework for fine-tuning diffusion models. Building on denoising diffusion probabilistic models as the pre-trained reference dynamics, our approach integrates linear dynamics control with Kullback-Leibler regularization. We establish the well-posedness and regularity of the stochastic control problem and develop a policy iteration algorithm (PI-FT) for numerical solution. We show that PI-FT achieves global convergence at a linear rate. Unlike existing work that assumes regularities throughout training, we prove that the control and value sequences generated by the algorithm maintain the regularity. Additionally, we explore extensions of our framework to parametric settings and continuous-time formulations.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "52",
        "title": "Token Highlighter: Inspecting and Mitigating Jailbreak Prompts for Large Language Models",
        "author": [
            "Xiaomeng Hu",
            "Pin-Yu Chen",
            "Tsung-Yi Ho"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18171",
        "abstract": "Large Language Models (LLMs) are increasingly being integrated into services such as ChatGPT to provide responses to user queries. To mitigate potential harm and prevent misuse, there have been concerted efforts to align the LLMs with human values and legal compliance by incorporating various techniques, such as Reinforcement Learning from Human Feedback (RLHF), into the training of the LLMs. However, recent research has exposed that even aligned LLMs are susceptible to adversarial manipulations known as Jailbreak Attacks. To address this challenge, this paper proposes a method called Token Highlighter to inspect and mitigate the potential jailbreak threats in the user query. Token Highlighter introduced a concept called Affirmation Loss to measure the LLM's willingness to answer the user query. It then uses the gradient of Affirmation Loss for each token in the user query to locate the jailbreak-critical tokens. Further, Token Highlighter exploits our proposed Soft Removal technique to mitigate the jailbreak effects of critical tokens via shrinking their token embeddings. Experimental results on two aligned LLMs (LLaMA-2 and Vicuna-V1.5) demonstrate that the proposed method can effectively defend against a variety of Jailbreak Attacks while maintaining competent performance on benign questions of the AlpacaEval benchmark. In addition, Token Highlighter is a cost-effective and interpretable defense because it only needs to query the protected LLM once to compute the Affirmation Loss and can highlight the critical tokens upon refusal.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "Vicuna"
        ]
    },
    {
        "id": "53",
        "title": "INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent",
        "author": [
            "Haohang Li",
            "Yupeng Cao",
            "Yangyang Yu",
            "Shashidhar Reddy Javaji",
            "Zhiyang Deng",
            "Yueru He",
            "Yuechen Jiang",
            "Zining Zhu",
            "Koduvayur Subbalakshmi",
            "Guojun Xiong",
            "Jimin Huang",
            "Lingfei Qian",
            "Xueqing Peng",
            "Qianqian Xie",
            "Jordan W. Suchow"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18174",
        "abstract": "Recent advancements have underscored the potential of large language model (LLM)-based agents in financial decision-making. Despite this progress, the field currently encounters two main challenges: (1) the lack of a comprehensive LLM agent framework adaptable to a variety of financial tasks, and (2) the absence of standardized benchmarks and consistent datasets for assessing agent performance. To tackle these issues, we introduce \\textsc{InvestorBench}, the first benchmark specifically designed for evaluating LLM-based agents in diverse financial decision-making contexts. InvestorBench enhances the versatility of LLM-enabled agents by providing a comprehensive suite of tasks applicable to different financial products, including single equities like stocks, cryptocurrencies and exchange-traded funds (ETFs). Additionally, we assess the reasoning and decision-making capabilities of our agent framework using thirteen different LLMs as backbone models, across various market environments and tasks. Furthermore, we have curated a diverse collection of open-source, multi-modal datasets and developed a comprehensive suite of environments for financial decision-making. This establishes a highly accessible platform for evaluating financial agents' performance across various scenarios.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "54",
        "title": "VisionGRU: A Linear-Complexity RNN Model for Efficient Image Analysis",
        "author": [
            "Shicheng Yin",
            "Kaixuan Yin",
            "Weixing Chen",
            "Enbo Huang",
            "Yang Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18178",
        "abstract": "Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) are two dominant models for image analysis. While CNNs excel at extracting multi-scale features and ViTs effectively capture global dependencies, both suffer from high computational costs, particularly when processing high-resolution images. Recently, state-space models (SSMs) and recurrent neural networks (RNNs) have attracted attention due to their efficiency. However, their performance in image classification tasks remains limited. To address these challenges, this paper introduces VisionGRU, a novel RNN-based architecture designed for efficient image classification. VisionGRU leverages a simplified Gated Recurrent Unit (minGRU) to process large-scale image features with linear complexity. It divides images into smaller patches and progressively reduces the sequence length while increasing the channel depth, thus facilitating multi-scale feature extraction. A hierarchical 2DGRU module with bidirectional scanning captures both local and global contexts, improving long-range dependency modeling, particularly for tasks like semantic segmentation. Experimental results on the ImageNet and ADE20K datasets demonstrate that VisionGRU outperforms ViTs, significantly reducing memory usage and computational costs, especially for high-resolution images. These findings underscore the potential of RNN-based approaches for developing efficient and scalable computer vision solutions. Codes will be available at https://github.com/YangLiu9208/VisionGRU.",
        "tags": [
            "RNN",
            "SSMs",
            "Segmentation",
            "State Space Models"
        ]
    },
    {
        "id": "55",
        "title": "TextMatch: Enhancing Image-Text Consistency Through Multimodal Optimization",
        "author": [
            "Yucong Luo",
            "Mingyue Cheng",
            "Jie Ouyang",
            "Xiaoyu Tao",
            "Qi Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18185",
        "abstract": "Text-to-image generative models excel in creating images from text but struggle with ensuring alignment and consistency between outputs and prompts. This paper introduces TextMatch, a novel framework that leverages multimodal optimization to address image-text discrepancies in text-to-image (T2I) generation and editing. TextMatch employs a scoring strategy powered by large language models (LLMs) and visual question-answering (VQA) models to evaluate semantic consistency between prompts and generated images. By integrating multimodal in-context learning and chain of thought reasoning, our method dynamically refines prompts through iterative optimization. This process ensures that the generated images better capture user intent of, resulting in higher fidelity and relevance. Extensive experiments demonstrate that TextMatch significantly improves text-image consistency across multiple benchmarks, establishing a reliable framework for advancing the capabilities of text-to-image generative models. Our code is available at https://anonymous.4open.science/r/TextMatch-F55C/.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Text-to-Image"
        ]
    },
    {
        "id": "56",
        "title": "VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics Manipulation with Long-Horizon Reasoning Tasks",
        "author": [
            "Shiduo Zhang",
            "Zhe Xu",
            "Peiju Liu",
            "Xiaopeng Yu",
            "Yuan Li",
            "Qinghui Gao",
            "Zhaoye Fei",
            "Zhangyue Yin",
            "Zuxuan Wu",
            "Yu-Gang Jiang",
            "Xipeng Qiu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18194",
        "abstract": "General-purposed embodied agents are designed to understand the users' natural instructions or intentions and act precisely to complete universal tasks. Recently, methods based on foundation models especially Vision-Language-Action models (VLAs) have shown a substantial potential to solve language-conditioned manipulation (LCM) tasks well. However, existing benchmarks do not adequately meet the needs of VLAs and relative algorithms. To better define such general-purpose tasks in the context of LLMs and advance the research in VLAs, we present VLABench, an open-source benchmark for evaluating universal LCM task learning. VLABench provides 100 carefully designed categories of tasks, with strong randomization in each category of task and a total of 2000+ objects. VLABench stands out from previous benchmarks in four key aspects: 1) tasks requiring world knowledge and common sense transfer, 2) natural language instructions with implicit human intentions rather than templates, 3) long-horizon tasks demanding multi-step reasoning, and 4) evaluation of both action policies and language model capabilities. The benchmark assesses multiple competencies including understanding of mesh\\&texture, spatial relationship, semantic instruction, physical laws, knowledge transfer and reasoning, etc. To support the downstream finetuning, we provide high-quality training data collected via an automated framework incorporating heuristic skills and prior information. The experimental results indicate that both the current state-of-the-art pretrained VLAs and the workflow based on VLMs face challenges in our tasks.",
        "tags": [
            "LLMs",
            "Robotics"
        ]
    },
    {
        "id": "57",
        "title": "Robustness-aware Automatic Prompt Optimization",
        "author": [
            "Zeru Shi",
            "Zhenting Wang",
            "Yongye Su",
            "Weidi Luo",
            "Fan Yang",
            "Yongfeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18196",
        "abstract": "The performance of Large Language Models (LLMs) is based on the quality of the prompts and the semantic and structural integrity information of the input data. However, current prompt generation methods primarily focus on generating prompts for clean input data, often overlooking the impact of perturbed inputs on prompt performance. To address this limitation, we propose BATprompt (By Adversarial Training prompt), a novel method for prompt generation designed to withstand input perturbations (such as typos in the input). Inspired by adversarial training techniques, BATprompt demonstrates strong performance on a variety of perturbed tasks through a two-step process: adversarial perturbation and iterative optimization on unperturbed input via LLM. Unlike conventional adversarial attack methods, BATprompt avoids reliance on real gradients or model parameters. Instead, it leverages the advanced reasoning, language understanding and self reflection capabilities of LLMs to simulate gradients, guiding the generation of adversarial perturbations and optimizing prompt performance. In our experiments, we evaluate BATprompt on multiple datasets across both language understanding and generation tasks. The results indicate that BATprompt outperforms existing prompt generation methods, delivering superior robustness and performance under diverse perturbation scenarios.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "58",
        "title": "Leveraging Deep Learning with Multi-Head Attention for Accurate Extraction of Medicine from Handwritten Prescriptions",
        "author": [
            "Usman Ali",
            "Sahil Ranmbail",
            "Muhammad Nadeem",
            "Hamid Ishfaq",
            "Muhammad Umer Ramzan",
            "Waqas Ali"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18199",
        "abstract": "Extracting medication names from handwritten doctor prescriptions is challenging due to the wide variability in handwriting styles and prescription formats. This paper presents a robust method for extracting medicine names using a combination of Mask R-CNN and Transformer-based Optical Character Recognition (TrOCR) with Multi-Head Attention and Positional Embeddings. A novel dataset, featuring diverse handwritten prescriptions from various regions of Pakistan, was utilized to fine-tune the model on different handwriting styles. The Mask R-CNN model segments the prescription images to focus on the medicinal sections, while the TrOCR model, enhanced by Multi-Head Attention and Positional Embeddings, transcribes the isolated text. The transcribed text is then matched against a pre-existing database for accurate identification. The proposed approach achieved a character error rate (CER) of 1.4% on standard benchmarks, highlighting its potential as a reliable and efficient tool for automating medicine name extraction.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "59",
        "title": "Adapting Large Language Models for Improving TCP Fairness over WiFi",
        "author": [
            "Shyam Kumar Shrestha",
            "Shiva Raj Pokhrel",
            "Jonathan Kua"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18200",
        "abstract": "The new transmission control protocol (TCP) relies on Deep Learning (DL) for prediction and optimization, but requires significant manual effort to design deep neural networks (DNNs) and struggles with generalization in dynamic environments. Inspired by the success of large language models (LLMs), this study proposes TCP-LLM, a novel framework leveraging LLMs for TCP applications. TCP-LLM utilizes pre-trained knowledge to reduce engineering effort, enhance generalization, and deliver superior performance across diverse TCP tasks. Applied to reducing flow unfairness, adapting congestion control, and preventing starvation, TCP-LLM demonstrates significant improvements over TCP with minimal fine-tuning.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "60",
        "title": "Accelerating AIGC Services with Latent Action Diffusion Scheduling in Edge Networks",
        "author": [
            "Changfu Xu",
            "Jianxiong Guo",
            "Wanyu Lin",
            "Haodong Zou",
            "Wentao Fan",
            "Tian Wang",
            "Xiaowen Chu",
            "Jiannong Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18212",
        "abstract": "Artificial Intelligence Generated Content (AIGC) has gained significant popularity for creating diverse content. Current AIGC models primarily focus on content quality within a centralized framework, resulting in a high service delay and negative user experiences. However, not only does the workload of an AIGC task depend on the AIGC model's complexity rather than the amount of data, but the large model and its multi-layer encoder structure also result in a huge demand for computational and memory resources. These unique characteristics pose new challenges in its modeling, deployment, and scheduling at edge networks. Thus, we model an offloading problem among edges for providing real AIGC services and propose LAD-TS, a novel Latent Action Diffusion-based Task Scheduling method that orchestrates multiple edge servers for expedited AIGC services. The LAD-TS generates a near-optimal offloading decision by leveraging the diffusion model's conditional generation capability and the reinforcement learning's environment interaction ability, thereby minimizing the service delays under multiple resource constraints. Meanwhile, a latent action diffusion strategy is designed to guide decision generation by utilizing historical action probability, enabling rapid achievement of near-optimal decisions. Furthermore, we develop DEdgeAI, a prototype edge system with a refined AIGC model deployment to implement and evaluate our LAD-TS method. DEdgeAI provides a real AIGC service for users, demonstrating up to 29.18% shorter service delays than the current five representative AIGC platforms. We release our open-source code at https://github.com/ChangfuXu/DEdgeAI/.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "61",
        "title": "ICM-Assistant: Instruction-tuning Multimodal Large Language Models for Rule-based Explainable Image Content Moderation",
        "author": [
            "Mengyang Wu",
            "Yuzhi Zhao",
            "Jialun Cao",
            "Mingjie Xu",
            "Zhongming Jiang",
            "Xuehui Wang",
            "Qinbin Li",
            "Guangneng Hu",
            "Shengchao Qin",
            "Chi-Wing Fu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18216",
        "abstract": "Controversial contents largely inundate the Internet, infringing various cultural norms and child protection standards. Traditional Image Content Moderation (ICM) models fall short in producing precise moderation decisions for diverse standards, while recent multimodal large language models (MLLMs), when adopted to general rule-based ICM, often produce classification and explanation results that are inconsistent with human moderators. Aiming at flexible, explainable, and accurate ICM, we design a novel rule-based dataset generation pipeline, decomposing concise human-defined rules and leveraging well-designed multi-stage prompts to enrich short explicit image annotations. Our ICM-Instruct dataset includes detailed moderation explanation and moderation Q-A pairs. Built upon it, we create our ICM-Assistant model in the framework of rule-based ICM, making it readily applicable in real practice. Our ICM-Assistant model demonstrates exceptional performance and flexibility. Specifically, it significantly outperforms existing approaches on various sources, improving both the moderation classification (36.8\\% on average) and moderation explanation quality (26.6\\% on average) consistently over existing MLLMs. Code/Data is available at https://github.com/zhaoyuzhi/ICM-Assistant.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "62",
        "title": "U-Mamba-Net: A highly efficient Mamba-based U-net style network for noisy and reverberant speech separation",
        "author": [
            "Shaoxiang Dang",
            "Tetsuya Matsumoto",
            "Yoshinori Takeuchi",
            "Hiroaki Kudo"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18217",
        "abstract": "The topic of speech separation involves separating mixed speech with multiple overlapping speakers into several streams, with each stream containing speech from only one speaker. Many highly effective models have emerged and proliferated rapidly over time. However, the size and computational load of these models have also increased accordingly. This is a disaster for the community, as researchers need more time and computational resources to reproduce and compare existing models. In this paper, we propose U-mamba-net: a lightweight Mamba-based U-style model for speech separation in complex environments. Mamba is a state space sequence model that incorporates feature selection capabilities. U-style network is a fully convolutional neural network whose symmetric contracting and expansive paths are able to learn multi-resolution features. In our work, Mamba serves as a feature filter, alternating with U-Net. We test the proposed model on Libri2mix. The results show that U-Mamba-Net achieves improved performance with quite low computational cost.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "63",
        "title": "Expand VSR Benchmark for VLLM to Expertize in Spatial Rules",
        "author": [
            "Peijin Xie",
            "Lin Sun",
            "Bingquan Liu",
            "Dexin Wang",
            "Xiangzheng Zhang",
            "Chengjie Sun",
            "Jiajia Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18224",
        "abstract": "Distinguishing spatial relations is a basic part of human cognition which requires fine-grained perception on cross-instance. Although benchmarks like MME, MMBench and SEED comprehensively have evaluated various capabilities which already include visual spatial reasoning(VSR). There is still a lack of sufficient quantity and quality evaluation and optimization datasets for Vision Large Language Models(VLLMs) specifically targeting visual positional reasoning. To handle this, we first diagnosed current VLLMs with the VSR dataset and proposed a unified test set. We found current VLLMs to exhibit a contradiction of over-sensitivity to language instructions and under-sensitivity to visual positional information. By expanding the original benchmark from two aspects of tunning data and model structure, we mitigated this phenomenon. To our knowledge, we expanded spatially positioned image data controllably using diffusion models for the first time and integrated original visual encoding(CLIP) with other 3 powerful visual encoders(SigLIP, SAM and DINO). After conducting combination experiments on scaling data and models, we obtained a VLLM VSR Expert(VSRE) that not only generalizes better to different instructions but also accurately distinguishes differences in visual positional information. VSRE achieved over a 27\\% increase in accuracy on the VSR test set. It becomes a performant VLLM on the position reasoning of both the VSR dataset and relevant subsets of other evaluation benchmarks. We open-sourced the expanded model with data and Appendix at \\url{https://github.com/peijin360/vsre} and hope it will accelerate advancements in VLLM on VSR learning.",
        "tags": [
            "CLIP",
            "Diffusion",
            "Large Language Models",
            "SAM"
        ]
    },
    {
        "id": "64",
        "title": "Combining GPT and Code-Based Similarity Checking for Effective Smart Contract Vulnerability Detection",
        "author": [
            "Jango Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18225",
        "abstract": "With the rapid growth of blockchain technology, smart contracts are now crucial to Decentralized Finance (DeFi) applications. Effective vulnerability detection is vital for securing these contracts against hackers and enhancing the accuracy and efficiency of security audits. In this paper, we present SimilarGPT, a unique vulnerability identification tool for smart contract, which combines Generative Pretrained Transformer (GPT) models with Code-based similarity checking methods. The main concept of the SimilarGPT tool is to measure the similarity between the code under inspection and the secure code from third-party libraries. To identify potential vulnerabilities, we connect the semantic understanding capability of large language models (LLMs) with Code-based similarity checking techniques. We propose optimizing the detection sequence using topological ordering to enhance logical coherence and reduce false positives during detection. Through analysis of code reuse patterns in smart contracts, we compile and process extensive third-party library code to establish a comprehensive reference codebase. Then, we utilize LLM to conduct an indepth analysis of similar codes to identify and explain potential vulnerabilities in the codes. The experimental findings indicate that SimilarGPT excels in detecting vulnerabilities in smart contracts, particularly in missed detections and minimizing false positives.",
        "tags": [
            "Detection",
            "GPT",
            "LLMs",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "65",
        "title": "Sch\\\"odinger Bridge Type Diffusion Models as an Extension of Variational Autoencoders",
        "author": [
            "Kentaro Kaba",
            "Reo Shimizu",
            "Masayuki Ohzeki",
            "Yuki Sughiyama"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18237",
        "abstract": "Generative diffusion models use time-forward and backward stochastic differential equations to connect the data and prior distributions. While conventional diffusion models (e.g., score-based models) only learn the backward process, more flexible frameworks have been proposed to also learn the forward process by employing the Schrödinger bridge (SB). However, due to the complexity of the mathematical structure behind SB-type models, we can not easily give an intuitive understanding of their objective function. In this work, we propose a unified framework to construct diffusion models by reinterpreting the SB-type models as an extension of variational autoencoders. In this context, the data processing inequality plays a crucial role. As a result, we find that the objective function consists of the prior loss and drift matching parts.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "66",
        "title": "Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study",
        "author": [
            "Xuefeng Jiang",
            "Lvhua Wu",
            "Sheng Sun",
            "Jia Li",
            "Jingjing Xue",
            "Yuwei Wang",
            "Tingting Wu",
            "Min Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18260",
        "abstract": "Code vulnerability detection (CVD) is essential for addressing and preventing system security issues, playing a crucial role in ensuring software security. Previous learning-based vulnerability detection methods rely on either fine-tuning medium-size sequence models or training smaller neural networks from scratch. Recent advancements in large pre-trained language models (LLMs) have showcased remarkable capabilities in various code intelligence tasks including code understanding and generation. However, the effectiveness of LLMs in detecting code vulnerabilities is largely under-explored. This work aims to investigate the gap by fine-tuning LLMs for the CVD task, involving four widely-used open-source LLMs. We also implement other five previous graph-based or medium-size sequence models for comparison. Experiments are conducted on five commonly-used CVD datasets, including both the part of short samples and long samples. In addition, we conduct quantitative experiments to investigate the class imbalance issue and the model's performance on samples of different lengths, which are rarely studied in previous works. To better facilitate communities, we open-source all codes and resources of this study in https://github.com/SakiRinn/LLM4CVD and https://huggingface.co/datasets/xuefen/VulResource.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "67",
        "title": "Annotating References to Mythological Entities in French Literature",
        "author": [
            "Thierry Poibeau"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18270",
        "abstract": "In this paper, we explore the relevance of large language models (LLMs) for annotating references to Roman and Greek mythological entities in modern and contemporary French literature. We present an annotation scheme and demonstrate that recent LLMs can be directly applied to follow this scheme effectively, although not without occasionally making significant analytical errors. Additionally, we show that LLMs (and, more specifically, ChatGPT) are capable of offering interpretative insights into the use of mythological references by literary authors. However, we also find that LLMs struggle to accurately identify relevant passages in novels (when used as an information retrieval engine), often hallucinating and generating fabricated examples-an issue that raises significant ethical concerns. Nonetheless, when used carefully, LLMs remain valuable tools for performing annotations with high accuracy, especially for tasks that would be difficult to annotate comprehensively on a large scale through manual methods alone.",
        "tags": [
            "ChatGPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "68",
        "title": "Sampling Bag of Views for Open-Vocabulary Object Detection",
        "author": [
            "Hojun Choi",
            "Junsuk Choe",
            "Hyunjung Shim"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18273",
        "abstract": "Existing open-vocabulary object detection (OVD) develops methods for testing unseen categories by aligning object region embeddings with corresponding VLM features. A recent study leverages the idea that VLMs implicitly learn compositional structures of semantic concepts within the image. Instead of using an individual region embedding, it utilizes a bag of region embeddings as a new representation to incorporate compositional structures into the OVD task. However, this approach often fails to capture the contextual concepts of each region, leading to noisy compositional structures. This results in only marginal performance improvements and reduced efficiency. To address this, we propose a novel concept-based alignment method that samples a more powerful and efficient compositional structure. Our approach groups contextually related ``concepts'' into a bag and adjusts the scale of concepts within the bag for more effective embedding alignment. Combined with Faster R-CNN, our method achieves improvements of 2.6 box AP50 and 0.5 mask AP over prior work on novel categories in the open-vocabulary COCO and LVIS benchmarks. Furthermore, our method reduces CLIP computation in FLOPs by 80.3% compared to previous research, significantly enhancing efficiency. Experimental results demonstrate that the proposed method outperforms previous state-of-the-art models on the OVD datasets.",
        "tags": [
            "CLIP",
            "Detection"
        ]
    },
    {
        "id": "69",
        "title": "GenAI Content Detection Task 2: AI vs. Human -- Academic Essay Authenticity Challenge",
        "author": [
            "Shammur Absar Chowdhury",
            "Hind Almerekhi",
            "Mucahid Kutlu",
            "Kaan Efe Keles",
            "Fatema Ahmad",
            "Tasnim Mohiuddin",
            "George Mikros",
            "Firoj Alam"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18274",
        "abstract": "This paper presents a comprehensive overview of the first edition of the Academic Essay Authenticity Challenge, organized as part of the GenAI Content Detection shared tasks collocated with COLING 2025. This challenge focuses on detecting machine-generated vs. human-authored essays for academic purposes. The task is defined as follows: \"Given an essay, identify whether it is generated by a machine or authored by a human.'' The challenge involves two languages: English and Arabic. During the evaluation phase, 25 teams submitted systems for English and 21 teams for Arabic, reflecting substantial interest in the task. Finally, seven teams submitted system description papers. The majority of submissions utilized fine-tuned transformer-based models, with one team employing Large Language Models (LLMs) such as Llama 2 and Llama 3. This paper outlines the task formulation, details the dataset construction process, and explains the evaluation framework. Additionally, we present a summary of the approaches adopted by participating teams. Nearly all submitted systems outperformed the n-gram-based baseline, with the top-performing systems achieving F1 scores exceeding 0.98 for both languages, indicating significant progress in the detection of machine-generated text.",
        "tags": [
            "Detection",
            "LLMs",
            "LLaMA",
            "Large Language Models",
            "Transformer"
        ]
    },
    {
        "id": "70",
        "title": "Improving Multi-Step Reasoning Abilities of Large Language Models with Direct Advantage Policy Optimization",
        "author": [
            "Jiacai Liu",
            "Chaojie Wang",
            "Chris Yuhao Liu",
            "Liang Zeng",
            "Rui Yan",
            "Yiwen Sun",
            "Yang Liu",
            "Yahui Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18279",
        "abstract": "The role of reinforcement learning (RL) in enhancing the reasoning of large language models (LLMs) is becoming increasingly significant. Despite the success of RL in many scenarios, there are still many challenges in improving the reasoning of LLMs. One challenge is the sparse reward, which makes optimization difficult for RL and necessitates a large amount of data samples. Another challenge stems from the inherent instability of RL, particularly when using Actor-Critic (AC) methods to derive optimal policies, which often leads to unstable training processes. To address these issues, we introduce Direct Advantage Policy Optimization (DAPO), an novel step-level offline RL algorithm. Unlike standard alignment that rely solely outcome rewards to optimize policies (such as DPO), DAPO employs a critic function to predict the reasoning accuracy at each step, thereby generating dense signals to refine the generation strategy. Additionally, the Actor and Critic components in DAPO are trained independently, avoiding the co-training instability observed in standard AC algorithms like PPO. We train DAPO on mathematical and code query datasets and then evaluate its performance on multiple benchmarks. Our results show that DAPO can effectively enhance the mathematical and code capabilities on both SFT models and RL models, demonstrating the effectiveness of DAPO.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RL"
        ]
    },
    {
        "id": "71",
        "title": "GDM4MMIMO: Generative Diffusion Models for Massive MIMO Communications",
        "author": [
            "Zhenzhou Jin",
            "Li You",
            "Huibin Zhou",
            "Yuanshuo Wang",
            "Xiaofeng Liu",
            "Xinrui Gong",
            "Xiqi Gao",
            "Derrick Wing Kwan Ng",
            "Xiang-Gen Xia"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18281",
        "abstract": "Massive multiple-input multiple-output (MIMO) offers significant advantages in spectral and energy efficiencies, positioning it as a cornerstone technology of fifth-generation (5G) wireless communication systems and a promising solution for the burgeoning data demands anticipated in sixth-generation (6G) networks. In recent years, with the continuous advancement of artificial intelligence (AI), a multitude of task-oriented generative foundation models (GFMs) have emerged, achieving remarkable performance in various fields such as computer vision (CV), natural language processing (NLP), and autonomous driving. As a pioneering force, these models are driving the paradigm shift in AI towards generative AI (GenAI). Among them, the generative diffusion model (GDM), as one of state-of-the-art families of generative models, demonstrates an exceptional capability to learn implicit prior knowledge and robust generalization capabilities, thereby enhancing its versatility and effectiveness across diverse applications. In this paper, we delve into the potential applications of GDM in massive MIMO communications. Specifically, we first provide an overview of massive MIMO communication, the framework of GFMs, and the working mechanism of GDM. Following this, we discuss recent research advancements in the field and present a case study of near-field channel estimation based on GDM, demonstrating its promising potential for facilitating efficient ultra-dimensional channel statement information (CSI) acquisition in the context of massive MIMO communications. Finally, we highlight several pressing challenges in future mobile communications and identify promising research directions surrounding GDM.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "72",
        "title": "Towards understanding how attention mechanism works in deep learning",
        "author": [
            "Tianyu Ruan",
            "Shihua Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18288",
        "abstract": "Attention mechanism has been extensively integrated within mainstream neural network architectures, such as Transformers and graph attention networks. Yet, its underlying working principles remain somewhat elusive. What is its essence? Are there any connections between it and traditional machine learning algorithms? In this study, we inspect the process of computing similarity using classic metrics and vector space properties in manifold learning, clustering, and supervised learning. We identify the key characteristics of similarity computation and information propagation in these methods and demonstrate that the self-attention mechanism in deep learning adheres to the same principles but operates more flexibly and adaptively. We decompose the self-attention mechanism into a learnable pseudo-metric function and an information propagation process based on similarity computation. We prove that the self-attention mechanism converges to a drift-diffusion process through continuous modeling provided the pseudo-metric is a transformation of a metric and certain reasonable assumptions hold. This equation could be transformed into a heat equation under a new metric. In addition, we give a first-order analysis of attention mechanism with a general pseudo-metric function. This study aids in understanding the effects and principle of attention mechanism through physical intuition. Finally, we propose a modified attention mechanism called metric-attention by leveraging the concept of metric learning to facilitate the ability to learn desired metrics more effectively. Experimental results demonstrate that it outperforms self-attention regarding training efficiency, accuracy, and robustness.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "73",
        "title": "DeepCRCEval: Revisiting the Evaluation of Code Review Comment Generation",
        "author": [
            "Junyi Lu",
            "Xiaojia Li",
            "Zihan Hua",
            "Lei Yu",
            "Shiqi Cheng",
            "Li Yang",
            "Fengjun Zhang",
            "Chun Zuo"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18291",
        "abstract": "Code review is a vital but demanding aspect of software development, generating significant interest in automating review comments. Traditional evaluation methods for these comments, primarily based on text similarity, face two major challenges: inconsistent reliability of human-authored comments in open-source projects and the weak correlation of text similarity with objectives like enhancing code quality and detecting defects.\nThis study empirically analyzes benchmark comments using a novel set of criteria informed by prior research and developer interviews. We then similarly revisit the evaluation of existing methodologies. Our evaluation framework, DeepCRCEval, integrates human evaluators and Large Language Models (LLMs) for a comprehensive reassessment of current techniques based on the criteria set. Besides, we also introduce an innovative and efficient baseline, LLM-Reviewer, leveraging the few-shot learning capabilities of LLMs for a target-oriented comparison.\nOur research highlights the limitations of text similarity metrics, finding that less than 10% of benchmark comments are high quality for automation. In contrast, DeepCRCEval effectively distinguishes between high and low-quality comments, proving to be a more reliable evaluation mechanism. Incorporating LLM evaluators into DeepCRCEval significantly boosts efficiency, reducing time and cost by 88.78% and 90.32%, respectively. Furthermore, LLM-Reviewer demonstrates significant potential of focusing task real targets in comment generation.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "74",
        "title": "Pirates of the RAG: Adaptively Attacking LLMs to Leak Knowledge Bases",
        "author": [
            "Christian Di Maio",
            "Cristian Cosci",
            "Marco Maggini",
            "Valentina Poggioni",
            "Stefano Melacci"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18295",
        "abstract": "The growing ubiquity of Retrieval-Augmented Generation (RAG) systems in several real-world services triggers severe concerns about their security. A RAG system improves the generative capabilities of a Large Language Models (LLM) by a retrieval mechanism which operates on a private knowledge base, whose unintended exposure could lead to severe consequences, including breaches of private and sensitive information. This paper presents a black-box attack to force a RAG system to leak its private knowledge base which, differently from existing approaches, is adaptive and automatic. A relevance-based mechanism and an attacker-side open-source LLM favor the generation of effective queries to leak most of the (hidden) knowledge base. Extensive experimentation proves the quality of the proposed algorithm in different RAG pipelines and domains, comparing to very recent related approaches, which turn out to be either not fully black-box, not adaptive, or not based on open-source models. The findings from our study remark the urgent need for more robust privacy safeguards in the design and deployment of RAG systems.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "RAG"
        ]
    },
    {
        "id": "75",
        "title": "M-Ped: Multi-Prompt Ensemble Decoding for Large Language Models",
        "author": [
            "Jiaxin Guo",
            "Daimeng Wei",
            "Yuanchang Luo",
            "Shimin Tao",
            "Hengchao Shang",
            "Zongyao Li",
            "Shaojun Li",
            "Jinlong Yang",
            "Zhanglin Wu",
            "Zhiqiang Rao",
            "Hao Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18299",
        "abstract": "With the widespread application of Large Language Models (LLMs) in the field of Natural Language Processing (NLP), enhancing their performance has become a research hotspot. This paper presents a novel multi-prompt ensemble decoding approach designed to bolster the generation quality of LLMs by leveraging the aggregation of outcomes from multiple prompts. Given a unique input $X$, we submit $n$ variations of prompts with $X$ to LLMs in batch mode to decode and derive probability distributions. For each token prediction, we calculate the ensemble probability by averaging the $n$ probability distributions within the batch, utilizing this aggregated probability to generate the token. This technique is dubbed Inner-Batch Ensemble. To facilitate efficient batch inference, we implement a Left-Padding strategy to maintain uniform input lengths across the n prompts. Through extensive experimentation on diverse NLP tasks, including machine translation, code generation, and text simplification, we demonstrate the efficacy of our method in enhancing LLM performance. The results show substantial improvements in BLEU scores, pass@$k$ rates, and LENS metrics over conventional methods.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "76",
        "title": "FameBias: Embedding Manipulation Bias Attack in Text-to-Image Models",
        "author": [
            "Jaechul Roh",
            "Andrew Yuan",
            "Jinsong Mao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18302",
        "abstract": "Text-to-Image (T2I) diffusion models have rapidly advanced, enabling the generation of high-quality images that align closely with textual descriptions. However, this progress has also raised concerns about their misuse for propaganda and other malicious activities. Recent studies reveal that attackers can embed biases into these models through simple fine-tuning, causing them to generate targeted imagery when triggered by specific phrases. This underscores the potential for T2I models to act as tools for disseminating propaganda, producing images aligned with an attacker's objective for end-users.\nBuilding on this concept, we introduce FameBias, a T2I biasing attack that manipulates the embeddings of input prompts to generate images featuring specific public figures. Unlike prior methods, Famebias operates solely on the input embedding vectors without requiring additional model training. We evaluate FameBias comprehensively using Stable Diffusion V2, generating a large corpus of images based on various trigger nouns and target public figures. Our experiments demonstrate that FameBias achieves a high attack success rate while preserving the semantic context of the original prompts across multiple trigger-target pairs.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "77",
        "title": "FloNa: Floor Plan Guided Embodied Visual Navigation",
        "author": [
            "Jiaxin Li",
            "Weiqi Huang",
            "Zan Wang",
            "Wei Liang",
            "Huijun Di",
            "Feng Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18335",
        "abstract": "Humans naturally rely on floor plans to navigate in unfamiliar environments, as they are readily available, reliable, and provide rich geometrical guidance. However, existing visual navigation settings overlook this valuable prior knowledge, leading to limited efficiency and accuracy. To eliminate this gap, we introduce a novel navigation task: Floor Plan Visual Navigation (FloNa), the first attempt to incorporate floor plan into embodied visual navigation. While the floor plan offers significant advantages, two key challenges emerge: (1) handling the spatial inconsistency between the floor plan and the actual scene layout for collision-free navigation, and (2) aligning observed images with the floor plan sketch despite their distinct modalities. To address these challenges, we propose FloDiff, a novel diffusion policy framework incorporating a localization module to facilitate alignment between the current observation and the floor plan. We further collect $20k$ navigation episodes across $117$ scenes in the iGibson simulator to support the training and evaluation. Extensive experiments demonstrate the effectiveness and efficiency of our framework in unfamiliar scenes using floor plan knowledge. Project website: https://gauleejx.github.io/flona/.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "78",
        "title": "Multi-Agents Based on Large Language Models for Knowledge-based Visual Question Answering",
        "author": [
            "Zhongjian Hu",
            "Peng Yang",
            "Bing Li",
            "Zhenqi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18351",
        "abstract": "Large Language Models (LLMs) have achieved impressive results in knowledge-based Visual Question Answering (VQA). However existing methods still have challenges: the inability to use external tools autonomously, and the inability to work in teams. Humans tend to know whether they need to use external tools when they encounter a new question, e.g., they tend to be able to give a direct answer to a familiar question, whereas they tend to use tools such as search engines when they encounter an unfamiliar question. In addition, humans also tend to collaborate and discuss with others to get better answers. Inspired by this, we propose the multi-agent voting framework. We design three LLM-based agents that simulate different levels of staff in a team, and assign the available tools according to the levels. Each agent provides the corresponding answer, and finally all the answers provided by the agents are voted to get the final answer. Experiments on OK-VQA and A-OKVQA show that our approach outperforms other baselines by 2.2 and 1.0, respectively.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "79",
        "title": "Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset",
        "author": [
            "Jiarui Liu",
            "Iman Ouzzani",
            "Wenkai Li",
            "Lechen Zhang",
            "Tianyue Ou",
            "Houda Bouamor",
            "Zhijing Jin",
            "Mona Diab"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18367",
        "abstract": "The field of machine translation has achieved significant advancements, yet domain-specific terminology translation, particularly in AI, remains challenging. We introduced GIST, a large-scale multilingual AI terminology dataset containing 5K terms extracted from top AI conference papers spanning 2000 to 2023. The terms were translated into Arabic, Chinese, French, Japanese, and Russian using a hybrid framework that combines LLMs for extraction with human expertise for translation. The dataset's quality was benchmarked against existing resources, demonstrating superior translation accuracy through crowdsourced evaluation. GIST was integrated into translation workflows using post-translation refinement methods that required no retraining, where LLM prompting consistently improved BLEU and COMET scores. A web demonstration on the ACL Anthology platform highlights its practical application, showcasing improved accessibility for non-English speakers. This work aims to address critical gaps in AI terminology resources and fosters global inclusivity and collaboration in AI research.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "80",
        "title": "Defining and Detecting the Defects of the Large Language Model-based Autonomous Agents",
        "author": [
            "Kaiwen Ning",
            "Jiachi Chen",
            "Jingwen Zhang",
            "Wei Lia",
            "Zexu Wang",
            "Yuming Feng",
            "Weizhe Zhang",
            "Zibin Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18371",
        "abstract": "AI agents are systems capable of perceiving their environment, autonomously planning and executing tasks. Recent advancements in LLM have introduced a transformative paradigm for AI agents, enabling them to interact with external resources and tools through prompts. In such agents, the workflow integrates developer-written code, which manages framework construction and logic control, with LLM-generated natural language that enhances dynamic decision-making and interaction. However, discrepancies between developer-implemented logic and the dynamically generated content of LLMs in terms of behavior and expected outcomes can lead to defects, such as tool invocation failures and task execution errors. These issues introduce specific risks, leading to various defects in LLM-based AI Agents, such as service interruptions. Despite the importance of these issues, there is a lack of systematic work that focuses on analyzing LLM-based AI Agents to uncover defects in their code. In this paper, we present the first study focused on identifying and detecting defects in LLM Agents. We collected and analyzed 6,854 relevant posts from StackOverflow to define 8 types of agent defects. For each type, we provided detailed descriptions with an example. Then, we designed a static analysis tool, named Agentable, to detect the defects. Agentable leverages Code Property Graphs and LLMs to analyze Agent workflows by efficiently identifying specific code patterns and analyzing natural language descriptions. To evaluate Agentable, we constructed two datasets: AgentSet, consists of 84 real-world Agents, and AgentTest, which contains 78 Agents specifically designed to include various types of defects. Our results show that Agentable achieved an overall accuracy of 88.79% and a recall rate of 91.03%. Furthermore, our analysis reveals the 889 defects of the AgentSet, highlighting the prevalence of these defects.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "81",
        "title": "ChaI-TeA: A Benchmark for Evaluating Autocompletion of Interactions with LLM-based Chatbots",
        "author": [
            "Shani Goren",
            "Oren Kalinsky",
            "Tomer Stav",
            "Yuri Rapoport",
            "Yaron Fairstein",
            "Ram Yazdy",
            "Nachshon Cohen",
            "Alexander Libov",
            "Guy Kushilevitz"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18377",
        "abstract": "The rise of LLMs has deflected a growing portion of human-computer interactions towards LLM-based chatbots. The remarkable abilities of these models allow users to interact using long, diverse natural language text covering a wide range of topics and styles. Phrasing these messages is a time and effort consuming task, calling for an autocomplete solution to assist users. We introduce the task of chatbot interaction autocomplete. We present ChaI-TeA: CHat InTEraction Autocomplete; An autcomplete evaluation framework for LLM-based chatbot interactions. The framework includes a formal definition of the task, coupled with suitable datasets and metrics. We use the framework to evaluate After formally defining the task along with suitable datasets and metrics, we test 9 models on the defined auto completion task, finding that while current off-the-shelf models perform fairly, there is still much room for improvement, mainly in ranking of the generated suggestions. We provide insights for practitioners working on this task and open new research directions for researchers in the field. We release our framework to serve as a foundation for future research.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "82",
        "title": "RDPM: Solve Diffusion Probabilistic Models via Recurrent Token Prediction",
        "author": [
            "Wu Xiaoping",
            "Hu Jie",
            "Wei Xiaoming"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18390",
        "abstract": "Diffusion Probabilistic Models (DPMs) have emerged as the de facto approach for high-fidelity image synthesis, operating diffusion processes on continuous VAE latent, which significantly differ from the text generation methods employed by Large Language Models (LLMs). In this paper, we introduce a novel generative framework, the Recurrent Diffusion Probabilistic Model (RDPM), which enhances the diffusion process through a recurrent token prediction mechanism, thereby pioneering the field of Discrete Diffusion. By progressively introducing Gaussian noise into the latent representations of images and encoding them into vector-quantized tokens in a recurrent manner, RDPM facilitates a unique diffusion process on discrete-value domains. This process iteratively predicts the token codes for subsequent timesteps, transforming the initial standard Gaussian noise into the source data distribution, aligning with GPT-style models in terms of the loss function. RDPM demonstrates superior performance while benefiting from the speed advantage of requiring only a few inference steps. This model not only leverages the diffusion process to ensure high-quality generation but also converts continuous signals into a series of high-fidelity discrete tokens, thereby maintaining a unified optimization strategy with other discrete tokens, such as text. We anticipate that this work will contribute to the development of a unified model for multimodal generation, specifically by integrating continuous signal domains such as images, videos, and audio with text. We will release the code and model weights to the open-source community.",
        "tags": [
            "Diffusion",
            "GPT",
            "LLMs",
            "Large Language Models",
            "VAE"
        ]
    },
    {
        "id": "83",
        "title": "Extract Free Dense Misalignment from CLIP",
        "author": [
            "JeongYeon Nam",
            "Jinbae Im",
            "Wonjae Kim",
            "Taeho Kil"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18404",
        "abstract": "Recent vision-language foundation models still frequently produce outputs misaligned with their inputs, evidenced by object hallucination in captioning and prompt misalignment in the text-to-image generation model. Recent studies have explored methods for identifying misaligned elements, aiming not only to enhance interpretability but also to improve model performance. However, current approaches primarily rely on large foundation models in a zero-shot manner or fine-tuned models with human annotations, which limits scalability due to significant computational costs. This work proposes a novel approach, dubbed CLIP4DM, for detecting dense misalignments from pre-trained CLIP, specifically focusing on pinpointing misaligned words between image and text. We carefully revamp the gradient-based attribution computation method, enabling negative gradient of individual text tokens to indicate misalignment. We also propose F-CLIPScore, which aggregates misaligned attributions with a global alignment score. We evaluate our method on various dense misalignment detection benchmarks, covering various image and text domains and misalignment types. Our method demonstrates state-of-the-art performance among zero-shot models and competitive performance with fine-tuned models while maintaining superior efficiency. Our qualitative examples show that our method has a unique strength to detect entity-level objects, intangible objects, and attributes that can not be easily detected for existing works. We conduct ablation studies and analyses to highlight the strengths and limitations of our approach. Our code is publicly available at https://github.com/naver-ai/CLIP4DM.",
        "tags": [
            "CLIP",
            "Detection",
            "Text-to-Image"
        ]
    },
    {
        "id": "84",
        "title": "Multilingual Mathematical Reasoning: Advancing Open-Source LLMs in Hindi and English",
        "author": [
            "Avinash Anand",
            "Kritarth Prasad",
            "Chhavi Kirtani",
            "Ashwin R Nair",
            "Manvendra Kumar Nema",
            "Raj Jaiswal",
            "Rajiv Ratn Shah"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18415",
        "abstract": "Large Language Models (LLMs) excel in linguistic tasks but struggle with mathematical reasoning, particularly in non English languages like Hindi. This research aims to enhance the mathematical reasoning skills of smaller, resource efficient open-source LLMs in both Hindi and English. We evaluate models like OpenHathi 7B, LLaMA-2 7B, WizardMath 7B, Mistral 7B, LLeMMa 7B, MAmmoTH 7B, Gemini Pro, and GPT-4 using zero-shot, few-shot chain-of-thought (CoT) methods, and supervised fine-tuning. Our approach incorporates curriculum learning, progressively training models on increasingly difficult problems, a novel Decomposition Strategy to simplify complex arithmetic operations, and a Structured Solution Design that divides solutions into phases. Our experiments result in notable performance enhancements. WizardMath 7B exceeds Gemini's accuracy on English datasets by +6% and matches Gemini's performance on Hindi datasets. Adopting a bilingual approach that combines English and Hindi samples achieves results comparable to individual language models, demonstrating the capability to learn mathematical reasoning in both languages. This research highlights the potential for improving mathematical reasoning in open-source LLMs.",
        "tags": [
            "GPT",
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "85",
        "title": "Fashionability-Enhancing Outfit Image Editing with Conditional Diffusion Models",
        "author": [
            "Qice Qin",
            "Yuki Hirakawa",
            "Ryotaro Shimizu",
            "Takuya Furusawa",
            "Edgar Simo-Serra"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18421",
        "abstract": "Image generation in the fashion domain has predominantly focused on preserving body characteristics or following input prompts, but little attention has been paid to improving the inherent fashionability of the output images. This paper presents a novel diffusion model-based approach that generates fashion images with improved fashionability while maintaining control over key attributes. Key components of our method include: 1) fashionability enhancement, which ensures that the generated images are more fashionable than the input; 2) preservation of body characteristics, encouraging the generated images to maintain the original shape and proportions of the input; and 3) automatic fashion optimization, which does not rely on manual input or external prompts. We also employ two methods to collect training data for guidance while generating and evaluating the images. In particular, we rate outfit images using fashionability scores annotated by multiple fashion experts through OpenSkill-based and five critical aspect-based pairwise comparisons. These methods provide complementary perspectives for assessing and improving the fashionability of the generated images. The experimental results show that our approach outperforms the baseline Fashion++ in generating images with superior fashionability, demonstrating its effectiveness in producing more stylish and appealing fashion images.",
        "tags": [
            "Diffusion",
            "Image Editing"
        ]
    },
    {
        "id": "86",
        "title": "GUI Testing Arena: A Unified Benchmark for Advancing Autonomous GUI Testing Agent",
        "author": [
            "Kangjia Zhao",
            "Jiahui Song",
            "Leigang Sha",
            "Haozhan Shen",
            "Zhi Chen",
            "Tiancheng Zhao",
            "Xiubo Liang",
            "Jianwei Yin"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18426",
        "abstract": "Nowadays, research on GUI agents is a hot topic in the AI community. However, current research focuses on GUI task automation, limiting the scope of applications in various GUI scenarios. In this paper, we propose a formalized and comprehensive environment to evaluate the entire process of automated GUI Testing (GTArena), offering a fair, standardized environment for consistent operation of diverse multimodal large language models. We divide the testing process into three key subtasks: test intention generation, test task execution, and GUI defect detection, and construct a benchmark dataset based on these to conduct a comprehensive evaluation. It evaluates the performance of different models using three data types: real mobile applications, mobile applications with artificially injected defects, and synthetic data, thoroughly assessing their capabilities in this relevant task. Additionally, we propose a method that helps researchers explore the correlation between the performance of multimodal language large models in specific scenarios and their general capabilities in standard benchmark tests. Experimental results indicate that even the most advanced models struggle to perform well across all sub-tasks of automated GUI Testing, highlighting a significant gap between the current capabilities of Autonomous GUI Testing and its practical, real-world applicability. This gap provides guidance for the future direction of GUI Agent development. Our code is available at https://github.com/ZJU-ACES-ISE/ChatUITest.",
        "tags": [
            "Detection",
            "Large Language Models"
        ]
    },
    {
        "id": "87",
        "title": "Unlocking the Potential of Multiple BERT Models for Bangla Question Answering in NCTB Textbooks",
        "author": [
            "Abdullah Khondoker",
            "Enam Ahmed Taufik",
            "Md Iftekhar Islam Tashik",
            "S M Ishtiak mahmud",
            "Antara Firoz Parsa"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18440",
        "abstract": "Evaluating text comprehension in educational settings is critical for understanding student performance and improving curricular effectiveness. This study investigates the capability of state-of-the-art language models-RoBERTa Base, Bangla-BERT, and BERT Base-in automatically assessing Bangla passage-based question-answering from the National Curriculum and Textbook Board (NCTB) textbooks for classes 6-10. A dataset of approximately 3,000 Bangla passage-based question-answering instances was compiled, and the models were evaluated using F1 Score and Exact Match (EM) metrics across various hyperparameter configurations. Our findings revealed that Bangla-BERT consistently outperformed the other models, achieving the highest F1 (0.75) and EM (0.53) scores, particularly with smaller batch sizes, the inclusion of stop words, and a moderate learning rate. In contrast, RoBERTa Base demonstrated the weakest performance, with the lowest F1 (0.19) and EM (0.27) scores under certain configurations. The results underscore the importance of fine-tuning hyperparameters for optimizing model performance and highlight the potential of machine learning models in evaluating text comprehension in educational contexts. However, limitations such as dataset size, spelling inconsistencies, and computational constraints emphasize the need for further research to enhance the robustness and applicability of these models. This study lays the groundwork for the future development of automated evaluation systems in educational institutions, providing critical insights into model performance in the context of Bangla text comprehension.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "88",
        "title": "Is Large Language Model Good at Triple Set Prediction? An Empirical Study",
        "author": [
            "Yuan Yuan",
            "Yajing Xu",
            "Wen Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18443",
        "abstract": "The core of the Knowledge Graph Completion (KGC) task is to predict and complete the missing relations or nodes in a KG. Common KGC tasks are mostly about inferring unknown elements with one or two elements being known in a triple. In comparison, the Triple Set Prediction (TSP) task is a more realistic knowledge graph completion task. It aims to predict all elements of unknown triples based on the information from known triples. In recent years, large language models (LLMs) have exhibited significant advancements in language comprehension, demonstrating considerable potential for KGC tasks. However, the potential of LLM on the TSP task has not yet to be investigated. Thus in this paper we proposed a new framework to explore the strengths and limitations of LLM in the TSP task. Specifically, the framework consists of LLM-based rule mining and LLM-based triple set prediction. The relation list of KG embedded within rich semantic information is first leveraged to prompt LLM in the generation of rules. This process is both efficient and independent of statistical information, making it easier to mine effective and realistic rules. For each subgraph, the specified rule is applied in conjunction with the relevant triples within that subgraph to guide the LLM in predicting the missing triples. Subsequently, the predictions from all subgraphs are consolidated to derive the complete set of predicted triples on KG. Finally, the method is evaluated on the relatively complete CFamily dataset. The experimental results indicate that when LLMs are required to adhere to a large amount of factual knowledge to predict missing triples, significant hallucinations occurs, leading to a noticeable decline in performance. To further explore the causes of this phenomenon, this paper presents a comprehensive analysis supported by a detailed case study.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "89",
        "title": "3DGraphLLM: Combining Semantic Graphs and Large Language Models for 3D Scene Understanding",
        "author": [
            "Tatiana Zemskova",
            "Dmitry Yudin"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18450",
        "abstract": "A 3D scene graph represents a compact scene model, storing information about the objects and the semantic relationships between them, making its use promising for robotic tasks. When interacting with a user, an embodied intelligent agent should be capable of responding to various queries about the scene formulated in natural language. Large Language Models (LLMs) are beneficial solutions for user-robot interaction due to their natural language understanding and reasoning abilities. Recent methods for creating learnable representations of 3D scenes have demonstrated the potential to improve the quality of LLMs responses by adapting to the 3D world. However, the existing methods do not explicitly utilize information about the semantic relationships between objects, limiting themselves to information about their coordinates. In this work, we propose a method 3DGraphLLM for constructing a learnable representation of a 3D scene graph. The learnable representation is used as input for LLMs to perform 3D vision-language tasks. In our experiments on popular ScanRefer, RIORefer, Multi3DRefer, ScanQA, Sqa3D, and Scan2cap datasets, we demonstrate the advantage of this approach over baseline methods that do not use information about the semantic relationships between objects. The code is publicly available at https://github.com/CognitiveAISystems/3DGraphLLM.",
        "tags": [
            "3D",
            "LLMs",
            "Large Language Models",
            "Robot"
        ]
    },
    {
        "id": "90",
        "title": "Segment-Based Attention Masking for GPTs",
        "author": [
            "Shahar Katz",
            "Liran Ringel",
            "Yaniv Romano",
            "Lior Wolf"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18487",
        "abstract": "Modern Language Models (LMs) owe much of their success to masked causal attention, the backbone of Generative Pre-Trained Transformer (GPT) models. Although GPTs can process the entire user prompt at once, the causal masking is applied to all input tokens step-by-step, mimicking the generation process. This imposes an unnecessary constraint during the initial \"prefill\" phase when the model processes the input prompt and generates the internal representations before producing any output tokens. In this work, attention is masked based on the known block structure at the prefill phase, followed by the conventional token-by-token autoregressive process after that. For example, in a typical chat prompt, the system prompt is treated as one block, and the user prompt as the next one. Each of these is treated as a unit for the purpose of masking, such that the first tokens in each block can access the subsequent tokens in a non-causal manner. Then, the model answer is generated in the conventional causal manner. This Segment-by-Segment scheme entails no additional computational overhead. When integrating it into models such as Llama and Qwen, state-of-the-art performance is consistently achieved.",
        "tags": [
            "GPT",
            "LLaMA",
            "Transformer"
        ]
    },
    {
        "id": "91",
        "title": "Think or Remember? Detecting and Directing LLMs Towards Memorization or Generalization",
        "author": [
            "Yi-Fu Fu",
            "Yu-Chieh Tu",
            "Tzu-Ling Cheng",
            "Cheng-Yu Lin",
            "Yi-Ting Yang",
            "Heng-Yi Liu",
            "Keng-Te Liao",
            "Da-Cheng Juan",
            "Shou-De Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18497",
        "abstract": "In this paper, we explore the foundational mechanisms of memorization and generalization in Large Language Models (LLMs), inspired by the functional specialization observed in the human brain. Our investigation serves as a case study leveraging specially designed datasets and experimental-scale LLMs to lay the groundwork for understanding these behaviors. Specifically, we aim to first enable LLMs to exhibit both memorization and generalization by training with the designed dataset, then (a) examine whether LLMs exhibit neuron-level spatial differentiation for memorization and generalization, (b) predict these behaviors using model internal representations, and (c) steer the behaviors through inference-time interventions. Our findings reveal that neuron-wise differentiation of memorization and generalization is observable in LLMs, and targeted interventions can successfully direct their behavior.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "92",
        "title": "The Key of Understanding Vision Tasks: Explanatory Instructions",
        "author": [
            "Yang Shen",
            "Xiu-Shen Wei",
            "Yifan Sun",
            "Yuxin Song",
            "Tao Yuan",
            "Jian Jin",
            "Heyang Xu",
            "Yazhou Yao",
            "Errui Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18525",
        "abstract": "Computer Vision (CV) has yet to fully achieve the zero-shot task generalization observed in Natural Language Processing (NLP), despite following many of the milestones established in NLP, such as large transformer models, extensive pre-training, and the auto-regression paradigm, among others. In this paper, we explore the idea that CV adopts discrete and terminological task definitions (\\eg, ``image segmentation''), which may be a key barrier to zero-shot task generalization. Our hypothesis is that without truly understanding previously-seen tasks--due to these terminological definitions--deep models struggle to generalize to novel tasks. To verify this, we introduce Explanatory Instructions, which provide an intuitive way to define CV task objectives through detailed linguistic transformations from input images to outputs. We create a large-scale dataset comprising 12 million ``image input $\\to$ explanatory instruction $\\to$ output'' triplets, and train an auto-regressive-based vision-language model (AR-based VLM) that takes both images and explanatory instructions as input. By learning to follow these instructions, the AR-based VLM achieves instruction-level zero-shot capabilities for previously-seen tasks and demonstrates strong zero-shot generalization for unseen CV tasks. Code and dataset will be openly available on our GitHub repository.",
        "tags": [
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "93",
        "title": "Automated Code Review In Practice",
        "author": [
            "Umut Cihan",
            "Vahid Haratian",
            "Arda İçöz",
            "Mert Kaan Gül",
            "Ömercan Devran",
            "Emircan Furkan Bayendur",
            "Baykal Mehmet Uçar",
            "Eray Tüzün"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18531",
        "abstract": "Code review is a widespread practice to improve software quality and transfer knowledge. It is often seen as time-consuming due to the need for manual effort and potential delays. Several AI-assisted tools, such as Qodo, GitHub Copilot, and Coderabbit, provide automated reviews using large language models (LLMs). The effects of such tools in the industry are yet to be examined.\nThis study examines the impact of LLM-based automated code review tools in an industrial setting. The study was conducted within a software development environment that adopted an AI-assisted review tool (based on open-source Qodo PR Agent). Around 238 practitioners across ten projects had access to the tool. We focused on three projects with 4,335 pull requests, 1,568 of which underwent automated reviews. Data collection comprised three sources: (1) a quantitative analysis of pull request data, including comment labels indicating whether developers acted on the automated comments, (2) surveys sent to developers regarding their experience with reviews on individual pull requests, and (3) a broader survey of 22 practitioners capturing their general opinions on automated reviews.\n73.8% of automated comments were resolved. However, the average pull request closure duration increased from five hours 52 minutes to eight hours 20 minutes, with varying trends across projects. Most practitioners reported a minor improvement in code quality due to automated reviews.\nThe LLM-based tool proved useful in software development, enhancing bug detection, increasing awareness of code quality, and promoting best practices. However, it also led to longer pull request closure times and introduced drawbacks like faulty reviews, unnecessary corrections, and irrelevant comments.",
        "tags": [
            "Detection",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "94",
        "title": "Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation",
        "author": [
            "Derong Xu Xinhang Li",
            "Ziheng Zhang",
            "Zhenxi Lin",
            "Zhihong Zhu",
            "Zhi Zheng",
            "Xian Wu",
            "Xiangyu Zhao",
            "Tong Xu",
            "Enhong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18537",
        "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities, yet struggle with hallucination and outdated knowledge when tasked with complex knowledge reasoning, resulting in factually incorrect outputs. Previous studies have attempted to mitigate it by retrieving factual knowledge from large-scale knowledge graphs (KGs) to assist LLMs in logical reasoning and prediction of answers. However, this kind of approach often introduces noise and irrelevant data, especially in situations with extensive context from multiple knowledge aspects. In this way, LLM attention can be potentially mislead from question and relevant information. In our study, we introduce an Adaptive Multi-Aspect Retrieval-augmented over KGs (Amar) framework. This method retrieves knowledge including entities, relations, and subgraphs, and converts each piece of retrieved text into prompt embeddings. The Amar framework comprises two key sub-components: 1) a self-alignment module that aligns commonalities among entities, relations, and subgraphs to enhance retrieved text, thereby reducing noise interference; 2) a relevance gating module that employs a soft gate to learn the relevance score between question and multi-aspect retrieved data, to determine which information should be used to enhance LLMs' output, or even filtered altogether. Our method has achieved state-of-the-art performance on two common datasets, WebQSP and CWQ, showing a 1.9\\% improvement in accuracy over its best competitor and a 6.6\\% improvement in logical form generation over a method that directly uses retrieved text as context prompts. These results demonstrate the effectiveness of Amar in improving the reasoning of LLMs.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "95",
        "title": "Token-Budget-Aware LLM Reasoning",
        "author": [
            "Tingxu Han",
            "Chunrong Fang",
            "Shiyu Zhao",
            "Shiqing Ma",
            "Zhenyu Chen",
            "Zhenting Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18547",
        "abstract": "Reasoning is critical for large language models (LLMs) to excel in a wide range of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM performance by decomposing problems into intermediate steps, they also incur significant overhead in token usage, leading to increased costs. We find that the reasoning process of current LLMs is unnecessarily lengthy and it can be compressed by including a reasonable token budget in the prompt, but the choice of token budget plays a crucial role in the actual compression effectiveness. We then propose a token-budget-aware LLM reasoning framework, which dynamically estimates token budgets for different problems based on reasoning complexity and uses the estimated token budgets to guide the reasoning process. Experiments show that our method effectively reduces token costs in CoT reasoning with only a slight performance reduction, offering a practical solution to balance efficiency and accuracy in LLM reasoning. Code: https://github.com/GeniusHTX/TALE.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "96",
        "title": "Libra-Leaderboard: Towards Responsible AI through a Balanced Leaderboard of Safety and Capability",
        "author": [
            "Haonan Li",
            "Xudong Han",
            "Zenan Zhai",
            "Honglin Mu",
            "Hao Wang",
            "Zhenxuan Zhang",
            "Yilin Geng",
            "Shom Lin",
            "Renxi Wang",
            "Artem Shelmanov",
            "Xiangyu Qi",
            "Yuxia Wang",
            "Donghai Hong",
            "Youliang Yuan",
            "Meng Chen",
            "Haoqin Tu",
            "Fajri Koto",
            "Tatsuki Kuribayashi",
            "Cong Zeng",
            "Rishabh Bhardwaj",
            "Bingchen Zhao",
            "Yawen Duan",
            "Yi Liu",
            "Emad A. Alghamdi",
            "Yaodong Yang",
            "Yinpeng Dong",
            "Soujanya Poria",
            "Pengfei Liu",
            "Zhengzhong Liu",
            "Xuguang Ren",
            "Eduard Hovy",
            "Iryna Gurevych",
            "Preslav Nakov",
            "Monojit Choudhury",
            "Timothy Baldwin"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18551",
        "abstract": "To address this gap, we introduce Libra-Leaderboard, a comprehensive framework designed to rank LLMs through a balanced evaluation of performance and safety. Combining a dynamic leaderboard with an interactive LLM arena, Libra-Leaderboard encourages the joint optimization of capability and safety. Unlike traditional approaches that average performance and safety metrics, Libra-Leaderboard uses a distance-to-optimal-score method to calculate the overall rankings. This approach incentivizes models to achieve a balance rather than excelling in one dimension at the expense of some other ones. In the first release, Libra-Leaderboard evaluates 26 mainstream LLMs from 14 leading organizations, identifying critical safety challenges even in state-of-the-art models.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "97",
        "title": "Distilling Fine-grained Sentiment Understanding from Large Language Models",
        "author": [
            "Yice Zhang",
            "Guangyu Xie",
            "Hongling Xu",
            "Kaiheng Hou",
            "Jianzhu Bao",
            "Qianlong Wang",
            "Shiwei Chen",
            "Ruifeng Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18552",
        "abstract": "Fine-grained sentiment analysis (FSA) aims to extract and summarize user opinions from vast opinionated text. Recent studies demonstrate that large language models (LLMs) possess exceptional sentiment understanding capabilities. However, directly deploying LLMs for FSA applications incurs high inference costs. Therefore, this paper investigates the distillation of fine-grained sentiment understanding from LLMs into small language models (SLMs). We prompt LLMs to examine and interpret the sentiments of given reviews and then utilize the generated content to pretrain SLMs. Additionally, we develop a comprehensive FSA benchmark to evaluate both SLMs and LLMs. Extensive experiments on this benchmark reveal that: (1) distillation significantly enhances the performance of SLMs in FSA tasks, achieving a 6.00\\% improvement in $F_1$-score, and the distilled model can outperform Llama-2-7b with only 220M parameters; (2) distillation equips SLMs with excellent zero-shot sentiment classification capabilities, enabling them to match or even exceed their teacher models. These results suggest that distillation from LLMs is a highly promising direction for FSA. We will release our code, data, and pretrained model weights at \\url{https://github.com/HITSZ-HLT/FSA-Distillation}.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "98",
        "title": "3DEnhancer: Consistent Multi-View Diffusion for 3D Enhancement",
        "author": [
            "Yihang Luo",
            "Shangchen Zhou",
            "Yushi Lan",
            "Xingang Pan",
            "Chen Change Loy"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18565",
        "abstract": "Despite advances in neural rendering, due to the scarcity of high-quality 3D datasets and the inherent limitations of multi-view diffusion models, view synthesis and 3D model generation are restricted to low resolutions with suboptimal multi-view consistency. In this study, we present a novel 3D enhancement pipeline, dubbed 3DEnhancer, which employs a multi-view latent diffusion model to enhance coarse 3D inputs while preserving multi-view consistency. Our method includes a pose-aware encoder and a diffusion-based denoiser to refine low-quality multi-view images, along with data augmentation and a multi-view attention module with epipolar aggregation to maintain consistent, high-quality 3D outputs across views. Unlike existing video-based approaches, our model supports seamless multi-view enhancement with improved coherence across diverse viewing angles. Extensive evaluations show that 3DEnhancer significantly outperforms existing methods, boosting both multi-view enhancement and per-instance 3D optimization tasks.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "99",
        "title": "Zero-resource Speech Translation and Recognition with LLMs",
        "author": [
            "Karel Mundnich",
            "Xing Niu",
            "Prashant Mathur",
            "Srikanth Ronanki",
            "Brady Houston",
            "Veera Raghavendra Elluru",
            "Nilaksh Das",
            "Zejiang Hou",
            "Goeric Huybrechts",
            "Anshu Bhatia",
            "Daniel Garcia-Romero",
            "Kyu J. Han",
            "Katrin Kirchhoff"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18566",
        "abstract": "Despite recent advancements in speech processing, zero-resource speech translation (ST) and automatic speech recognition (ASR) remain challenging problems. In this work, we propose to leverage a multilingual Large Language Model (LLM) to perform ST and ASR in languages for which the model has never seen paired audio-text data. We achieve this by using a pre-trained multilingual speech encoder, a multilingual LLM, and a lightweight adaptation module that maps the audio representations to the token embedding space of the LLM. We perform several experiments both in ST and ASR to understand how to best train the model and what data has the most impact on performance in previously unseen languages. In ST, our best model is capable to achieve BLEU scores over 23 in CoVoST2 for two previously unseen languages, while in ASR, we achieve WERs of up to 28.2\\%. We finally show that the performance of our system is bounded by the ability of the LLM to output text in the desired language.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "100",
        "title": "How Well Do LLMs Generate Code for Different Application Domains? Benchmark and Evaluation",
        "author": [
            "Dewu Zheng",
            "Yanlin Wang",
            "Ensheng Shi",
            "Hongyu Zhang",
            "Zibin Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18573",
        "abstract": "Recently, an increasing number of AI-driven programming assistants powered by code LLMs have been integrated into various real-world software development environments, significantly boosting developer productivity. However, existing code generation benchmarks primarily focus on general-purpose scenarios, leaving the code generation performance of LLMs for specific application domains largely unknown. In this paper, we introduce a new benchmark, MultiCodeBench, to fill this gap. MultiCodeBench comprises 2,400 programming tasks, covering 12 popular software development domains and 15 programming languages. Specifically, we perform in-depth research to identify these 12 application domains. Given that each domain may involve multiple technical frameworks, and that different frameworks present distinct challenges in the coding process, we categorize the commonly used frameworks and platforms within each domain. We then sample programming problems from GitHub repositories related to these subdomains. To ensure the quality of the tasks and mitigate data leakage issues, we invite annotators to rewrite the docstrings for each task in MultiCodeBench. Additionally, we build a static analysis-based dependency parsing tool to extract the dependencies in the ground truth for each task, enabling deeper performance analysis. Through extensive experiments on MultiCodeBench with eleven representative mainstream LLMs, we reveal the code generation performance of the LLMs across different application domains, providing practical insights for developers in downstream fields when selecting LLMs. Furthermore, we analyze the reasons behind the models' failures in completing software application development tasks, offering guidance for model developers to enhance domain-specific code generation capabilities.",
        "tags": [
            "LLMs"
        ]
    },
    {
        "id": "101",
        "title": "Exploring Embedding Priors in Prompt-Tuning for Improved Interpretability and Control",
        "author": [
            "Sergey Sedov",
            "Sumanth Bharadwaj Hachalli Karanam",
            "Venu Gopal Kadamba"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18582",
        "abstract": "Prompt-Tuning is an efficient method for adapting pre-trained language models to new tasks with minimal computational overhead by modifying prompt embeddings. In this work, we investigate how crucial the phenomenon of embedding collapse, frequently observed in Prompt-Tuning, is for the final performance of the model. To address this question, we designed embedding priors and compared them with posteriors of the converged Soft and Deep Prompt-Tuning methods. Our findings suggest that priors strongly affect the position of the tuned embeddings, and models can effectively work with embeddings from different parts of activation spaces, including completely new regions. As the final Prompt-Tuning capabilities are limited, we hypothesize that controllable Prompt-Tuning posteriors may serve as a good starting point for tasks such as chain-of-thought (COT) distillation. Our experiments also show that generated trajectories are not localized in the activation space of the models. However, there are distinct clusters of activations for distant tasks (e.g., NLP and arithmetic), while activations between NLP tasks (e.g., Question-Answering and MLM) lie in the same cluster. These observations raise questions about the importance of a single activation cluster for the generalization abilities of large language models.",
        "tags": [
            "Large Language Models"
        ]
    },
    {
        "id": "102",
        "title": "A Paragraph is All It Takes: Rich Robot Behaviors from Interacting, Trusted LLMs",
        "author": [
            "OpenMind",
            "Shaohong Zhong",
            "Adam Zhou",
            "Boyuan Chen",
            "Homin Luo",
            "Jan Liphardt"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18588",
        "abstract": "Large Language Models (LLMs) are compact representations of all public knowledge of our physical environment and animal and human behaviors. The application of LLMs to robotics may offer a path to highly capable robots that perform well across most human tasks with limited or even zero tuning. Aside from increasingly sophisticated reasoning and task planning, networks of (suitably designed) LLMs offer ease of upgrading capabilities and allow humans to directly observe the robot's thinking. Here we explore the advantages, limitations, and particularities of using LLMs to control physical robots. The basic system consists of four LLMs communicating via a human language data bus implemented via web sockets and ROS2 message passing. Surprisingly, rich robot behaviors and good performance across different tasks could be achieved despite the robot's data fusion cycle running at only 1Hz and the central data bus running at the extremely limited rates of the human brain, of around 40 bits/s. The use of natural language for inter-LLM communication allowed the robot's reasoning and decision making to be directly observed by humans and made it trivial to bias the system's behavior with sets of rules written in plain English. These rules were immutably written into Ethereum, a global, public, and censorship resistant Turing-complete computer. We suggest that by using natural language as the data bus among interacting AIs, and immutable public ledgers to store behavior constraints, it is possible to build robots that combine unexpectedly rich performance, upgradability, and durable alignment with humans.",
        "tags": [
            "LLMs",
            "Large Language Models",
            "Robot",
            "Robotics"
        ]
    },
    {
        "id": "103",
        "title": "LatentCRF: Continuous CRF for Efficient Latent Diffusion",
        "author": [
            "Kanchana Ranasinghe",
            "Sadeep Jayasumana",
            "Andreas Veit",
            "Ayan Chakrabarti",
            "Daniel Glasner",
            "Michael S Ryoo",
            "Srikumar Ramalingam",
            "Sanjiv Kumar"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18596",
        "abstract": "Latent Diffusion Models (LDMs) produce high-quality, photo-realistic images, however, the latency incurred by multiple costly inference iterations can restrict their applicability. We introduce LatentCRF, a continuous Conditional Random Field (CRF) model, implemented as a neural network layer, that models the spatial and semantic relationships among the latent vectors in the LDM. By replacing some of the computationally-intensive LDM inference iterations with our lightweight LatentCRF, we achieve a superior balance between quality, speed and diversity. We increase inference efficiency by 33% with no loss in image quality or diversity compared to the full LDM. LatentCRF is an easy add-on, which does not require modifying the LDM.",
        "tags": [
            "Diffusion",
            "LDMs"
        ]
    },
    {
        "id": "104",
        "title": "DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation",
        "author": [
            "Minghong Cai",
            "Xiaodong Cun",
            "Xiaoyu Li",
            "Wenze Liu",
            "Zhaoyang Zhang",
            "Yong Zhang",
            "Ying Shan",
            "Xiangyu Yue"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18597",
        "abstract": "Sora-like video generation models have achieved remarkable progress with a Multi-Modal Diffusion Transformer MM-DiT architecture. However, the current video generation models predominantly focus on single-prompt, struggling to generate coherent scenes with multiple sequential prompts that better reflect real-world dynamic scenarios. While some pioneering works have explored multi-prompt video generation, they face significant challenges including strict training data requirements, weak prompt following, and unnatural transitions. To address these problems, we propose DiTCtrl, a training-free multi-prompt video generation method under MM-DiT architectures for the first time. Our key idea is to take the multi-prompt video generation task as temporal video editing with smooth transitions. To achieve this goal, we first analyze MM-DiT's attention mechanism, finding that the 3D full attention behaves similarly to that of the cross/self-attention blocks in the UNet-like diffusion models, enabling mask-guided precise semantic control across different prompts with attention sharing for multi-prompt video generation. Based on our careful design, the video generated by DiTCtrl achieves smooth transitions and consistent object motion given multiple sequential prompts without additional training. Besides, we also present MPVBench, a new benchmark specially designed for multi-prompt video generation to evaluate the performance of multi-prompt generation. Extensive experiments demonstrate that our method achieves state-of-the-art performance without additional training.",
        "tags": [
            "3D",
            "DiT",
            "Diffusion",
            "Diffusion Transformer",
            "Sora",
            "Transformer",
            "Video Editing",
            "Video Generation"
        ]
    },
    {
        "id": "105",
        "title": "ZeroHSI: Zero-Shot 4D Human-Scene Interaction by Video Generation",
        "author": [
            "Hongjie Li",
            "Hong-Xing Yu",
            "Jiaman Li",
            "Jiajun Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18600",
        "abstract": "Human-scene interaction (HSI) generation is crucial for applications in embodied AI, virtual reality, and robotics. While existing methods can synthesize realistic human motions in 3D scenes and generate plausible human-object interactions, they heavily rely on datasets containing paired 3D scene and motion capture data, which are expensive and time-consuming to collect across diverse environments and interactions. We present ZeroHSI, a novel approach that enables zero-shot 4D human-scene interaction synthesis by integrating video generation and neural human rendering. Our key insight is to leverage the rich motion priors learned by state-of-the-art video generation models, which have been trained on vast amounts of natural human movements and interactions, and use differentiable rendering to reconstruct human-scene interactions. ZeroHSI can synthesize realistic human motions in both static scenes and environments with dynamic objects, without requiring any ground-truth motion data. We evaluate ZeroHSI on a curated dataset of different types of various indoor and outdoor scenes with different interaction prompts, demonstrating its ability to generate diverse and contextually appropriate human-scene interactions.",
        "tags": [
            "3D",
            "Robotics",
            "Video Generation"
        ]
    },
    {
        "id": "106",
        "title": "Decentralized Intelligence in GameFi: Embodied AI Agents and the Convergence of DeFi and Virtual Ecosystems",
        "author": [
            "Fernando Jia",
            "Jade Zheng",
            "Florence Li"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18601",
        "abstract": "In the rapidly evolving landscape of GameFi, a fusion of gaming and decentralized finance (DeFi), there exists a critical need to enhance player engagement and economic interaction within gaming ecosystems. Our GameFi ecosystem aims to fundamentally transform this landscape by integrating advanced embodied AI agents into GameFi platforms. These AI agents, developed using cutting-edge large language models (LLMs), such as GPT-4 and Claude AI, are capable of proactive, adaptive, and contextually rich interactions with players. By going beyond traditional scripted responses, these agents become integral participants in the game's narrative and economic systems, directly influencing player strategies and in-game economies. We address the limitations of current GameFi platforms, which often lack immersive AI interactions and mechanisms for community engagement or creator monetization. Through the deep integration of AI agents with blockchain technology, we establish a consensus-driven, decentralized GameFi ecosystem. This ecosystem empowers creators to monetize their contributions and fosters democratic collaboration among players and creators. Furthermore, by embedding DeFi mechanisms into the gaming experience, we enhance economic participation and provide new opportunities for financial interactions within the game. Our approach enhances player immersion and retention and advances the GameFi ecosystem by bridging traditional gaming with Web3 technologies. By integrating sophisticated AI and DeFi elements, we contribute to the development of more engaging, economically robust, and community-centric gaming environments. This project represents a significant advancement in the state-of-the-art in GameFi, offering insights and methodologies that can be applied throughout the gaming industry.",
        "tags": [
            "GPT",
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "107",
        "title": "Explaining in Diffusion: Explaining a Classifier Through Hierarchical Semantics with Text-to-Image Diffusion Models",
        "author": [
            "Tahira Kazimi",
            "Ritika Allada",
            "Pinar Yanardag"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18604",
        "abstract": "Classifiers are important components in many computer vision tasks, serving as the foundational backbone of a wide variety of models employed across diverse applications. However, understanding the decision-making process of classifiers remains a significant challenge. We propose DiffEx, a novel method that leverages the capabilities of text-to-image diffusion models to explain classifier decisions. Unlike traditional GAN-based explainability models, which are limited to simple, single-concept analyses and typically require training a new model for each classifier, our approach can explain classifiers that focus on single concepts (such as faces or animals) as well as those that handle complex scenes involving multiple concepts. DiffEx employs vision-language models to create a hierarchical list of semantics, allowing users to identify not only the overarching semantic influences on classifiers (e.g., the 'beard' semantic in a facial classifier) but also their sub-types, such as 'goatee' or 'Balbo' beard. Our experiments demonstrate that DiffEx is able to cover a significantly broader spectrum of semantics compared to its GAN counterparts, providing a hierarchical tool that delivers a more detailed and fine-grained understanding of classifier decisions.",
        "tags": [
            "Diffusion",
            "GAN",
            "Text-to-Image"
        ]
    },
    {
        "id": "108",
        "title": "DrivingGPT: Unifying Driving World Modeling and Planning with Multi-modal Autoregressive Transformers",
        "author": [
            "Yuntao Chen",
            "Yuqi Wang",
            "Zhaoxiang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18607",
        "abstract": "World model-based searching and planning are widely recognized as a promising path toward human-level physical intelligence. However, current driving world models primarily rely on video diffusion models, which specialize in visual generation but lack the flexibility to incorporate other modalities like action. In contrast, autoregressive transformers have demonstrated exceptional capability in modeling multimodal data. Our work aims to unify both driving model simulation and trajectory planning into a single sequence modeling problem. We introduce a multimodal driving language based on interleaved image and action tokens, and develop DrivingGPT to learn joint world modeling and planning through standard next-token prediction. Our DrivingGPT demonstrates strong performance in both action-conditioned video generation and end-to-end planning, outperforming strong baselines on large-scale nuPlan and NAVSIM benchmarks.",
        "tags": [
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "109",
        "title": "PartGen: Part-level 3D Generation and Reconstruction with Multi-View Diffusion Models",
        "author": [
            "Minghao Chen",
            "Roman Shapovalov",
            "Iro Laina",
            "Tom Monnier",
            "Jianyuan Wang",
            "David Novotny",
            "Andrea Vedaldi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18608",
        "abstract": "Text- or image-to-3D generators and 3D scanners can now produce 3D assets with high-quality shapes and textures. These assets typically consist of a single, fused representation, like an implicit neural field, a Gaussian mixture, or a mesh, without any useful structure. However, most applications and creative workflows require assets to be made of several meaningful parts that can be manipulated independently. To address this gap, we introduce PartGen, a novel approach that generates 3D objects composed of meaningful parts starting from text, an image, or an unstructured 3D object. First, given multiple views of a 3D object, generated or rendered, a multi-view diffusion model extracts a set of plausible and view-consistent part segmentations, dividing the object into parts. Then, a second multi-view diffusion model takes each part separately, fills in the occlusions, and uses those completed views for 3D reconstruction by feeding them to a 3D reconstruction network. This completion process considers the context of the entire object to ensure that the parts integrate cohesively. The generative completion model can make up for the information missing due to occlusions; in extreme cases, it can hallucinate entirely invisible parts based on the input 3D asset. We evaluate our method on generated and real 3D assets and show that it outperforms segmentation and part-extraction baselines by a large margin. We also showcase downstream applications such as 3D part editing.",
        "tags": [
            "3D",
            "Diffusion",
            "Image-to-3D",
            "Segmentation"
        ]
    },
    {
        "id": "110",
        "title": "Video-Panda: Parameter-efficient Alignment for Encoder-free Video-Language Models",
        "author": [
            "Jinhui Yi",
            "Syed Talal Wasim",
            "Yanan Luo",
            "Muzammal Naseer",
            "Juergen Gall"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18609",
        "abstract": "We present an efficient encoder-free approach for video-language understanding that achieves competitive performance while significantly reducing computational overhead. Current video-language models typically rely on heavyweight image encoders (300M-1.1B parameters) or video encoders (1B-1.4B parameters), creating a substantial computational burden when processing multi-frame videos. Our method introduces a novel Spatio-Temporal Alignment Block (STAB) that directly processes video inputs without requiring pre-trained encoders while using only 45M parameters for visual processing - at least a 6.5$\\times$ reduction compared to traditional approaches. The STAB architecture combines Local Spatio-Temporal Encoding for fine-grained feature extraction, efficient spatial downsampling through learned attention and separate mechanisms for modeling frame-level and video-level relationships. Our model achieves comparable or superior performance to encoder-based approaches for open-ended video question answering on standard benchmarks. The fine-grained video question-answering evaluation demonstrates our model's effectiveness, outperforming the encoder-based approaches Video-ChatGPT and Video-LLaVA in key aspects like correctness and temporal understanding. Extensive ablation studies validate our architectural choices and demonstrate the effectiveness of our spatio-temporal modeling approach while achieving 3-4$\\times$ faster processing speeds than previous methods. Code is available at \\url{https://github.com/jh-yi/Video-Panda}.",
        "tags": [
            "ChatGPT",
            "LLaVA"
        ]
    },
    {
        "id": "111",
        "title": "MANGO: Multimodal Acuity traNsformer for intelliGent ICU Outcomes",
        "author": [
            "Jiaqing Zhang",
            "Miguel Contreras",
            "Sabyasachi Bandyopadhyay",
            "Andrea Davidson",
            "Jessica Sena",
            "Yuanfang Ren",
            "Ziyuan Guan",
            "Tezcan Ozrazgat-Baslanti",
            "Tyler J. Loftus",
            "Subhash Nerella",
            "Azra Bihorac",
            "Parisa Rashidi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17832",
        "abstract": "Estimation of patient acuity in the Intensive Care Unit (ICU) is vital to ensure timely and appropriate interventions. Advances in artificial intelligence (AI) technologies have significantly improved the accuracy of acuity predictions. However, prior studies using machine learning for acuity prediction have predominantly relied on electronic health records (EHR) data, often overlooking other critical aspects of ICU stay, such as patient mobility, environmental factors, and facial cues indicating pain or agitation. To address this gap, we present MANGO: the Multimodal Acuity traNsformer for intelliGent ICU Outcomes, designed to enhance the prediction of patient acuity states, transitions, and the need for life-sustaining therapy. We collected a multimodal dataset ICU-Multimodal, incorporating four key modalities, EHR data, wearable sensor data, video of patient's facial cues, and ambient sensor data, which we utilized to train MANGO. The MANGO model employs a multimodal feature fusion network powered by Transformer masked self-attention method, enabling it to capture and learn complex interactions across these diverse data modalities even when some modalities are absent. Our results demonstrated that integrating multiple modalities significantly improved the model's ability to predict acuity status, transitions, and the need for life-sustaining therapy. The best-performing models achieved an area under the receiver operating characteristic curve (AUROC) of 0.76 (95% CI: 0.72-0.79) for predicting transitions in acuity status and the need for life-sustaining therapy, while 0.82 (95% CI: 0.69-0.89) for acuity status prediction...",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "112",
        "title": "Shifted Composition III: Local Error Framework for KL Divergence",
        "author": [
            "Jason M. Altschuler",
            "Sinho Chewi"
        ],
        "pdf": "https://arxiv.org/pdf/2412.17997",
        "abstract": "Coupling arguments are a central tool for bounding the deviation between two stochastic processes, but traditionally have been limited to Wasserstein metrics. In this paper, we apply the shifted composition rule--an information-theoretic principle introduced in our earlier work--in order to adapt coupling arguments to the Kullback-Leibler (KL) divergence. Our framework combine the strengths of two previously disparate approaches: local error analysis and Girsanov's theorem. Akin to the former, it yields tight bounds by incorporating the so-called weak error, and is user-friendly in that it only requires easily verified local assumptions; and akin to the latter, it yields KL divergence guarantees and applies beyond Wasserstein contractivity.\nWe apply this framework to the problem of sampling from a target distribution $\\pi$. Here, the two stochastic processes are the Langevin diffusion and an algorithmic discretization thereof. Our framework provides a unified analysis when $\\pi$ is assumed to be strongly log-concave (SLC), weakly log-concave (WLC), or to satisfy a log-Sobolev inequality (LSI). Among other results, this yields KL guarantees for the randomized midpoint discretization of the Langevin diffusion. Notably, our result: (1) yields the optimal $\\tilde O(\\sqrt d/\\epsilon)$ rate in the SLC and LSI settings; (2) is the first result to hold beyond the 2-Wasserstein metric in the SLC setting; and (3) is the first result to hold in \\emph{any} metric in the WLC and LSI settings.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "113",
        "title": "An information theoretic limit to data amplification",
        "author": [
            "S. J. Watts",
            "L. Crow"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18041",
        "abstract": "In recent years generative artificial intelligence has been used to create data to support science analysis. For example, Generative Adversarial Networks (GANs) have been trained using Monte Carlo simulated input and then used to generate data for the same problem. This has the advantage that a GAN creates data in a significantly reduced computing time. N training events for a GAN can result in GN generated events with the gain factor, G, being more than one. This appears to violate the principle that one cannot get information for free. This is not the only way to amplify data so this process will be referred to as data amplification which is studied using information theoretic concepts. It is shown that a gain of greater than one is possible whilst keeping the information content of the data unchanged. This leads to a mathematical bound which only depends on the number of generated and training events. This study determines conditions on both the underlying and reconstructed probability distributions to ensure this bound. In particular, the resolution of variables in amplified data is not improved by the process but the increase in sample size can still improve statistical significance. The bound is confirmed using computer simulation and analysis of GAN generated data from the literature.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "114",
        "title": "scReader: Prompting Large Language Models to Interpret scRNA-seq Data",
        "author": [
            "Cong Li",
            "Qingqing Long",
            "Yuanchun Zhou",
            "Meng Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18156",
        "abstract": "Large language models (LLMs) have demonstrated remarkable advancements, primarily due to their capabilities in modeling the hidden relationships within text sequences. This innovation presents a unique opportunity in the field of life sciences, where vast collections of single-cell omics data from multiple species provide a foundation for training foundational models. However, the challenge lies in the disparity of data scales across different species, hindering the development of a comprehensive model for interpreting genetic data across diverse organisms. In this study, we propose an innovative hybrid approach that integrates the general knowledge capabilities of LLMs with domain-specific representation models for single-cell omics data interpretation. We begin by focusing on genes as the fundamental unit of representation. Gene representations are initialized using functional descriptions, leveraging the strengths of mature language models such as LLaMA-2. By inputting single-cell gene-level expression data with prompts, we effectively model cellular representations based on the differential expression levels of genes across various species and cell types. In the experiments, we constructed developmental cells from humans and mice, specifically targeting cells that are challenging to annotate. We evaluated our methodology through basic tasks such as cell annotation and visualization analysis. The results demonstrate the efficacy of our approach compared to other methods using LLMs, highlighting significant improvements in accuracy and interoperability. Our hybrid approach enhances the representation of single-cell data and offers a robust framework for future research in cross-species genetic analysis.",
        "tags": [
            "LLMs",
            "LLaMA",
            "Large Language Models"
        ]
    },
    {
        "id": "115",
        "title": "Leveraging Convolutional Neural Network-Transformer Synergy for Predictive Modeling in Risk-Based Applications",
        "author": [
            "Yuhan Wang",
            "Zhen Xu",
            "Yue Yao",
            "Jinsong Liu",
            "Jiating Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18222",
        "abstract": "With the development of the financial industry, credit default prediction, as an important task in financial risk management, has received increasing attention. Traditional credit default prediction methods mostly rely on machine learning models, such as decision trees and random forests, but these methods have certain limitations in processing complex data and capturing potential risk patterns. To this end, this paper proposes a deep learning model based on the combination of convolutional neural networks (CNN) and Transformer for credit user default prediction. The model combines the advantages of CNN in local feature extraction with the ability of Transformer in global dependency modeling, effectively improving the accuracy and robustness of credit default prediction. Through experiments on public credit default datasets, the results show that the CNN+Transformer model outperforms traditional machine learning models, such as random forests and XGBoost, in multiple evaluation indicators such as accuracy, AUC, and KS value, demonstrating its powerful ability in complex financial data modeling. Further experimental analysis shows that appropriate optimizer selection and learning rate adjustment play a vital role in improving model performance. In addition, the ablation experiment of the model verifies the advantages of the combination of CNN and Transformer and proves the complementarity of the two in credit default prediction. This study provides a new idea for credit default prediction and provides strong support for risk assessment and intelligent decision-making in the financial field. Future research can further improve the prediction effect and generalization ability by introducing more unstructured data and improving the model architecture.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "116",
        "title": "A Statistical Framework for Ranking LLM-Based Chatbots",
        "author": [
            "Siavash Ameli",
            "Siyuan Zhuang",
            "Ion Stoica",
            "Michael W. Mahoney"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18407",
        "abstract": "Large language models (LLMs) have transformed natural language processing, with frameworks like Chatbot Arena providing pioneering platforms for evaluating these models. By facilitating millions of pairwise comparisons based on human judgments, Chatbot Arena has become a cornerstone in LLM evaluation, offering rich datasets for ranking models in open-ended conversational tasks. Building upon this foundation, we propose a statistical framework that incorporates key advancements to address specific challenges in pairwise comparison analysis. First, we introduce a factored tie model that enhances the ability to handle ties -- an integral aspect of human-judged comparisons -- significantly improving the model's fit to observed data. Second, we extend the framework to model covariance between competitors, enabling deeper insights into performance relationships and facilitating intuitive groupings into performance tiers. Third, we resolve optimization challenges arising from parameter non-uniqueness by introducing novel constraints, ensuring stable and interpretable parameter estimation. Through rigorous evaluation and extensive experimentation, our framework demonstrates substantial improvements over existing methods in modeling pairwise comparison data. To support reproducibility and practical adoption, we release leaderbot, an open-source Python package implementing our models and analyses.",
        "tags": [
            "LLMs",
            "Large Language Models"
        ]
    },
    {
        "id": "117",
        "title": "Discovery of 2D Materials via Symmetry-Constrained Diffusion Model",
        "author": [
            "Shihang Xu",
            "Shibing Chu",
            "Rami Mrad",
            "Zhejun Zhang",
            "Zhelin Li",
            "Runxian Jiao",
            "Yuanping Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2412.18414",
        "abstract": "Generative model for 2D materials has shown significant promise in accelerating the material discovery process. The stability and performance of these materials are strongly influenced by their underlying symmetry. However, existing generative models for 2D materials often neglect symmetry constraints, which limits both the diversity and quality of the generated structures. Here, we introduce a symmetry-constrained diffusion model (SCDM) that integrates space group symmetry into the generative process. By incorporating Wyckoff positions, the model ensures adherence to symmetry principles, leading to the generation of 2,000 candidate structures. DFT calculations were conducted to evaluate the convex hull energies of these structures after structural relaxation. From the generated samples, 843 materials that met the energy stability criteria (Ehull < 0.6 eV/atom) were identified. Among these, six candidates were selected for further stability analysis, including phonon band structure evaluations and electronic properties investigations, all of which exhibited phonon spectrum stability. To benchmark the performance of SCDM, a symmetry-unconstrained diffusion model was also evaluated via crystal structure prediction model. The results highlight that incorporating symmetry constraints enhances the effectiveness of generated 2D materials, making a contribution to the discovery of 2D materials through generative modeling.",
        "tags": [
            "Diffusion"
        ]
    }
]